{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T07:53:29.111119Z",
     "start_time": "2018-06-05T07:53:29.105681Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import scipy\n",
    "#rate,data = scipy.io.wavfile.read('./vocalSeparation/origin_mix.wav')\n",
    "#scipy.io.wavfile.write('./vocalSeparation/morigin_mix.wav',rate,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T07:53:29.116793Z",
     "start_time": "2018-06-05T07:53:29.113405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import soundfile as sf\n",
    "#data, samplerate = sf.read('./vocalSeparation/pred_mix.wav', dtype='float32')\n",
    "#data = librosa.resample(data.T, samplerate, 16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T07:53:30.929798Z",
     "start_time": "2018-06-05T07:53:29.118755Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import os\\nos.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Training script for the WaveNet network on the VCTK corpus.\n",
    "\n",
    "This script trains a network with the WaveNet using data from the VCTK corpus,\n",
    "which can be freely downloaded at the following site (~10 GB):\n",
    "http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "import soundfile as sf\n",
    "\n",
    "from wavenetVS import WaveNetModel, AudioReader, optimizer_factory\n",
    "\n",
    "\n",
    "'''import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T07:53:30.942544Z",
     "start_time": "2018-06-05T07:53:30.931719Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DATA_DIRECTORY = './vsCorpus'\n",
    "LOGDIR_ROOT = './logdirVS'\n",
    "CHECKPOINT_EVERY = 50\n",
    "NUM_STEPS = int(1e5)\n",
    "LEARNING_RATE = 1e-3\n",
    "WAVENET_PARAMS = './wavenet_params.json'\n",
    "STARTED_DATESTRING = \"{0:%Y-%m-%dT%H-%M-%S}\".format(datetime.now())\n",
    "SAMPLE_SIZE = 100000\n",
    "L2_REGULARIZATION_STRENGTH = 1e-4\n",
    "#SILENCE_THRESHOLD = 0.3\n",
    "SILENCE_THRESHOLD = 0\n",
    "EPSILON = 0.001\n",
    "MOMENTUM = 0.9\n",
    "MAX_TO_KEEP = 5\n",
    "METADATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T07:53:31.004285Z",
     "start_time": "2018-06-05T07:53:30.944420Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    def _str_to_bool(s):\n",
    "        \"\"\"Convert string to bool (in argparse context).\"\"\"\n",
    "        if s.lower() not in ['true', 'false']:\n",
    "            raise ValueError('Argument needs to be a '\n",
    "                             'boolean, got {}'.format(s))\n",
    "        return {'true': True, 'false': False}[s.lower()]\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='WaveNet example network')\n",
    "    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE,\n",
    "                        help='How many wav files to process at once. Default: ' + str(BATCH_SIZE) + '.')\n",
    "    parser.add_argument('--data_dir', type=str, default=DATA_DIRECTORY,\n",
    "                        help='The directory containing the VCTK corpus.')\n",
    "    parser.add_argument('--store_metadata', type=bool, default=METADATA,\n",
    "                        help='Whether to store advanced debugging information '\n",
    "                        '(execution time, memory consumption) for use with '\n",
    "                        'TensorBoard. Default: ' + str(METADATA) + '.')\n",
    "    parser.add_argument('--logdir', type=str, default=None,\n",
    "                        help='Directory in which to store the logging '\n",
    "                        'information for TensorBoard. '\n",
    "                        'If the model already exists, it will restore '\n",
    "                        'the state and will continue training. '\n",
    "                        'Cannot use with --logdir_root and --restore_from.')\n",
    "    parser.add_argument('--logdir_root', type=str, default=None,\n",
    "                        help='Root directory to place the logging '\n",
    "                        'output and generated model. These are stored '\n",
    "                        'under the dated subdirectory of --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--restore_from', type=str, default=None,\n",
    "                        help='Directory in which to restore the model from. '\n",
    "                        'This creates the new model under the dated directory '\n",
    "                        'in --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--checkpoint_every', type=int,\n",
    "                        default=CHECKPOINT_EVERY,\n",
    "                        help='How many steps to save each checkpoint after. Default: ' + str(CHECKPOINT_EVERY) + '.')\n",
    "    parser.add_argument('--num_steps', type=int, default=NUM_STEPS,\n",
    "                        help='Number of training steps. Default: ' + str(NUM_STEPS) + '.')\n",
    "    parser.add_argument('--learning_rate', type=float, default=LEARNING_RATE,\n",
    "                        help='Learning rate for training. Default: ' + str(LEARNING_RATE) + '.')\n",
    "    parser.add_argument('--wavenet_params', type=str, default=WAVENET_PARAMS,\n",
    "                        help='JSON file with the network parameters. Default: ' + WAVENET_PARAMS + '.')\n",
    "    parser.add_argument('--sample_size', type=int, default=SAMPLE_SIZE,\n",
    "                        help='Concatenate and cut audio samples to this many '\n",
    "                        'samples. Default: ' + str(SAMPLE_SIZE) + '.')\n",
    "    parser.add_argument('--l2_regularization_strength', type=float,\n",
    "                        default=L2_REGULARIZATION_STRENGTH,\n",
    "                        help='Coefficient in the L2 regularization. '\n",
    "                        'Default: False')\n",
    "    parser.add_argument('--silence_threshold', type=float,\n",
    "                        default=SILENCE_THRESHOLD,\n",
    "                        help='Volume threshold below which to trim the start '\n",
    "                        'and the end from the training set samples. Default: ' + str(SILENCE_THRESHOLD) + '.')\n",
    "    parser.add_argument('--optimizer', type=str, default='adam',\n",
    "                        choices=optimizer_factory.keys(),\n",
    "                        help='Select the optimizer specified by this option. Default: adam.')\n",
    "    parser.add_argument('--momentum', type=float,\n",
    "                        default=MOMENTUM, help='Specify the momentum to be '\n",
    "                        'used by sgd or rmsprop optimizer. Ignored by the '\n",
    "                        'adam optimizer. Default: ' + str(MOMENTUM) + '.')\n",
    "    parser.add_argument('--histograms', type=_str_to_bool, default=False,\n",
    "                        help='Whether to store histogram summaries. Default: False')\n",
    "    parser.add_argument('--gc_channels', type=int, default=None,\n",
    "                        help='Number of global condition channels. Default: None. Expecting: Int')\n",
    "    parser.add_argument('--max_checkpoints', type=int, default=MAX_TO_KEEP,\n",
    "                        help='Maximum amount of checkpoints that will be kept alive. Default: '\n",
    "                             + str(MAX_TO_KEEP) + '.')\n",
    "    return parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T07:53:31.014806Z",
     "start_time": "2018-06-05T07:53:31.005919Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-05T07:53:31.030484Z",
     "start_time": "2018-06-05T07:53:31.016338Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(saver, sess, logdir):\n",
    "    print(\"Trying to restore saved checkpoints from {} ...\".format(logdir),\n",
    "          end=\"\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(logdir)\n",
    "    if ckpt:\n",
    "        print(\"  Checkpoint found: {}\".format(ckpt.model_checkpoint_path))\n",
    "        global_step = int(ckpt.model_checkpoint_path\n",
    "                          .split('/')[-1]\n",
    "                          .split('-')[-1])\n",
    "        print(\"  Global step was: {}\".format(global_step))\n",
    "        print(\"  Restoring...\", end=\"\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\" Done.\")\n",
    "        return global_step\n",
    "    else:\n",
    "        print(\" No checkpoint found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-05T07:53:29.063Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_default_logdir(logdir_root):\n",
    "    logdir = os.path.join(logdir_root, 'train', STARTED_DATESTRING)\n",
    "    return logdir\n",
    "\n",
    "\n",
    "def validate_directories(args):\n",
    "    \"\"\"Validate and arrange directory related arguments.\"\"\"\n",
    "\n",
    "    # Validation\n",
    "    if args.logdir and args.logdir_root:\n",
    "        raise ValueError(\"--logdir and --logdir_root cannot be \"\n",
    "                         \"specified at the same time.\")\n",
    "\n",
    "    if args.logdir and args.restore_from:\n",
    "        raise ValueError(\n",
    "            \"--logdir and --restore_from cannot be specified at the same \"\n",
    "            \"time. This is to keep your previous model from unexpected \"\n",
    "            \"overwrites.\\n\"\n",
    "            \"Use --logdir_root to specify the root of the directory which \"\n",
    "            \"will be automatically created with current date and time, or use \"\n",
    "            \"only --logdir to just continue the training from the last \"\n",
    "            \"checkpoint.\")\n",
    "\n",
    "    # Arrangement\n",
    "    logdir_root = args.logdir_root\n",
    "    if logdir_root is None:\n",
    "        logdir_root = LOGDIR_ROOT\n",
    "\n",
    "    logdir = args.logdir\n",
    "    if logdir is None:\n",
    "        logdir = get_default_logdir(logdir_root)\n",
    "        print('Using default logdir: {}'.format(logdir))\n",
    "\n",
    "    restore_from = args.restore_from\n",
    "    if restore_from is None:\n",
    "        # args.logdir and args.restore_from are exclusive,\n",
    "        # so it is guaranteed the logdir here is newly created.\n",
    "        restore_from = logdir\n",
    "\n",
    "    return {\n",
    "        'logdir': logdir,\n",
    "        'logdir_root': args.logdir_root,\n",
    "        'restore_from': restore_from\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-05T07:53:29.065Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default logdir: ./logdirVS/train/2018-06-05T15-53-30\n",
      "trdequeue\n",
      "val ['./vsCorpus/pred_mix.wav', './vsCorpus/pred_vocal.wav']\n",
      "raw_output Tensor(\"wavenet_2/postprocessing/Add_1:0\", shape=(?, ?, 256), dtype=float32)\n",
      "ans0 (?,)\n",
      "Trying to restore saved checkpoints from ./logdirVS/train/2018-06-05T15-53-30 ... No checkpoint found.\n",
      "step 0 - trloss = 6.088, (17.813 sec/step)\n",
      "stored done\n",
      "validateLoss = 5.625, (17.813 sec/step)\n",
      "step 1 - trloss = 6.061, (2.486 sec/step)\n",
      "step 2 - trloss = 6.034, (2.485 sec/step)\n",
      "step 3 - trloss = 6.003, (2.485 sec/step)\n",
      "step 4 - trloss = 5.979, (2.486 sec/step)\n",
      "step 5 - trloss = 5.958, (2.486 sec/step)\n",
      "step 6 - trloss = 5.955, (2.496 sec/step)\n",
      "step 7 - trloss = 5.937, (2.487 sec/step)\n",
      "step 8 - trloss = 5.951, (2.488 sec/step)\n",
      "step 9 - trloss = 5.944, (2.491 sec/step)\n",
      "step 10 - trloss = 5.924, (2.486 sec/step)\n",
      "step 11 - trloss = 5.879, (2.500 sec/step)\n",
      "step 12 - trloss = 5.901, (2.492 sec/step)\n",
      "step 13 - trloss = 5.901, (2.495 sec/step)\n",
      "step 14 - trloss = 5.903, (2.492 sec/step)\n",
      "step 15 - trloss = 5.848, (2.495 sec/step)\n",
      "step 16 - trloss = 5.881, (2.495 sec/step)\n",
      "step 17 - trloss = 5.883, (2.495 sec/step)\n",
      "step 18 - trloss = 5.870, (2.494 sec/step)\n",
      "step 19 - trloss = 5.823, (2.493 sec/step)\n",
      "step 20 - trloss = 5.826, (2.496 sec/step)\n",
      "step 21 - trloss = 5.873, (2.493 sec/step)\n",
      "step 22 - trloss = 5.843, (2.494 sec/step)\n",
      "step 23 - trloss = 5.803, (2.521 sec/step)\n",
      "step 24 - trloss = 5.948, (2.492 sec/step)\n",
      "step 25 - trloss = 5.872, (2.492 sec/step)\n",
      "step 26 - trloss = 5.858, (2.490 sec/step)\n",
      "step 27 - trloss = 5.873, (2.489 sec/step)\n",
      "step 28 - trloss = 5.871, (2.490 sec/step)\n",
      "step 29 - trloss = 5.871, (2.492 sec/step)\n",
      "step 30 - trloss = 5.887, (2.491 sec/step)\n",
      "step 31 - trloss = 5.850, (2.494 sec/step)\n",
      "step 32 - trloss = 5.867, (2.493 sec/step)\n",
      "step 33 - trloss = 5.826, (2.492 sec/step)\n",
      "step 34 - trloss = 5.816, (2.493 sec/step)\n",
      "step 35 - trloss = 5.874, (2.491 sec/step)\n",
      "step 36 - trloss = 5.906, (2.495 sec/step)\n",
      "step 37 - trloss = 5.870, (2.493 sec/step)\n",
      "step 38 - trloss = 5.837, (2.498 sec/step)\n",
      "step 39 - trloss = 5.831, (2.495 sec/step)\n",
      "step 40 - trloss = 5.848, (2.495 sec/step)\n",
      "step 41 - trloss = 5.896, (2.496 sec/step)\n",
      "step 42 - trloss = 5.857, (2.495 sec/step)\n",
      "step 43 - trloss = 5.900, (2.495 sec/step)\n",
      "step 44 - trloss = 5.824, (2.496 sec/step)\n",
      "step 45 - trloss = 5.815, (2.494 sec/step)\n",
      "step 46 - trloss = 5.895, (2.499 sec/step)\n",
      "step 47 - trloss = 5.832, (2.495 sec/step)\n",
      "step 48 - trloss = 5.859, (2.495 sec/step)\n",
      "step 49 - trloss = 5.809, (2.495 sec/step)\n",
      "step 50 - trloss = 5.851, (2.496 sec/step)\n",
      "stored done\n",
      "validateLoss = 5.413, (2.496 sec/step)\n",
      "step 51 - trloss = 5.850, (2.515 sec/step)\n",
      "step 52 - trloss = 5.781, (2.496 sec/step)\n",
      "step 53 - trloss = 5.863, (2.495 sec/step)\n",
      "step 54 - trloss = 5.836, (2.496 sec/step)\n",
      "step 55 - trloss = 5.837, (2.495 sec/step)\n",
      "step 56 - trloss = 5.840, (2.496 sec/step)\n",
      "step 57 - trloss = 5.806, (2.494 sec/step)\n",
      "step 58 - trloss = 5.849, (2.495 sec/step)\n",
      "step 59 - trloss = 5.876, (2.493 sec/step)\n",
      "step 60 - trloss = 5.863, (2.494 sec/step)\n",
      "step 61 - trloss = 5.822, (2.493 sec/step)\n",
      "step 62 - trloss = 5.847, (2.496 sec/step)\n",
      "step 63 - trloss = 5.871, (2.500 sec/step)\n",
      "step 64 - trloss = 5.814, (2.495 sec/step)\n",
      "step 65 - trloss = 5.847, (2.504 sec/step)\n",
      "step 66 - trloss = 5.862, (2.495 sec/step)\n",
      "step 67 - trloss = 5.800, (2.495 sec/step)\n",
      "step 68 - trloss = 5.807, (2.499 sec/step)\n",
      "step 69 - trloss = 5.849, (2.499 sec/step)\n",
      "step 70 - trloss = 5.777, (2.494 sec/step)\n",
      "step 71 - trloss = 5.873, (2.497 sec/step)\n",
      "step 72 - trloss = 5.833, (2.495 sec/step)\n",
      "step 73 - trloss = 5.805, (2.493 sec/step)\n",
      "step 74 - trloss = 5.834, (2.494 sec/step)\n",
      "step 75 - trloss = 5.790, (2.494 sec/step)\n",
      "step 76 - trloss = 5.828, (2.495 sec/step)\n",
      "step 77 - trloss = 5.813, (2.495 sec/step)\n",
      "step 78 - trloss = 5.785, (2.498 sec/step)\n",
      "step 79 - trloss = 5.792, (2.495 sec/step)\n",
      "step 80 - trloss = 5.805, (2.495 sec/step)\n",
      "step 81 - trloss = 5.745, (2.493 sec/step)\n",
      "step 82 - trloss = 5.794, (2.496 sec/step)\n",
      "step 83 - trloss = 5.774, (2.493 sec/step)\n",
      "step 84 - trloss = 5.762, (2.494 sec/step)\n",
      "step 85 - trloss = 5.761, (2.495 sec/step)\n",
      "step 86 - trloss = 5.751, (2.493 sec/step)\n",
      "step 87 - trloss = 5.760, (2.506 sec/step)\n",
      "step 88 - trloss = 5.692, (2.492 sec/step)\n",
      "step 89 - trloss = 5.649, (2.494 sec/step)\n",
      "step 90 - trloss = 5.726, (2.494 sec/step)\n",
      "step 91 - trloss = 5.621, (2.494 sec/step)\n",
      "step 92 - trloss = 5.727, (2.496 sec/step)\n",
      "step 93 - trloss = 5.704, (2.497 sec/step)\n",
      "step 94 - trloss = 5.710, (2.495 sec/step)\n",
      "step 95 - trloss = 5.595, (2.497 sec/step)\n",
      "step 96 - trloss = 5.740, (2.495 sec/step)\n",
      "step 97 - trloss = 5.762, (2.495 sec/step)\n",
      "step 98 - trloss = 5.741, (2.495 sec/step)\n",
      "step 99 - trloss = 5.693, (2.495 sec/step)\n",
      "step 100 - trloss = 5.624, (2.496 sec/step)\n",
      "stored done\n",
      "validateLoss = 5.220, (2.496 sec/step)\n",
      "step 101 - trloss = 5.681, (2.497 sec/step)\n",
      "step 102 - trloss = 5.658, (2.498 sec/step)\n",
      "step 103 - trloss = 5.618, (2.518 sec/step)\n",
      "step 104 - trloss = 5.619, (2.498 sec/step)\n",
      "step 105 - trloss = 5.657, (2.497 sec/step)\n",
      "step 106 - trloss = 5.611, (2.499 sec/step)\n",
      "step 107 - trloss = 5.641, (2.499 sec/step)\n",
      "step 108 - trloss = 5.599, (2.498 sec/step)\n",
      "step 109 - trloss = 5.604, (2.499 sec/step)\n",
      "step 110 - trloss = 5.599, (2.496 sec/step)\n",
      "step 111 - trloss = 5.589, (2.496 sec/step)\n",
      "step 112 - trloss = 5.596, (2.496 sec/step)\n",
      "step 113 - trloss = 5.586, (2.497 sec/step)\n",
      "step 114 - trloss = 5.563, (2.496 sec/step)\n",
      "step 115 - trloss = 5.574, (2.498 sec/step)\n",
      "step 116 - trloss = 5.574, (2.498 sec/step)\n",
      "step 117 - trloss = 5.579, (2.498 sec/step)\n",
      "step 118 - trloss = 5.552, (2.498 sec/step)\n",
      "step 119 - trloss = 5.510, (2.497 sec/step)\n",
      "step 120 - trloss = 5.505, (2.499 sec/step)\n",
      "step 121 - trloss = 5.537, (2.499 sec/step)\n",
      "step 122 - trloss = 5.573, (2.496 sec/step)\n",
      "step 123 - trloss = 5.458, (2.498 sec/step)\n",
      "step 124 - trloss = 5.564, (2.499 sec/step)\n",
      "step 125 - trloss = 5.545, (2.497 sec/step)\n",
      "step 126 - trloss = 5.554, (2.496 sec/step)\n",
      "step 127 - trloss = 5.495, (2.497 sec/step)\n",
      "step 128 - trloss = 5.510, (2.500 sec/step)\n",
      "step 129 - trloss = 5.455, (2.500 sec/step)\n",
      "step 130 - trloss = 5.502, (2.500 sec/step)\n",
      "step 131 - trloss = 5.517, (2.498 sec/step)\n",
      "step 132 - trloss = 5.473, (2.499 sec/step)\n",
      "step 133 - trloss = 5.434, (2.497 sec/step)\n",
      "step 134 - trloss = 5.508, (2.500 sec/step)\n",
      "step 135 - trloss = 5.542, (2.498 sec/step)\n",
      "step 136 - trloss = 5.460, (2.503 sec/step)\n",
      "step 137 - trloss = 5.465, (2.498 sec/step)\n",
      "step 138 - trloss = 5.491, (2.499 sec/step)\n",
      "step 139 - trloss = 5.504, (2.499 sec/step)\n",
      "step 140 - trloss = 5.504, (2.501 sec/step)\n",
      "step 141 - trloss = 5.569, (2.499 sec/step)\n",
      "step 142 - trloss = 5.513, (2.500 sec/step)\n",
      "step 143 - trloss = 5.534, (2.500 sec/step)\n",
      "step 144 - trloss = 5.533, (2.499 sec/step)\n",
      "step 145 - trloss = 5.596, (2.501 sec/step)\n",
      "step 146 - trloss = 5.550, (2.499 sec/step)\n",
      "step 147 - trloss = 5.524, (2.500 sec/step)\n",
      "step 148 - trloss = 5.496, (2.501 sec/step)\n",
      "step 149 - trloss = 5.481, (2.508 sec/step)\n",
      "step 150 - trloss = 5.564, (2.501 sec/step)\n",
      "stored done\n",
      "validateLoss = 5.203, (2.501 sec/step)\n",
      "step 151 - trloss = 5.527, (2.500 sec/step)\n",
      "step 152 - trloss = 5.527, (2.499 sec/step)\n",
      "step 153 - trloss = 5.491, (2.500 sec/step)\n",
      "step 154 - trloss = 5.561, (2.497 sec/step)\n",
      "step 155 - trloss = 5.501, (2.501 sec/step)\n",
      "step 156 - trloss = 5.458, (2.499 sec/step)\n",
      "step 157 - trloss = 5.449, (2.500 sec/step)\n",
      "step 158 - trloss = 5.590, (2.499 sec/step)\n",
      "step 159 - trloss = 5.442, (2.498 sec/step)\n",
      "step 160 - trloss = 5.438, (2.503 sec/step)\n",
      "step 161 - trloss = 5.457, (2.500 sec/step)\n",
      "step 162 - trloss = 5.470, (2.499 sec/step)\n",
      "step 163 - trloss = 5.439, (2.497 sec/step)\n",
      "step 164 - trloss = 5.483, (2.498 sec/step)\n",
      "step 165 - trloss = 5.405, (2.496 sec/step)\n",
      "step 166 - trloss = 5.454, (2.498 sec/step)\n",
      "step 167 - trloss = 5.483, (2.502 sec/step)\n",
      "step 168 - trloss = 5.492, (2.510 sec/step)\n",
      "step 169 - trloss = 5.424, (2.496 sec/step)\n",
      "step 170 - trloss = 5.410, (2.498 sec/step)\n",
      "step 171 - trloss = 5.452, (2.497 sec/step)\n",
      "step 172 - trloss = 5.419, (2.495 sec/step)\n",
      "step 173 - trloss = 5.436, (2.494 sec/step)\n",
      "step 174 - trloss = 5.457, (2.496 sec/step)\n",
      "step 175 - trloss = 5.423, (2.493 sec/step)\n",
      "step 176 - trloss = 5.430, (2.512 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 177 - trloss = 5.449, (2.495 sec/step)\n",
      "step 178 - trloss = 5.484, (2.498 sec/step)\n",
      "step 179 - trloss = 5.439, (2.495 sec/step)\n",
      "step 180 - trloss = 5.456, (2.496 sec/step)\n",
      "step 181 - trloss = 5.388, (2.494 sec/step)\n",
      "step 182 - trloss = 5.406, (2.495 sec/step)\n",
      "step 183 - trloss = 5.526, (2.497 sec/step)\n",
      "step 184 - trloss = 5.413, (2.496 sec/step)\n",
      "step 185 - trloss = 5.485, (2.495 sec/step)\n",
      "step 186 - trloss = 5.484, (2.496 sec/step)\n",
      "step 187 - trloss = 5.425, (2.496 sec/step)\n",
      "step 188 - trloss = 5.482, (2.496 sec/step)\n",
      "step 189 - trloss = 5.475, (2.498 sec/step)\n",
      "step 190 - trloss = 5.407, (2.497 sec/step)\n",
      "step 191 - trloss = 5.488, (2.498 sec/step)\n",
      "step 192 - trloss = 5.449, (2.506 sec/step)\n",
      "step 193 - trloss = 5.401, (2.499 sec/step)\n",
      "step 194 - trloss = 5.443, (2.501 sec/step)\n",
      "step 195 - trloss = 5.437, (2.498 sec/step)\n",
      "step 196 - trloss = 5.416, (2.499 sec/step)\n",
      "step 197 - trloss = 5.401, (2.502 sec/step)\n",
      "step 198 - trloss = 5.435, (2.502 sec/step)\n",
      "step 199 - trloss = 5.409, (2.499 sec/step)\n",
      "step 200 - trloss = 5.383, (2.501 sec/step)\n",
      "stored done\n",
      "validateLoss = 5.283, (2.501 sec/step)\n",
      "step 201 - trloss = 5.477, (2.507 sec/step)\n",
      "step 202 - trloss = 5.403, (2.500 sec/step)\n",
      "step 203 - trloss = 5.381, (2.498 sec/step)\n",
      "step 204 - trloss = 5.386, (2.501 sec/step)\n",
      "step 205 - trloss = 5.367, (2.501 sec/step)\n",
      "step 206 - trloss = 5.392, (2.499 sec/step)\n",
      "step 207 - trloss = 5.388, (2.500 sec/step)\n",
      "step 208 - trloss = 5.373, (2.497 sec/step)\n",
      "step 209 - trloss = 5.404, (2.499 sec/step)\n",
      "step 210 - trloss = 5.453, (2.498 sec/step)\n",
      "step 211 - trloss = 5.401, (2.497 sec/step)\n",
      "step 212 - trloss = 5.503, (2.498 sec/step)\n",
      "step 213 - trloss = 5.411, (2.498 sec/step)\n",
      "step 214 - trloss = 5.410, (2.496 sec/step)\n",
      "step 215 - trloss = 5.354, (2.499 sec/step)\n",
      "step 216 - trloss = 5.382, (2.498 sec/step)\n",
      "step 217 - trloss = 5.370, (2.498 sec/step)\n",
      "step 218 - trloss = 5.425, (2.497 sec/step)\n",
      "step 219 - trloss = 5.387, (2.504 sec/step)\n",
      "step 220 - trloss = 5.354, (2.508 sec/step)\n",
      "step 221 - trloss = 5.295, (2.498 sec/step)\n",
      "step 222 - trloss = 5.349, (2.498 sec/step)\n",
      "step 223 - trloss = 5.411, (2.501 sec/step)\n",
      "step 224 - trloss = 5.375, (2.499 sec/step)\n",
      "step 225 - trloss = 5.311, (2.501 sec/step)\n",
      "step 226 - trloss = 5.546, (2.500 sec/step)\n",
      "step 227 - trloss = 5.395, (2.500 sec/step)\n",
      "step 228 - trloss = 5.317, (2.500 sec/step)\n",
      "step 229 - trloss = 5.316, (2.500 sec/step)\n",
      "step 230 - trloss = 5.332, (2.502 sec/step)\n",
      "step 231 - trloss = 5.329, (2.500 sec/step)\n",
      "step 232 - trloss = 5.364, (2.500 sec/step)\n",
      "step 233 - trloss = 5.313, (2.500 sec/step)\n",
      "step 234 - trloss = 5.369, (2.500 sec/step)\n",
      "step 235 - trloss = 5.291, (2.499 sec/step)\n",
      "step 236 - trloss = 5.329, (2.502 sec/step)\n",
      "step 237 - trloss = 5.313, (2.499 sec/step)\n",
      "step 238 - trloss = 5.296, (2.499 sec/step)\n",
      "step 239 - trloss = 5.282, (2.499 sec/step)\n",
      "step 240 - trloss = 5.262, (2.503 sec/step)\n",
      "step 241 - trloss = 5.222, (2.497 sec/step)\n",
      "step 242 - trloss = 5.232, (2.498 sec/step)\n",
      "step 243 - trloss = 5.300, (2.501 sec/step)\n",
      "step 244 - trloss = 5.215, (2.501 sec/step)\n",
      "step 245 - trloss = 5.299, (2.497 sec/step)\n",
      "step 246 - trloss = 5.220, (2.499 sec/step)\n",
      "step 247 - trloss = 5.314, (2.501 sec/step)\n",
      "step 248 - trloss = 5.235, (2.500 sec/step)\n",
      "step 249 - trloss = 5.312, (2.503 sec/step)\n",
      "step 250 - trloss = 5.172, (2.498 sec/step)\n",
      "stored done\n",
      "validateLoss = 5.035, (2.498 sec/step)\n",
      "step 251 - trloss = 5.233, (2.497 sec/step)\n",
      "step 252 - trloss = 5.251, (2.499 sec/step)\n",
      "step 253 - trloss = 5.182, (2.510 sec/step)\n",
      "step 254 - trloss = 5.247, (2.497 sec/step)\n",
      "step 255 - trloss = 5.138, (2.495 sec/step)\n",
      "step 256 - trloss = 5.233, (2.506 sec/step)\n",
      "step 257 - trloss = 5.112, (2.496 sec/step)\n",
      "step 258 - trloss = 5.139, (2.498 sec/step)\n",
      "step 259 - trloss = 5.274, (2.496 sec/step)\n",
      "step 260 - trloss = 5.222, (2.496 sec/step)\n",
      "step 261 - trloss = 5.099, (2.493 sec/step)\n",
      "step 262 - trloss = 5.259, (2.492 sec/step)\n",
      "step 263 - trloss = 5.098, (2.496 sec/step)\n",
      "step 264 - trloss = 5.078, (2.493 sec/step)\n",
      "step 265 - trloss = 5.064, (2.494 sec/step)\n",
      "step 266 - trloss = 5.143, (2.492 sec/step)\n",
      "step 267 - trloss = 5.091, (2.493 sec/step)\n",
      "step 268 - trloss = 5.055, (2.493 sec/step)\n",
      "step 269 - trloss = 5.024, (2.495 sec/step)\n",
      "step 270 - trloss = 5.194, (2.502 sec/step)\n",
      "step 271 - trloss = 5.124, (2.493 sec/step)\n",
      "step 272 - trloss = 5.328, (2.497 sec/step)\n",
      "step 273 - trloss = 5.162, (2.498 sec/step)\n",
      "step 274 - trloss = 5.204, (2.495 sec/step)\n",
      "step 275 - trloss = 5.062, (2.496 sec/step)\n",
      "step 276 - trloss = 5.186, (2.497 sec/step)\n",
      "step 277 - trloss = 5.096, (2.497 sec/step)\n",
      "step 278 - trloss = 5.233, (2.495 sec/step)\n",
      "step 279 - trloss = 5.175, (2.496 sec/step)\n",
      "step 280 - trloss = 5.193, (2.497 sec/step)\n",
      "step 281 - trloss = 5.126, (2.495 sec/step)\n",
      "step 282 - trloss = 5.020, (2.495 sec/step)\n",
      "step 283 - trloss = 5.050, (2.496 sec/step)\n",
      "step 284 - trloss = 5.062, (2.505 sec/step)\n",
      "step 285 - trloss = 5.081, (2.499 sec/step)\n",
      "step 286 - trloss = 5.186, (2.502 sec/step)\n",
      "step 287 - trloss = 5.208, (2.496 sec/step)\n",
      "step 288 - trloss = 5.177, (2.497 sec/step)\n",
      "step 289 - trloss = 5.052, (2.498 sec/step)\n",
      "step 290 - trloss = 5.090, (2.500 sec/step)\n",
      "step 291 - trloss = 5.181, (2.500 sec/step)\n",
      "step 292 - trloss = 5.107, (2.498 sec/step)\n",
      "step 293 - trloss = 5.141, (2.499 sec/step)\n",
      "step 294 - trloss = 5.093, (2.500 sec/step)\n",
      "step 295 - trloss = 5.090, (2.501 sec/step)\n",
      "step 296 - trloss = 5.106, (2.506 sec/step)\n",
      "step 297 - trloss = 5.012, (2.497 sec/step)\n",
      "step 298 - trloss = 5.105, (2.498 sec/step)\n",
      "step 299 - trloss = 5.244, (2.497 sec/step)\n",
      "step 300 - trloss = 5.106, (2.498 sec/step)\n",
      "stored done\n",
      "validateLoss = 4.673, (2.498 sec/step)\n",
      "step 301 - trloss = 5.158, (2.498 sec/step)\n",
      "step 302 - trloss = 5.234, (2.498 sec/step)\n",
      "step 303 - trloss = 5.283, (2.498 sec/step)\n",
      "step 304 - trloss = 5.191, (2.497 sec/step)\n",
      "step 305 - trloss = 5.171, (2.496 sec/step)\n",
      "step 306 - trloss = 5.134, (2.494 sec/step)\n",
      "step 307 - trloss = 5.236, (2.506 sec/step)\n",
      "step 308 - trloss = 5.155, (2.495 sec/step)\n",
      "step 309 - trloss = 5.187, (2.497 sec/step)\n",
      "step 310 - trloss = 5.178, (2.497 sec/step)\n",
      "step 311 - trloss = 5.145, (2.495 sec/step)\n",
      "step 312 - trloss = 5.191, (2.496 sec/step)\n",
      "step 313 - trloss = 5.157, (2.495 sec/step)\n",
      "step 314 - trloss = 5.053, (2.496 sec/step)\n",
      "step 315 - trloss = 5.121, (2.498 sec/step)\n",
      "step 316 - trloss = 5.150, (2.495 sec/step)\n",
      "step 317 - trloss = 5.046, (2.496 sec/step)\n",
      "step 318 - trloss = 5.085, (2.496 sec/step)\n",
      "step 319 - trloss = 5.042, (2.496 sec/step)\n",
      "step 320 - trloss = 5.112, (2.495 sec/step)\n",
      "step 321 - trloss = 5.081, (2.496 sec/step)\n",
      "step 322 - trloss = 5.107, (2.497 sec/step)\n",
      "step 323 - trloss = 5.056, (2.497 sec/step)\n",
      "step 324 - trloss = 5.016, (2.495 sec/step)\n",
      "step 325 - trloss = 5.057, (2.496 sec/step)\n",
      "step 326 - trloss = 5.029, (2.497 sec/step)\n",
      "step 327 - trloss = 5.144, (2.496 sec/step)\n",
      "step 328 - trloss = 5.039, (2.496 sec/step)\n",
      "step 329 - trloss = 5.057, (2.498 sec/step)\n",
      "step 330 - trloss = 5.078, (2.497 sec/step)\n",
      "step 331 - trloss = 5.154, (2.498 sec/step)\n",
      "step 332 - trloss = 5.088, (2.499 sec/step)\n",
      "step 333 - trloss = 5.042, (2.497 sec/step)\n",
      "step 334 - trloss = 5.105, (2.497 sec/step)\n",
      "step 335 - trloss = 5.124, (2.504 sec/step)\n",
      "step 336 - trloss = 4.961, (2.497 sec/step)\n",
      "step 337 - trloss = 4.943, (2.498 sec/step)\n",
      "step 338 - trloss = 5.001, (2.500 sec/step)\n",
      "step 339 - trloss = 5.142, (2.501 sec/step)\n",
      "step 340 - trloss = 5.043, (2.499 sec/step)\n",
      "step 341 - trloss = 4.990, (2.500 sec/step)\n",
      "step 342 - trloss = 4.966, (2.498 sec/step)\n",
      "step 343 - trloss = 5.010, (2.500 sec/step)\n",
      "step 344 - trloss = 5.014, (2.501 sec/step)\n",
      "step 345 - trloss = 5.029, (2.502 sec/step)\n",
      "step 346 - trloss = 5.250, (2.498 sec/step)\n",
      "step 347 - trloss = 5.135, (2.499 sec/step)\n",
      "step 348 - trloss = 5.017, (2.499 sec/step)\n",
      "step 349 - trloss = 5.116, (2.498 sec/step)\n",
      "step 350 - trloss = 4.927, (2.499 sec/step)\n",
      "stored done\n",
      "validateLoss = 4.808, (2.499 sec/step)\n",
      "step 351 - trloss = 5.124, (2.497 sec/step)\n",
      "step 352 - trloss = 5.276, (2.498 sec/step)\n",
      "step 353 - trloss = 5.163, (2.497 sec/step)\n",
      "step 354 - trloss = 5.062, (2.494 sec/step)\n",
      "step 355 - trloss = 5.103, (2.495 sec/step)\n",
      "step 356 - trloss = 5.271, (2.498 sec/step)\n",
      "step 357 - trloss = 4.966, (2.496 sec/step)\n",
      "step 358 - trloss = 5.098, (2.497 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 359 - trloss = 5.208, (2.496 sec/step)\n",
      "step 360 - trloss = 5.061, (2.496 sec/step)\n",
      "step 361 - trloss = 5.048, (2.497 sec/step)\n",
      "step 362 - trloss = 5.049, (2.495 sec/step)\n",
      "step 363 - trloss = 5.122, (2.497 sec/step)\n",
      "step 364 - trloss = 5.023, (2.496 sec/step)\n",
      "step 365 - trloss = 5.092, (2.499 sec/step)\n",
      "step 366 - trloss = 5.142, (2.497 sec/step)\n",
      "step 367 - trloss = 5.169, (2.499 sec/step)\n",
      "step 368 - trloss = 5.152, (2.497 sec/step)\n",
      "step 369 - trloss = 5.076, (2.502 sec/step)\n",
      "step 370 - trloss = 5.082, (2.498 sec/step)\n",
      "step 371 - trloss = 5.101, (2.498 sec/step)\n",
      "step 372 - trloss = 5.076, (2.497 sec/step)\n",
      "step 373 - trloss = 5.007, (2.496 sec/step)\n",
      "step 374 - trloss = 4.972, (2.496 sec/step)\n",
      "step 375 - trloss = 5.051, (2.497 sec/step)\n",
      "step 376 - trloss = 5.025, (2.496 sec/step)\n",
      "step 377 - trloss = 5.017, (2.497 sec/step)\n",
      "step 378 - trloss = 5.040, (2.497 sec/step)\n",
      "step 379 - trloss = 5.048, (2.497 sec/step)\n",
      "step 380 - trloss = 5.063, (2.498 sec/step)\n",
      "step 381 - trloss = 5.055, (2.498 sec/step)\n",
      "step 382 - trloss = 5.016, (2.498 sec/step)\n",
      "step 383 - trloss = 5.019, (2.499 sec/step)\n",
      "step 384 - trloss = 5.099, (2.495 sec/step)\n",
      "step 385 - trloss = 5.046, (2.497 sec/step)\n",
      "step 386 - trloss = 5.064, (2.496 sec/step)\n",
      "step 387 - trloss = 5.046, (2.498 sec/step)\n",
      "step 388 - trloss = 5.015, (2.498 sec/step)\n",
      "step 389 - trloss = 5.168, (2.506 sec/step)\n",
      "step 390 - trloss = 4.982, (2.498 sec/step)\n",
      "step 391 - trloss = 5.083, (2.505 sec/step)\n",
      "step 392 - trloss = 5.050, (2.497 sec/step)\n",
      "step 393 - trloss = 4.973, (2.499 sec/step)\n",
      "step 394 - trloss = 4.895, (2.498 sec/step)\n",
      "step 395 - trloss = 5.030, (2.496 sec/step)\n",
      "step 396 - trloss = 4.995, (2.496 sec/step)\n",
      "step 397 - trloss = 5.051, (2.496 sec/step)\n",
      "step 398 - trloss = 5.057, (2.497 sec/step)\n",
      "step 399 - trloss = 4.946, (2.497 sec/step)\n",
      "step 400 - trloss = 5.074, (2.495 sec/step)\n",
      "stored done\n",
      "validateLoss = 4.725, (2.495 sec/step)\n",
      "step 401 - trloss = 5.056, (2.496 sec/step)\n",
      "step 402 - trloss = 4.901, (2.496 sec/step)\n",
      "step 403 - trloss = 4.983, (2.496 sec/step)\n",
      "step 404 - trloss = 4.982, (2.496 sec/step)\n",
      "step 405 - trloss = 5.218, (2.498 sec/step)\n",
      "step 406 - trloss = 4.963, (2.497 sec/step)\n",
      "step 407 - trloss = 5.008, (2.497 sec/step)\n",
      "step 408 - trloss = 4.922, (2.497 sec/step)\n",
      "step 409 - trloss = 4.965, (2.508 sec/step)\n",
      "step 410 - trloss = 4.956, (2.500 sec/step)\n",
      "step 411 - trloss = 5.080, (2.503 sec/step)\n",
      "step 412 - trloss = 4.972, (2.499 sec/step)\n",
      "step 413 - trloss = 4.929, (2.500 sec/step)\n",
      "step 414 - trloss = 4.947, (2.499 sec/step)\n",
      "step 415 - trloss = 4.909, (2.501 sec/step)\n",
      "step 416 - trloss = 5.066, (2.501 sec/step)\n",
      "step 417 - trloss = 4.886, (2.502 sec/step)\n",
      "step 418 - trloss = 4.932, (2.503 sec/step)\n",
      "step 419 - trloss = 4.940, (2.501 sec/step)\n",
      "step 420 - trloss = 5.009, (2.500 sec/step)\n",
      "step 421 - trloss = 5.086, (2.501 sec/step)\n",
      "step 422 - trloss = 4.931, (2.499 sec/step)\n",
      "step 423 - trloss = 5.115, (2.500 sec/step)\n",
      "step 424 - trloss = 4.986, (2.500 sec/step)\n",
      "step 425 - trloss = 5.090, (2.500 sec/step)\n",
      "step 426 - trloss = 5.065, (2.500 sec/step)\n",
      "step 427 - trloss = 4.972, (2.501 sec/step)\n",
      "step 428 - trloss = 5.092, (2.499 sec/step)\n",
      "step 429 - trloss = 4.941, (2.501 sec/step)\n",
      "step 430 - trloss = 4.868, (2.499 sec/step)\n",
      "step 431 - trloss = 4.986, (2.499 sec/step)\n",
      "step 432 - trloss = 4.968, (2.500 sec/step)\n",
      "step 433 - trloss = 5.028, (2.503 sec/step)\n",
      "step 434 - trloss = 4.967, (2.499 sec/step)\n",
      "step 435 - trloss = 5.008, (2.514 sec/step)\n",
      "step 436 - trloss = 4.992, (2.497 sec/step)\n",
      "step 437 - trloss = 5.041, (2.500 sec/step)\n",
      "step 438 - trloss = 4.861, (2.497 sec/step)\n",
      "step 439 - trloss = 5.220, (2.498 sec/step)\n",
      "step 440 - trloss = 4.915, (2.497 sec/step)\n",
      "step 441 - trloss = 5.123, (2.496 sec/step)\n",
      "step 442 - trloss = 5.074, (2.498 sec/step)\n",
      "step 443 - trloss = 5.086, (2.497 sec/step)\n",
      "step 444 - trloss = 4.897, (2.497 sec/step)\n",
      "step 445 - trloss = 4.981, (2.495 sec/step)\n",
      "step 446 - trloss = 5.036, (2.495 sec/step)\n",
      "step 447 - trloss = 5.031, (2.495 sec/step)\n",
      "step 448 - trloss = 5.093, (2.499 sec/step)\n",
      "step 449 - trloss = 4.979, (2.495 sec/step)\n",
      "step 450 - trloss = 5.055, (2.495 sec/step)\n",
      "stored done\n",
      "validateLoss = 4.779, (2.495 sec/step)\n",
      "step 451 - trloss = 5.058, (2.494 sec/step)\n",
      "step 452 - trloss = 4.997, (2.495 sec/step)\n",
      "step 453 - trloss = 4.998, (2.495 sec/step)\n",
      "step 454 - trloss = 4.887, (2.498 sec/step)\n",
      "step 455 - trloss = 5.025, (2.496 sec/step)\n",
      "step 456 - trloss = 5.010, (2.497 sec/step)\n",
      "step 457 - trloss = 4.995, (2.496 sec/step)\n",
      "step 458 - trloss = 4.959, (2.493 sec/step)\n",
      "step 459 - trloss = 4.939, (2.497 sec/step)\n",
      "step 460 - trloss = 4.995, (2.497 sec/step)\n",
      "step 461 - trloss = 4.849, (2.496 sec/step)\n",
      "step 462 - trloss = 5.071, (2.496 sec/step)\n",
      "step 463 - trloss = 4.959, (2.497 sec/step)\n",
      "step 464 - trloss = 5.051, (2.497 sec/step)\n",
      "step 465 - trloss = 4.974, (2.509 sec/step)\n"
     ]
    }
   ],
   "source": [
    "args = get_arguments()\n",
    "\n",
    "try:\n",
    "    directories = validate_directories(args)\n",
    "except ValueError as e:\n",
    "    print(\"Some arguments are wrong:\")\n",
    "    print(str(e))\n",
    "\n",
    "logdir = directories['logdir']\n",
    "restore_from = directories['restore_from']\n",
    "\n",
    "# Even if we restored the model, we will treat it as new training\n",
    "# if the trained model is written into an arbitrary location.\n",
    "is_overwritten_training = logdir != restore_from\n",
    "\n",
    "with open(args.wavenet_params, 'r') as f:\n",
    "    wavenet_params = json.load(f)\n",
    "\n",
    "# Create coordinator.\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "# Load raw waveform from VCTK corpus.\n",
    "with tf.name_scope('create_inputs'):\n",
    "    # Allow silence trimming to be skipped by specifying a threshold near\n",
    "    # zero.\n",
    "    silence_threshold = args.silence_threshold if args.silence_threshold > \\\n",
    "                                                  EPSILON else None\n",
    "    gc_enabled = args.gc_channels is not None\n",
    "    reader = AudioReader(\n",
    "        args.data_dir,\n",
    "        coord,\n",
    "        sample_rate=wavenet_params['sample_rate'],   #\"sample_rate\": 16000,\n",
    "        gc_enabled=gc_enabled,\n",
    "        receptive_field=WaveNetModel.calculate_receptive_field(wavenet_params[\"filter_width\"],\n",
    "                                                               wavenet_params[\"dilations\"],\n",
    "                                                               wavenet_params[\"scalar_input\"],\n",
    "                                                               wavenet_params[\"initial_filter_width\"]),\n",
    "        sample_size=args.sample_size,  #SAMPLE_SIZE = 100000\n",
    "        silence_threshold=silence_threshold)\n",
    "    traudio_batch = reader.trdequeue(args.batch_size)  #BATCH_SIZE = 1\n",
    "    if gc_enabled:\n",
    "        ##TODO train and val\n",
    "        gc_id_batch = reader.dequeue_gc(args.batch_size)\n",
    "    else:\n",
    "        gc_id_batch = None\n",
    "\n",
    "# Create network.\n",
    "net = WaveNetModel(\n",
    "    batch_size=args.batch_size,\n",
    "    dilations=wavenet_params[\"dilations\"],\n",
    "    filter_width=wavenet_params[\"filter_width\"],\n",
    "    residual_channels=wavenet_params[\"residual_channels\"],\n",
    "    dilation_channels=wavenet_params[\"dilation_channels\"],\n",
    "    skip_channels=wavenet_params[\"skip_channels\"],\n",
    "    quantization_channels=wavenet_params[\"quantization_channels\"],\n",
    "    use_biases=wavenet_params[\"use_biases\"],\n",
    "    scalar_input=wavenet_params[\"scalar_input\"],\n",
    "    initial_filter_width=wavenet_params[\"initial_filter_width\"],\n",
    "    histograms=args.histograms,\n",
    "    global_condition_channels=args.gc_channels,\n",
    "    global_condition_cardinality=reader.gc_category_cardinality)\n",
    "\n",
    "if args.l2_regularization_strength == 0:\n",
    "    args.l2_regularization_strength = None\n",
    "trloss = net.trloss(input_batch=traudio_batch,\n",
    "                global_condition_batch=gc_id_batch,\n",
    "                l2_regularization_strength=args.l2_regularization_strength)\n",
    "optimizer = optimizer_factory[args.optimizer](\n",
    "                learning_rate=args.learning_rate,\n",
    "                momentum=args.momentum)\n",
    "trainable = tf.trainable_variables()\n",
    "optim = optimizer.minimize(trloss, var_list=trainable)\n",
    "\n",
    "# Set up logging for TensorBoard.\n",
    "writer = tf.summary.FileWriter(logdir)\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "run_metadata = tf.RunMetadata()\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "# Set up session\n",
    "config = tf.ConfigProto(log_device_placement=False)\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "#sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "\n",
    "vaudio_batch = reader.valbatch()\n",
    "valloss = net.valloss(input_batch=vaudio_batch,\n",
    "                global_condition_batch=gc_id_batch,\n",
    "                l2_regularization_strength=args.l2_regularization_strength)\n",
    "genfile = net.generateFile(input_batch=vaudio_batch,\n",
    "                global_condition_batch=gc_id_batch,\n",
    "                l2_regularization_strength=args.l2_regularization_strength)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Saver for storing checkpoints of the model.\n",
    "saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=args.max_checkpoints)\n",
    "\n",
    "try:\n",
    "    saved_global_step = load(saver, sess, restore_from)\n",
    "    if is_overwritten_training or saved_global_step is None:\n",
    "        # The first training step will be saved_global_step + 1,\n",
    "        # therefore we put -1 here for new or overwritten trainings.\n",
    "        saved_global_step = -1\n",
    "\n",
    "except:\n",
    "    print(\"Something went wrong while restoring checkpoint. \"\n",
    "          \"We will terminate training to avoid accidentally overwriting \"\n",
    "          \"the previous model.\")\n",
    "    raise\n",
    "\n",
    "    \n",
    "    \n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "reader.start_threads(sess)\n",
    "\n",
    "\n",
    "step = None\n",
    "last_saved_step = saved_global_step\n",
    "minvalloss = 10000\n",
    "try:\n",
    "    for step in range(saved_global_step + 1, args.num_steps):\n",
    "        start_time = time.time()\n",
    "        if args.store_metadata and step % 50 == 0:\n",
    "            # Slow run that stores extra information for debugging.\n",
    "            print('Storing metadata')\n",
    "            run_options = tf.RunOptions(\n",
    "                trace_level=tf.RunOptions.FULL_TRACE)\n",
    "            summary, trloss_value, _ = sess.run(\n",
    "                [summaries, trloss, optim],\n",
    "                options=run_options,\n",
    "                run_metadata=run_metadata)\n",
    "            writer.add_summary(summary, step)\n",
    "            writer.add_run_metadata(run_metadata,\n",
    "                                    'step_{:04d}'.format(step))\n",
    "            tl = timeline.Timeline(run_metadata.step_stats)\n",
    "            timeline_path = os.path.join(logdir, 'timeline.trace')\n",
    "            with open(timeline_path, 'w') as f:\n",
    "                f.write(tl.generate_chrome_trace_format(show_memory=True))\n",
    "        else:\n",
    "            summary, trloss_value, _ = sess.run([summaries, trloss, optim])\n",
    "            writer.add_summary(summary, step)\n",
    "        duration = time.time() - start_time\n",
    "        print('step {:d} - trloss = {:.3f}, ({:.3f} sec/step)'\n",
    "              .format(step, trloss_value, duration))\n",
    "        \n",
    "        \n",
    "        if step % args.checkpoint_every == 0:\n",
    "            ans = sess.run(genfile)\n",
    "            #print(ans.shape)\n",
    "            sf.write('./vsCorpus/ans/'+str(step)+'.wav',ans.reshape(-1),16000)\n",
    "            print('stored done')\n",
    "            valloss_value = sess.run(valloss)\n",
    "            print('validateLoss = {:.3f}, ({:.3f} sec/step)'\n",
    "              .format(valloss_value, duration))\n",
    "            #if(valloss_value < minvalloss):\n",
    "                #save(saver, sess, logdir, step)\n",
    "                #last_saved_step = step\n",
    "                #minvalloss = valloss_value\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Introduce a line break after ^C is displayed so save message\n",
    "    # is on its own line.\n",
    "    print()\n",
    "finally:\n",
    "    if step > last_saved_step:\n",
    "        save(saver, sess, logdir, step)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-05T07:53:29.066Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = bytes(\"<stripped %d bytes>\"%max_const_size, 'utf-8')\n",
    "                \n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-05T07:53:29.068Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
