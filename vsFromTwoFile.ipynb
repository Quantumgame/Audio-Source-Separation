{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:08.078963Z",
     "start_time": "2018-06-09T17:45:08.065924Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:08.248785Z",
     "start_time": "2018-06-09T17:45:08.229297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2555"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize = 50000\n",
    "sample_rate = 16000\n",
    "quantization_channels = 256\n",
    "# dilations=[2**i for i in range(8)]*20\n",
    "# \"residualDim=32\n",
    "dilations = [2 ** i for i in range(9)] * 5\n",
    "residualDim = 32\n",
    "skipDim = 512\n",
    "filterSize = 3\n",
    "initfilter=3\n",
    "pad = np.sum(dilations)\n",
    "shapeoftest = 190500\n",
    "lossrecord = []\n",
    "resumefile='classifyregress'\n",
    "continueTrain=True\n",
    "receptive_field = (sum(dilations) + 1)\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:08.382512Z",
     "start_time": "2018-06-09T17:45:08.379462Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:08.561846Z",
     "start_time": "2018-06-09T17:45:08.545842Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device = 'cpu'\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:08.731116Z",
     "start_time": "2018-06-09T17:45:08.691026Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_law_encode(audio, quantization_channels=quantization_channels,forX=False):\n",
    "    '''Quantizes waveform amplitudes.'''\n",
    "    mu = (quantization_channels - 1)*1.0\n",
    "    # Perform mu-law companding transformation (ITU-T, 1988).\n",
    "    # Minimum operation is here to deal with rare large amplitudes caused\n",
    "    # by resampling.\n",
    "    safe_audio_abs = np.minimum(np.abs(audio), 1.0)\n",
    "    magnitude = np.log1p(mu * safe_audio_abs) / np.log1p(mu)\n",
    "    signal = np.sign(audio) * magnitude\n",
    "    # Quantize signal to the specified number of levels.\n",
    "    if(forX):return signal\n",
    "    return ((signal + 1) / 2 * mu + 0.5).astype(int)\n",
    "def mu_law_decode(output, quantization_channels=quantization_channels):\n",
    "    '''Recovers waveform from quantized values.'''\n",
    "    mu = quantization_channels - 1\n",
    "    # Map values back to [-1, 1].\n",
    "    signal = 2 * ((output*1.0) / mu) - 1\n",
    "    # Perform inverse of mu-law transformation.\n",
    "    magnitude = (1 / mu) * ((1 + mu)**np.abs(signal) - 1)\n",
    "    return np.sign(signal) * magnitude\n",
    "def cateToSignal(output, quantization_channels=quantization_channels):\n",
    "    mu = quantization_channels - 1\n",
    "    # Map values back to [-1, 1].\n",
    "    signal = 2 * ((output*1.0) / mu) - 1\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:25.599579Z",
     "start_time": "2018-06-09T17:45:08.865160Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readAudio(name):\n",
    "    audio0, samplerate = sf.read(name, dtype='float32')\n",
    "    return librosa.resample(audio0.T, samplerate, sample_rate).reshape(-1)\n",
    "p=['./vsCorpus/origin_mix.wav','./vsCorpus/origin_vocal.wav',\n",
    "   './vsCorpus/origin_mix.wav','./vsCorpus/origin_vocal.wav','./vsCorpus/pred_mix.wav']\n",
    "xtrain,ytrain,xval,yval,xtest=readAudio(p[0]),readAudio(p[1]),readAudio(p[2]),readAudio(p[3]),readAudio(p[4])\n",
    "assert((xtrain==xval).all())\n",
    "assert((ytrain==yval).all())\n",
    "assert((xtrain != ytrain).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.129274Z",
     "start_time": "2018-06-09T17:45:25.601225Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain,yval=mu_law_encode(ytrain),mu_law_encode(yval)\n",
    "xytrain,xyval=mu_law_encode(ytrain,forX=True),mu_law_encode(yval,forX=True)\n",
    "xtrain,xval,xtest=mu_law_encode(xtrain,forX=True),mu_law_encode(xval,forX=True),mu_law_encode(xtest,forX=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.152376Z",
     "start_time": "2018-06-09T17:45:26.130980Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmean,xstd = xtrain.mean(),xtrain.std()\n",
    "xtrain=(xtrain-xmean)/xstd\n",
    "xval=(xval-xmean)/xstd\n",
    "xtest=(xtest-xmean)/xstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.270021Z",
     "start_time": "2018-06-09T17:45:26.154161Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain=np.pad(xtrain, (receptive_field, receptive_field), 'constant')\n",
    "xval=np.pad(xval, (receptive_field, receptive_field), 'constant')\n",
    "xtest=np.pad(xtest, (receptive_field, receptive_field), 'constant')\n",
    "yval=np.pad(yval, (receptive_field, receptive_field), 'constant')\n",
    "ytrain=np.pad(ytrain, (receptive_field, receptive_field), 'constant')\n",
    "xyval=np.pad(xyval, (receptive_field, receptive_field), 'constant')\n",
    "xytrain=np.pad(xytrain, (receptive_field, receptive_field), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.276428Z",
     "start_time": "2018-06-09T17:45:26.271770Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,xval,xtest=xtrain.reshape(1,1,-1),xval.reshape(1,1,-1),xtest.reshape(1,1,-1)\n",
    "ytrain,yval=ytrain.reshape(1,-1),yval.reshape(1,-1)\n",
    "xytrain,xyval=ytrain.reshape(1,1,-1),yval.reshape(1,1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.280648Z",
     "start_time": "2018-06-09T17:45:26.277887Z"
    }
   },
   "outputs": [],
   "source": [
    "#xtrain = np.concatenate((xtrain,xytrain.reshape(xtrain.shape)),axis=1)\n",
    "#xval = np.concatenate((xval,xyval.reshape(xval.shape)),axis=1)\n",
    "#xtest = np.concatenate((xtest,np.zeros_like(xtest)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.298245Z",
     "start_time": "2018-06-09T17:45:26.282230Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,ytrain,xval,yval,xtest = torch.from_numpy(xtrain).type(torch.float32),\\\n",
    "                                torch.from_numpy(ytrain).type(torch.LongTensor),\\\n",
    "                                torch.from_numpy(xval).type(torch.float32),\\\n",
    "                                torch.from_numpy(yval).type(torch.LongTensor),\\\n",
    "                                torch.from_numpy(xtest).type(torch.float32)\n",
    "xytrain,xyval=torch.from_numpy(xytrain).type(torch.float32),torch.from_numpy(xyval).type(torch.float32),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.548273Z",
     "start_time": "2018-06-09T17:45:26.300244Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        sd,qd,rd = skipDim,quantization_channels,residualDim\n",
    "        self.xcausal = nn.Conv1d(in_channels=1,out_channels=rd,kernel_size=initfilter,padding=1)\n",
    "        self.ycausal = nn.Conv1d(in_channels=1,out_channels=rd,kernel_size=initfilter,padding=1)\n",
    "        self.ly=dict()\n",
    "        self.lx=dict()\n",
    "        for i, d in enumerate(dilations):\n",
    "            self.lx['tanh'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=3,dilation=d)\n",
    "            self.lx['sigmoid'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=3,dilation=d)\n",
    "            self.lx['skip'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=sd,kernel_size=1)\n",
    "            self.lx['dense'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=1)\n",
    "            \n",
    "            self.ly['tanh'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=2,dilation=d)\n",
    "            self.ly['sigmoid'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=2,dilation=d)\n",
    "            self.ly['skip'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=sd,kernel_size=1)\n",
    "            self.ly['dense'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=1)\n",
    "        self.post1 = nn.Conv1d(in_channels=sd,out_channels=sd,kernel_size=1,padding=0)\n",
    "        self.post2 = nn.Conv1d(in_channels=sd,out_channels=qd,kernel_size=1,padding=0)\n",
    "        self.tanh,self.sigmoid = nn.Tanh(),nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        finallen = x.shape[-1]-2*receptive_field\n",
    "        x = self.xcausal(x)\n",
    "        y = self.ycausal(y)\n",
    "        skipx = torch.zeros([1,skipDim,finallen],dtype=torch.float32,device=device)\n",
    "        skipy = torch.zeros([1,skipDim,finallen],dtype=torch.float32,device=device)\n",
    "        accumulate=1\n",
    "        for i, dilation in enumerate(dilations):\n",
    "            accumulate+=dilations\n",
    "            yinput = y.clone()[:,:,:-dilation]\n",
    "            y1 = self.tanh(self.ly['tanh'+str(i)](y))\n",
    "            y2 = self.sigmoid(self.ly['sigmoid'+str(i)](y))\n",
    "            y=y1*y2\n",
    "            skipy += (self.ly['skip'+str(i)](y)).\\\n",
    "                narrow(2,int(receptive_field-accumulate),int(finallen))\n",
    "            \n",
    "            xinput = x.clone()[:,:,dilation:-dilation]\n",
    "            x1 = self.tanh(self.lx['tanh'+str(i)](x))\n",
    "            x2 = self.sigmoid(self.lx['sigmoid'+str(i)](x))\n",
    "            x = x1*x2\n",
    "            cutlen = (x.shape[-1] - finallen)//2\n",
    "            skipx += (self.lx['skip'+str(i)](x)).narrow(2,int(cutlen),int(finallen))\n",
    "            x = self.lx['dense'+str(i)](x)\n",
    "            x += xinput\n",
    "        x = self.post2(F.relu(self.post1(F.relu(torch.cat((skipx,skipy), dim=1)))))\n",
    "        return x\n",
    "\n",
    "model = Net().cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-5)*\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.9, weight_decay=1e-5)\n",
    "#scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.558739Z",
     "start_time": "2018-06-09T17:45:26.549958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'classifyregress'\n"
     ]
    }
   ],
   "source": [
    "if continueTrain:\n",
    "    if os.path.isfile(resumefile):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resumefile))\n",
    "        checkpoint = torch.load(resumefile)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        #best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        #optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(resumefile, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resumefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.695925Z",
     "start_time": "2018-06-09T17:45:26.560381Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def val():\n",
    "    model.eval()\n",
    "    startval_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        # data, target = xval.to(device), yval.to(device)\n",
    "        data, target = xtrain[:, :, 0:2 * receptive_field + shapeoftest].to(device),\\\n",
    "            ytrain[:, receptive_field:shapeoftest + receptive_field].to(device)\n",
    "        output = model(data)\n",
    "        # print(output.shape)\n",
    "        # print(output[:,:,:10])\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item() / pred.shape[-1]\n",
    "        val_loss = criterion(output, target).item()\n",
    "    print(correct, 'accurate')\n",
    "    print('\\nval set:loss{:.4f}:, ({:.3f} sec/step)\\n'.format(val_loss, time.time() - startval_time))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    startval_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = model(xtest.to(device))\n",
    "        pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "        ans = mu_law_decode(pred)\n",
    "        sf.write('./vsCorpus/resultxte.wav', ans, sample_rate)\n",
    "\n",
    "        # output = model(xtrain[:,:,:sampleSize].to(device))\n",
    "        output = model(xtrain[:, :, 0:2 * receptive_field + shapeoftest].to(device))\n",
    "        pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "        ans = mu_law_decode(pred)\n",
    "        sf.write('./vsCorpus/resultxtr.wav', ans, sample_rate)\n",
    "        print('stored done\\n')\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    # idx = np.arange(xtrain.shape[-1] - 2 * sampleSize,1000)\n",
    "    # 176000\n",
    "    idx = np.arange(receptive_field, xtrain.shape[-1] - receptive_field - sampleSize - 1, 16000)\n",
    "    np.random.shuffle(idx)\n",
    "    for i, ind in enumerate(idx):\n",
    "        start_time = time.time()\n",
    "        datax = xtrain[:,:,ind - receptive_field:ind + sampleSize + receptive_field].to(device)\n",
    "        datay = xytrain[:,:,ind - receptive_field:ind + sampleSize + receptive_field].to(device)\n",
    "        target = ytrain[:,ind:ind + sampleSize].to(device)\n",
    "            \n",
    "        output = model(datax,datay)\n",
    "        # print(output.shape)\n",
    "        loss = criterion(output, target)\n",
    "        lossrecord.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss:{:.6f}: , ({:.3f} sec/step)'.format(\n",
    "            epoch, i, len(idx), 100. * i / len(idx), loss.item(), time.time() - start_time))\n",
    "        if i % 100 == 0:\n",
    "            #val()\n",
    "            #test()\n",
    "            state={'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()}\n",
    "            torch.save(state, resumefile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T17:45:26.728205Z",
     "start_time": "2018-06-09T17:45:26.697643Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-1d9f599dae74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m#test()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#scheduler.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-25465976a175>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msampleSize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatax\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;31m# print(output.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-71-f716f1a27d2c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mfinallen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreceptive_field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxcausal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mycausal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mskipx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskipDim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinallen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 176\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.cuda.FloatTensor for argument #2 'weight'"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    train(epoch)\n",
    "    #test()\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-09T05:35:28.878437Z",
     "start_time": "2018-06-09T05:35:28.808957Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "#torch.save(model, 'loss3.2step24h_repeat5*2**10resu96sample50000')"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLalgorithm/mnistPyTorch.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
