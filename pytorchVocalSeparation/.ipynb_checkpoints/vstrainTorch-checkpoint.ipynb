{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:57:04.980981Z",
     "start_time": "2018-06-06T15:57:03.778096Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:57:04.989735Z",
     "start_time": "2018-06-06T15:57:04.983483Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleSize=100000\n",
    "sample_rate=16000\n",
    "quantization_channels=256\n",
    "dilations=[2**i for i in range(9)]*5\n",
    "skipDim=512\n",
    "residualDim=32\n",
    "filterSize=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:57:05.697675Z",
     "start_time": "2018-06-06T15:57:04.991193Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#device = 'cpu'\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:57:05.719740Z",
     "start_time": "2018-06-06T15:57:05.699743Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_law_encode(audio, quantization_channels=quantization_channels):\n",
    "    '''Quantizes waveform amplitudes.'''\n",
    "    mu = (quantization_channels - 1)*1.0\n",
    "    # Perform mu-law companding transformation (ITU-T, 1988).\n",
    "    # Minimum operation is here to deal with rare large amplitudes caused\n",
    "    # by resampling.\n",
    "    safe_audio_abs = np.minimum(np.abs(audio), 1.0)\n",
    "    magnitude = np.log1p(mu * safe_audio_abs) / np.log1p(mu)\n",
    "    signal = np.sign(audio) * magnitude\n",
    "    # Quantize signal to the specified number of levels.\n",
    "    #if(forX):return signal\n",
    "    return ((signal + 1) / 2 * mu + 0.5).astype(int)\n",
    "def mu_law_decode(output, quantization_channels=quantization_channels):\n",
    "    '''Recovers waveform from quantized values.'''\n",
    "    mu = quantization_channels - 1\n",
    "    # Map values back to [-1, 1].\n",
    "    signal = 2 * ((output*1.0) / mu) - 1\n",
    "    # Perform inverse of mu-law transformation.\n",
    "    magnitude = (1 / mu) * ((1 + mu)**np.abs(signal) - 1)\n",
    "    return np.sign(signal) * magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:57:22.624195Z",
     "start_time": "2018-06-06T15:57:05.721605Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readAudio(name):\n",
    "    audio0, samplerate = sf.read(name, dtype='float32')\n",
    "    return librosa.resample(audio0.T, samplerate, sample_rate).reshape(-1)\n",
    "p=['../vsCorpus/origin_mix.wav','../vsCorpus/origin_mix.wav',\n",
    "   '../vsCorpus/origin_mix.wav','../vsCorpus/origin_mix.wav','../vsCorpus/pred_mix.wav']\n",
    "xtrain,ytrain,xval,yval,xtest=readAudio(p[0]),readAudio(p[1]),readAudio(p[2]),readAudio(p[3]),readAudio(p[4])\n",
    "xtrain,ytrain,xval,yval=xtrain[:-sampleSize],ytrain[:-sampleSize],xval[-sampleSize:],yval[-sampleSize:]\n",
    "xtrain,xval,xtest=xtrain.reshape(1,1,-1),xval.reshape(1,1,-1),xtest.reshape(1,1,-1)\n",
    "ytrain,yval=ytrain.reshape(1,-1),yval.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:57:22.785835Z",
     "start_time": "2018-06-06T15:57:22.626620Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain=(xtrain-xtrain.mean())/xtrain.std()\n",
    "xval=(xval-xtrain.mean())/xtrain.std()\n",
    "xtest=(xtest-xtrain.mean())/xtrain.std()\n",
    "ytrain,yval=mu_law_encode(ytrain),mu_law_encode(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:57:22.792145Z",
     "start_time": "2018-06-06T15:57:22.787682Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,ytrain,xval,yval,xtest = torch.from_numpy(xtrain).type(torch.float32),\\\n",
    "                                torch.from_numpy(ytrain).type(torch.LongTensor),\\\n",
    "                                torch.from_numpy(xval).type(torch.float32),\\\n",
    "                                torch.from_numpy(yval).type(torch.LongTensor),\\\n",
    "                                torch.from_numpy(xtest).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T15:57:27.124870Z",
     "start_time": "2018-06-06T15:57:22.793798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        sd,qd,rd = skipDim,quantization_channels,residualDim\n",
    "        self.causal = nn.Conv1d(in_channels=1,out_channels=rd,kernel_size=3,padding=1)\n",
    "        self.dilated=dict()\n",
    "        for i, d in enumerate(dilations):\n",
    "            self.dilated['tanh'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=3,padding=d,dilation=d)\n",
    "            self.dilated['sigmoid'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=3,padding=d,dilation=d)\n",
    "            self.dilated['skip'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=sd,kernel_size=1,padding=0)\n",
    "            self.dilated['dense'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=1,padding=0)\n",
    "        self.post1 = nn.Conv1d(in_channels=sd,out_channels=sd,kernel_size=1,padding=0)\n",
    "        self.post2 = nn.Conv1d(in_channels=sd,out_channels=qd,kernel_size=1,padding=0)\n",
    "        self.tanh,self.sigmoid = nn.Tanh(),nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.causal(x)\n",
    "        skip_connections = torch.zeros([1,skipDim,x.shape[2]], dtype=torch.float32)\n",
    "        for i, dilation in enumerate(dilations):\n",
    "            xinput=x.clone()\n",
    "            #print(x.shape)\n",
    "            x1 = self.tanh(self.dilated['tanh'+str(i)](x))\n",
    "            x2 = self.sigmoid(self.dilated['sigmoid'+str(i)](x))\n",
    "            x = x1*x2\n",
    "            skip_connections += self.dilated['skip'+str(i)](x).clone()\n",
    "            x = self.dilated['dense'+str(i)](x)\n",
    "            x += xinput.clone()\n",
    "        x = F.relu(x)\n",
    "        x = self.post2(F.relu(self.post1(skip_connections)))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer = optim.Adam(model.parameters(),weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:29:06.479063Z",
     "start_time": "2018-06-06T16:29:06.419621Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def val():\n",
    "    model.eval()\n",
    "    startval_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        data, target = xval.to(device), yval.to(device)\n",
    "        output = model(data)\n",
    "        val_loss = F.nll_loss(output, target).item()\n",
    "    print('\\nval set:  {:.4f}, ({:.3f} sec/step)\\n'.format(val_loss,time.time()-startval_time))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    startval_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        #output = model(xtest.to(device))\n",
    "        output = model(xtrain[:,:,:sampleSize].to(device).to(device))\n",
    "        pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "        ans = mu_law_decode(pred)\n",
    "        sf.write('../vsCorpus/ans/result.wav', ans, sample_rate)\n",
    "        print('stored done\\n')\n",
    "    \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    idx = np.arange(xtrain.shape[-1] - 2*sampleSize)\n",
    "    np.random.shuffle(idx)\n",
    "    for i, ind in enumerate(idx):\n",
    "        start_time = time.time()\n",
    "        data, target = xtrain[:,:,ind:ind+sampleSize].to(device), ytrain[:,ind:ind+sampleSize].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f} , ({:.3f} sec/step)'.format(\n",
    "                epoch, i, len(idx),100. * i / len(idx), loss.item(),time.time() - start_time))\n",
    "        if i % 100 == 0:\n",
    "            val()\n",
    "            test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-06T16:29:06.814Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3471161 (0%)] Loss: 1.494972 , (1.219 sec/step)\n",
      "\n",
      "val set:  60.3992, (0.523 sec/step)\n",
      "\n",
      "stored done\n",
      "\n",
      "Train Epoch: 0 [1/3471161 (0%)] Loss: 1.557807 , (1.219 sec/step)\n",
      "Train Epoch: 0 [2/3471161 (0%)] Loss: 1.523415 , (1.218 sec/step)\n",
      "Train Epoch: 0 [3/3471161 (0%)] Loss: 1.562079 , (1.219 sec/step)\n",
      "Train Epoch: 0 [4/3471161 (0%)] Loss: 1.401049 , (1.217 sec/step)\n",
      "Train Epoch: 0 [5/3471161 (0%)] Loss: 1.504515 , (1.218 sec/step)\n",
      "Train Epoch: 0 [6/3471161 (0%)] Loss: 1.495328 , (1.217 sec/step)\n",
      "Train Epoch: 0 [7/3471161 (0%)] Loss: 1.576459 , (1.219 sec/step)\n",
      "Train Epoch: 0 [8/3471161 (0%)] Loss: 1.529001 , (1.219 sec/step)\n",
      "Train Epoch: 0 [9/3471161 (0%)] Loss: 1.564052 , (1.218 sec/step)\n",
      "Train Epoch: 0 [10/3471161 (0%)] Loss: 1.425454 , (1.220 sec/step)\n",
      "Train Epoch: 0 [11/3471161 (0%)] Loss: 1.426787 , (1.218 sec/step)\n",
      "Train Epoch: 0 [12/3471161 (0%)] Loss: 1.451862 , (1.218 sec/step)\n",
      "Train Epoch: 0 [13/3471161 (0%)] Loss: 1.504987 , (1.219 sec/step)\n",
      "Train Epoch: 0 [14/3471161 (0%)] Loss: 1.471897 , (1.218 sec/step)\n",
      "Train Epoch: 0 [15/3471161 (0%)] Loss: 1.421918 , (1.219 sec/step)\n",
      "Train Epoch: 0 [16/3471161 (0%)] Loss: 1.525315 , (1.218 sec/step)\n",
      "Train Epoch: 0 [17/3471161 (0%)] Loss: 1.557677 , (1.218 sec/step)\n",
      "Train Epoch: 0 [18/3471161 (0%)] Loss: 1.401667 , (1.219 sec/step)\n",
      "Train Epoch: 0 [19/3471161 (0%)] Loss: 1.513606 , (1.219 sec/step)\n",
      "Train Epoch: 0 [20/3471161 (0%)] Loss: 1.420182 , (1.218 sec/step)\n",
      "Train Epoch: 0 [21/3471161 (0%)] Loss: 1.460142 , (1.220 sec/step)\n",
      "Train Epoch: 0 [22/3471161 (0%)] Loss: 1.505682 , (1.219 sec/step)\n",
      "Train Epoch: 0 [23/3471161 (0%)] Loss: 1.527390 , (1.218 sec/step)\n",
      "Train Epoch: 0 [24/3471161 (0%)] Loss: 1.424209 , (1.218 sec/step)\n",
      "Train Epoch: 0 [25/3471161 (0%)] Loss: 1.485830 , (1.217 sec/step)\n",
      "Train Epoch: 0 [26/3471161 (0%)] Loss: 1.544935 , (1.218 sec/step)\n",
      "Train Epoch: 0 [27/3471161 (0%)] Loss: 1.424974 , (1.218 sec/step)\n",
      "Train Epoch: 0 [28/3471161 (0%)] Loss: 1.512336 , (1.218 sec/step)\n",
      "Train Epoch: 0 [29/3471161 (0%)] Loss: 1.512840 , (1.217 sec/step)\n",
      "Train Epoch: 0 [30/3471161 (0%)] Loss: 1.425333 , (1.217 sec/step)\n",
      "Train Epoch: 0 [31/3471161 (0%)] Loss: 1.413372 , (1.217 sec/step)\n",
      "Train Epoch: 0 [32/3471161 (0%)] Loss: 1.495775 , (1.217 sec/step)\n",
      "Train Epoch: 0 [33/3471161 (0%)] Loss: 1.550584 , (1.218 sec/step)\n",
      "Train Epoch: 0 [34/3471161 (0%)] Loss: 1.504672 , (1.218 sec/step)\n",
      "Train Epoch: 0 [35/3471161 (0%)] Loss: 1.445337 , (1.219 sec/step)\n",
      "Train Epoch: 0 [36/3471161 (0%)] Loss: 1.511792 , (1.218 sec/step)\n",
      "Train Epoch: 0 [37/3471161 (0%)] Loss: 1.475492 , (1.217 sec/step)\n",
      "Train Epoch: 0 [38/3471161 (0%)] Loss: 1.454767 , (1.218 sec/step)\n",
      "Train Epoch: 0 [39/3471161 (0%)] Loss: 1.483520 , (1.218 sec/step)\n",
      "Train Epoch: 0 [40/3471161 (0%)] Loss: 1.484062 , (1.217 sec/step)\n",
      "Train Epoch: 0 [41/3471161 (0%)] Loss: 1.484592 , (1.218 sec/step)\n",
      "Train Epoch: 0 [42/3471161 (0%)] Loss: 1.542382 , (1.218 sec/step)\n",
      "Train Epoch: 0 [43/3471161 (0%)] Loss: 1.488184 , (1.218 sec/step)\n",
      "Train Epoch: 0 [44/3471161 (0%)] Loss: 1.500895 , (1.218 sec/step)\n",
      "Train Epoch: 0 [45/3471161 (0%)] Loss: 1.493700 , (1.217 sec/step)\n",
      "Train Epoch: 0 [46/3471161 (0%)] Loss: 1.412792 , (1.217 sec/step)\n",
      "Train Epoch: 0 [47/3471161 (0%)] Loss: 1.485679 , (1.218 sec/step)\n",
      "Train Epoch: 0 [48/3471161 (0%)] Loss: 1.531199 , (1.218 sec/step)\n",
      "Train Epoch: 0 [49/3471161 (0%)] Loss: 1.551270 , (1.219 sec/step)\n",
      "Train Epoch: 0 [50/3471161 (0%)] Loss: 1.442269 , (1.218 sec/step)\n",
      "Train Epoch: 0 [51/3471161 (0%)] Loss: 1.519138 , (1.219 sec/step)\n",
      "Train Epoch: 0 [52/3471161 (0%)] Loss: 1.528140 , (1.218 sec/step)\n",
      "Train Epoch: 0 [53/3471161 (0%)] Loss: 1.402610 , (1.218 sec/step)\n",
      "Train Epoch: 0 [54/3471161 (0%)] Loss: 1.522495 , (1.218 sec/step)\n",
      "Train Epoch: 0 [55/3471161 (0%)] Loss: 1.489079 , (1.218 sec/step)\n",
      "Train Epoch: 0 [56/3471161 (0%)] Loss: 1.521626 , (1.218 sec/step)\n",
      "Train Epoch: 0 [57/3471161 (0%)] Loss: 1.490839 , (1.218 sec/step)\n",
      "Train Epoch: 0 [58/3471161 (0%)] Loss: 1.497568 , (1.218 sec/step)\n",
      "Train Epoch: 0 [59/3471161 (0%)] Loss: 1.421155 , (1.218 sec/step)\n",
      "Train Epoch: 0 [60/3471161 (0%)] Loss: 1.505039 , (1.218 sec/step)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLalgorithm/mnistPyTorch.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
