{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:30:44.786369Z",
     "start_time": "2018-06-06T16:30:43.723935Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:30:44.794201Z",
     "start_time": "2018-06-06T16:30:44.788330Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleSize=100000\n",
    "sample_rate=16000\n",
    "quantization_channels=256\n",
    "dilations=[2**i for i in range(9)]*5\n",
    "skipDim=512\n",
    "residualDim=32\n",
    "filterSize=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:30:45.753863Z",
     "start_time": "2018-06-06T16:30:44.795999Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#device = 'cpu'\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:30:45.774874Z",
     "start_time": "2018-06-06T16:30:45.756708Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_law_encode(audio, quantization_channels=quantization_channels):\n",
    "    '''Quantizes waveform amplitudes.'''\n",
    "    mu = (quantization_channels - 1)*1.0\n",
    "    # Perform mu-law companding transformation (ITU-T, 1988).\n",
    "    # Minimum operation is here to deal with rare large amplitudes caused\n",
    "    # by resampling.\n",
    "    safe_audio_abs = np.minimum(np.abs(audio), 1.0)\n",
    "    magnitude = np.log1p(mu * safe_audio_abs) / np.log1p(mu)\n",
    "    signal = np.sign(audio) * magnitude\n",
    "    # Quantize signal to the specified number of levels.\n",
    "    #if(forX):return signal\n",
    "    return ((signal + 1) / 2 * mu + 0.5).astype(int)\n",
    "def mu_law_decode(output, quantization_channels=quantization_channels):\n",
    "    '''Recovers waveform from quantized values.'''\n",
    "    mu = quantization_channels - 1\n",
    "    # Map values back to [-1, 1].\n",
    "    signal = 2 * ((output*1.0) / mu) - 1\n",
    "    # Perform inverse of mu-law transformation.\n",
    "    magnitude = (1 / mu) * ((1 + mu)**np.abs(signal) - 1)\n",
    "    return np.sign(signal) * magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:31:02.959500Z",
     "start_time": "2018-06-06T16:30:45.776600Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readAudio(name):\n",
    "    audio0, samplerate = sf.read(name, dtype='float32')\n",
    "    return librosa.resample(audio0.T, samplerate, sample_rate).reshape(-1)\n",
    "p=['../vsCorpus/origin_mix.wav','../vsCorpus/origin_mix.wav',\n",
    "   '../vsCorpus/origin_mix.wav','../vsCorpus/origin_mix.wav','../vsCorpus/pred_mix.wav']\n",
    "xtrain,ytrain,xval,yval,xtest=readAudio(p[0]),readAudio(p[1]),readAudio(p[2]),readAudio(p[3]),readAudio(p[4])\n",
    "xtrain,ytrain,xval,yval=xtrain[:-sampleSize],ytrain[:-sampleSize],xval[-sampleSize:],yval[-sampleSize:]\n",
    "xtrain,xval,xtest=xtrain.reshape(1,1,-1),xval.reshape(1,1,-1),xtest.reshape(1,1,-1)\n",
    "ytrain,yval=ytrain.reshape(1,-1),yval.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:31:03.110037Z",
     "start_time": "2018-06-06T16:31:02.961817Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain=(xtrain-xtrain.mean())/xtrain.std()\n",
    "xval=(xval-xtrain.mean())/xtrain.std()\n",
    "xtest=(xtest-xtrain.mean())/xtrain.std()\n",
    "ytrain,yval=mu_law_encode(ytrain),mu_law_encode(yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:31:03.116555Z",
     "start_time": "2018-06-06T16:31:03.111853Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,ytrain,xval,yval,xtest = torch.from_numpy(xtrain).type(torch.float32),\\\n",
    "                                torch.from_numpy(ytrain).type(torch.LongTensor),\\\n",
    "                                torch.from_numpy(xval).type(torch.float32),\\\n",
    "                                torch.from_numpy(yval).type(torch.LongTensor),\\\n",
    "                                torch.from_numpy(xtest).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-06T16:31:07.137476Z",
     "start_time": "2018-06-06T16:31:03.118790Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        sd,qd,rd = skipDim,quantization_channels,residualDim\n",
    "        self.causal = nn.Conv1d(in_channels=1,out_channels=rd,kernel_size=3,padding=1)\n",
    "        self.dilated=dict()\n",
    "        for i, d in enumerate(dilations):\n",
    "            self.dilated['tanh'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=3,padding=d,dilation=d)\n",
    "            self.dilated['sigmoid'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=3,padding=d,dilation=d)\n",
    "            self.dilated['skip'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=sd,kernel_size=1,padding=0)\n",
    "            self.dilated['dense'+str(i)] = nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=1,padding=0)\n",
    "        self.post1 = nn.Conv1d(in_channels=sd,out_channels=sd,kernel_size=1,padding=0)\n",
    "        self.post2 = nn.Conv1d(in_channels=sd,out_channels=qd,kernel_size=1,padding=0)\n",
    "        self.tanh,self.sigmoid = nn.Tanh(),nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.causal(x)\n",
    "        skip_connections = torch.zeros([1,skipDim,x.shape[2]], dtype=torch.float32)\n",
    "        for i, dilation in enumerate(dilations):\n",
    "            xinput=x.clone()\n",
    "            #print(x.shape)\n",
    "            x1 = self.tanh(self.dilated['tanh'+str(i)](x))\n",
    "            x2 = self.sigmoid(self.dilated['sigmoid'+str(i)](x))\n",
    "            x = x1*x2\n",
    "            skip_connections += self.dilated['skip'+str(i)](x).clone()\n",
    "            x = self.dilated['dense'+str(i)](x)\n",
    "            x += xinput.clone()\n",
    "        x = F.relu(x)\n",
    "        x = self.post2(F.relu(self.post1(skip_connections)))\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "model = Net().to(device)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer = optim.Adam(model.parameters(),weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:57:56.120757Z",
     "start_time": "2018-06-07T02:57:56.031503Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def val():\n",
    "    model.eval()\n",
    "    startval_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        data, target = xval.to(device), yval.to(device)\n",
    "        output = model(data)\n",
    "        val_loss = F.nll_loss(output, target).item()\n",
    "    print('\\nval set:  {:.4f}, ({:.3f} sec/step)\\n'.format(val_loss,time.time()-startval_time))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    startval_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        #output = model(xtest.to(device))\n",
    "        output = model(xtrain[:,:,:sampleSize].to(device).to(device))\n",
    "        pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "        ans = mu_law_decode(pred)\n",
    "        sf.write('../vsCorpus/ans/result.wav', ans, sample_rate)\n",
    "        print('stored done\\n')\n",
    "    \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    idx = np.arange(xtrain.shape[-1] - 2*sampleSize)\n",
    "    np.random.shuffle(idx)\n",
    "    for i, ind in enumerate(idx):\n",
    "        start_time = time.time()\n",
    "        data, target = xtrain[:,:,ind:ind+sampleSize].to(device), ytrain[:,ind:ind+sampleSize].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f} , ({:.3f} sec/step)'.format(\n",
    "                epoch, i, len(idx),100. * i / len(idx), loss.item(),time.time() - start_time))\n",
    "        if i % 100 == 0:\n",
    "            val()\n",
    "            test()\n",
    "            torch.save(model, 'torchmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-07T02:59:39.610467Z",
     "start_time": "2018-06-07T02:57:57.029665Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/3471161 (0%)] Loss: 0.780638 , (1.909 sec/step)\n",
      "\n",
      "val set:  90.5904, (0.836 sec/step)\n",
      "\n",
      "stored done\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/torch/serialization.py:193: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [1/3471161 (0%)] Loss: 0.681600 , (1.907 sec/step)\n",
      "Train Epoch: 0 [2/3471161 (0%)] Loss: 0.688992 , (1.910 sec/step)\n",
      "Train Epoch: 0 [3/3471161 (0%)] Loss: 0.751900 , (1.908 sec/step)\n",
      "Train Epoch: 0 [4/3471161 (0%)] Loss: 0.718980 , (1.910 sec/step)\n",
      "Train Epoch: 0 [5/3471161 (0%)] Loss: 0.767370 , (1.908 sec/step)\n",
      "Train Epoch: 0 [6/3471161 (0%)] Loss: 0.632362 , (1.906 sec/step)\n",
      "Train Epoch: 0 [7/3471161 (0%)] Loss: 0.727764 , (1.907 sec/step)\n",
      "Train Epoch: 0 [8/3471161 (0%)] Loss: 0.764388 , (1.908 sec/step)\n",
      "Train Epoch: 0 [9/3471161 (0%)] Loss: 0.685936 , (1.907 sec/step)\n",
      "Train Epoch: 0 [10/3471161 (0%)] Loss: 0.646965 , (1.906 sec/step)\n",
      "Train Epoch: 0 [11/3471161 (0%)] Loss: 0.635891 , (1.907 sec/step)\n",
      "Train Epoch: 0 [12/3471161 (0%)] Loss: 0.730553 , (1.907 sec/step)\n",
      "Train Epoch: 0 [13/3471161 (0%)] Loss: 0.736452 , (1.908 sec/step)\n",
      "Train Epoch: 0 [14/3471161 (0%)] Loss: 0.743291 , (1.907 sec/step)\n",
      "Train Epoch: 0 [15/3471161 (0%)] Loss: 0.752918 , (1.906 sec/step)\n",
      "Train Epoch: 0 [16/3471161 (0%)] Loss: 0.752264 , (1.908 sec/step)\n",
      "Train Epoch: 0 [17/3471161 (0%)] Loss: 0.730969 , (1.907 sec/step)\n",
      "Train Epoch: 0 [18/3471161 (0%)] Loss: 0.725600 , (1.906 sec/step)\n",
      "Train Epoch: 0 [19/3471161 (0%)] Loss: 0.732956 , (1.906 sec/step)\n",
      "Train Epoch: 0 [20/3471161 (0%)] Loss: 0.699508 , (1.907 sec/step)\n",
      "Train Epoch: 0 [21/3471161 (0%)] Loss: 0.735201 , (1.907 sec/step)\n",
      "Train Epoch: 0 [22/3471161 (0%)] Loss: 0.632950 , (1.908 sec/step)\n",
      "Train Epoch: 0 [23/3471161 (0%)] Loss: 0.725495 , (1.908 sec/step)\n",
      "Train Epoch: 0 [24/3471161 (0%)] Loss: 0.760561 , (1.908 sec/step)\n",
      "Train Epoch: 0 [25/3471161 (0%)] Loss: 0.709703 , (1.907 sec/step)\n",
      "Train Epoch: 0 [26/3471161 (0%)] Loss: 0.688796 , (1.905 sec/step)\n",
      "Train Epoch: 0 [27/3471161 (0%)] Loss: 0.755916 , (1.907 sec/step)\n",
      "Train Epoch: 0 [28/3471161 (0%)] Loss: 0.620545 , (1.907 sec/step)\n",
      "Train Epoch: 0 [29/3471161 (0%)] Loss: 0.724986 , (1.909 sec/step)\n",
      "Train Epoch: 0 [30/3471161 (0%)] Loss: 0.741378 , (1.907 sec/step)\n",
      "Train Epoch: 0 [31/3471161 (0%)] Loss: 0.629133 , (1.906 sec/step)\n",
      "Train Epoch: 0 [32/3471161 (0%)] Loss: 0.746224 , (1.908 sec/step)\n",
      "Train Epoch: 0 [33/3471161 (0%)] Loss: 0.793472 , (1.908 sec/step)\n",
      "Train Epoch: 0 [34/3471161 (0%)] Loss: 0.609353 , (1.907 sec/step)\n",
      "Train Epoch: 0 [35/3471161 (0%)] Loss: 0.687822 , (1.907 sec/step)\n",
      "Train Epoch: 0 [36/3471161 (0%)] Loss: 0.756897 , (1.907 sec/step)\n",
      "Train Epoch: 0 [37/3471161 (0%)] Loss: 0.726480 , (1.907 sec/step)\n",
      "Train Epoch: 0 [38/3471161 (0%)] Loss: 0.731303 , (1.908 sec/step)\n",
      "Train Epoch: 0 [39/3471161 (0%)] Loss: 0.624242 , (1.907 sec/step)\n",
      "Train Epoch: 0 [40/3471161 (0%)] Loss: 0.669283 , (1.905 sec/step)\n",
      "Train Epoch: 0 [41/3471161 (0%)] Loss: 0.777713 , (1.856 sec/step)\n",
      "Train Epoch: 0 [42/3471161 (0%)] Loss: 0.761500 , (1.920 sec/step)\n",
      "Train Epoch: 0 [43/3471161 (0%)] Loss: 0.712450 , (1.916 sec/step)\n",
      "Train Epoch: 0 [44/3471161 (0%)] Loss: 0.732633 , (1.915 sec/step)\n",
      "Train Epoch: 0 [45/3471161 (0%)] Loss: 0.749353 , (1.914 sec/step)\n",
      "Train Epoch: 0 [46/3471161 (0%)] Loss: 0.760050 , (1.912 sec/step)\n",
      "Train Epoch: 0 [47/3471161 (0%)] Loss: 0.770042 , (1.912 sec/step)\n",
      "Train Epoch: 0 [48/3471161 (0%)] Loss: 0.762680 , (1.909 sec/step)\n",
      "Train Epoch: 0 [49/3471161 (0%)] Loss: 0.731361 , (1.908 sec/step)\n",
      "Train Epoch: 0 [50/3471161 (0%)] Loss: 0.736842 , (1.910 sec/step)\n",
      "Train Epoch: 0 [51/3471161 (0%)] Loss: 0.734378 , (1.911 sec/step)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5c88ff7181bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-538095319377>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.6f} , ({:.3f} sec/step)'.format(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = torch.load('torchmodel')"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLalgorithm/mnistPyTorch.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
