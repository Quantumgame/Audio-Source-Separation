{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T07:19:08.318209Z",
     "start_time": "2018-06-02T07:19:08.313809Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.pad(np.array([[1,2,3,4]]).reshape(-1,1), [[5, 0], [0, 0]],'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T07:19:08.337621Z",
     "start_time": "2018-06-02T07:19:08.320424Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import librosa\\nimport numpy as np\\nenergy = librosa.feature.rmse(np.array([1,0,0,4],dtype=float), frame_length=2,hop_length=1,center=True)\\nprint(energy)\\nframes = np.nonzero(energy > 0)\\nprint(librosa.core.frames_to_samples(frames,hop_length=1))\\nindices = librosa.core.frames_to_samples(frames,hop_length=1)[1]'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import librosa\n",
    "import numpy as np\n",
    "energy = librosa.feature.rmse(np.array([1,0,0,4],dtype=float), frame_length=2,hop_length=1,center=True)\n",
    "print(energy)\n",
    "frames = np.nonzero(energy > 0)\n",
    "print(librosa.core.frames_to_samples(frames,hop_length=1))\n",
    "indices = librosa.core.frames_to_samples(frames,hop_length=1)[1]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T07:19:08.344220Z",
     "start_time": "2018-06-02T07:19:08.339833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import re\\nFILE_PATTERN = r'p([0-9]+)_([0-9]+)\\\\.wav'\\nid_reg_exp = re.compile(FILE_PATTERN)\\nids = id_reg_exp.findall('./VCTK-Corpus/wav48/p257/p257_390.wav')\\nprint(ids[0][0])\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import re\n",
    "FILE_PATTERN = r'p([0-9]+)_([0-9]+)\\.wav'\n",
    "id_reg_exp = re.compile(FILE_PATTERN)\n",
    "ids = id_reg_exp.findall('./VCTK-Corpus/wav48/p257/p257_390.wav')\n",
    "print(ids[0][0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T07:19:10.080891Z",
     "start_time": "2018-06-02T07:19:08.346342Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Training script for the WaveNet network on the VCTK corpus.\n",
    "\n",
    "This script trains a network with the WaveNet using data from the VCTK corpus,\n",
    "which can be freely downloaded at the following site (~10 GB):\n",
    "http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "from wavenet import WaveNetModel, AudioReader, optimizer_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T07:19:10.093639Z",
     "start_time": "2018-06-02T07:19:10.082973Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DATA_DIRECTORY = './VCTK-Corpus'\n",
    "LOGDIR_ROOT = './logdir'\n",
    "CHECKPOINT_EVERY = 50\n",
    "NUM_STEPS = int(1e5)\n",
    "LEARNING_RATE = 1e-3\n",
    "WAVENET_PARAMS = './wavenet_params.json'\n",
    "STARTED_DATESTRING = \"{0:%Y-%m-%dT%H-%M-%S}\".format(datetime.now())\n",
    "SAMPLE_SIZE = 100000\n",
    "L2_REGULARIZATION_STRENGTH = 0\n",
    "#SILENCE_THRESHOLD = 0.3\n",
    "SILENCE_THRESHOLD = 0\n",
    "EPSILON = 0.001\n",
    "MOMENTUM = 0.9\n",
    "MAX_TO_KEEP = 5\n",
    "METADATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T07:19:10.155510Z",
     "start_time": "2018-06-02T07:19:10.095260Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    def _str_to_bool(s):\n",
    "        \"\"\"Convert string to bool (in argparse context).\"\"\"\n",
    "        if s.lower() not in ['true', 'false']:\n",
    "            raise ValueError('Argument needs to be a '\n",
    "                             'boolean, got {}'.format(s))\n",
    "        return {'true': True, 'false': False}[s.lower()]\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='WaveNet example network')\n",
    "    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE,\n",
    "                        help='How many wav files to process at once. Default: ' + str(BATCH_SIZE) + '.')\n",
    "    parser.add_argument('--data_dir', type=str, default=DATA_DIRECTORY,\n",
    "                        help='The directory containing the VCTK corpus.')\n",
    "    parser.add_argument('--store_metadata', type=bool, default=METADATA,\n",
    "                        help='Whether to store advanced debugging information '\n",
    "                        '(execution time, memory consumption) for use with '\n",
    "                        'TensorBoard. Default: ' + str(METADATA) + '.')\n",
    "    parser.add_argument('--logdir', type=str, default=None,\n",
    "                        help='Directory in which to store the logging '\n",
    "                        'information for TensorBoard. '\n",
    "                        'If the model already exists, it will restore '\n",
    "                        'the state and will continue training. '\n",
    "                        'Cannot use with --logdir_root and --restore_from.')\n",
    "    parser.add_argument('--logdir_root', type=str, default=None,\n",
    "                        help='Root directory to place the logging '\n",
    "                        'output and generated model. These are stored '\n",
    "                        'under the dated subdirectory of --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--restore_from', type=str, default=None,\n",
    "                        help='Directory in which to restore the model from. '\n",
    "                        'This creates the new model under the dated directory '\n",
    "                        'in --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--checkpoint_every', type=int,\n",
    "                        default=CHECKPOINT_EVERY,\n",
    "                        help='How many steps to save each checkpoint after. Default: ' + str(CHECKPOINT_EVERY) + '.')\n",
    "    parser.add_argument('--num_steps', type=int, default=NUM_STEPS,\n",
    "                        help='Number of training steps. Default: ' + str(NUM_STEPS) + '.')\n",
    "    parser.add_argument('--learning_rate', type=float, default=LEARNING_RATE,\n",
    "                        help='Learning rate for training. Default: ' + str(LEARNING_RATE) + '.')\n",
    "    parser.add_argument('--wavenet_params', type=str, default=WAVENET_PARAMS,\n",
    "                        help='JSON file with the network parameters. Default: ' + WAVENET_PARAMS + '.')\n",
    "    parser.add_argument('--sample_size', type=int, default=SAMPLE_SIZE,\n",
    "                        help='Concatenate and cut audio samples to this many '\n",
    "                        'samples. Default: ' + str(SAMPLE_SIZE) + '.')\n",
    "    parser.add_argument('--l2_regularization_strength', type=float,\n",
    "                        default=L2_REGULARIZATION_STRENGTH,\n",
    "                        help='Coefficient in the L2 regularization. '\n",
    "                        'Default: False')\n",
    "    parser.add_argument('--silence_threshold', type=float,\n",
    "                        default=SILENCE_THRESHOLD,\n",
    "                        help='Volume threshold below which to trim the start '\n",
    "                        'and the end from the training set samples. Default: ' + str(SILENCE_THRESHOLD) + '.')\n",
    "    parser.add_argument('--optimizer', type=str, default='adam',\n",
    "                        choices=optimizer_factory.keys(),\n",
    "                        help='Select the optimizer specified by this option. Default: adam.')\n",
    "    parser.add_argument('--momentum', type=float,\n",
    "                        default=MOMENTUM, help='Specify the momentum to be '\n",
    "                        'used by sgd or rmsprop optimizer. Ignored by the '\n",
    "                        'adam optimizer. Default: ' + str(MOMENTUM) + '.')\n",
    "    parser.add_argument('--histograms', type=_str_to_bool, default=False,\n",
    "                        help='Whether to store histogram summaries. Default: False')\n",
    "    parser.add_argument('--gc_channels', type=int, default=None,\n",
    "                        help='Number of global condition channels. Default: None. Expecting: Int')\n",
    "    parser.add_argument('--max_checkpoints', type=int, default=MAX_TO_KEEP,\n",
    "                        help='Maximum amount of checkpoints that will be kept alive. Default: '\n",
    "                             + str(MAX_TO_KEEP) + '.')\n",
    "    return parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T07:19:10.165990Z",
     "start_time": "2018-06-02T07:19:10.157268Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T07:19:10.181804Z",
     "start_time": "2018-06-02T07:19:10.167614Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(saver, sess, logdir):\n",
    "    print(\"Trying to restore saved checkpoints from {} ...\".format(logdir),\n",
    "          end=\"\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(logdir)\n",
    "    if ckpt:\n",
    "        print(\"  Checkpoint found: {}\".format(ckpt.model_checkpoint_path))\n",
    "        global_step = int(ckpt.model_checkpoint_path\n",
    "                          .split('/')[-1]\n",
    "                          .split('-')[-1])\n",
    "        print(\"  Global step was: {}\".format(global_step))\n",
    "        print(\"  Restoring...\", end=\"\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\" Done.\")\n",
    "        return global_step\n",
    "    else:\n",
    "        print(\" No checkpoint found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-02T07:19:08.318Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_default_logdir(logdir_root):\n",
    "    logdir = os.path.join(logdir_root, 'train', STARTED_DATESTRING)\n",
    "    return logdir\n",
    "\n",
    "\n",
    "def validate_directories(args):\n",
    "    \"\"\"Validate and arrange directory related arguments.\"\"\"\n",
    "\n",
    "    # Validation\n",
    "    if args.logdir and args.logdir_root:\n",
    "        raise ValueError(\"--logdir and --logdir_root cannot be \"\n",
    "                         \"specified at the same time.\")\n",
    "\n",
    "    if args.logdir and args.restore_from:\n",
    "        raise ValueError(\n",
    "            \"--logdir and --restore_from cannot be specified at the same \"\n",
    "            \"time. This is to keep your previous model from unexpected \"\n",
    "            \"overwrites.\\n\"\n",
    "            \"Use --logdir_root to specify the root of the directory which \"\n",
    "            \"will be automatically created with current date and time, or use \"\n",
    "            \"only --logdir to just continue the training from the last \"\n",
    "            \"checkpoint.\")\n",
    "\n",
    "    # Arrangement\n",
    "    logdir_root = args.logdir_root\n",
    "    if logdir_root is None:\n",
    "        logdir_root = LOGDIR_ROOT\n",
    "\n",
    "    logdir = args.logdir\n",
    "    if logdir is None:\n",
    "        logdir = get_default_logdir(logdir_root)\n",
    "        print('Using default logdir: {}'.format(logdir))\n",
    "\n",
    "    restore_from = args.restore_from\n",
    "    if restore_from is None:\n",
    "        # args.logdir and args.restore_from are exclusive,\n",
    "        # so it is guaranteed the logdir here is newly created.\n",
    "        restore_from = logdir\n",
    "\n",
    "    return {\n",
    "        'logdir': logdir,\n",
    "        'logdir_root': args.logdir_root,\n",
    "        'restore_from': restore_from\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-02T07:19:08.322Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default logdir: ./logdir/train/2018-06-02T15-19-10\n",
      "WARNING:tensorflow:From /home/coder.chenshicheng/WaveNetSeparateAudio/wavenet/model.py:665: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Trying to restore saved checkpoints from ./logdir/train/2018-06-02T15-19-10 ... No checkpoint found.\n",
      "files length: 44257\n",
      "./VCTK-Corpus/wav48/p271/p271_419.wav 271\n",
      "./VCTK-Corpus/wav48/p339/p339_181.wav 339\n",
      "./VCTK-Corpus/wav48/p361/p361_117.wav 361\n",
      "./VCTK-Corpus/wav48/p268/p268_299.wav 268\n",
      "./VCTK-Corpus/wav48/p286/p286_118.wav 286\n",
      "./VCTK-Corpus/wav48/p239/p239_002.wav 239\n",
      "./VCTK-Corpus/wav48/p274/p274_295.wav 274\n",
      "./VCTK-Corpus/wav48/p345/p345_277.wav 345\n",
      "./VCTK-Corpus/wav48/p360/p360_068.wav 360\n",
      "./VCTK-Corpus/wav48/p253/p253_303.wav 253\n",
      "./VCTK-Corpus/wav48/p298/p298_226.wav 298\n",
      "./VCTK-Corpus/wav48/p229/p229_155.wav 229\n",
      "./VCTK-Corpus/wav48/p277/p277_387.wav 277\n",
      "./VCTK-Corpus/wav48/p266/p266_078.wav 266\n",
      "./VCTK-Corpus/wav48/p234/p234_199.wav 234\n",
      "./VCTK-Corpus/wav48/p343/p343_088.wav 343\n",
      "./VCTK-Corpus/wav48/p236/p236_049.wav 236\n",
      "./VCTK-Corpus/wav48/p256/p256_148.wav 256\n",
      "./VCTK-Corpus/wav48/p305/p305_034.wav 305\n",
      "./VCTK-Corpus/wav48/p258/p258_123.wav 258\n",
      "./VCTK-Corpus/wav48/p305/p305_260.wav 305\n",
      "./VCTK-Corpus/wav48/p343/p343_215.wav 343\n",
      "./VCTK-Corpus/wav48/p347/p347_107.wav 347\n",
      "./VCTK-Corpus/wav48/p306/p306_179.wav 306\n",
      "./VCTK-Corpus/wav48/p292/p292_202.wav 292\n",
      "./VCTK-Corpus/wav48/p294/p294_237.wav 294\n",
      "./VCTK-Corpus/wav48/p287/p287_036.wav 287\n",
      "./VCTK-Corpus/wav48/p339/p339_332.wav 339\n",
      "./VCTK-Corpus/wav48/p339/p339_148.wav 339\n",
      "./VCTK-Corpus/wav48/p238/p238_276.wav 238\n",
      "./VCTK-Corpus/wav48/p341/p341_295.wav 341\n",
      "./VCTK-Corpus/wav48/p277/p277_422.wav 277\n",
      "./VCTK-Corpus/wav48/p271/p271_206.wav 271\n",
      "./VCTK-Corpus/wav48/p251/p251_201.wav 251\n",
      "step 0 - loss = 5.636, (16.644 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-06-02T15-19-10 ... Done.\n",
      "./VCTK-Corpus/wav48/p314/p314_060.wav 314\n",
      "step 1 - loss = 5.570, (3.620 sec/step)\n",
      "./VCTK-Corpus/wav48/p232/p232_139.wav 232\n",
      "step 2 - loss = 5.472, (3.859 sec/step)\n",
      "./VCTK-Corpus/wav48/p266/p266_217.wav 266\n",
      "step 3 - loss = 5.293, (3.059 sec/step)\n",
      "./VCTK-Corpus/wav48/p232/p232_296.wav 232\n",
      "step 4 - loss = 5.449, (4.089 sec/step)\n",
      "./VCTK-Corpus/wav48/p243/p243_289.wav 243\n",
      "step 5 - loss = 5.281, (2.845 sec/step)\n",
      "./VCTK-Corpus/wav48/p301/p301_310.wav 301\n",
      "step 6 - loss = 5.243, (2.869 sec/step)\n",
      "./VCTK-Corpus/wav48/p233/p233_066.wav 233\n",
      "step 7 - loss = 5.172, (2.872 sec/step)\n",
      "./VCTK-Corpus/wav48/p326/p326_137.wav 326\n",
      "step 8 - loss = 5.148, (3.262 sec/step)\n",
      "./VCTK-Corpus/wav48/p376/p376_167.wav 376\n",
      "step 9 - loss = 4.883, (6.441 sec/step)\n",
      "step 10 - loss = 4.850, (2.987 sec/step)\n",
      "./VCTK-Corpus/wav48/p302/p302_228.wav 302\n",
      "step 11 - loss = 5.459, (2.593 sec/step)\n",
      "./VCTK-Corpus/wav48/p251/p251_209.wav 251\n",
      "step 12 - loss = 4.994, (2.008 sec/step)\n",
      "./VCTK-Corpus/wav48/p326/p326_025.wav 326\n"
     ]
    }
   ],
   "source": [
    "args = get_arguments()\n",
    "\n",
    "try:\n",
    "    directories = validate_directories(args)\n",
    "except ValueError as e:\n",
    "    print(\"Some arguments are wrong:\")\n",
    "    print(str(e))\n",
    "\n",
    "logdir = directories['logdir']\n",
    "restore_from = directories['restore_from']\n",
    "\n",
    "# Even if we restored the model, we will treat it as new training\n",
    "# if the trained model is written into an arbitrary location.\n",
    "is_overwritten_training = logdir != restore_from\n",
    "\n",
    "with open(args.wavenet_params, 'r') as f:\n",
    "    wavenet_params = json.load(f)\n",
    "\n",
    "# Create coordinator.\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "# Load raw waveform from VCTK corpus.\n",
    "with tf.name_scope('create_inputs'):\n",
    "    # Allow silence trimming to be skipped by specifying a threshold near\n",
    "    # zero.\n",
    "    silence_threshold = args.silence_threshold if args.silence_threshold > \\\n",
    "                                                  EPSILON else None\n",
    "    gc_enabled = args.gc_channels is not None\n",
    "    reader = AudioReader(\n",
    "        args.data_dir,\n",
    "        coord,\n",
    "        sample_rate=wavenet_params['sample_rate'],   #\"sample_rate\": 16000,\n",
    "        gc_enabled=gc_enabled,\n",
    "        receptive_field=WaveNetModel.calculate_receptive_field(wavenet_params[\"filter_width\"],\n",
    "                                                               wavenet_params[\"dilations\"],\n",
    "                                                               wavenet_params[\"scalar_input\"],\n",
    "                                                               wavenet_params[\"initial_filter_width\"]),\n",
    "        sample_size=args.sample_size,  #SAMPLE_SIZE = 100000\n",
    "        silence_threshold=silence_threshold)\n",
    "    audio_batch = reader.dequeue(args.batch_size)  #BATCH_SIZE = 1\n",
    "    if gc_enabled:\n",
    "        gc_id_batch = reader.dequeue_gc(args.batch_size)\n",
    "    else:\n",
    "        gc_id_batch = None\n",
    "\n",
    "# Create network.\n",
    "net = WaveNetModel(\n",
    "    batch_size=args.batch_size,\n",
    "    dilations=wavenet_params[\"dilations\"],\n",
    "    filter_width=wavenet_params[\"filter_width\"],\n",
    "    residual_channels=wavenet_params[\"residual_channels\"],\n",
    "    dilation_channels=wavenet_params[\"dilation_channels\"],\n",
    "    skip_channels=wavenet_params[\"skip_channels\"],\n",
    "    quantization_channels=wavenet_params[\"quantization_channels\"],\n",
    "    use_biases=wavenet_params[\"use_biases\"],\n",
    "    scalar_input=wavenet_params[\"scalar_input\"],\n",
    "    initial_filter_width=wavenet_params[\"initial_filter_width\"],\n",
    "    histograms=args.histograms,\n",
    "    global_condition_channels=args.gc_channels,\n",
    "    global_condition_cardinality=reader.gc_category_cardinality)\n",
    "\n",
    "if args.l2_regularization_strength == 0:\n",
    "    args.l2_regularization_strength = None\n",
    "#print('audio_batch',audio_batch)\n",
    "loss = net.loss(input_batch=audio_batch,\n",
    "                global_condition_batch=gc_id_batch,\n",
    "                l2_regularization_strength=args.l2_regularization_strength)\n",
    "optimizer = optimizer_factory[args.optimizer](\n",
    "                learning_rate=args.learning_rate,\n",
    "                momentum=args.momentum)\n",
    "trainable = tf.trainable_variables()\n",
    "optim = optimizer.minimize(loss, var_list=trainable)\n",
    "\n",
    "# Set up logging for TensorBoard.\n",
    "writer = tf.summary.FileWriter(logdir)\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "run_metadata = tf.RunMetadata()\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "# Set up session\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Saver for storing checkpoints of the model.\n",
    "saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=args.max_checkpoints)\n",
    "\n",
    "try:\n",
    "    saved_global_step = load(saver, sess, restore_from)\n",
    "    if is_overwritten_training or saved_global_step is None:\n",
    "        # The first training step will be saved_global_step + 1,\n",
    "        # therefore we put -1 here for new or overwritten trainings.\n",
    "        saved_global_step = -1\n",
    "\n",
    "except:\n",
    "    print(\"Something went wrong while restoring checkpoint. \"\n",
    "          \"We will terminate training to avoid accidentally overwriting \"\n",
    "          \"the previous model.\")\n",
    "    raise\n",
    "\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "reader.start_threads(sess)\n",
    "\n",
    "step = None\n",
    "last_saved_step = saved_global_step\n",
    "try:\n",
    "    for step in range(saved_global_step + 1, args.num_steps):\n",
    "        start_time = time.time()\n",
    "        if args.store_metadata and step % 50 == 0:\n",
    "            # Slow run that stores extra information for debugging.\n",
    "            print('Storing metadata')\n",
    "            run_options = tf.RunOptions(\n",
    "                trace_level=tf.RunOptions.FULL_TRACE)\n",
    "            summary, loss_value, _ = sess.run(\n",
    "                [summaries, loss, optim],\n",
    "                options=run_options,\n",
    "                run_metadata=run_metadata)\n",
    "            writer.add_summary(summary, step)\n",
    "            writer.add_run_metadata(run_metadata,\n",
    "                                    'step_{:04d}'.format(step))\n",
    "            tl = timeline.Timeline(run_metadata.step_stats)\n",
    "            timeline_path = os.path.join(logdir, 'timeline.trace')\n",
    "            with open(timeline_path, 'w') as f:\n",
    "                f.write(tl.generate_chrome_trace_format(show_memory=True))\n",
    "        else:\n",
    "            summary, loss_value, _ = sess.run([summaries, loss, optim])\n",
    "            writer.add_summary(summary, step)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        print('step {:d} - loss = {:.3f}, ({:.3f} sec/step)'\n",
    "              .format(step, loss_value, duration))\n",
    "\n",
    "        if step % args.checkpoint_every == 0:\n",
    "            save(saver, sess, logdir, step)\n",
    "            last_saved_step = step\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Introduce a line break after ^C is displayed so save message\n",
    "    # is on its own line.\n",
    "    print()\n",
    "finally:\n",
    "    if step > last_saved_step:\n",
    "        save(saver, sess, logdir, step)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
