{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:55:57.914564Z",
     "start_time": "2018-06-10T13:55:56.714973Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:55:57.934412Z",
     "start_time": "2018-06-10T13:55:57.917013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleSize=16000\n",
    "sample_rate=16000\n",
    "quantization_channels=256\n",
    "#dilations=[2**i for i in range(8)]*20\n",
    "#\"residualDim=32\n",
    "dilations=[2**i for i in range(9)]*1\n",
    "residualDim=256\n",
    "skipDim=512\n",
    "filterSize=3\n",
    "pad = np.sum(dilations)\n",
    "lossrecord=[]\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:55:57.938453Z",
     "start_time": "2018-06-10T13:55:57.936022Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:55:58.733625Z",
     "start_time": "2018-06-10T13:55:57.940001Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#device = 'cpu'\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:55:58.755346Z",
     "start_time": "2018-06-10T13:55:58.735489Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_law_encode(audio, quantization_channels=quantization_channels,forX=False):\n",
    "    '''Quantizes waveform amplitudes.'''\n",
    "    mu = (quantization_channels - 1)*1.0\n",
    "    # Perform mu-law companding transformation (ITU-T, 1988).\n",
    "    # Minimum operation is here to deal with rare large amplitudes caused\n",
    "    # by resampling.\n",
    "    safe_audio_abs = np.minimum(np.abs(audio), 1.0)\n",
    "    magnitude = np.log1p(mu * safe_audio_abs) / np.log1p(mu)\n",
    "    signal = np.sign(audio) * magnitude\n",
    "    # Quantize signal to the specified number of levels.\n",
    "    if(forX):return signal\n",
    "    return ((signal + 1) / 2 * mu + 0.5).astype(int)\n",
    "def mu_law_decode(output, quantization_channels=quantization_channels):\n",
    "    '''Recovers waveform from quantized values.'''\n",
    "    mu = quantization_channels - 1\n",
    "    # Map values back to [-1, 1].\n",
    "    signal = 2 * ((output*1.0) / mu) - 1\n",
    "    # Perform inverse of mu-law transformation.\n",
    "    magnitude = (1 / mu) * ((1 + mu)**np.abs(signal) - 1)\n",
    "    return np.sign(signal) * magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:56:16.071168Z",
     "start_time": "2018-06-10T13:55:58.757090Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readAudio(name):\n",
    "    audio0, samplerate = sf.read(name, dtype='float32')\n",
    "    return librosa.resample(audio0.T, samplerate, sample_rate).reshape(-1)\n",
    "p=['./vsCorpus/origin_mix.wav','./vsCorpus/origin_vocal.wav',\n",
    "   './vsCorpus/origin_mix.wav','./vsCorpus/origin_vocal.wav','./vsCorpus/pred_mix.wav']\n",
    "xtrain,ytrain,xval,yval,xtest=readAudio(p[0]),readAudio(p[1]),readAudio(p[2]),readAudio(p[3]),readAudio(p[4])\n",
    "assert((xtrain==xval).all())\n",
    "assert((ytrain==yval).all())\n",
    "assert((xtrain != ytrain).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:56:16.475059Z",
     "start_time": "2018-06-10T13:56:16.074502Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ytrain,yval=mu_law_encode(ytrain),mu_law_encode(yval)\n",
    "xtrain,xval,xtest=mu_law_encode(xtrain,forX=True),mu_law_encode(xval,forX=True),mu_law_encode(xtest,forX=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:56:16.480770Z",
     "start_time": "2018-06-10T13:56:16.476725Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xmean,xstd = xtrain.mean(),xtrain.std()\\nxtrain=(xtrain-xmean)/xstd\\nxval=(xval-xmean)/xstd\\nxtest=(xtest-xmean)/xstd'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''xmean,xstd = xtrain.mean(),xtrain.std()\n",
    "xtrain=(xtrain-xmean)/xstd\n",
    "xval=(xval-xmean)/xstd\n",
    "xtest=(xtest-xmean)/xstd'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:56:16.690117Z",
     "start_time": "2018-06-10T13:56:16.482364Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xtrain,ytrain=xtrain[:xtest.shape[0]],ytrain[:xtest.shape[0]]\n",
    "#xval,yval=xval[:xtest.shape[0]],yval[:xtest.shape[0]]\n",
    "xtrain=np.pad(xtrain, (pad, pad), 'constant')\n",
    "xval=np.pad(xval, (pad, pad), 'constant')\n",
    "xtest=np.pad(xtest, (pad, pad), 'constant')\n",
    "yval=np.pad(yval, (pad, pad), 'constant')\n",
    "ytrain=np.pad(ytrain, (pad, pad), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:56:16.695720Z",
     "start_time": "2018-06-10T13:56:16.691828Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#xtrain,ytrain,xval,yval=xtrain[:-sampleSize],ytrain[:-sampleSize],xval[-sampleSize:],yval[-sampleSize:]\n",
    "#xtrain,ytrain,xval,yval=xtrain[:-sampleSize],ytrain[:-sampleSize],xval[:sampleSize],yval[:sampleSize]\n",
    "xtrain,xval,xtest=xtrain.reshape(1,1,-1),xval.reshape(1,1,-1),xtest.reshape(1,1,-1)\n",
    "ytrain,yval=ytrain.reshape(1,-1),yval.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:56:16.701817Z",
     "start_time": "2018-06-10T13:56:16.697243Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,ytrain,xval,yval,xtest = torch.from_numpy(xtrain).type(torch.float32),\\\n",
    "                                torch.from_numpy(ytrain).type(torch.LongTensor),\\\n",
    "                                torch.from_numpy(xval).type(torch.float32),\\\n",
    "                                torch.from_numpy(yval).type(torch.LongTensor),\\\n",
    "                                torch.from_numpy(xtest).type(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:57:17.589793Z",
     "start_time": "2018-06-10T13:57:17.421526Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        sd,qd,rd = skipDim,quantization_channels,residualDim\n",
    "        self.causal = nn.Conv1d(in_channels=1,out_channels=rd,kernel_size=3,padding=1)\n",
    "        self.tanhconvs = nn.ModuleList()\n",
    "        self.sigmoidconvs = nn.ModuleList()\n",
    "        self.skipconvs = nn.ModuleList()\n",
    "        self.denseconvs = nn.ModuleList()\n",
    "        for i, d in enumerate(dilations):\n",
    "            self.tanhconvs.append(nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=3,padding=0,dilation=d))\n",
    "            self.sigmoidconvs.append(nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=3,padding=0,dilation=d))\n",
    "            self.skipconvs.append(nn.Conv1d(in_channels=rd,out_channels=sd,kernel_size=1))\n",
    "            self.denseconvs.append(nn.Conv1d(in_channels=rd,out_channels=rd,kernel_size=1))\n",
    "        self.post1 = nn.Conv1d(in_channels=sd,out_channels=sd,kernel_size=1)\n",
    "        self.post2 = nn.Conv1d(in_channels=sd,out_channels=qd,kernel_size=1)\n",
    "        self.tanh,self.sigmoid = nn.Tanh(),nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        finallen = x.shape[-1]-2*pad\n",
    "        x = self.causal(x)\n",
    "        for i, dilation in enumerate(dilations):\n",
    "            xinput = x.clone()[:,:,dilation:-dilation]\n",
    "            x1 = self.tanh(self.tanhconvs[i](x))\n",
    "            x2 = self.sigmoid(self.sigmoidconvs[i](x))\n",
    "            x = x1*x2\n",
    "            cutlen = (x.shape[-1] - finallen)//2\n",
    "            if(i == 0):skip_connections= (self.skipconvs[i](x)).narrow(2,int(cutlen),int(finallen))\n",
    "            else :skip_connections += (self.skipconvs[i](x)).narrow(2,int(cutlen),int(finallen))\n",
    "            x = self.denseconvs[i](x)\n",
    "            x += xinput\n",
    "        x = self.post2(F.relu(self.post1(F.relu(skip_connections))))\n",
    "        return x\n",
    "\n",
    "model = Net()#.cuda()\n",
    "criterion = nn.CrossEntropyLoss()#.cuda()\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer = optim.Adam(model.parameters(),weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:57:18.197290Z",
     "start_time": "2018-06-10T13:57:17.960468Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def val():\n",
    "    model.eval()\n",
    "    startval_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        idx = np.arange(pad,xtrain.shape[-1]-pad-sampleSize,1000)\n",
    "        np.random.shuffle(idx)\n",
    "        data = xtrain[:,:,idx[0]-pad:pad+idx[0]+sampleSize].to(device)\n",
    "        target = ytrain[:,idx[0]:idx[0]+sampleSize].to(device)\n",
    "        output = model(data)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item() / pred.shape[-1]\n",
    "        val_loss = criterion(output, target).item()\n",
    "    print(correct,'accurate')\n",
    "    print('\\nval set:loss{:.4f}:, ({:.3f} sec/step)\\n'.format(val_loss,time.time()-startval_time))\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    startval_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        listofpred = []\n",
    "        for ind in range(pad, xtest.shape[-1] - pad, sampleSize):\n",
    "            output = model(xtest[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "            pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "            listofpred.append(pred)\n",
    "        ans = mu_law_decode(np.concatenate(listofpred))\n",
    "        sf.write('./vsCorpus/resultxte.wav', ans, sample_rate)\n",
    "\n",
    "        listofpred=[]\n",
    "        for ind in range(pad,xtrain.shape[-1]-pad,sampleSize):\n",
    "            output = model(xtrain[:, :, ind-pad:ind+sampleSize+pad].to(device))\n",
    "            pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "            listofpred.append(pred)\n",
    "        ans = mu_law_decode(np.concatenate(listofpred))\n",
    "        sf.write('./vsCorpus/resultxtr.wav', ans, sample_rate)\n",
    "        print('stored done\\n')\n",
    "    \n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    #idx = np.arange(xtrain.shape[-1] - 2 * sampleSize,1000)\n",
    "    #176000\n",
    "    idx = np.arange(pad,xtrain.shape[-1]-pad-sampleSize,16000)\n",
    "    np.random.shuffle(idx)\n",
    "    for i, ind in enumerate(idx):\n",
    "        start_time = time.time()\n",
    "        data, target = xtrain[:,:,ind-pad:ind+sampleSize+pad].to(device), ytrain[:,ind:ind+sampleSize].to(device)\n",
    "        #cur=model.tanhconvs[0].weight.clone()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        lossrecord.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #assert((model.tanhconvs[0].weight == cur).cpu().numpy().all())\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss:{:.6f}: , ({:.3f} sec/step)'.format(\n",
    "                epoch, i, len(idx),100. * i / len(idx), loss.item(),time.time() - start_time))\n",
    "        if i % 100 == 0:\n",
    "            with open(\"./lossRecord/newmodellossfile.txt\", \"w\") as f:\n",
    "                for s in lossrecord:\n",
    "                    f.write(str(s) +\"\\n\")\n",
    "            print('write finish')\n",
    "            state={'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()}\n",
    "            torch.save(state, 'newModifiedModel')\n",
    "    test()\n",
    "    val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-10T13:57:18.660Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/235 (0%)] Loss:5.545600: , (0.520 sec/step)\n",
      "write finish\n",
      "Train Epoch: 0 [1/235 (0%)] Loss:5.502888: , (0.518 sec/step)\n",
      "Train Epoch: 0 [2/235 (1%)] Loss:5.472961: , (0.518 sec/step)\n",
      "Train Epoch: 0 [3/235 (1%)] Loss:5.322281: , (0.517 sec/step)\n",
      "Train Epoch: 0 [4/235 (2%)] Loss:5.316733: , (0.516 sec/step)\n",
      "Train Epoch: 0 [5/235 (2%)] Loss:5.044542: , (0.517 sec/step)\n",
      "Train Epoch: 0 [6/235 (3%)] Loss:5.550271: , (0.516 sec/step)\n",
      "Train Epoch: 0 [7/235 (3%)] Loss:5.203669: , (0.516 sec/step)\n",
      "Train Epoch: 0 [8/235 (3%)] Loss:5.158384: , (0.516 sec/step)\n",
      "Train Epoch: 0 [9/235 (4%)] Loss:5.140691: , (0.516 sec/step)\n",
      "Train Epoch: 0 [10/235 (4%)] Loss:5.187211: , (0.516 sec/step)\n",
      "Train Epoch: 0 [11/235 (5%)] Loss:5.118204: , (0.517 sec/step)\n",
      "Train Epoch: 0 [12/235 (5%)] Loss:5.154421: , (0.516 sec/step)\n",
      "Train Epoch: 0 [13/235 (6%)] Loss:5.432991: , (0.517 sec/step)\n",
      "Train Epoch: 0 [14/235 (6%)] Loss:5.122524: , (0.516 sec/step)\n",
      "Train Epoch: 0 [15/235 (6%)] Loss:5.266912: , (0.517 sec/step)\n",
      "Train Epoch: 0 [16/235 (7%)] Loss:5.207812: , (0.516 sec/step)\n",
      "Train Epoch: 0 [17/235 (7%)] Loss:5.045971: , (0.516 sec/step)\n",
      "Train Epoch: 0 [18/235 (8%)] Loss:5.068138: , (0.516 sec/step)\n",
      "Train Epoch: 0 [19/235 (8%)] Loss:5.322633: , (0.517 sec/step)\n",
      "Train Epoch: 0 [20/235 (9%)] Loss:5.010511: , (0.517 sec/step)\n",
      "Train Epoch: 0 [21/235 (9%)] Loss:5.174698: , (0.516 sec/step)\n",
      "Train Epoch: 0 [22/235 (9%)] Loss:5.118405: , (0.517 sec/step)\n",
      "Train Epoch: 0 [23/235 (10%)] Loss:5.020063: , (0.517 sec/step)\n",
      "Train Epoch: 0 [24/235 (10%)] Loss:5.024170: , (0.516 sec/step)\n",
      "Train Epoch: 0 [25/235 (11%)] Loss:4.989151: , (0.517 sec/step)\n",
      "Train Epoch: 0 [26/235 (11%)] Loss:5.115785: , (0.517 sec/step)\n",
      "Train Epoch: 0 [27/235 (11%)] Loss:4.813157: , (0.517 sec/step)\n",
      "Train Epoch: 0 [28/235 (12%)] Loss:5.040486: , (0.517 sec/step)\n",
      "Train Epoch: 0 [29/235 (12%)] Loss:5.030226: , (0.517 sec/step)\n",
      "Train Epoch: 0 [30/235 (13%)] Loss:4.770164: , (0.517 sec/step)\n",
      "Train Epoch: 0 [31/235 (13%)] Loss:5.239775: , (0.517 sec/step)\n",
      "Train Epoch: 0 [32/235 (14%)] Loss:5.125395: , (0.518 sec/step)\n",
      "Train Epoch: 0 [33/235 (14%)] Loss:5.435914: , (0.516 sec/step)\n",
      "Train Epoch: 0 [34/235 (14%)] Loss:5.233218: , (0.517 sec/step)\n",
      "Train Epoch: 0 [35/235 (15%)] Loss:5.009539: , (0.518 sec/step)\n",
      "Train Epoch: 0 [36/235 (15%)] Loss:5.109108: , (0.517 sec/step)\n",
      "Train Epoch: 0 [37/235 (16%)] Loss:5.169400: , (0.518 sec/step)\n",
      "Train Epoch: 0 [38/235 (16%)] Loss:5.008713: , (0.519 sec/step)\n",
      "Train Epoch: 0 [39/235 (17%)] Loss:5.177068: , (0.518 sec/step)\n",
      "Train Epoch: 0 [40/235 (17%)] Loss:5.352380: , (0.518 sec/step)\n",
      "Train Epoch: 0 [41/235 (17%)] Loss:4.697183: , (0.518 sec/step)\n",
      "Train Epoch: 0 [42/235 (18%)] Loss:5.282678: , (0.517 sec/step)\n",
      "Train Epoch: 0 [43/235 (18%)] Loss:5.292554: , (0.518 sec/step)\n",
      "Train Epoch: 0 [44/235 (19%)] Loss:5.101848: , (0.519 sec/step)\n",
      "Train Epoch: 0 [45/235 (19%)] Loss:5.123889: , (0.520 sec/step)\n",
      "Train Epoch: 0 [46/235 (20%)] Loss:4.879399: , (0.519 sec/step)\n",
      "Train Epoch: 0 [47/235 (20%)] Loss:5.058409: , (0.520 sec/step)\n",
      "Train Epoch: 0 [48/235 (20%)] Loss:4.991204: , (0.520 sec/step)\n",
      "Train Epoch: 0 [49/235 (21%)] Loss:4.749141: , (0.520 sec/step)\n",
      "Train Epoch: 0 [50/235 (21%)] Loss:4.924041: , (0.520 sec/step)\n",
      "Train Epoch: 0 [51/235 (22%)] Loss:4.789143: , (0.519 sec/step)\n",
      "Train Epoch: 0 [52/235 (22%)] Loss:4.965472: , (0.519 sec/step)\n",
      "Train Epoch: 0 [53/235 (23%)] Loss:4.731125: , (0.520 sec/step)\n",
      "Train Epoch: 0 [54/235 (23%)] Loss:5.088818: , (0.520 sec/step)\n",
      "Train Epoch: 0 [55/235 (23%)] Loss:4.821186: , (0.520 sec/step)\n",
      "Train Epoch: 0 [56/235 (24%)] Loss:5.011600: , (0.520 sec/step)\n",
      "Train Epoch: 0 [57/235 (24%)] Loss:5.016937: , (0.520 sec/step)\n",
      "Train Epoch: 0 [58/235 (25%)] Loss:5.045105: , (0.519 sec/step)\n",
      "Train Epoch: 0 [59/235 (25%)] Loss:4.924715: , (0.520 sec/step)\n",
      "Train Epoch: 0 [60/235 (26%)] Loss:4.892739: , (0.520 sec/step)\n",
      "Train Epoch: 0 [61/235 (26%)] Loss:4.977192: , (0.520 sec/step)\n",
      "Train Epoch: 0 [62/235 (26%)] Loss:5.069331: , (0.519 sec/step)\n",
      "Train Epoch: 0 [63/235 (27%)] Loss:5.007230: , (0.520 sec/step)\n",
      "Train Epoch: 0 [64/235 (27%)] Loss:5.134181: , (0.520 sec/step)\n",
      "Train Epoch: 0 [65/235 (28%)] Loss:4.999404: , (0.520 sec/step)\n",
      "Train Epoch: 0 [66/235 (28%)] Loss:5.021348: , (0.520 sec/step)\n",
      "Train Epoch: 0 [67/235 (29%)] Loss:5.158100: , (0.521 sec/step)\n",
      "Train Epoch: 0 [68/235 (29%)] Loss:4.758568: , (0.520 sec/step)\n",
      "Train Epoch: 0 [69/235 (29%)] Loss:4.914480: , (0.520 sec/step)\n",
      "Train Epoch: 0 [70/235 (30%)] Loss:5.051396: , (0.520 sec/step)\n",
      "Train Epoch: 0 [71/235 (30%)] Loss:4.761080: , (0.520 sec/step)\n",
      "Train Epoch: 0 [72/235 (31%)] Loss:4.963311: , (0.520 sec/step)\n",
      "Train Epoch: 0 [73/235 (31%)] Loss:4.752736: , (0.520 sec/step)\n",
      "Train Epoch: 0 [74/235 (31%)] Loss:4.937314: , (0.520 sec/step)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-10T13:56:21.143163Z",
     "start_time": "2018-06-10T13:55:56.703Z"
    }
   },
   "outputs": [],
   "source": [
    "#torch.save(model, 'loss2.5~3.5step10h_repeat5*2**9resu32sample50000')"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLalgorithm/mnistPyTorch.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
