{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:29:27.835146Z",
     "start_time": "2018-06-16T02:29:26.042763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import time\n",
    "import os\n",
    "from torch.utils import data\n",
    "from wavenet import Wavenet\n",
    "from transformData import x_mu_law_encode,y_mu_law_encode,mu_law_decode,onehot,cateToSignal\n",
    "from readDataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:29:27.846389Z",
     "start_time": "2018-06-16T02:29:27.837087Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleSize=32000#the length of the sample size\n",
    "quantization_channels=256\n",
    "sample_rate=16000\n",
    "dilations=[2**i for i in range(9)]*5  #idea from wavenet, have more receptive field\n",
    "residualDim=128 #\n",
    "skipDim=512\n",
    "shapeoftest = 190500\n",
    "filterSize=3\n",
    "resumefile='./model/testac' # name of checkpoint\n",
    "lossname='testacloss.txt' # name of loss file\n",
    "continueTrain=True # whether use checkpoint\n",
    "pad = np.sum(dilations) # padding for dilate convolutional layers\n",
    "lossrecord=[]  #list for record loss\n",
    "#pad=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #            |----------------------------------------|     *residual*\n",
    "    #            |                                        |\n",
    "    #            |    |-- conv -- tanh --|                |\n",
    "    # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n",
    "    #                 |-- conv -- sigm --|     |    ||\n",
    "    #                                         1x1=residualDim\n",
    "    #                                          |\n",
    "    # ---------------------------------------> + ------------->\t*skip=skipDim*\n",
    "    image changed from https://github.com/vincentherrmann/pytorch-wavenet/blob/master/wavenet_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:29:27.850407Z",
     "start_time": "2018-06-16T02:29:27.847826Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # use specific GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:29:27.898103Z",
     "start_time": "2018-06-16T02:29:27.851836Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available() # whether have available GPU\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#device = 'cpu'\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor') #set_default_tensor_type as cuda tensor\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:29:27.905118Z",
     "start_time": "2018-06-16T02:29:27.899970Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 1,'shuffle': True,'num_workers': 1}\n",
    "training_set = Dataset(['origin_mix'],['origin_vocal'],'./vsCorpus/','./vsCorpus/')\n",
    "testing_set = Dataset(['pred_mix'],['pred_mix'],'./vsCorpus/','./vsCorpus/')\n",
    "loadtr = data.DataLoader(training_set, **params) #pytorch dataloader, more faster than mine\n",
    "loadval = data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:29:32.371942Z",
     "start_time": "2018-06-16T02:29:27.906590Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Wavenet(pad,skipDim,quantization_channels,residualDim,dilations).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#in wavenet paper, they said crossentropyloss is far better than MSELoss\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3,weight_decay=1e-5)\n",
    "#use adam to train\n",
    "#optimizer = optim.SGD(model.parameters(), lr = 0.1, momentum=0.9, weight_decay=1e-5)\n",
    "#scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[20,40], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:29:32.383870Z",
     "start_time": "2018-06-16T02:29:32.374147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> no checkpoint found at 'testac'\n"
     ]
    }
   ],
   "source": [
    "if continueTrain:# if continueTrain, the program will find the checkpoints\n",
    "    if os.path.isfile(resumefile):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resumefile))\n",
    "        checkpoint = torch.load(resumefile)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        #best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(resumefile, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resumefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:29:32.667892Z",
     "start_time": "2018-06-16T02:29:32.385373Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def val(xtrain,ytrain): #validation last 15 seconds of the audio.\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        idx = np.arange(xtrain.shape[-1]-pad-10*sampleSize,xtrain.shape[-1]-pad-sampleSize,1000)\n",
    "        np.random.shuffle(idx)\n",
    "        data = xtrain[:,:,idx[0]-pad:pad+idx[0]+sampleSize].to(device)\n",
    "        target = ytrain[:,idx[0]:idx[0]+sampleSize].to(device)\n",
    "        output = model(data)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item() / pred.shape[-1]\n",
    "        val_loss = criterion(output, target).item()\n",
    "        print(correct,'accurate')\n",
    "        print('\\nval set:loss{:.4f}:, ({:.3f} sec/step)\\n'.format(val_loss,time.time()-start_time))\n",
    "        \n",
    "        listofpred = []\n",
    "        for ind in range(xtrain.shape[-1]-pad-10*sampleSize,xtrain.shape[-1]-pad-sampleSize,sampleSize):\n",
    "            output = model(xtrain[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "            pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "            listofpred.append(pred)\n",
    "        ans = mu_law_decode(np.concatenate(listofpred))\n",
    "        sf.write('./vsCorpus/notexval.wav', ans, sample_rate)\n",
    "        print('val stored done',time.time() - start_time)\n",
    "        \n",
    "\n",
    "def test(xtrain):# testing data\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for iloader,(xtest,_) in enumerate(loadval):\n",
    "            listofpred = []\n",
    "            for ind in range(pad, xtest.shape[-1] - pad, sampleSize):\n",
    "                output = model(xtest[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "                pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "                listofpred.append(pred)\n",
    "            ans = mu_law_decode(np.concatenate(listofpred))\n",
    "            sf.write('./vsCorpus/notexte.wav', ans, sample_rate)\n",
    "\n",
    "            listofpred=[]\n",
    "            for ind in range(pad,xtrain.shape[-1]-pad,sampleSize):\n",
    "                output = model(xtrain[:, :, ind-pad:ind+sampleSize+pad].to(device))\n",
    "                pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "                listofpred.append(pred)\n",
    "            ans = mu_law_decode(np.concatenate(listofpred))\n",
    "            sf.write('./vsCorpus/notextr.wav', ans, sample_rate)\n",
    "            print('test stored done',time.time() - start_time)\n",
    "    \n",
    "def train(epoch):#training data, the audio except for last 15 seconds\n",
    "    model.train()\n",
    "    for iloader,(xtrain,ytrain) in enumerate(loadtr):\n",
    "        idx = np.arange(pad,xtrain.shape[-1]-pad-11*sampleSize,16000)\n",
    "        np.random.shuffle(idx)#random the starting points\n",
    "        for i, ind in enumerate(idx):\n",
    "            start_time = time.time()\n",
    "            data, target = xtrain[:,:,ind-pad:ind+sampleSize+pad].to(device), ytrain[:,ind:ind+sampleSize].to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            lossrecord.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss:{:.6f}: , ({:.3f} sec/step)'.format(\n",
    "                    epoch, i, len(idx),100. * i / len(idx), loss.item(),time.time() - start_time))\n",
    "            if i % 100 == 0:\n",
    "                with open(\"./lossRecord/\"+lossname, \"w\") as f:\n",
    "                    for s in lossrecord:\n",
    "                        f.write(str(s) +\"\\n\")\n",
    "                print('write finish')\n",
    "\n",
    "        val(xtrain,ytrain)\n",
    "        test(xtrain)\n",
    "        state={'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()}\n",
    "        torch.save(state, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:30:09.200909Z",
     "start_time": "2018-06-16T02:29:32.669601Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/214 (0%)] Loss:5.567682: , (2.149 sec/step)\n",
      "write finish\n",
      "Train Epoch: 0 [1/214 (0%)] Loss:5.509311: , (2.117 sec/step)\n",
      "Train Epoch: 0 [2/214 (1%)] Loss:5.414552: , (2.116 sec/step)\n",
      "Train Epoch: 0 [3/214 (1%)] Loss:5.382193: , (2.116 sec/step)\n",
      "Train Epoch: 0 [4/214 (2%)] Loss:5.745721: , (2.114 sec/step)\n",
      "Train Epoch: 0 [5/214 (2%)] Loss:5.333701: , (2.115 sec/step)\n",
      "Train Epoch: 0 [6/214 (3%)] Loss:5.292008: , (2.116 sec/step)\n",
      "Train Epoch: 0 [7/214 (3%)] Loss:5.417538: , (2.116 sec/step)\n",
      "Train Epoch: 0 [8/214 (4%)] Loss:5.327732: , (2.117 sec/step)\n",
      "Train Epoch: 0 [9/214 (4%)] Loss:5.473708: , (2.118 sec/step)\n",
      "Train Epoch: 0 [10/214 (5%)] Loss:5.272099: , (2.119 sec/step)\n",
      "Train Epoch: 0 [11/214 (5%)] Loss:5.346041: , (2.119 sec/step)\n",
      "Train Epoch: 0 [12/214 (6%)] Loss:5.248786: , (2.119 sec/step)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fe2d05db278>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 9251) exited unexpectedly with exit code 1.\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-6efb5b007c8e>\", line 2, in <module>\n",
      "    train(epoch)\n",
      "  File \"<ipython-input-8-06776f8255ec>\", line 58, in train\n",
      "    lossrecord.append(loss.item())\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1806, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/inspect.py\", line 1480, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/inspect.py\", line 1438, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/posixpath.py\", line 386, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/posixpath.py\", line 419, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/posixpath.py\", line 79, in join\n",
      "    sep = _get_sep(a)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/posixpath.py\", line 40, in _get_sep\n",
      "    if isinstance(path, bytes):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLalgorithm/mnistPyTorch.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
