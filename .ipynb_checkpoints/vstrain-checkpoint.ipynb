{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:56:56.909722Z",
     "start_time": "2018-06-13T13:56:55.383839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import time\n",
    "import os\n",
    "from torch.utils import data\n",
    "from wavenet import Wavenet\n",
    "from transformData import x_mu_law_encode,y_mu_law_encode,mu_law_decode,onehot,cateToSignal\n",
    "from readDataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:56:56.927256Z",
     "start_time": "2018-06-13T13:56:56.912509Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleSize=32000#the length of the sample size\n",
    "quantization_channels=256\n",
    "sample_rate=16000\n",
    "dilations=[2**i for i in range(9)]*5  #idea from wavenet, have more receptive field\n",
    "residualDim=128 #\n",
    "skipDim=512\n",
    "shapeoftest = 190500\n",
    "filterSize=3\n",
    "resumefile='trypadmodel' # name of checkpoint\n",
    "lossname='trypadlossfile.txt' # name of loss file\n",
    "continueTrain=False # whether use checkpoint\n",
    "pad = np.sum(dilations) # padding for dilate convolutional layers\n",
    "lossrecord=[]  #list for record loss\n",
    "pad=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #            |----------------------------------------|     *residual*\n",
    "    #            |                                        |\n",
    "    #            |    |-- conv -- tanh --|                |\n",
    "    # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n",
    "    #                 |-- conv -- sigm --|     |    ||\n",
    "    #                                         1x1=residualDim\n",
    "    #                                          |\n",
    "    # ---------------------------------------> + ------------->\t*skip=skipDim*\n",
    "    image changed from https://github.com/vincentherrmann/pytorch-wavenet/blob/master/wavenet_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:56:56.931711Z",
     "start_time": "2018-06-13T13:56:56.928944Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # use specific GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:56:57.763602Z",
     "start_time": "2018-06-13T13:56:56.933447Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available() # whether have available GPU\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#device = 'cpu'\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor') #set_default_tensor_type as cuda tensor\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:56:57.773413Z",
     "start_time": "2018-06-13T13:56:57.766276Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 1,'shuffle': True,'num_workers': 2}\n",
    "training_set = Dataset(['origin_mix'],['origin_vocal'],'./vsCorpus/','./vsCorpus/')\n",
    "testing_set = Dataset(['pred_mix'],['pred_mix'],'./vsCorpus/','./vsCorpus/')\n",
    "loadtr = data.DataLoader(training_set, **params) #pytorch dataloader, more faster than mine\n",
    "loadval = data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:57:02.668188Z",
     "start_time": "2018-06-13T13:56:57.776211Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Wavenet(pad,skipDim,quantization_channels,residualDim,dilations).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#in wavenet paper, they said crossentropyloss is far better than MSELoss\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3,weight_decay=1e-5)\n",
    "#use adam to train\n",
    "#optimizer = optim.SGD(model.parameters(), lr = 0.1, momentum=0.9, weight_decay=1e-5)\n",
    "#scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[20,40], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:57:02.683013Z",
     "start_time": "2018-06-13T13:57:02.671907Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if continueTrain:# if continueTrain, the program will find the checkpoints\n",
    "    if os.path.isfile(resumefile):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resumefile))\n",
    "        checkpoint = torch.load(resumefile)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        #best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(resumefile, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resumefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-13T13:56:55.343Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def val(xtrain,ytrain): #validation last 15 seconds of the audio.\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        idx = np.arange(xtrain.shape[-1]-pad-10*sampleSize,xtrain.shape[-1]-pad-sampleSize,1000)\n",
    "        np.random.shuffle(idx)\n",
    "        data = xtrain[:,:,idx[0]-pad:pad+idx[0]+sampleSize].to(device)\n",
    "        target = ytrain[:,idx[0]:idx[0]+sampleSize].to(device)\n",
    "        output = model(data)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item() / pred.shape[-1]\n",
    "        val_loss = criterion(output, target).item()\n",
    "        print(correct,'accurate')\n",
    "        print('\\nval set:loss{:.4f}:, ({:.3f} sec/step)\\n'.format(val_loss,time.time()-start_time))\n",
    "        \n",
    "        listofpred = []\n",
    "        for ind in range(xtrain.shape[-1]-pad-10*sampleSize,xtrain.shape[-1]-pad-sampleSize,sampleSize):\n",
    "            output = model(xtrain[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "            pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "            listofpred.append(pred)\n",
    "        ans = mu_law_decode(np.concatenate(listofpred))\n",
    "        sf.write('./vsCorpus/notexval.wav', ans, sample_rate)\n",
    "        print('val stored done',time.time() - start_time)\n",
    "        \n",
    "\n",
    "def test(xtrain):# testing data\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for iloader,(xtest,_) in enumerate(loadval):\n",
    "            listofpred = []\n",
    "            for ind in range(pad, xtest.shape[-1] - pad, sampleSize):\n",
    "                output = model(xtest[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "                pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "                listofpred.append(pred)\n",
    "            ans = mu_law_decode(np.concatenate(listofpred))\n",
    "            sf.write('./vsCorpus/notexte.wav', ans, sample_rate)\n",
    "\n",
    "            listofpred=[]\n",
    "            for ind in range(pad,xtrain.shape[-1]-pad,sampleSize):\n",
    "                output = model(xtrain[:, :, ind-pad:ind+sampleSize+pad].to(device))\n",
    "                pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "                listofpred.append(pred)\n",
    "            ans = mu_law_decode(np.concatenate(listofpred))\n",
    "            sf.write('./vsCorpus/notextr.wav', ans, sample_rate)\n",
    "            print('test stored done',time.time() - start_time)\n",
    "    \n",
    "def train(epoch):#training data, the audio except for last 15 seconds\n",
    "    model.train()\n",
    "    for iloader,(xtrain,ytrain) in enumerate(loadtr):\n",
    "        idx = np.arange(pad,xtrain.shape[-1]-pad-11*sampleSize,16000)\n",
    "        np.random.shuffle(idx)#random the starting points\n",
    "        for i, ind in enumerate(idx):\n",
    "            start_time = time.time()\n",
    "            data, target = xtrain[:,:,ind-pad:ind+sampleSize+pad].to(device), ytrain[:,ind:ind+sampleSize].to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            lossrecord.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss:{:.6f}: , ({:.3f} sec/step)'.format(\n",
    "                    epoch, i, len(idx),100. * i / len(idx), loss.item(),time.time() - start_time))\n",
    "            if i % 100 == 0:\n",
    "                with open(\"./lossRecord/\"+lossname, \"w\") as f:\n",
    "                    for s in lossrecord:\n",
    "                        f.write(str(s) +\"\\n\")\n",
    "                print('write finish')\n",
    "\n",
    "        val(xtrain,ytrain)\n",
    "        test(xtrain)\n",
    "        state={'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()}\n",
    "        torch.save(state, './model/'+resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-13T13:56:55.347Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/225 (0%)] Loss:5.562654: , (0.992 sec/step)\n",
      "write finish\n",
      "Train Epoch: 0 [1/225 (0%)] Loss:5.716089: , (0.964 sec/step)\n",
      "Train Epoch: 0 [2/225 (1%)] Loss:5.495899: , (0.967 sec/step)\n",
      "Train Epoch: 0 [3/225 (1%)] Loss:5.518339: , (0.958 sec/step)\n",
      "Train Epoch: 0 [4/225 (2%)] Loss:5.429954: , (0.962 sec/step)\n",
      "Train Epoch: 0 [5/225 (2%)] Loss:5.460109: , (0.962 sec/step)\n",
      "Train Epoch: 0 [6/225 (3%)] Loss:5.232277: , (0.960 sec/step)\n",
      "Train Epoch: 0 [7/225 (3%)] Loss:5.163388: , (0.961 sec/step)\n",
      "Train Epoch: 0 [8/225 (4%)] Loss:5.154132: , (0.959 sec/step)\n",
      "Train Epoch: 0 [9/225 (4%)] Loss:5.220576: , (0.962 sec/step)\n",
      "Train Epoch: 0 [10/225 (4%)] Loss:4.981515: , (0.968 sec/step)\n",
      "Train Epoch: 0 [11/225 (5%)] Loss:5.163872: , (0.963 sec/step)\n",
      "Train Epoch: 0 [12/225 (5%)] Loss:5.216908: , (0.968 sec/step)\n",
      "Train Epoch: 0 [13/225 (6%)] Loss:5.115715: , (0.968 sec/step)\n",
      "Train Epoch: 0 [14/225 (6%)] Loss:5.255981: , (0.970 sec/step)\n",
      "Train Epoch: 0 [15/225 (7%)] Loss:5.089722: , (0.962 sec/step)\n",
      "Train Epoch: 0 [16/225 (7%)] Loss:5.098732: , (0.967 sec/step)\n",
      "Train Epoch: 0 [17/225 (8%)] Loss:5.002105: , (0.962 sec/step)\n",
      "Train Epoch: 0 [18/225 (8%)] Loss:5.293984: , (0.962 sec/step)\n",
      "Train Epoch: 0 [19/225 (8%)] Loss:5.544025: , (0.969 sec/step)\n",
      "Train Epoch: 0 [20/225 (9%)] Loss:5.086675: , (0.968 sec/step)\n",
      "Train Epoch: 0 [21/225 (9%)] Loss:5.157087: , (0.964 sec/step)\n",
      "Train Epoch: 0 [22/225 (10%)] Loss:5.097489: , (0.967 sec/step)\n",
      "Train Epoch: 0 [23/225 (10%)] Loss:5.047933: , (0.972 sec/step)\n",
      "Train Epoch: 0 [24/225 (11%)] Loss:5.382326: , (0.968 sec/step)\n",
      "Train Epoch: 0 [25/225 (11%)] Loss:5.156254: , (0.969 sec/step)\n",
      "Train Epoch: 0 [26/225 (12%)] Loss:5.215007: , (0.973 sec/step)\n",
      "Train Epoch: 0 [27/225 (12%)] Loss:5.104496: , (0.967 sec/step)\n",
      "Train Epoch: 0 [28/225 (12%)] Loss:5.067018: , (0.969 sec/step)\n",
      "Train Epoch: 0 [29/225 (13%)] Loss:5.369797: , (0.968 sec/step)\n",
      "Train Epoch: 0 [30/225 (13%)] Loss:4.996730: , (0.970 sec/step)\n",
      "Train Epoch: 0 [31/225 (14%)] Loss:5.089293: , (0.968 sec/step)\n",
      "Train Epoch: 0 [32/225 (14%)] Loss:5.313207: , (0.965 sec/step)\n",
      "Train Epoch: 0 [33/225 (15%)] Loss:5.113919: , (0.969 sec/step)\n",
      "Train Epoch: 0 [34/225 (15%)] Loss:5.010753: , (0.967 sec/step)\n",
      "Train Epoch: 0 [35/225 (16%)] Loss:4.909447: , (0.967 sec/step)\n",
      "Train Epoch: 0 [36/225 (16%)] Loss:5.059819: , (0.967 sec/step)\n",
      "Train Epoch: 0 [37/225 (16%)] Loss:5.180137: , (0.966 sec/step)\n",
      "Train Epoch: 0 [38/225 (17%)] Loss:5.297040: , (0.965 sec/step)\n",
      "Train Epoch: 0 [39/225 (17%)] Loss:4.980281: , (0.965 sec/step)\n",
      "Train Epoch: 0 [40/225 (18%)] Loss:4.983051: , (0.966 sec/step)\n",
      "Train Epoch: 0 [41/225 (18%)] Loss:4.983532: , (0.968 sec/step)\n",
      "Train Epoch: 0 [42/225 (19%)] Loss:4.959545: , (0.967 sec/step)\n",
      "Train Epoch: 0 [43/225 (19%)] Loss:4.912762: , (0.967 sec/step)\n",
      "Train Epoch: 0 [44/225 (20%)] Loss:4.957312: , (0.966 sec/step)\n",
      "Train Epoch: 0 [45/225 (20%)] Loss:5.290670: , (0.967 sec/step)\n",
      "Train Epoch: 0 [46/225 (20%)] Loss:5.731941: , (0.964 sec/step)\n",
      "Train Epoch: 0 [47/225 (21%)] Loss:5.141293: , (0.965 sec/step)\n",
      "Train Epoch: 0 [48/225 (21%)] Loss:5.030804: , (0.968 sec/step)\n",
      "Train Epoch: 0 [49/225 (22%)] Loss:4.797207: , (0.971 sec/step)\n",
      "Train Epoch: 0 [50/225 (22%)] Loss:4.991424: , (0.967 sec/step)\n",
      "Train Epoch: 0 [51/225 (23%)] Loss:5.303397: , (0.968 sec/step)\n",
      "Train Epoch: 0 [52/225 (23%)] Loss:5.386720: , (0.973 sec/step)\n",
      "Train Epoch: 0 [53/225 (24%)] Loss:5.037517: , (0.966 sec/step)\n",
      "Train Epoch: 0 [54/225 (24%)] Loss:4.969516: , (0.972 sec/step)\n",
      "Train Epoch: 0 [55/225 (24%)] Loss:5.137751: , (0.967 sec/step)\n",
      "Train Epoch: 0 [56/225 (25%)] Loss:5.091533: , (0.971 sec/step)\n",
      "Train Epoch: 0 [57/225 (25%)] Loss:4.960257: , (0.966 sec/step)\n",
      "Train Epoch: 0 [58/225 (26%)] Loss:5.034120: , (0.970 sec/step)\n",
      "Train Epoch: 0 [59/225 (26%)] Loss:4.966536: , (0.974 sec/step)\n",
      "Train Epoch: 0 [60/225 (27%)] Loss:5.504070: , (0.971 sec/step)\n",
      "Train Epoch: 0 [61/225 (27%)] Loss:5.041726: , (0.974 sec/step)\n",
      "Train Epoch: 0 [62/225 (28%)] Loss:5.183050: , (0.971 sec/step)\n",
      "Train Epoch: 0 [63/225 (28%)] Loss:5.117734: , (0.969 sec/step)\n",
      "Train Epoch: 0 [64/225 (28%)] Loss:5.251432: , (0.969 sec/step)\n",
      "Train Epoch: 0 [65/225 (29%)] Loss:5.025191: , (0.971 sec/step)\n",
      "Train Epoch: 0 [66/225 (29%)] Loss:5.009180: , (0.970 sec/step)\n",
      "Train Epoch: 0 [67/225 (30%)] Loss:5.025342: , (0.969 sec/step)\n",
      "Train Epoch: 0 [68/225 (30%)] Loss:5.023200: , (0.968 sec/step)\n",
      "Train Epoch: 0 [69/225 (31%)] Loss:4.913152: , (0.970 sec/step)\n",
      "Train Epoch: 0 [70/225 (31%)] Loss:4.983978: , (0.969 sec/step)\n",
      "Train Epoch: 0 [71/225 (32%)] Loss:5.154137: , (0.969 sec/step)\n",
      "Train Epoch: 0 [72/225 (32%)] Loss:4.855218: , (0.969 sec/step)\n",
      "Train Epoch: 0 [73/225 (32%)] Loss:4.862963: , (0.974 sec/step)\n",
      "Train Epoch: 0 [74/225 (33%)] Loss:4.986695: , (0.967 sec/step)\n",
      "Train Epoch: 0 [75/225 (33%)] Loss:4.724514: , (0.971 sec/step)\n",
      "Train Epoch: 0 [76/225 (34%)] Loss:5.294784: , (0.969 sec/step)\n",
      "Train Epoch: 0 [77/225 (34%)] Loss:4.668725: , (0.969 sec/step)\n",
      "Train Epoch: 0 [78/225 (35%)] Loss:4.809318: , (0.969 sec/step)\n",
      "Train Epoch: 0 [79/225 (35%)] Loss:4.786165: , (0.972 sec/step)\n",
      "Train Epoch: 0 [80/225 (36%)] Loss:4.738842: , (0.970 sec/step)\n",
      "Train Epoch: 0 [81/225 (36%)] Loss:4.708056: , (0.968 sec/step)\n",
      "Train Epoch: 0 [82/225 (36%)] Loss:4.920041: , (0.965 sec/step)\n",
      "Train Epoch: 0 [83/225 (37%)] Loss:4.950016: , (0.965 sec/step)\n",
      "Train Epoch: 0 [84/225 (37%)] Loss:4.742284: , (0.973 sec/step)\n",
      "Train Epoch: 0 [85/225 (38%)] Loss:4.902220: , (0.967 sec/step)\n",
      "Train Epoch: 0 [86/225 (38%)] Loss:4.647994: , (0.968 sec/step)\n",
      "Train Epoch: 0 [87/225 (39%)] Loss:5.040668: , (0.969 sec/step)\n",
      "Train Epoch: 0 [88/225 (39%)] Loss:4.848823: , (0.963 sec/step)\n",
      "Train Epoch: 0 [89/225 (40%)] Loss:4.676458: , (0.964 sec/step)\n",
      "Train Epoch: 0 [90/225 (40%)] Loss:4.898558: , (0.964 sec/step)\n",
      "Train Epoch: 0 [91/225 (40%)] Loss:5.535730: , (0.964 sec/step)\n",
      "Train Epoch: 0 [92/225 (41%)] Loss:4.923197: , (0.971 sec/step)\n",
      "Train Epoch: 0 [93/225 (41%)] Loss:4.711740: , (0.966 sec/step)\n",
      "Train Epoch: 0 [94/225 (42%)] Loss:4.872523: , (0.967 sec/step)\n",
      "Train Epoch: 0 [95/225 (42%)] Loss:4.823025: , (0.963 sec/step)\n",
      "Train Epoch: 0 [96/225 (43%)] Loss:4.583892: , (0.967 sec/step)\n",
      "Train Epoch: 0 [97/225 (43%)] Loss:5.173486: , (0.968 sec/step)\n",
      "Train Epoch: 0 [98/225 (44%)] Loss:4.671267: , (0.968 sec/step)\n",
      "Train Epoch: 0 [99/225 (44%)] Loss:4.815291: , (0.968 sec/step)\n",
      "Train Epoch: 0 [100/225 (44%)] Loss:4.743950: , (0.967 sec/step)\n",
      "write finish\n",
      "Train Epoch: 0 [101/225 (45%)] Loss:4.819713: , (0.969 sec/step)\n",
      "Train Epoch: 0 [102/225 (45%)] Loss:4.770731: , (0.973 sec/step)\n",
      "Train Epoch: 0 [103/225 (46%)] Loss:4.948306: , (0.969 sec/step)\n",
      "Train Epoch: 0 [104/225 (46%)] Loss:4.674835: , (0.968 sec/step)\n",
      "Train Epoch: 0 [105/225 (47%)] Loss:5.049408: , (0.969 sec/step)\n",
      "Train Epoch: 0 [106/225 (47%)] Loss:4.741433: , (0.969 sec/step)\n",
      "Train Epoch: 0 [107/225 (48%)] Loss:4.693145: , (0.970 sec/step)\n",
      "Train Epoch: 0 [108/225 (48%)] Loss:4.927032: , (0.969 sec/step)\n",
      "Train Epoch: 0 [109/225 (48%)] Loss:4.569774: , (0.969 sec/step)\n",
      "Train Epoch: 0 [110/225 (49%)] Loss:4.777620: , (0.969 sec/step)\n",
      "Train Epoch: 0 [111/225 (49%)] Loss:4.924980: , (0.969 sec/step)\n",
      "Train Epoch: 0 [112/225 (50%)] Loss:4.735942: , (0.973 sec/step)\n",
      "Train Epoch: 0 [113/225 (50%)] Loss:4.694448: , (0.968 sec/step)\n",
      "Train Epoch: 0 [114/225 (51%)] Loss:4.559412: , (0.968 sec/step)\n",
      "Train Epoch: 0 [115/225 (51%)] Loss:4.608974: , (0.963 sec/step)\n",
      "Train Epoch: 0 [116/225 (52%)] Loss:4.743071: , (0.964 sec/step)\n",
      "Train Epoch: 0 [117/225 (52%)] Loss:5.384665: , (0.970 sec/step)\n",
      "Train Epoch: 0 [118/225 (52%)] Loss:4.652910: , (0.969 sec/step)\n",
      "Train Epoch: 0 [119/225 (53%)] Loss:4.530834: , (0.970 sec/step)\n",
      "Train Epoch: 0 [120/225 (53%)] Loss:4.607334: , (0.969 sec/step)\n",
      "Train Epoch: 0 [121/225 (54%)] Loss:4.522105: , (0.968 sec/step)\n",
      "Train Epoch: 0 [122/225 (54%)] Loss:4.729160: , (0.969 sec/step)\n",
      "Train Epoch: 0 [123/225 (55%)] Loss:5.255981: , (0.974 sec/step)\n",
      "Train Epoch: 0 [124/225 (55%)] Loss:4.597700: , (0.968 sec/step)\n",
      "Train Epoch: 0 [125/225 (56%)] Loss:4.685538: , (0.965 sec/step)\n",
      "Train Epoch: 0 [126/225 (56%)] Loss:4.834816: , (0.966 sec/step)\n",
      "Train Epoch: 0 [127/225 (56%)] Loss:4.438421: , (0.968 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [128/225 (57%)] Loss:4.587815: , (0.974 sec/step)\n",
      "Train Epoch: 0 [129/225 (57%)] Loss:4.511615: , (0.985 sec/step)\n",
      "Train Epoch: 0 [130/225 (58%)] Loss:4.595767: , (0.969 sec/step)\n",
      "Train Epoch: 0 [131/225 (58%)] Loss:4.736981: , (0.969 sec/step)\n",
      "Train Epoch: 0 [132/225 (59%)] Loss:5.643888: , (0.969 sec/step)\n",
      "Train Epoch: 0 [133/225 (59%)] Loss:4.479773: , (0.974 sec/step)\n",
      "Train Epoch: 0 [134/225 (60%)] Loss:4.942872: , (0.969 sec/step)\n",
      "Train Epoch: 0 [135/225 (60%)] Loss:4.592852: , (0.969 sec/step)\n",
      "Train Epoch: 0 [136/225 (60%)] Loss:4.824415: , (0.972 sec/step)\n",
      "Train Epoch: 0 [137/225 (61%)] Loss:4.917338: , (0.970 sec/step)\n",
      "Train Epoch: 0 [138/225 (61%)] Loss:4.709607: , (0.969 sec/step)\n",
      "Train Epoch: 0 [139/225 (62%)] Loss:4.600952: , (0.969 sec/step)\n",
      "Train Epoch: 0 [140/225 (62%)] Loss:4.496799: , (0.971 sec/step)\n",
      "Train Epoch: 0 [141/225 (63%)] Loss:4.965366: , (0.967 sec/step)\n",
      "Train Epoch: 0 [142/225 (63%)] Loss:4.983974: , (0.970 sec/step)\n",
      "Train Epoch: 0 [143/225 (64%)] Loss:4.836432: , (0.977 sec/step)\n",
      "Train Epoch: 0 [144/225 (64%)] Loss:4.748126: , (0.972 sec/step)\n",
      "Train Epoch: 0 [145/225 (64%)] Loss:4.556406: , (0.970 sec/step)\n",
      "Train Epoch: 0 [146/225 (65%)] Loss:4.671785: , (0.974 sec/step)\n",
      "Train Epoch: 0 [147/225 (65%)] Loss:4.819889: , (0.974 sec/step)\n",
      "Train Epoch: 0 [148/225 (66%)] Loss:4.759358: , (0.975 sec/step)\n",
      "Train Epoch: 0 [149/225 (66%)] Loss:4.830353: , (0.969 sec/step)\n",
      "Train Epoch: 0 [150/225 (67%)] Loss:4.506007: , (0.969 sec/step)\n",
      "Train Epoch: 0 [151/225 (67%)] Loss:4.692760: , (0.974 sec/step)\n",
      "Train Epoch: 0 [152/225 (68%)] Loss:4.659531: , (0.969 sec/step)\n",
      "Train Epoch: 0 [153/225 (68%)] Loss:4.595487: , (0.970 sec/step)\n",
      "Train Epoch: 0 [154/225 (68%)] Loss:5.224373: , (0.970 sec/step)\n",
      "Train Epoch: 0 [155/225 (69%)] Loss:5.236339: , (0.970 sec/step)\n",
      "Train Epoch: 0 [156/225 (69%)] Loss:4.912311: , (0.970 sec/step)\n",
      "Train Epoch: 0 [157/225 (70%)] Loss:5.010794: , (0.971 sec/step)\n",
      "Train Epoch: 0 [158/225 (70%)] Loss:5.017382: , (0.973 sec/step)\n",
      "Train Epoch: 0 [159/225 (71%)] Loss:4.989830: , (0.974 sec/step)\n",
      "Train Epoch: 0 [160/225 (71%)] Loss:4.851320: , (0.967 sec/step)\n",
      "Train Epoch: 0 [161/225 (72%)] Loss:5.098825: , (0.969 sec/step)\n",
      "Train Epoch: 0 [162/225 (72%)] Loss:4.611209: , (0.970 sec/step)\n",
      "Train Epoch: 0 [163/225 (72%)] Loss:4.902143: , (0.974 sec/step)\n",
      "Train Epoch: 0 [164/225 (73%)] Loss:4.554415: , (0.966 sec/step)\n",
      "Train Epoch: 0 [165/225 (73%)] Loss:4.582911: , (0.965 sec/step)\n",
      "Train Epoch: 0 [166/225 (74%)] Loss:4.650445: , (0.969 sec/step)\n",
      "Train Epoch: 0 [167/225 (74%)] Loss:4.549505: , (0.971 sec/step)\n",
      "Train Epoch: 0 [168/225 (75%)] Loss:4.659379: , (0.969 sec/step)\n",
      "Train Epoch: 0 [169/225 (75%)] Loss:5.181846: , (0.969 sec/step)\n",
      "Train Epoch: 0 [170/225 (76%)] Loss:4.674181: , (0.969 sec/step)\n",
      "Train Epoch: 0 [171/225 (76%)] Loss:4.836667: , (0.971 sec/step)\n",
      "Train Epoch: 0 [172/225 (76%)] Loss:4.442369: , (0.969 sec/step)\n",
      "Train Epoch: 0 [173/225 (77%)] Loss:4.509300: , (0.966 sec/step)\n",
      "Train Epoch: 0 [174/225 (77%)] Loss:4.933115: , (0.972 sec/step)\n",
      "Train Epoch: 0 [175/225 (78%)] Loss:4.710429: , (0.969 sec/step)\n",
      "Train Epoch: 0 [176/225 (78%)] Loss:4.659003: , (0.968 sec/step)\n",
      "Train Epoch: 0 [177/225 (79%)] Loss:4.492382: , (0.965 sec/step)\n",
      "Train Epoch: 0 [178/225 (79%)] Loss:4.573504: , (0.966 sec/step)\n",
      "Train Epoch: 0 [179/225 (80%)] Loss:4.785060: , (0.973 sec/step)\n",
      "Train Epoch: 0 [180/225 (80%)] Loss:4.844397: , (0.968 sec/step)\n",
      "Train Epoch: 0 [181/225 (80%)] Loss:4.913287: , (0.975 sec/step)\n",
      "Train Epoch: 0 [182/225 (81%)] Loss:4.375165: , (0.967 sec/step)\n",
      "Train Epoch: 0 [183/225 (81%)] Loss:4.476277: , (0.969 sec/step)\n",
      "Train Epoch: 0 [184/225 (82%)] Loss:4.640912: , (0.970 sec/step)\n",
      "Train Epoch: 0 [185/225 (82%)] Loss:4.619507: , (0.970 sec/step)\n",
      "Train Epoch: 0 [186/225 (83%)] Loss:4.727063: , (0.969 sec/step)\n",
      "Train Epoch: 0 [187/225 (83%)] Loss:4.844348: , (0.970 sec/step)\n",
      "Train Epoch: 0 [188/225 (84%)] Loss:4.689513: , (0.969 sec/step)\n",
      "Train Epoch: 0 [189/225 (84%)] Loss:4.585379: , (0.972 sec/step)\n",
      "Train Epoch: 0 [190/225 (84%)] Loss:4.656536: , (0.970 sec/step)\n",
      "Train Epoch: 0 [191/225 (85%)] Loss:4.593309: , (0.971 sec/step)\n",
      "Train Epoch: 0 [192/225 (85%)] Loss:4.422370: , (0.972 sec/step)\n",
      "Train Epoch: 0 [193/225 (86%)] Loss:4.895529: , (0.971 sec/step)\n",
      "Train Epoch: 0 [194/225 (86%)] Loss:4.668413: , (0.969 sec/step)\n",
      "Train Epoch: 0 [195/225 (87%)] Loss:4.578629: , (0.971 sec/step)\n",
      "Train Epoch: 0 [196/225 (87%)] Loss:4.448452: , (0.971 sec/step)\n",
      "Train Epoch: 0 [197/225 (88%)] Loss:4.765522: , (0.970 sec/step)\n",
      "Train Epoch: 0 [198/225 (88%)] Loss:4.461183: , (0.971 sec/step)\n",
      "Train Epoch: 0 [199/225 (88%)] Loss:4.435691: , (0.977 sec/step)\n",
      "Train Epoch: 0 [200/225 (89%)] Loss:4.506879: , (0.977 sec/step)\n",
      "write finish\n",
      "Train Epoch: 0 [201/225 (89%)] Loss:4.628365: , (0.977 sec/step)\n",
      "Train Epoch: 0 [202/225 (90%)] Loss:4.356676: , (0.972 sec/step)\n",
      "Train Epoch: 0 [203/225 (90%)] Loss:4.872477: , (0.971 sec/step)\n",
      "Train Epoch: 0 [204/225 (91%)] Loss:4.568497: , (0.968 sec/step)\n",
      "Train Epoch: 0 [205/225 (91%)] Loss:5.356275: , (0.970 sec/step)\n",
      "Train Epoch: 0 [206/225 (92%)] Loss:4.696265: , (0.968 sec/step)\n",
      "Train Epoch: 0 [207/225 (92%)] Loss:5.144825: , (0.972 sec/step)\n",
      "Train Epoch: 0 [208/225 (92%)] Loss:4.313738: , (0.969 sec/step)\n",
      "Train Epoch: 0 [209/225 (93%)] Loss:4.797860: , (0.974 sec/step)\n",
      "Train Epoch: 0 [210/225 (93%)] Loss:4.518174: , (0.969 sec/step)\n",
      "Train Epoch: 0 [211/225 (94%)] Loss:4.638374: , (0.968 sec/step)\n",
      "Train Epoch: 0 [212/225 (94%)] Loss:4.784343: , (0.969 sec/step)\n",
      "Train Epoch: 0 [213/225 (95%)] Loss:4.985952: , (0.963 sec/step)\n",
      "Train Epoch: 0 [214/225 (95%)] Loss:4.503131: , (0.963 sec/step)\n",
      "Train Epoch: 0 [215/225 (96%)] Loss:4.688854: , (0.967 sec/step)\n",
      "Train Epoch: 0 [216/225 (96%)] Loss:4.824499: , (0.974 sec/step)\n",
      "Train Epoch: 0 [217/225 (96%)] Loss:4.914196: , (0.967 sec/step)\n",
      "Train Epoch: 0 [218/225 (97%)] Loss:4.475874: , (0.967 sec/step)\n",
      "Train Epoch: 0 [219/225 (97%)] Loss:4.963628: , (0.968 sec/step)\n",
      "Train Epoch: 0 [220/225 (98%)] Loss:4.553228: , (0.967 sec/step)\n",
      "Train Epoch: 0 [221/225 (98%)] Loss:5.062594: , (0.977 sec/step)\n",
      "Train Epoch: 0 [222/225 (99%)] Loss:4.698453: , (0.972 sec/step)\n",
      "Train Epoch: 0 [223/225 (99%)] Loss:4.501914: , (0.974 sec/step)\n",
      "Train Epoch: 0 [224/225 (100%)] Loss:4.501676: , (0.965 sec/step)\n",
      "0.0128125 accurate\n",
      "\n",
      "val set:loss5.0721:, (0.299 sec/step)\n",
      "\n",
      "val stored done 2.996603488922119\n",
      "test stored done 75.25654649734497\n",
      "Train Epoch: 1 [0/225 (0%)] Loss:4.734784: , (0.973 sec/step)\n",
      "write finish\n",
      "Train Epoch: 1 [1/225 (0%)] Loss:4.736379: , (0.968 sec/step)\n",
      "Train Epoch: 1 [2/225 (1%)] Loss:4.703381: , (0.971 sec/step)\n",
      "Train Epoch: 1 [3/225 (1%)] Loss:4.521787: , (0.972 sec/step)\n",
      "Train Epoch: 1 [4/225 (2%)] Loss:4.600588: , (0.970 sec/step)\n",
      "Train Epoch: 1 [5/225 (2%)] Loss:4.280152: , (0.974 sec/step)\n",
      "Train Epoch: 1 [6/225 (3%)] Loss:5.940082: , (0.970 sec/step)\n",
      "Train Epoch: 1 [7/225 (3%)] Loss:4.605032: , (0.979 sec/step)\n",
      "Train Epoch: 1 [8/225 (4%)] Loss:4.946275: , (0.970 sec/step)\n",
      "Train Epoch: 1 [9/225 (4%)] Loss:4.650243: , (0.966 sec/step)\n",
      "Train Epoch: 1 [10/225 (4%)] Loss:4.678780: , (0.973 sec/step)\n",
      "Train Epoch: 1 [11/225 (5%)] Loss:4.701249: , (0.974 sec/step)\n",
      "Train Epoch: 1 [12/225 (5%)] Loss:4.520621: , (0.968 sec/step)\n",
      "Train Epoch: 1 [13/225 (6%)] Loss:4.506123: , (0.973 sec/step)\n",
      "Train Epoch: 1 [14/225 (6%)] Loss:4.369358: , (0.966 sec/step)\n",
      "Train Epoch: 1 [15/225 (7%)] Loss:4.638701: , (0.968 sec/step)\n",
      "Train Epoch: 1 [16/225 (7%)] Loss:4.613545: , (0.970 sec/step)\n",
      "Train Epoch: 1 [17/225 (8%)] Loss:4.345858: , (0.970 sec/step)\n",
      "Train Epoch: 1 [18/225 (8%)] Loss:4.897330: , (0.968 sec/step)\n",
      "Train Epoch: 1 [19/225 (8%)] Loss:5.111693: , (0.968 sec/step)\n",
      "Train Epoch: 1 [20/225 (9%)] Loss:4.809963: , (0.968 sec/step)\n",
      "Train Epoch: 1 [21/225 (9%)] Loss:4.948494: , (0.969 sec/step)\n",
      "Train Epoch: 1 [22/225 (10%)] Loss:4.786725: , (0.972 sec/step)\n",
      "Train Epoch: 1 [23/225 (10%)] Loss:4.782001: , (0.965 sec/step)\n",
      "Train Epoch: 1 [24/225 (11%)] Loss:4.770505: , (0.970 sec/step)\n",
      "Train Epoch: 1 [25/225 (11%)] Loss:4.749779: , (0.972 sec/step)\n",
      "Train Epoch: 1 [26/225 (12%)] Loss:4.626399: , (0.969 sec/step)\n",
      "Train Epoch: 1 [27/225 (12%)] Loss:4.474505: , (0.970 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [28/225 (12%)] Loss:4.517032: , (0.969 sec/step)\n",
      "Train Epoch: 1 [29/225 (13%)] Loss:5.141685: , (0.974 sec/step)\n",
      "Train Epoch: 1 [30/225 (13%)] Loss:4.640535: , (0.968 sec/step)\n",
      "Train Epoch: 1 [31/225 (14%)] Loss:4.736751: , (0.970 sec/step)\n",
      "Train Epoch: 1 [32/225 (14%)] Loss:4.820307: , (0.968 sec/step)\n",
      "Train Epoch: 1 [33/225 (15%)] Loss:4.892005: , (0.973 sec/step)\n",
      "Train Epoch: 1 [34/225 (15%)] Loss:4.692860: , (0.968 sec/step)\n",
      "Train Epoch: 1 [35/225 (16%)] Loss:4.588810: , (0.973 sec/step)\n",
      "Train Epoch: 1 [36/225 (16%)] Loss:4.665474: , (0.970 sec/step)\n",
      "Train Epoch: 1 [37/225 (16%)] Loss:4.461129: , (0.968 sec/step)\n",
      "Train Epoch: 1 [38/225 (17%)] Loss:5.208352: , (0.972 sec/step)\n",
      "Train Epoch: 1 [39/225 (17%)] Loss:4.843254: , (0.972 sec/step)\n",
      "Train Epoch: 1 [40/225 (18%)] Loss:5.012890: , (0.975 sec/step)\n",
      "Train Epoch: 1 [41/225 (18%)] Loss:4.853118: , (0.971 sec/step)\n",
      "Train Epoch: 1 [42/225 (19%)] Loss:4.825848: , (0.970 sec/step)\n",
      "Train Epoch: 1 [43/225 (19%)] Loss:4.879505: , (0.968 sec/step)\n",
      "Train Epoch: 1 [44/225 (20%)] Loss:4.737422: , (0.969 sec/step)\n",
      "Train Epoch: 1 [45/225 (20%)] Loss:4.655277: , (0.971 sec/step)\n",
      "Train Epoch: 1 [46/225 (20%)] Loss:5.013679: , (0.969 sec/step)\n",
      "Train Epoch: 1 [47/225 (21%)] Loss:4.637033: , (0.967 sec/step)\n",
      "Train Epoch: 1 [48/225 (21%)] Loss:4.587505: , (0.968 sec/step)\n",
      "Train Epoch: 1 [49/225 (22%)] Loss:4.950667: , (0.972 sec/step)\n",
      "Train Epoch: 1 [50/225 (22%)] Loss:4.427038: , (0.971 sec/step)\n",
      "Train Epoch: 1 [51/225 (23%)] Loss:4.455565: , (0.972 sec/step)\n",
      "Train Epoch: 1 [52/225 (23%)] Loss:4.423059: , (0.975 sec/step)\n",
      "Train Epoch: 1 [53/225 (24%)] Loss:4.563010: , (0.971 sec/step)\n",
      "Train Epoch: 1 [54/225 (24%)] Loss:4.568380: , (0.971 sec/step)\n",
      "Train Epoch: 1 [55/225 (24%)] Loss:4.522532: , (0.968 sec/step)\n",
      "Train Epoch: 1 [56/225 (25%)] Loss:5.389234: , (0.971 sec/step)\n",
      "Train Epoch: 1 [57/225 (25%)] Loss:4.612248: , (0.971 sec/step)\n",
      "Train Epoch: 1 [58/225 (26%)] Loss:4.437223: , (0.968 sec/step)\n",
      "Train Epoch: 1 [59/225 (26%)] Loss:4.536742: , (0.970 sec/step)\n",
      "Train Epoch: 1 [60/225 (27%)] Loss:4.310390: , (0.969 sec/step)\n",
      "Train Epoch: 1 [61/225 (27%)] Loss:4.643347: , (0.969 sec/step)\n",
      "Train Epoch: 1 [62/225 (28%)] Loss:4.317976: , (0.971 sec/step)\n",
      "Train Epoch: 1 [63/225 (28%)] Loss:4.519794: , (0.968 sec/step)\n",
      "Train Epoch: 1 [64/225 (28%)] Loss:4.407760: , (0.966 sec/step)\n",
      "Train Epoch: 1 [65/225 (29%)] Loss:4.585119: , (0.966 sec/step)\n",
      "Train Epoch: 1 [66/225 (29%)] Loss:4.480191: , (0.968 sec/step)\n",
      "Train Epoch: 1 [67/225 (30%)] Loss:4.310863: , (0.968 sec/step)\n",
      "Train Epoch: 1 [68/225 (30%)] Loss:4.888956: , (0.968 sec/step)\n",
      "Train Epoch: 1 [69/225 (31%)] Loss:4.581997: , (0.968 sec/step)\n",
      "Train Epoch: 1 [70/225 (31%)] Loss:4.969137: , (0.964 sec/step)\n",
      "Train Epoch: 1 [71/225 (32%)] Loss:4.491411: , (0.966 sec/step)\n",
      "Train Epoch: 1 [72/225 (32%)] Loss:4.275666: , (0.966 sec/step)\n",
      "Train Epoch: 1 [73/225 (32%)] Loss:4.514664: , (0.966 sec/step)\n",
      "Train Epoch: 1 [74/225 (33%)] Loss:5.311280: , (0.962 sec/step)\n",
      "Train Epoch: 1 [75/225 (33%)] Loss:4.861123: , (0.967 sec/step)\n",
      "Train Epoch: 1 [76/225 (34%)] Loss:5.279293: , (0.967 sec/step)\n",
      "Train Epoch: 1 [77/225 (34%)] Loss:4.941967: , (0.966 sec/step)\n",
      "Train Epoch: 1 [78/225 (35%)] Loss:4.771451: , (0.965 sec/step)\n",
      "Train Epoch: 1 [79/225 (35%)] Loss:4.831970: , (0.972 sec/step)\n",
      "Train Epoch: 1 [80/225 (36%)] Loss:4.839373: , (0.966 sec/step)\n",
      "Train Epoch: 1 [81/225 (36%)] Loss:4.834942: , (0.967 sec/step)\n",
      "Train Epoch: 1 [82/225 (36%)] Loss:5.080256: , (0.966 sec/step)\n",
      "Train Epoch: 1 [83/225 (37%)] Loss:5.004458: , (0.969 sec/step)\n",
      "Train Epoch: 1 [84/225 (37%)] Loss:4.575897: , (0.968 sec/step)\n",
      "Train Epoch: 1 [85/225 (38%)] Loss:4.873548: , (0.970 sec/step)\n",
      "Train Epoch: 1 [86/225 (38%)] Loss:4.637519: , (0.970 sec/step)\n",
      "Train Epoch: 1 [87/225 (39%)] Loss:4.554435: , (0.969 sec/step)\n",
      "Train Epoch: 1 [88/225 (39%)] Loss:4.779628: , (0.974 sec/step)\n",
      "Train Epoch: 1 [89/225 (40%)] Loss:4.486340: , (0.970 sec/step)\n",
      "Train Epoch: 1 [90/225 (40%)] Loss:5.311067: , (0.970 sec/step)\n",
      "Train Epoch: 1 [91/225 (40%)] Loss:4.620614: , (0.969 sec/step)\n",
      "Train Epoch: 1 [92/225 (41%)] Loss:4.650906: , (0.972 sec/step)\n",
      "Train Epoch: 1 [93/225 (41%)] Loss:4.638417: , (0.972 sec/step)\n",
      "Train Epoch: 1 [94/225 (42%)] Loss:4.345929: , (0.971 sec/step)\n",
      "Train Epoch: 1 [95/225 (42%)] Loss:4.651584: , (0.969 sec/step)\n",
      "Train Epoch: 1 [96/225 (43%)] Loss:4.528720: , (0.969 sec/step)\n",
      "Train Epoch: 1 [97/225 (43%)] Loss:4.742372: , (0.969 sec/step)\n",
      "Train Epoch: 1 [98/225 (44%)] Loss:4.396400: , (0.971 sec/step)\n",
      "Train Epoch: 1 [99/225 (44%)] Loss:4.514745: , (0.972 sec/step)\n",
      "Train Epoch: 1 [100/225 (44%)] Loss:4.595428: , (0.973 sec/step)\n",
      "write finish\n",
      "Train Epoch: 1 [101/225 (45%)] Loss:4.454948: , (0.970 sec/step)\n",
      "Train Epoch: 1 [102/225 (45%)] Loss:4.624988: , (0.972 sec/step)\n",
      "Train Epoch: 1 [103/225 (46%)] Loss:4.327885: , (0.975 sec/step)\n",
      "Train Epoch: 1 [104/225 (46%)] Loss:4.524417: , (0.982 sec/step)\n",
      "Train Epoch: 1 [105/225 (47%)] Loss:4.761003: , (0.971 sec/step)\n",
      "Train Epoch: 1 [106/225 (47%)] Loss:4.623365: , (0.970 sec/step)\n",
      "Train Epoch: 1 [107/225 (48%)] Loss:4.965171: , (0.969 sec/step)\n",
      "Train Epoch: 1 [108/225 (48%)] Loss:4.582920: , (0.967 sec/step)\n",
      "Train Epoch: 1 [109/225 (48%)] Loss:4.693784: , (0.968 sec/step)\n",
      "Train Epoch: 1 [110/225 (49%)] Loss:4.636900: , (0.975 sec/step)\n",
      "Train Epoch: 1 [111/225 (49%)] Loss:4.751303: , (0.973 sec/step)\n",
      "Train Epoch: 1 [112/225 (50%)] Loss:4.465714: , (0.972 sec/step)\n",
      "Train Epoch: 1 [113/225 (50%)] Loss:4.409344: , (0.970 sec/step)\n",
      "Train Epoch: 1 [114/225 (51%)] Loss:4.492617: , (0.974 sec/step)\n",
      "Train Epoch: 1 [115/225 (51%)] Loss:5.002284: , (0.977 sec/step)\n",
      "Train Epoch: 1 [116/225 (52%)] Loss:4.381930: , (0.970 sec/step)\n",
      "Train Epoch: 1 [117/225 (52%)] Loss:4.377234: , (0.968 sec/step)\n",
      "Train Epoch: 1 [118/225 (52%)] Loss:4.536877: , (0.978 sec/step)\n",
      "Train Epoch: 1 [119/225 (53%)] Loss:4.707277: , (0.970 sec/step)\n",
      "Train Epoch: 1 [120/225 (53%)] Loss:4.719771: , (0.964 sec/step)\n",
      "Train Epoch: 1 [121/225 (54%)] Loss:4.691597: , (0.968 sec/step)\n",
      "Train Epoch: 1 [122/225 (54%)] Loss:4.372089: , (0.975 sec/step)\n",
      "Train Epoch: 1 [123/225 (55%)] Loss:4.560735: , (0.968 sec/step)\n",
      "Train Epoch: 1 [124/225 (55%)] Loss:4.704803: , (0.967 sec/step)\n",
      "Train Epoch: 1 [125/225 (56%)] Loss:4.746853: , (0.965 sec/step)\n",
      "Train Epoch: 1 [126/225 (56%)] Loss:4.442989: , (0.967 sec/step)\n",
      "Train Epoch: 1 [127/225 (56%)] Loss:4.958660: , (0.966 sec/step)\n",
      "Train Epoch: 1 [128/225 (57%)] Loss:4.662228: , (0.967 sec/step)\n",
      "Train Epoch: 1 [129/225 (57%)] Loss:4.442957: , (0.966 sec/step)\n",
      "Train Epoch: 1 [130/225 (58%)] Loss:4.666650: , (0.967 sec/step)\n",
      "Train Epoch: 1 [131/225 (58%)] Loss:4.848789: , (0.972 sec/step)\n",
      "Train Epoch: 1 [132/225 (59%)] Loss:4.348295: , (0.970 sec/step)\n",
      "Train Epoch: 1 [133/225 (59%)] Loss:4.469922: , (0.971 sec/step)\n",
      "Train Epoch: 1 [134/225 (60%)] Loss:4.704365: , (0.972 sec/step)\n",
      "Train Epoch: 1 [135/225 (60%)] Loss:4.728700: , (0.967 sec/step)\n",
      "Train Epoch: 1 [136/225 (60%)] Loss:4.569338: , (0.967 sec/step)\n",
      "Train Epoch: 1 [137/225 (61%)] Loss:4.329973: , (0.967 sec/step)\n",
      "Train Epoch: 1 [138/225 (61%)] Loss:4.228675: , (0.971 sec/step)\n",
      "Train Epoch: 1 [139/225 (62%)] Loss:4.505919: , (0.969 sec/step)\n",
      "Train Epoch: 1 [140/225 (62%)] Loss:4.325940: , (0.971 sec/step)\n",
      "Train Epoch: 1 [141/225 (63%)] Loss:4.552537: , (0.969 sec/step)\n",
      "Train Epoch: 1 [142/225 (63%)] Loss:4.612945: , (0.969 sec/step)\n",
      "Train Epoch: 1 [143/225 (64%)] Loss:4.844024: , (0.968 sec/step)\n",
      "Train Epoch: 1 [144/225 (64%)] Loss:4.544017: , (0.969 sec/step)\n",
      "Train Epoch: 1 [145/225 (64%)] Loss:4.645123: , (0.971 sec/step)\n",
      "Train Epoch: 1 [146/225 (65%)] Loss:4.495651: , (0.969 sec/step)\n",
      "Train Epoch: 1 [147/225 (65%)] Loss:5.023765: , (0.969 sec/step)\n",
      "Train Epoch: 1 [148/225 (66%)] Loss:4.948019: , (0.973 sec/step)\n",
      "Train Epoch: 1 [149/225 (66%)] Loss:4.652054: , (0.973 sec/step)\n",
      "Train Epoch: 1 [150/225 (67%)] Loss:4.295935: , (0.966 sec/step)\n",
      "Train Epoch: 1 [151/225 (67%)] Loss:4.672946: , (0.968 sec/step)\n",
      "Train Epoch: 1 [152/225 (68%)] Loss:4.413908: , (0.973 sec/step)\n",
      "Train Epoch: 1 [153/225 (68%)] Loss:4.536675: , (0.971 sec/step)\n",
      "Train Epoch: 1 [154/225 (68%)] Loss:4.829288: , (0.966 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [155/225 (69%)] Loss:4.839801: , (0.970 sec/step)\n",
      "Train Epoch: 1 [156/225 (69%)] Loss:4.435427: , (0.970 sec/step)\n",
      "Train Epoch: 1 [157/225 (70%)] Loss:4.649490: , (0.966 sec/step)\n",
      "Train Epoch: 1 [158/225 (70%)] Loss:4.942344: , (0.968 sec/step)\n",
      "Train Epoch: 1 [159/225 (71%)] Loss:4.704841: , (0.971 sec/step)\n",
      "Train Epoch: 1 [160/225 (71%)] Loss:4.486390: , (0.966 sec/step)\n",
      "Train Epoch: 1 [161/225 (72%)] Loss:4.591437: , (0.971 sec/step)\n",
      "Train Epoch: 1 [162/225 (72%)] Loss:4.338559: , (0.965 sec/step)\n",
      "Train Epoch: 1 [163/225 (72%)] Loss:4.781577: , (0.965 sec/step)\n",
      "Train Epoch: 1 [164/225 (73%)] Loss:4.548286: , (0.968 sec/step)\n",
      "Train Epoch: 1 [165/225 (73%)] Loss:4.853921: , (0.965 sec/step)\n",
      "Train Epoch: 1 [166/225 (74%)] Loss:4.455798: , (0.967 sec/step)\n",
      "Train Epoch: 1 [167/225 (74%)] Loss:4.348245: , (0.972 sec/step)\n",
      "Train Epoch: 1 [168/225 (75%)] Loss:4.317028: , (0.968 sec/step)\n",
      "Train Epoch: 1 [169/225 (75%)] Loss:4.539629: , (0.967 sec/step)\n",
      "Train Epoch: 1 [170/225 (76%)] Loss:4.326192: , (0.968 sec/step)\n",
      "Train Epoch: 1 [171/225 (76%)] Loss:4.660019: , (0.966 sec/step)\n",
      "Train Epoch: 1 [172/225 (76%)] Loss:5.003522: , (0.965 sec/step)\n",
      "Train Epoch: 1 [173/225 (77%)] Loss:4.519968: , (0.964 sec/step)\n",
      "Train Epoch: 1 [174/225 (77%)] Loss:4.478463: , (0.965 sec/step)\n",
      "Train Epoch: 1 [175/225 (78%)] Loss:4.585877: , (0.964 sec/step)\n",
      "Train Epoch: 1 [176/225 (78%)] Loss:4.874780: , (0.966 sec/step)\n",
      "Train Epoch: 1 [177/225 (79%)] Loss:4.478329: , (0.968 sec/step)\n",
      "Train Epoch: 1 [178/225 (79%)] Loss:4.268542: , (0.971 sec/step)\n",
      "Train Epoch: 1 [179/225 (80%)] Loss:4.397337: , (0.970 sec/step)\n",
      "Train Epoch: 1 [180/225 (80%)] Loss:4.693056: , (0.966 sec/step)\n",
      "Train Epoch: 1 [181/225 (80%)] Loss:4.530721: , (0.967 sec/step)\n",
      "Train Epoch: 1 [182/225 (81%)] Loss:4.517642: , (0.969 sec/step)\n",
      "Train Epoch: 1 [183/225 (81%)] Loss:4.669904: , (0.969 sec/step)\n",
      "Train Epoch: 1 [184/225 (82%)] Loss:4.599454: , (0.970 sec/step)\n",
      "Train Epoch: 1 [185/225 (82%)] Loss:4.665568: , (0.970 sec/step)\n",
      "Train Epoch: 1 [186/225 (83%)] Loss:5.235034: , (0.968 sec/step)\n",
      "Train Epoch: 1 [187/225 (83%)] Loss:4.580557: , (0.970 sec/step)\n",
      "Train Epoch: 1 [188/225 (84%)] Loss:4.592892: , (0.970 sec/step)\n",
      "Train Epoch: 1 [189/225 (84%)] Loss:4.713431: , (0.978 sec/step)\n",
      "Train Epoch: 1 [190/225 (84%)] Loss:4.394518: , (0.975 sec/step)\n",
      "Train Epoch: 1 [191/225 (85%)] Loss:4.260485: , (0.972 sec/step)\n",
      "Train Epoch: 1 [192/225 (85%)] Loss:4.143268: , (0.969 sec/step)\n",
      "Train Epoch: 1 [193/225 (86%)] Loss:4.583055: , (0.967 sec/step)\n",
      "Train Epoch: 1 [194/225 (86%)] Loss:4.146044: , (0.967 sec/step)\n",
      "Train Epoch: 1 [195/225 (87%)] Loss:4.259468: , (0.967 sec/step)\n",
      "Train Epoch: 1 [196/225 (87%)] Loss:4.602652: , (0.967 sec/step)\n",
      "Train Epoch: 1 [197/225 (88%)] Loss:4.459372: , (0.967 sec/step)\n",
      "Train Epoch: 1 [198/225 (88%)] Loss:4.439076: , (0.965 sec/step)\n",
      "Train Epoch: 1 [199/225 (88%)] Loss:4.486948: , (0.966 sec/step)\n",
      "Train Epoch: 1 [200/225 (89%)] Loss:4.433705: , (0.966 sec/step)\n",
      "write finish\n",
      "Train Epoch: 1 [201/225 (89%)] Loss:4.509493: , (0.964 sec/step)\n",
      "Train Epoch: 1 [202/225 (90%)] Loss:4.806804: , (0.965 sec/step)\n",
      "Train Epoch: 1 [203/225 (90%)] Loss:4.455236: , (0.966 sec/step)\n",
      "Train Epoch: 1 [204/225 (91%)] Loss:4.449834: , (0.966 sec/step)\n",
      "Train Epoch: 1 [205/225 (91%)] Loss:4.632483: , (0.965 sec/step)\n",
      "Train Epoch: 1 [206/225 (92%)] Loss:4.586511: , (0.966 sec/step)\n",
      "Train Epoch: 1 [207/225 (92%)] Loss:4.372633: , (0.965 sec/step)\n",
      "Train Epoch: 1 [208/225 (92%)] Loss:4.387298: , (0.964 sec/step)\n",
      "Train Epoch: 1 [209/225 (93%)] Loss:4.737339: , (0.965 sec/step)\n",
      "Train Epoch: 1 [210/225 (93%)] Loss:4.587965: , (0.965 sec/step)\n",
      "Train Epoch: 1 [211/225 (94%)] Loss:4.349760: , (0.964 sec/step)\n",
      "Train Epoch: 1 [212/225 (94%)] Loss:4.316794: , (0.965 sec/step)\n",
      "Train Epoch: 1 [213/225 (95%)] Loss:4.134721: , (0.965 sec/step)\n",
      "Train Epoch: 1 [214/225 (95%)] Loss:4.265305: , (0.965 sec/step)\n",
      "Train Epoch: 1 [215/225 (96%)] Loss:4.355482: , (0.965 sec/step)\n",
      "Train Epoch: 1 [216/225 (96%)] Loss:4.284152: , (0.971 sec/step)\n",
      "Train Epoch: 1 [217/225 (96%)] Loss:5.107680: , (0.965 sec/step)\n",
      "Train Epoch: 1 [218/225 (97%)] Loss:4.482762: , (0.965 sec/step)\n",
      "Train Epoch: 1 [219/225 (97%)] Loss:4.359178: , (0.963 sec/step)\n",
      "Train Epoch: 1 [220/225 (98%)] Loss:4.364068: , (0.963 sec/step)\n",
      "Train Epoch: 1 [221/225 (98%)] Loss:4.715908: , (0.963 sec/step)\n",
      "Train Epoch: 1 [222/225 (99%)] Loss:4.704342: , (0.963 sec/step)\n",
      "Train Epoch: 1 [223/225 (99%)] Loss:4.656057: , (0.964 sec/step)\n",
      "Train Epoch: 1 [224/225 (100%)] Loss:4.595506: , (0.964 sec/step)\n",
      "0.0241875 accurate\n",
      "\n",
      "val set:loss4.5846:, (0.299 sec/step)\n",
      "\n",
      "val stored done 2.9914603233337402\n",
      "test stored done 75.07414197921753\n",
      "Train Epoch: 2 [0/225 (0%)] Loss:4.526466: , (0.966 sec/step)\n",
      "write finish\n",
      "Train Epoch: 2 [1/225 (0%)] Loss:4.770789: , (0.965 sec/step)\n",
      "Train Epoch: 2 [2/225 (1%)] Loss:4.610925: , (0.964 sec/step)\n",
      "Train Epoch: 2 [3/225 (1%)] Loss:4.125274: , (0.965 sec/step)\n",
      "Train Epoch: 2 [4/225 (2%)] Loss:4.442424: , (0.964 sec/step)\n",
      "Train Epoch: 2 [5/225 (2%)] Loss:4.488194: , (0.966 sec/step)\n",
      "Train Epoch: 2 [6/225 (3%)] Loss:4.446574: , (0.964 sec/step)\n",
      "Train Epoch: 2 [7/225 (3%)] Loss:4.337028: , (0.965 sec/step)\n",
      "Train Epoch: 2 [8/225 (4%)] Loss:4.569938: , (0.965 sec/step)\n",
      "Train Epoch: 2 [9/225 (4%)] Loss:4.388069: , (0.965 sec/step)\n",
      "Train Epoch: 2 [10/225 (4%)] Loss:4.780287: , (0.965 sec/step)\n",
      "Train Epoch: 2 [11/225 (5%)] Loss:4.427468: , (0.965 sec/step)\n",
      "Train Epoch: 2 [12/225 (5%)] Loss:4.679151: , (0.966 sec/step)\n",
      "Train Epoch: 2 [13/225 (6%)] Loss:4.853678: , (0.966 sec/step)\n",
      "Train Epoch: 2 [14/225 (6%)] Loss:4.830008: , (0.965 sec/step)\n",
      "Train Epoch: 2 [15/225 (7%)] Loss:4.495874: , (0.965 sec/step)\n",
      "Train Epoch: 2 [16/225 (7%)] Loss:4.413357: , (0.966 sec/step)\n",
      "Train Epoch: 2 [17/225 (8%)] Loss:4.503360: , (0.966 sec/step)\n",
      "Train Epoch: 2 [18/225 (8%)] Loss:4.610673: , (0.965 sec/step)\n",
      "Train Epoch: 2 [19/225 (8%)] Loss:4.345715: , (0.966 sec/step)\n",
      "Train Epoch: 2 [20/225 (9%)] Loss:4.892129: , (0.967 sec/step)\n",
      "Train Epoch: 2 [21/225 (9%)] Loss:4.458108: , (0.966 sec/step)\n",
      "Train Epoch: 2 [22/225 (10%)] Loss:4.489081: , (0.967 sec/step)\n",
      "Train Epoch: 2 [23/225 (10%)] Loss:4.838424: , (0.966 sec/step)\n",
      "Train Epoch: 2 [24/225 (11%)] Loss:4.599790: , (0.967 sec/step)\n",
      "Train Epoch: 2 [25/225 (11%)] Loss:4.427088: , (0.967 sec/step)\n",
      "Train Epoch: 2 [26/225 (12%)] Loss:4.503032: , (0.966 sec/step)\n",
      "Train Epoch: 2 [27/225 (12%)] Loss:4.209699: , (0.967 sec/step)\n",
      "Train Epoch: 2 [28/225 (12%)] Loss:4.920614: , (0.966 sec/step)\n",
      "Train Epoch: 2 [29/225 (13%)] Loss:4.206193: , (0.969 sec/step)\n",
      "Train Epoch: 2 [30/225 (13%)] Loss:4.570444: , (0.967 sec/step)\n",
      "Train Epoch: 2 [31/225 (14%)] Loss:4.530966: , (0.967 sec/step)\n",
      "Train Epoch: 2 [32/225 (14%)] Loss:4.587836: , (0.968 sec/step)\n",
      "Train Epoch: 2 [33/225 (15%)] Loss:4.242215: , (0.969 sec/step)\n",
      "Train Epoch: 2 [34/225 (15%)] Loss:4.697780: , (0.973 sec/step)\n",
      "Train Epoch: 2 [35/225 (16%)] Loss:4.683770: , (0.970 sec/step)\n",
      "Train Epoch: 2 [36/225 (16%)] Loss:4.523048: , (0.969 sec/step)\n",
      "Train Epoch: 2 [37/225 (16%)] Loss:5.035579: , (0.969 sec/step)\n",
      "Train Epoch: 2 [38/225 (17%)] Loss:4.446554: , (0.969 sec/step)\n",
      "Train Epoch: 2 [39/225 (17%)] Loss:4.514720: , (0.969 sec/step)\n",
      "Train Epoch: 2 [40/225 (18%)] Loss:4.527827: , (0.968 sec/step)\n",
      "Train Epoch: 2 [41/225 (18%)] Loss:4.531692: , (0.968 sec/step)\n",
      "Train Epoch: 2 [42/225 (19%)] Loss:4.582983: , (0.967 sec/step)\n",
      "Train Epoch: 2 [43/225 (19%)] Loss:4.458076: , (0.967 sec/step)\n",
      "Train Epoch: 2 [44/225 (20%)] Loss:4.645339: , (0.968 sec/step)\n",
      "Train Epoch: 2 [45/225 (20%)] Loss:4.537505: , (0.968 sec/step)\n",
      "Train Epoch: 2 [46/225 (20%)] Loss:4.801348: , (0.968 sec/step)\n",
      "Train Epoch: 2 [47/225 (21%)] Loss:4.174607: , (0.968 sec/step)\n",
      "Train Epoch: 2 [48/225 (21%)] Loss:4.393933: , (0.967 sec/step)\n",
      "Train Epoch: 2 [49/225 (22%)] Loss:4.389688: , (0.968 sec/step)\n",
      "Train Epoch: 2 [50/225 (22%)] Loss:4.888781: , (0.967 sec/step)\n",
      "Train Epoch: 2 [51/225 (23%)] Loss:4.342471: , (0.967 sec/step)\n",
      "Train Epoch: 2 [52/225 (23%)] Loss:4.267981: , (0.967 sec/step)\n",
      "Train Epoch: 2 [53/225 (24%)] Loss:4.221206: , (0.967 sec/step)\n",
      "Train Epoch: 2 [54/225 (24%)] Loss:4.708225: , (0.967 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [55/225 (24%)] Loss:4.794455: , (0.968 sec/step)\n",
      "Train Epoch: 2 [56/225 (25%)] Loss:4.366204: , (0.968 sec/step)\n",
      "Train Epoch: 2 [57/225 (25%)] Loss:4.528606: , (0.968 sec/step)\n",
      "Train Epoch: 2 [58/225 (26%)] Loss:4.660017: , (0.967 sec/step)\n",
      "Train Epoch: 2 [59/225 (26%)] Loss:4.180252: , (0.968 sec/step)\n",
      "Train Epoch: 2 [60/225 (27%)] Loss:4.633027: , (0.967 sec/step)\n",
      "Train Epoch: 2 [61/225 (27%)] Loss:4.626294: , (0.967 sec/step)\n",
      "Train Epoch: 2 [62/225 (28%)] Loss:4.489344: , (0.966 sec/step)\n",
      "Train Epoch: 2 [63/225 (28%)] Loss:4.645239: , (0.966 sec/step)\n",
      "Train Epoch: 2 [64/225 (28%)] Loss:4.476544: , (0.965 sec/step)\n",
      "Train Epoch: 2 [65/225 (29%)] Loss:4.289710: , (0.965 sec/step)\n",
      "Train Epoch: 2 [66/225 (29%)] Loss:4.292818: , (0.966 sec/step)\n",
      "Train Epoch: 2 [67/225 (30%)] Loss:4.534282: , (0.964 sec/step)\n",
      "Train Epoch: 2 [68/225 (30%)] Loss:4.219175: , (0.966 sec/step)\n",
      "Train Epoch: 2 [69/225 (31%)] Loss:4.286251: , (0.965 sec/step)\n",
      "Train Epoch: 2 [70/225 (31%)] Loss:4.366259: , (0.965 sec/step)\n",
      "Train Epoch: 2 [71/225 (32%)] Loss:4.589512: , (0.966 sec/step)\n",
      "Train Epoch: 2 [72/225 (32%)] Loss:4.336916: , (0.965 sec/step)\n",
      "Train Epoch: 2 [73/225 (32%)] Loss:4.270715: , (0.965 sec/step)\n",
      "Train Epoch: 2 [74/225 (33%)] Loss:4.208695: , (0.966 sec/step)\n",
      "Train Epoch: 2 [75/225 (33%)] Loss:4.345740: , (0.966 sec/step)\n",
      "Train Epoch: 2 [76/225 (34%)] Loss:4.657532: , (0.965 sec/step)\n",
      "Train Epoch: 2 [77/225 (34%)] Loss:4.682330: , (0.966 sec/step)\n",
      "Train Epoch: 2 [78/225 (35%)] Loss:4.157576: , (0.966 sec/step)\n",
      "Train Epoch: 2 [79/225 (35%)] Loss:4.529637: , (0.965 sec/step)\n",
      "Train Epoch: 2 [80/225 (36%)] Loss:4.101242: , (0.965 sec/step)\n",
      "Train Epoch: 2 [81/225 (36%)] Loss:4.221102: , (0.965 sec/step)\n",
      "Train Epoch: 2 [82/225 (36%)] Loss:4.441623: , (0.965 sec/step)\n",
      "Train Epoch: 2 [83/225 (37%)] Loss:4.295143: , (0.966 sec/step)\n",
      "Train Epoch: 2 [84/225 (37%)] Loss:4.326855: , (0.966 sec/step)\n",
      "Train Epoch: 2 [85/225 (38%)] Loss:4.116152: , (0.966 sec/step)\n",
      "Train Epoch: 2 [86/225 (38%)] Loss:4.391911: , (0.966 sec/step)\n",
      "Train Epoch: 2 [87/225 (39%)] Loss:4.104594: , (0.967 sec/step)\n",
      "Train Epoch: 2 [88/225 (39%)] Loss:4.361962: , (0.966 sec/step)\n",
      "Train Epoch: 2 [89/225 (40%)] Loss:4.244621: , (0.975 sec/step)\n",
      "Train Epoch: 2 [90/225 (40%)] Loss:4.471296: , (0.976 sec/step)\n",
      "Train Epoch: 2 [91/225 (40%)] Loss:4.232475: , (0.977 sec/step)\n",
      "Train Epoch: 2 [92/225 (41%)] Loss:4.769958: , (0.977 sec/step)\n",
      "Train Epoch: 2 [93/225 (41%)] Loss:4.233565: , (0.979 sec/step)\n",
      "Train Epoch: 2 [94/225 (42%)] Loss:4.604824: , (0.977 sec/step)\n",
      "Train Epoch: 2 [95/225 (42%)] Loss:4.577273: , (0.979 sec/step)\n",
      "Train Epoch: 2 [96/225 (43%)] Loss:4.425805: , (0.976 sec/step)\n",
      "Train Epoch: 2 [97/225 (43%)] Loss:4.236661: , (0.977 sec/step)\n",
      "Train Epoch: 2 [98/225 (44%)] Loss:4.606947: , (0.976 sec/step)\n",
      "Train Epoch: 2 [99/225 (44%)] Loss:4.381178: , (0.979 sec/step)\n",
      "Train Epoch: 2 [100/225 (44%)] Loss:4.478572: , (0.979 sec/step)\n",
      "write finish\n",
      "Train Epoch: 2 [101/225 (45%)] Loss:4.591876: , (0.978 sec/step)\n",
      "Train Epoch: 2 [102/225 (45%)] Loss:4.318916: , (0.978 sec/step)\n",
      "Train Epoch: 2 [103/225 (46%)] Loss:4.706838: , (0.977 sec/step)\n",
      "Train Epoch: 2 [104/225 (46%)] Loss:4.719440: , (0.978 sec/step)\n",
      "Train Epoch: 2 [105/225 (47%)] Loss:4.989328: , (0.979 sec/step)\n",
      "Train Epoch: 2 [106/225 (47%)] Loss:4.323253: , (0.980 sec/step)\n",
      "Train Epoch: 2 [107/225 (48%)] Loss:4.265097: , (0.978 sec/step)\n",
      "Train Epoch: 2 [108/225 (48%)] Loss:4.982522: , (0.978 sec/step)\n",
      "Train Epoch: 2 [109/225 (48%)] Loss:4.354590: , (0.978 sec/step)\n",
      "Train Epoch: 2 [110/225 (49%)] Loss:4.261733: , (0.977 sec/step)\n",
      "Train Epoch: 2 [111/225 (49%)] Loss:4.414864: , (0.978 sec/step)\n",
      "Train Epoch: 2 [112/225 (50%)] Loss:4.416875: , (0.977 sec/step)\n",
      "Train Epoch: 2 [113/225 (50%)] Loss:4.206492: , (0.978 sec/step)\n",
      "Train Epoch: 2 [114/225 (51%)] Loss:4.525912: , (0.977 sec/step)\n",
      "Train Epoch: 2 [115/225 (51%)] Loss:4.505916: , (0.977 sec/step)\n",
      "Train Epoch: 2 [116/225 (52%)] Loss:4.417863: , (0.977 sec/step)\n",
      "Train Epoch: 2 [117/225 (52%)] Loss:4.117059: , (0.977 sec/step)\n",
      "Train Epoch: 2 [118/225 (52%)] Loss:4.518188: , (0.977 sec/step)\n",
      "Train Epoch: 2 [119/225 (53%)] Loss:4.067005: , (0.977 sec/step)\n",
      "Train Epoch: 2 [120/225 (53%)] Loss:4.494445: , (0.979 sec/step)\n",
      "Train Epoch: 2 [121/225 (54%)] Loss:4.441021: , (0.976 sec/step)\n",
      "Train Epoch: 2 [122/225 (54%)] Loss:4.312883: , (0.977 sec/step)\n",
      "Train Epoch: 2 [123/225 (55%)] Loss:4.382030: , (0.977 sec/step)\n",
      "Train Epoch: 2 [124/225 (55%)] Loss:4.190578: , (0.980 sec/step)\n",
      "Train Epoch: 2 [125/225 (56%)] Loss:4.249556: , (0.980 sec/step)\n",
      "Train Epoch: 2 [126/225 (56%)] Loss:4.547144: , (0.979 sec/step)\n",
      "Train Epoch: 2 [127/225 (56%)] Loss:4.422812: , (0.980 sec/step)\n",
      "Train Epoch: 2 [128/225 (57%)] Loss:4.167585: , (0.978 sec/step)\n",
      "Train Epoch: 2 [129/225 (57%)] Loss:4.267580: , (0.978 sec/step)\n",
      "Train Epoch: 2 [130/225 (58%)] Loss:4.264321: , (0.979 sec/step)\n",
      "Train Epoch: 2 [131/225 (58%)] Loss:4.171989: , (0.978 sec/step)\n",
      "Train Epoch: 2 [132/225 (59%)] Loss:5.163496: , (0.977 sec/step)\n",
      "Train Epoch: 2 [133/225 (59%)] Loss:4.542008: , (0.978 sec/step)\n",
      "Train Epoch: 2 [134/225 (60%)] Loss:4.466567: , (0.978 sec/step)\n",
      "Train Epoch: 2 [135/225 (60%)] Loss:4.454361: , (0.977 sec/step)\n",
      "Train Epoch: 2 [136/225 (60%)] Loss:4.416651: , (0.977 sec/step)\n",
      "Train Epoch: 2 [137/225 (61%)] Loss:4.465759: , (0.977 sec/step)\n",
      "Train Epoch: 2 [138/225 (61%)] Loss:4.665816: , (0.975 sec/step)\n",
      "Train Epoch: 2 [139/225 (62%)] Loss:4.906058: , (0.975 sec/step)\n",
      "Train Epoch: 2 [140/225 (62%)] Loss:4.391360: , (0.975 sec/step)\n",
      "Train Epoch: 2 [141/225 (63%)] Loss:4.390510: , (0.976 sec/step)\n",
      "Train Epoch: 2 [142/225 (63%)] Loss:4.502613: , (0.977 sec/step)\n",
      "Train Epoch: 2 [143/225 (64%)] Loss:4.219125: , (0.977 sec/step)\n",
      "Train Epoch: 2 [144/225 (64%)] Loss:4.465512: , (0.977 sec/step)\n",
      "Train Epoch: 2 [145/225 (64%)] Loss:4.485339: , (0.977 sec/step)\n",
      "Train Epoch: 2 [146/225 (65%)] Loss:4.653289: , (0.977 sec/step)\n",
      "Train Epoch: 2 [147/225 (65%)] Loss:4.468042: , (0.977 sec/step)\n",
      "Train Epoch: 2 [148/225 (66%)] Loss:4.737835: , (0.977 sec/step)\n",
      "Train Epoch: 2 [149/225 (66%)] Loss:4.177330: , (0.977 sec/step)\n",
      "Train Epoch: 2 [150/225 (67%)] Loss:4.422976: , (0.976 sec/step)\n",
      "Train Epoch: 2 [151/225 (67%)] Loss:4.252127: , (0.975 sec/step)\n",
      "Train Epoch: 2 [152/225 (68%)] Loss:4.472170: , (0.976 sec/step)\n",
      "Train Epoch: 2 [153/225 (68%)] Loss:4.938813: , (0.976 sec/step)\n",
      "Train Epoch: 2 [154/225 (68%)] Loss:4.374614: , (0.976 sec/step)\n",
      "Train Epoch: 2 [155/225 (69%)] Loss:4.395281: , (0.976 sec/step)\n",
      "Train Epoch: 2 [156/225 (69%)] Loss:4.684923: , (0.981 sec/step)\n",
      "Train Epoch: 2 [157/225 (70%)] Loss:4.472126: , (0.975 sec/step)\n",
      "Train Epoch: 2 [158/225 (70%)] Loss:4.232932: , (0.976 sec/step)\n",
      "Train Epoch: 2 [159/225 (71%)] Loss:4.493475: , (0.975 sec/step)\n",
      "Train Epoch: 2 [160/225 (71%)] Loss:4.415865: , (0.975 sec/step)\n",
      "Train Epoch: 2 [161/225 (72%)] Loss:4.952046: , (0.977 sec/step)\n",
      "Train Epoch: 2 [162/225 (72%)] Loss:4.916780: , (0.976 sec/step)\n",
      "Train Epoch: 2 [163/225 (72%)] Loss:4.541465: , (0.974 sec/step)\n",
      "Train Epoch: 2 [164/225 (73%)] Loss:4.169275: , (0.975 sec/step)\n",
      "Train Epoch: 2 [165/225 (73%)] Loss:4.589753: , (0.976 sec/step)\n",
      "Train Epoch: 2 [166/225 (74%)] Loss:4.488832: , (0.975 sec/step)\n",
      "Train Epoch: 2 [167/225 (74%)] Loss:4.479786: , (0.975 sec/step)\n",
      "Train Epoch: 2 [168/225 (75%)] Loss:4.464945: , (0.976 sec/step)\n",
      "Train Epoch: 2 [169/225 (75%)] Loss:4.461205: , (0.980 sec/step)\n",
      "Train Epoch: 2 [170/225 (76%)] Loss:4.251683: , (0.977 sec/step)\n",
      "Train Epoch: 2 [171/225 (76%)] Loss:4.489587: , (0.978 sec/step)\n",
      "Train Epoch: 2 [172/225 (76%)] Loss:5.283901: , (0.977 sec/step)\n",
      "Train Epoch: 2 [173/225 (77%)] Loss:4.539873: , (0.978 sec/step)\n",
      "Train Epoch: 2 [174/225 (77%)] Loss:4.798571: , (0.978 sec/step)\n",
      "Train Epoch: 2 [175/225 (78%)] Loss:4.336283: , (0.979 sec/step)\n",
      "Train Epoch: 2 [176/225 (78%)] Loss:4.768770: , (0.968 sec/step)\n",
      "Train Epoch: 2 [177/225 (79%)] Loss:4.309563: , (0.968 sec/step)\n",
      "Train Epoch: 2 [178/225 (79%)] Loss:4.629174: , (0.969 sec/step)\n",
      "Train Epoch: 2 [179/225 (80%)] Loss:4.976325: , (0.967 sec/step)\n",
      "Train Epoch: 2 [180/225 (80%)] Loss:4.654655: , (0.966 sec/step)\n",
      "Train Epoch: 2 [181/225 (80%)] Loss:4.890936: , (0.966 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [182/225 (81%)] Loss:4.441373: , (0.967 sec/step)\n",
      "Train Epoch: 2 [183/225 (81%)] Loss:4.324302: , (0.967 sec/step)\n",
      "Train Epoch: 2 [184/225 (82%)] Loss:4.439819: , (0.967 sec/step)\n",
      "Train Epoch: 2 [185/225 (82%)] Loss:4.455052: , (0.968 sec/step)\n",
      "Train Epoch: 2 [186/225 (83%)] Loss:4.251844: , (0.968 sec/step)\n",
      "Train Epoch: 2 [187/225 (83%)] Loss:4.161716: , (0.968 sec/step)\n",
      "Train Epoch: 2 [188/225 (84%)] Loss:4.480475: , (0.967 sec/step)\n",
      "Train Epoch: 2 [189/225 (84%)] Loss:4.558204: , (0.967 sec/step)\n",
      "Train Epoch: 2 [190/225 (84%)] Loss:4.667998: , (0.967 sec/step)\n",
      "Train Epoch: 2 [191/225 (85%)] Loss:4.860841: , (0.967 sec/step)\n",
      "Train Epoch: 2 [192/225 (85%)] Loss:4.371067: , (0.967 sec/step)\n",
      "Train Epoch: 2 [193/225 (86%)] Loss:4.587024: , (0.967 sec/step)\n",
      "Train Epoch: 2 [194/225 (86%)] Loss:4.904831: , (0.966 sec/step)\n",
      "Train Epoch: 2 [195/225 (87%)] Loss:4.077463: , (0.966 sec/step)\n",
      "Train Epoch: 2 [196/225 (87%)] Loss:4.599611: , (0.966 sec/step)\n",
      "Train Epoch: 2 [197/225 (88%)] Loss:4.569277: , (0.965 sec/step)\n",
      "Train Epoch: 2 [198/225 (88%)] Loss:4.648374: , (0.966 sec/step)\n",
      "Train Epoch: 2 [199/225 (88%)] Loss:4.398630: , (0.965 sec/step)\n",
      "Train Epoch: 2 [200/225 (89%)] Loss:4.639908: , (0.965 sec/step)\n",
      "write finish\n",
      "Train Epoch: 2 [201/225 (89%)] Loss:4.220988: , (0.965 sec/step)\n",
      "Train Epoch: 2 [202/225 (90%)] Loss:4.566605: , (0.965 sec/step)\n",
      "Train Epoch: 2 [203/225 (90%)] Loss:4.237203: , (0.965 sec/step)\n",
      "Train Epoch: 2 [204/225 (91%)] Loss:4.122894: , (0.965 sec/step)\n",
      "Train Epoch: 2 [205/225 (91%)] Loss:4.278986: , (0.963 sec/step)\n",
      "Train Epoch: 2 [206/225 (92%)] Loss:4.262755: , (0.963 sec/step)\n",
      "Train Epoch: 2 [207/225 (92%)] Loss:4.257847: , (0.964 sec/step)\n",
      "Train Epoch: 2 [208/225 (92%)] Loss:4.385818: , (0.963 sec/step)\n",
      "Train Epoch: 2 [209/225 (93%)] Loss:4.752743: , (0.964 sec/step)\n",
      "Train Epoch: 2 [210/225 (93%)] Loss:4.496085: , (0.963 sec/step)\n",
      "Train Epoch: 2 [211/225 (94%)] Loss:4.492752: , (0.965 sec/step)\n",
      "Train Epoch: 2 [212/225 (94%)] Loss:4.234731: , (0.962 sec/step)\n",
      "Train Epoch: 2 [213/225 (95%)] Loss:4.579879: , (0.962 sec/step)\n",
      "Train Epoch: 2 [214/225 (95%)] Loss:4.670814: , (0.964 sec/step)\n",
      "Train Epoch: 2 [215/225 (96%)] Loss:4.570681: , (0.962 sec/step)\n",
      "Train Epoch: 2 [216/225 (96%)] Loss:4.246449: , (0.962 sec/step)\n",
      "Train Epoch: 2 [217/225 (96%)] Loss:4.439811: , (0.962 sec/step)\n",
      "Train Epoch: 2 [218/225 (97%)] Loss:3.915243: , (0.965 sec/step)\n",
      "Train Epoch: 2 [219/225 (97%)] Loss:4.323681: , (0.965 sec/step)\n",
      "Train Epoch: 2 [220/225 (98%)] Loss:4.562229: , (0.967 sec/step)\n",
      "Train Epoch: 2 [221/225 (98%)] Loss:4.696496: , (0.965 sec/step)\n",
      "Train Epoch: 2 [222/225 (99%)] Loss:4.351190: , (0.964 sec/step)\n",
      "Train Epoch: 2 [223/225 (99%)] Loss:4.422888: , (0.965 sec/step)\n",
      "Train Epoch: 2 [224/225 (100%)] Loss:4.490225: , (0.965 sec/step)\n",
      "0.043375 accurate\n",
      "\n",
      "val set:loss4.0579:, (0.299 sec/step)\n",
      "\n",
      "val stored done 2.9921603202819824\n",
      "test stored done 75.10015177726746\n",
      "Train Epoch: 3 [0/225 (0%)] Loss:4.444243: , (0.967 sec/step)\n",
      "write finish\n",
      "Train Epoch: 3 [1/225 (0%)] Loss:4.111167: , (0.967 sec/step)\n",
      "Train Epoch: 3 [2/225 (1%)] Loss:5.020833: , (0.966 sec/step)\n",
      "Train Epoch: 3 [3/225 (1%)] Loss:4.209455: , (0.967 sec/step)\n",
      "Train Epoch: 3 [4/225 (2%)] Loss:4.419995: , (0.967 sec/step)\n",
      "Train Epoch: 3 [5/225 (2%)] Loss:4.288956: , (0.967 sec/step)\n",
      "Train Epoch: 3 [6/225 (3%)] Loss:4.940524: , (0.965 sec/step)\n",
      "Train Epoch: 3 [7/225 (3%)] Loss:4.308654: , (0.967 sec/step)\n",
      "Train Epoch: 3 [8/225 (4%)] Loss:4.353325: , (0.967 sec/step)\n",
      "Train Epoch: 3 [9/225 (4%)] Loss:4.349432: , (0.965 sec/step)\n",
      "Train Epoch: 3 [10/225 (4%)] Loss:4.079808: , (0.965 sec/step)\n",
      "Train Epoch: 3 [11/225 (5%)] Loss:4.786120: , (0.967 sec/step)\n",
      "Train Epoch: 3 [12/225 (5%)] Loss:4.489738: , (0.967 sec/step)\n",
      "Train Epoch: 3 [13/225 (6%)] Loss:4.462770: , (0.966 sec/step)\n",
      "Train Epoch: 3 [14/225 (6%)] Loss:4.278501: , (0.967 sec/step)\n",
      "Train Epoch: 3 [15/225 (7%)] Loss:4.607058: , (0.968 sec/step)\n",
      "Train Epoch: 3 [16/225 (7%)] Loss:4.396675: , (0.967 sec/step)\n",
      "Train Epoch: 3 [17/225 (8%)] Loss:4.590634: , (0.968 sec/step)\n",
      "Train Epoch: 3 [18/225 (8%)] Loss:4.395119: , (0.967 sec/step)\n",
      "Train Epoch: 3 [19/225 (8%)] Loss:4.469257: , (0.967 sec/step)\n",
      "Train Epoch: 3 [20/225 (9%)] Loss:4.249393: , (0.966 sec/step)\n",
      "Train Epoch: 3 [21/225 (9%)] Loss:4.355619: , (0.966 sec/step)\n",
      "Train Epoch: 3 [22/225 (10%)] Loss:4.334721: , (0.966 sec/step)\n",
      "Train Epoch: 3 [23/225 (10%)] Loss:4.173789: , (0.969 sec/step)\n",
      "Train Epoch: 3 [24/225 (11%)] Loss:4.263144: , (0.967 sec/step)\n",
      "Train Epoch: 3 [25/225 (11%)] Loss:4.283568: , (0.967 sec/step)\n",
      "Train Epoch: 3 [26/225 (12%)] Loss:4.134964: , (0.968 sec/step)\n",
      "Train Epoch: 3 [27/225 (12%)] Loss:4.515390: , (0.971 sec/step)\n",
      "Train Epoch: 3 [28/225 (12%)] Loss:4.334139: , (0.969 sec/step)\n",
      "Train Epoch: 3 [29/225 (13%)] Loss:4.406388: , (0.967 sec/step)\n",
      "Train Epoch: 3 [30/225 (13%)] Loss:4.380170: , (0.967 sec/step)\n",
      "Train Epoch: 3 [31/225 (14%)] Loss:4.017858: , (0.967 sec/step)\n",
      "Train Epoch: 3 [32/225 (14%)] Loss:5.027864: , (0.970 sec/step)\n",
      "Train Epoch: 3 [33/225 (15%)] Loss:4.427386: , (0.967 sec/step)\n",
      "Train Epoch: 3 [34/225 (15%)] Loss:4.234641: , (0.964 sec/step)\n",
      "Train Epoch: 3 [35/225 (16%)] Loss:4.156297: , (0.964 sec/step)\n",
      "Train Epoch: 3 [36/225 (16%)] Loss:4.343481: , (0.964 sec/step)\n",
      "Train Epoch: 3 [37/225 (16%)] Loss:4.527680: , (0.964 sec/step)\n",
      "Train Epoch: 3 [38/225 (17%)] Loss:4.203041: , (0.963 sec/step)\n",
      "Train Epoch: 3 [39/225 (17%)] Loss:4.465646: , (0.963 sec/step)\n",
      "Train Epoch: 3 [40/225 (18%)] Loss:4.524495: , (0.964 sec/step)\n",
      "Train Epoch: 3 [41/225 (18%)] Loss:4.517606: , (0.963 sec/step)\n",
      "Train Epoch: 3 [42/225 (19%)] Loss:4.339828: , (0.962 sec/step)\n",
      "Train Epoch: 3 [43/225 (19%)] Loss:4.812606: , (0.964 sec/step)\n",
      "Train Epoch: 3 [44/225 (20%)] Loss:4.217630: , (0.964 sec/step)\n",
      "Train Epoch: 3 [45/225 (20%)] Loss:4.309579: , (0.963 sec/step)\n",
      "Train Epoch: 3 [46/225 (20%)] Loss:4.342691: , (0.963 sec/step)\n",
      "Train Epoch: 3 [47/225 (21%)] Loss:4.256502: , (0.963 sec/step)\n",
      "Train Epoch: 3 [48/225 (21%)] Loss:4.169866: , (0.963 sec/step)\n",
      "Train Epoch: 3 [49/225 (22%)] Loss:3.987125: , (0.964 sec/step)\n",
      "Train Epoch: 3 [50/225 (22%)] Loss:4.550775: , (0.964 sec/step)\n",
      "Train Epoch: 3 [51/225 (23%)] Loss:4.476470: , (0.965 sec/step)\n",
      "Train Epoch: 3 [52/225 (23%)] Loss:4.316430: , (0.966 sec/step)\n",
      "Train Epoch: 3 [53/225 (24%)] Loss:4.183112: , (0.965 sec/step)\n",
      "Train Epoch: 3 [54/225 (24%)] Loss:4.589817: , (0.965 sec/step)\n",
      "Train Epoch: 3 [55/225 (24%)] Loss:4.194018: , (0.966 sec/step)\n",
      "Train Epoch: 3 [56/225 (25%)] Loss:4.667594: , (0.966 sec/step)\n",
      "Train Epoch: 3 [57/225 (25%)] Loss:4.591281: , (0.966 sec/step)\n",
      "Train Epoch: 3 [58/225 (26%)] Loss:4.507462: , (0.966 sec/step)\n",
      "Train Epoch: 3 [59/225 (26%)] Loss:4.188385: , (0.967 sec/step)\n",
      "Train Epoch: 3 [60/225 (27%)] Loss:4.630642: , (0.967 sec/step)\n",
      "Train Epoch: 3 [61/225 (27%)] Loss:4.091392: , (0.969 sec/step)\n",
      "Train Epoch: 3 [62/225 (28%)] Loss:4.269470: , (0.969 sec/step)\n",
      "Train Epoch: 3 [63/225 (28%)] Loss:4.555685: , (0.969 sec/step)\n",
      "Train Epoch: 3 [64/225 (28%)] Loss:4.228374: , (0.969 sec/step)\n",
      "Train Epoch: 3 [65/225 (29%)] Loss:4.387815: , (0.969 sec/step)\n",
      "Train Epoch: 3 [66/225 (29%)] Loss:4.720763: , (0.969 sec/step)\n",
      "Train Epoch: 3 [67/225 (30%)] Loss:4.627531: , (0.969 sec/step)\n",
      "Train Epoch: 3 [68/225 (30%)] Loss:4.749660: , (0.969 sec/step)\n",
      "Train Epoch: 3 [69/225 (31%)] Loss:4.818609: , (0.970 sec/step)\n",
      "Train Epoch: 3 [70/225 (31%)] Loss:4.624520: , (0.970 sec/step)\n",
      "Train Epoch: 3 [71/225 (32%)] Loss:4.317679: , (0.969 sec/step)\n",
      "Train Epoch: 3 [72/225 (32%)] Loss:4.214359: , (0.969 sec/step)\n",
      "Train Epoch: 3 [73/225 (32%)] Loss:4.821343: , (0.968 sec/step)\n",
      "Train Epoch: 3 [74/225 (33%)] Loss:4.814616: , (0.966 sec/step)\n",
      "Train Epoch: 3 [75/225 (33%)] Loss:4.460376: , (0.967 sec/step)\n",
      "Train Epoch: 3 [76/225 (34%)] Loss:4.216387: , (0.967 sec/step)\n",
      "Train Epoch: 3 [77/225 (34%)] Loss:4.502643: , (0.966 sec/step)\n",
      "Train Epoch: 3 [78/225 (35%)] Loss:4.252206: , (0.966 sec/step)\n",
      "Train Epoch: 3 [79/225 (35%)] Loss:4.548058: , (0.967 sec/step)\n",
      "Train Epoch: 3 [80/225 (36%)] Loss:4.420798: , (0.967 sec/step)\n",
      "Train Epoch: 3 [81/225 (36%)] Loss:4.305721: , (0.966 sec/step)\n",
      "Train Epoch: 3 [82/225 (36%)] Loss:4.174000: , (0.968 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [83/225 (37%)] Loss:4.458068: , (0.966 sec/step)\n",
      "Train Epoch: 3 [84/225 (37%)] Loss:4.461591: , (0.965 sec/step)\n",
      "Train Epoch: 3 [85/225 (38%)] Loss:4.347257: , (0.967 sec/step)\n",
      "Train Epoch: 3 [86/225 (38%)] Loss:4.425258: , (0.967 sec/step)\n",
      "Train Epoch: 3 [87/225 (39%)] Loss:4.857972: , (0.966 sec/step)\n",
      "Train Epoch: 3 [88/225 (39%)] Loss:4.498806: , (0.966 sec/step)\n",
      "Train Epoch: 3 [89/225 (40%)] Loss:4.258389: , (0.966 sec/step)\n",
      "Train Epoch: 3 [90/225 (40%)] Loss:4.392921: , (0.966 sec/step)\n",
      "Train Epoch: 3 [91/225 (40%)] Loss:4.502265: , (0.965 sec/step)\n",
      "Train Epoch: 3 [92/225 (41%)] Loss:4.547730: , (0.965 sec/step)\n",
      "Train Epoch: 3 [93/225 (41%)] Loss:4.761978: , (0.966 sec/step)\n",
      "Train Epoch: 3 [94/225 (42%)] Loss:4.406674: , (0.966 sec/step)\n",
      "Train Epoch: 3 [95/225 (42%)] Loss:4.466932: , (0.966 sec/step)\n",
      "Train Epoch: 3 [96/225 (43%)] Loss:4.550851: , (0.965 sec/step)\n",
      "Train Epoch: 3 [97/225 (43%)] Loss:4.350196: , (0.966 sec/step)\n",
      "Train Epoch: 3 [98/225 (44%)] Loss:4.135541: , (0.964 sec/step)\n",
      "Train Epoch: 3 [99/225 (44%)] Loss:4.411805: , (0.964 sec/step)\n",
      "Train Epoch: 3 [100/225 (44%)] Loss:4.504101: , (0.964 sec/step)\n",
      "write finish\n",
      "Train Epoch: 3 [101/225 (45%)] Loss:4.329695: , (0.964 sec/step)\n",
      "Train Epoch: 3 [102/225 (45%)] Loss:4.534572: , (0.964 sec/step)\n",
      "Train Epoch: 3 [103/225 (46%)] Loss:4.394362: , (0.965 sec/step)\n",
      "Train Epoch: 3 [104/225 (46%)] Loss:4.471624: , (0.964 sec/step)\n",
      "Train Epoch: 3 [105/225 (47%)] Loss:4.493536: , (0.964 sec/step)\n",
      "Train Epoch: 3 [106/225 (47%)] Loss:4.178292: , (0.965 sec/step)\n",
      "Train Epoch: 3 [107/225 (48%)] Loss:4.100239: , (0.966 sec/step)\n",
      "Train Epoch: 3 [108/225 (48%)] Loss:4.232057: , (0.965 sec/step)\n",
      "Train Epoch: 3 [109/225 (48%)] Loss:4.933668: , (0.964 sec/step)\n",
      "Train Epoch: 3 [110/225 (49%)] Loss:4.135891: , (0.965 sec/step)\n",
      "Train Epoch: 3 [111/225 (49%)] Loss:3.908240: , (0.966 sec/step)\n",
      "Train Epoch: 3 [112/225 (50%)] Loss:4.573250: , (0.965 sec/step)\n",
      "Train Epoch: 3 [113/225 (50%)] Loss:4.285932: , (0.966 sec/step)\n",
      "Train Epoch: 3 [114/225 (51%)] Loss:4.401770: , (0.966 sec/step)\n",
      "Train Epoch: 3 [115/225 (51%)] Loss:4.303946: , (0.966 sec/step)\n",
      "Train Epoch: 3 [116/225 (52%)] Loss:4.183446: , (0.967 sec/step)\n",
      "Train Epoch: 3 [117/225 (52%)] Loss:5.009020: , (0.967 sec/step)\n",
      "Train Epoch: 3 [118/225 (52%)] Loss:4.225121: , (0.966 sec/step)\n",
      "Train Epoch: 3 [119/225 (53%)] Loss:4.733802: , (0.966 sec/step)\n",
      "Train Epoch: 3 [120/225 (53%)] Loss:4.165780: , (0.967 sec/step)\n",
      "Train Epoch: 3 [121/225 (54%)] Loss:4.651423: , (0.968 sec/step)\n",
      "Train Epoch: 3 [122/225 (54%)] Loss:4.250890: , (0.968 sec/step)\n",
      "Train Epoch: 3 [123/225 (55%)] Loss:4.271903: , (0.968 sec/step)\n",
      "Train Epoch: 3 [124/225 (55%)] Loss:4.308805: , (0.968 sec/step)\n",
      "Train Epoch: 3 [125/225 (56%)] Loss:4.156271: , (0.967 sec/step)\n",
      "Train Epoch: 3 [126/225 (56%)] Loss:4.472289: , (0.969 sec/step)\n",
      "Train Epoch: 3 [127/225 (56%)] Loss:4.494594: , (0.970 sec/step)\n",
      "Train Epoch: 3 [128/225 (57%)] Loss:4.445460: , (0.972 sec/step)\n",
      "Train Epoch: 3 [129/225 (57%)] Loss:4.050622: , (0.969 sec/step)\n",
      "Train Epoch: 3 [130/225 (58%)] Loss:4.536118: , (0.968 sec/step)\n",
      "Train Epoch: 3 [131/225 (58%)] Loss:4.422659: , (0.978 sec/step)\n",
      "Train Epoch: 3 [132/225 (59%)] Loss:4.508353: , (0.967 sec/step)\n",
      "Train Epoch: 3 [133/225 (59%)] Loss:4.743820: , (0.966 sec/step)\n",
      "Train Epoch: 3 [134/225 (60%)] Loss:4.088322: , (0.967 sec/step)\n",
      "Train Epoch: 3 [135/225 (60%)] Loss:4.353921: , (0.966 sec/step)\n",
      "Train Epoch: 3 [136/225 (60%)] Loss:4.230454: , (0.965 sec/step)\n",
      "Train Epoch: 3 [137/225 (61%)] Loss:4.449328: , (0.965 sec/step)\n",
      "Train Epoch: 3 [138/225 (61%)] Loss:4.380784: , (0.965 sec/step)\n",
      "Train Epoch: 3 [139/225 (62%)] Loss:4.453107: , (0.969 sec/step)\n",
      "Train Epoch: 3 [140/225 (62%)] Loss:4.194673: , (0.968 sec/step)\n",
      "Train Epoch: 3 [141/225 (63%)] Loss:4.305122: , (0.966 sec/step)\n",
      "Train Epoch: 3 [142/225 (63%)] Loss:5.184388: , (0.964 sec/step)\n",
      "Train Epoch: 3 [143/225 (64%)] Loss:4.167817: , (0.964 sec/step)\n",
      "Train Epoch: 3 [144/225 (64%)] Loss:4.294235: , (0.965 sec/step)\n",
      "Train Epoch: 3 [145/225 (64%)] Loss:4.140956: , (0.964 sec/step)\n",
      "Train Epoch: 3 [146/225 (65%)] Loss:4.407731: , (0.965 sec/step)\n",
      "Train Epoch: 3 [147/225 (65%)] Loss:4.188415: , (0.964 sec/step)\n",
      "Train Epoch: 3 [148/225 (66%)] Loss:4.444911: , (0.964 sec/step)\n",
      "Train Epoch: 3 [149/225 (66%)] Loss:4.320820: , (0.963 sec/step)\n",
      "Train Epoch: 3 [150/225 (67%)] Loss:4.361141: , (0.961 sec/step)\n",
      "Train Epoch: 3 [151/225 (67%)] Loss:4.505267: , (0.963 sec/step)\n",
      "Train Epoch: 3 [152/225 (68%)] Loss:4.059202: , (0.962 sec/step)\n",
      "Train Epoch: 3 [153/225 (68%)] Loss:4.401324: , (0.962 sec/step)\n",
      "Train Epoch: 3 [154/225 (68%)] Loss:4.531917: , (0.963 sec/step)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLalgorithm/mnistPyTorch.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
