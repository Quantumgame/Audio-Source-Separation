{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T15:25:36.814125Z",
     "start_time": "2018-06-17T15:25:35.815711Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import time\n",
    "import os\n",
    "from torch.utils import data\n",
    "from wavenet import Wavenet\n",
    "from transformData import x_mu_law_encode,y_mu_law_encode,mu_law_decode,onehot,cateToSignal\n",
    "from readDataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T15:25:36.828483Z",
     "start_time": "2018-06-17T15:25:36.816178Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleSize=16000#the length of the sample size\n",
    "quantization_channels=256\n",
    "sample_rate=16000\n",
    "dilations=[2**i for i in range(9)]*5  #idea from wavenet, have more receptive field\n",
    "residualDim=256 #\n",
    "skipDim=512\n",
    "shapeoftest = 190500\n",
    "filterSize=3\n",
    "songnum=10\n",
    "savemusic='./vsCorpus/notextr{}.wav'\n",
    "resumefile='./model/testac' # name of checkpoint\n",
    "lossname='testacloss.txt' # name of loss file\n",
    "continueTrain=False # whether use checkpoint\n",
    "pad = np.sum(dilations) # padding for dilate convolutional layers\n",
    "lossrecord=[]  #list for record loss\n",
    "#pad=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #            |----------------------------------------|     *residual*\n",
    "    #            |                                        |\n",
    "    #            |    |-- conv -- tanh --|                |\n",
    "    # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n",
    "    #                 |-- conv -- sigm --|     |    ||\n",
    "    #                                         1x1=residualDim\n",
    "    #                                          |\n",
    "    # ---------------------------------------> + ------------->\t*skip=skipDim*\n",
    "    image changed from https://github.com/vincentherrmann/pytorch-wavenet/blob/master/wavenet_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T15:25:36.832497Z",
     "start_time": "2018-06-17T15:25:36.830080Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # use specific GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T15:25:36.844808Z",
     "start_time": "2018-06-17T15:25:36.833969Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available() # whether have available GPU\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#device = 'cpu'\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor') #set_default_tensor_type as cuda tensor\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T15:25:36.851820Z",
     "start_time": "2018-06-17T15:25:36.846372Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size':1, 'shuffle': True, 'num_workers': 1}\n",
    "training_set = Dataset(np.arange(0, songnum), np.arange(0, songnum), 'ccmixter2/x/', 'ccmixter2/y/')\n",
    "validation_set = Dataset(np.arange(0, songnum), np.arange(0, songnum), 'ccmixter2/x/', 'ccmixter2/y/')\n",
    "loadtr = data.DataLoader(training_set, **params)  # pytorch dataloader, more faster than mine\n",
    "loadval = data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T15:25:40.810233Z",
     "start_time": "2018-06-17T15:25:36.853364Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Wavenet(pad,skipDim,quantization_channels,residualDim,dilations).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#in wavenet paper, they said crossentropyloss is far better than MSELoss\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3,weight_decay=1e-5)\n",
    "#use adam to train\n",
    "#optimizer = optim.SGD(model.parameters(), lr = 0.1, momentum=0.9, weight_decay=1e-5)\n",
    "#scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[20,40], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T15:25:40.820907Z",
     "start_time": "2018-06-17T15:25:40.812521Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if continueTrain:# if continueTrain, the program will find the checkpoints\n",
    "    if os.path.isfile(resumefile):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resumefile))\n",
    "        checkpoint = torch.load(resumefile)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        #best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(resumefile, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resumefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T15:25:40.913438Z",
     "start_time": "2018-06-17T15:25:40.822619Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''def val(xtrain,ytrain): #validation last 15 seconds of the audio.\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        idx = np.arange(xtrain.shape[-1]-pad-10*sampleSize,xtrain.shape[-1]-pad-sampleSize,1000)\n",
    "        np.random.shuffle(idx)\n",
    "        data = xtrain[:,:,idx[0]-pad:pad+idx[0]+sampleSize].to(device)\n",
    "        target = ytrain[:,idx[0]:idx[0]+sampleSize].to(device)\n",
    "        output = model(data)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item() / pred.shape[-1]\n",
    "        val_loss = criterion(output, target).item()\n",
    "        print(correct,'accurate')\n",
    "        print('\\nval set:loss{:.4f}:, ({:.3f} sec/step)\\n'.format(val_loss,time.time()-start_time))\n",
    "        \n",
    "        listofpred = []\n",
    "        for ind in range(xtrain.shape[-1]-pad-10*sampleSize,xtrain.shape[-1]-pad-sampleSize,sampleSize):\n",
    "            output = model(xtrain[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "            pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "            listofpred.append(pred)\n",
    "        ans = mu_law_decode(np.concatenate(listofpred))\n",
    "        sf.write('./vsCorpus/notexval.wav', ans, sample_rate)\n",
    "        print('val stored done',time.time() - start_time)'''\n",
    "        \n",
    "\n",
    "def test(xtrain,iloader):# testing data\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        '''for iloader,(xtest,_) in enumerate(loadval):\n",
    "            listofpred = []\n",
    "            for ind in range(pad, xtest.shape[-1] - pad, sampleSize):\n",
    "                output = model(xtest[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "                pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "                listofpred.append(pred)\n",
    "            ans = mu_law_decode(np.concatenate(listofpred))\n",
    "            sf.write('./vsCorpus/notexte.wav', ans, sample_rate)'''\n",
    "\n",
    "        listofpred=[]\n",
    "        for ind in range(pad,xtrain.shape[-1]-pad,sampleSize):\n",
    "            output = model(xtrain[:, :, ind-pad:ind+sampleSize+pad].to(device))\n",
    "            pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(xtrain.shape[0],-1)\n",
    "            listofpred.append(pred)\n",
    "        ans = mu_law_decode(np.concatenate(listofpred,axis=1))\n",
    "        for i in range(xtrain.shape[0]):\n",
    "            sf.write(savemusic.format(iloader), ans[i], sample_rate)\n",
    "        print('test stored done',time.time() - start_time)\n",
    "    \n",
    "def train(epoch):#training data, the audio except for last 15 seconds\n",
    "    model.train()\n",
    "    for iloader,(xtrain,ytrain) in enumerate(loadtr):\n",
    "        idx = np.arange(pad,xtrain.shape[-1]-pad-sampleSize,1000)\n",
    "        np.random.shuffle(idx)#random the starting points\n",
    "        lens = idx.shape[-1] // songnum\n",
    "        lens = 100\n",
    "        idx = idx[:lens]\n",
    "        for i, ind in enumerate(idx):\n",
    "            start_time = time.time()\n",
    "            data, target = xtrain[:,:,ind-pad:ind+sampleSize+pad].to(device), ytrain[:,ind:ind+sampleSize].to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            lossrecord.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Train Epoch: {} iloader:{} [{}/{} ({:.0f}%)] Loss:{:.6f}: , ({:.3f} sec/step)'.format(\n",
    "                epoch, iloader, i, len(idx), 100. * i / len(idx), loss.item(), time.time() - start_time))\n",
    "            if i % 100 == 0:\n",
    "                with open(\"./lossRecord/\"+lossname, \"w\") as f:\n",
    "                    for s in lossrecord:\n",
    "                        f.write(str(s) +\"\\n\")\n",
    "                print('write finish')\n",
    "\n",
    "        test(xtrain,iloader)\n",
    "        state={'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()}\n",
    "        torch.save(state, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-17T15:29:42.852117Z",
     "start_time": "2018-06-17T15:25:40.915059Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 iloader:0 [0/100 (0%)] Loss:5.563398: , (2.831 sec/step)\n",
      "write finish\n",
      "Train Epoch: 0 iloader:0 [1/100 (1%)] Loss:5.725231: , (2.789 sec/step)\n",
      "Train Epoch: 0 iloader:0 [2/100 (2%)] Loss:5.490965: , (2.772 sec/step)\n",
      "Train Epoch: 0 iloader:0 [3/100 (3%)] Loss:5.609787: , (2.771 sec/step)\n",
      "Train Epoch: 0 iloader:0 [4/100 (4%)] Loss:5.682382: , (2.772 sec/step)\n",
      "Train Epoch: 0 iloader:0 [5/100 (5%)] Loss:5.356299: , (2.774 sec/step)\n",
      "Train Epoch: 0 iloader:0 [6/100 (6%)] Loss:5.166770: , (2.775 sec/step)\n",
      "Train Epoch: 0 iloader:0 [7/100 (7%)] Loss:5.037503: , (2.774 sec/step)\n",
      "Train Epoch: 0 iloader:0 [8/100 (8%)] Loss:4.611549: , (2.775 sec/step)\n",
      "Train Epoch: 0 iloader:0 [9/100 (9%)] Loss:5.103407: , (2.777 sec/step)\n",
      "Train Epoch: 0 iloader:0 [10/100 (10%)] Loss:5.150637: , (2.774 sec/step)\n",
      "Train Epoch: 0 iloader:0 [11/100 (11%)] Loss:5.002323: , (2.776 sec/step)\n",
      "Train Epoch: 0 iloader:0 [12/100 (12%)] Loss:4.867420: , (2.776 sec/step)\n",
      "Train Epoch: 0 iloader:0 [13/100 (13%)] Loss:5.028297: , (2.777 sec/step)\n",
      "Train Epoch: 0 iloader:0 [14/100 (14%)] Loss:4.698952: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [15/100 (15%)] Loss:4.859529: , (2.777 sec/step)\n",
      "Train Epoch: 0 iloader:0 [16/100 (16%)] Loss:4.739008: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [17/100 (17%)] Loss:4.753353: , (2.777 sec/step)\n",
      "Train Epoch: 0 iloader:0 [18/100 (18%)] Loss:5.009564: , (2.778 sec/step)\n",
      "Train Epoch: 0 iloader:0 [19/100 (19%)] Loss:4.778862: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [20/100 (20%)] Loss:4.579783: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [21/100 (21%)] Loss:4.350072: , (2.777 sec/step)\n",
      "Train Epoch: 0 iloader:0 [22/100 (22%)] Loss:4.727266: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [23/100 (23%)] Loss:4.798418: , (2.781 sec/step)\n",
      "Train Epoch: 0 iloader:0 [24/100 (24%)] Loss:4.759556: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [25/100 (25%)] Loss:4.982446: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [26/100 (26%)] Loss:5.187700: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [27/100 (27%)] Loss:5.313762: , (2.780 sec/step)\n",
      "Train Epoch: 0 iloader:0 [28/100 (28%)] Loss:4.932019: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [29/100 (29%)] Loss:4.759396: , (2.780 sec/step)\n",
      "Train Epoch: 0 iloader:0 [30/100 (30%)] Loss:4.845295: , (2.780 sec/step)\n",
      "Train Epoch: 0 iloader:0 [31/100 (31%)] Loss:4.494446: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [32/100 (32%)] Loss:4.706308: , (2.780 sec/step)\n",
      "Train Epoch: 0 iloader:0 [33/100 (33%)] Loss:4.888179: , (2.780 sec/step)\n",
      "Train Epoch: 0 iloader:0 [34/100 (34%)] Loss:4.932807: , (2.781 sec/step)\n",
      "Train Epoch: 0 iloader:0 [35/100 (35%)] Loss:4.753174: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [36/100 (36%)] Loss:4.797591: , (2.781 sec/step)\n",
      "Train Epoch: 0 iloader:0 [37/100 (37%)] Loss:4.593184: , (2.781 sec/step)\n",
      "Train Epoch: 0 iloader:0 [38/100 (38%)] Loss:4.888381: , (2.781 sec/step)\n",
      "Train Epoch: 0 iloader:0 [39/100 (39%)] Loss:4.772369: , (2.781 sec/step)\n",
      "Train Epoch: 0 iloader:0 [40/100 (40%)] Loss:4.488051: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [41/100 (41%)] Loss:4.679126: , (2.779 sec/step)\n",
      "Train Epoch: 0 iloader:0 [42/100 (42%)] Loss:4.315912: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [43/100 (43%)] Loss:4.221713: , (2.780 sec/step)\n",
      "Train Epoch: 0 iloader:0 [44/100 (44%)] Loss:4.650633: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [45/100 (45%)] Loss:4.580922: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [46/100 (46%)] Loss:4.135912: , (2.781 sec/step)\n",
      "Train Epoch: 0 iloader:0 [47/100 (47%)] Loss:4.854846: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [48/100 (48%)] Loss:4.742785: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [49/100 (49%)] Loss:4.607407: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [50/100 (50%)] Loss:4.710959: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [51/100 (51%)] Loss:4.698033: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [52/100 (52%)] Loss:4.633800: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [53/100 (53%)] Loss:4.505031: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [54/100 (54%)] Loss:4.746127: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [55/100 (55%)] Loss:4.538257: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [56/100 (56%)] Loss:4.240988: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [57/100 (57%)] Loss:4.943356: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [58/100 (58%)] Loss:4.560728: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [59/100 (59%)] Loss:4.572328: , (2.781 sec/step)\n",
      "Train Epoch: 0 iloader:0 [60/100 (60%)] Loss:4.669536: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [61/100 (61%)] Loss:4.323239: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [62/100 (62%)] Loss:4.615390: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [63/100 (63%)] Loss:4.479826: , (2.785 sec/step)\n",
      "Train Epoch: 0 iloader:0 [64/100 (64%)] Loss:4.554935: , (2.785 sec/step)\n",
      "Train Epoch: 0 iloader:0 [65/100 (65%)] Loss:4.785062: , (2.785 sec/step)\n",
      "Train Epoch: 0 iloader:0 [66/100 (66%)] Loss:4.505611: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [67/100 (67%)] Loss:4.669356: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [68/100 (68%)] Loss:4.683285: , (2.782 sec/step)\n",
      "Train Epoch: 0 iloader:0 [69/100 (69%)] Loss:4.674063: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [70/100 (70%)] Loss:4.501315: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [71/100 (71%)] Loss:4.640339: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [72/100 (72%)] Loss:4.437553: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [73/100 (73%)] Loss:4.568157: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [74/100 (74%)] Loss:4.488984: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [75/100 (75%)] Loss:4.182531: , (2.785 sec/step)\n",
      "Train Epoch: 0 iloader:0 [76/100 (76%)] Loss:4.484262: , (2.785 sec/step)\n",
      "Train Epoch: 0 iloader:0 [77/100 (77%)] Loss:4.531245: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [78/100 (78%)] Loss:4.360930: , (2.784 sec/step)\n",
      "Train Epoch: 0 iloader:0 [79/100 (79%)] Loss:4.181403: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [80/100 (80%)] Loss:4.625581: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [81/100 (81%)] Loss:4.430632: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [82/100 (82%)] Loss:4.541249: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [83/100 (83%)] Loss:4.683211: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [84/100 (84%)] Loss:4.708347: , (2.783 sec/step)\n",
      "Train Epoch: 0 iloader:0 [85/100 (85%)] Loss:4.474904: , (2.783 sec/step)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fd514051400>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 347, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 51869) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6efb5b007c8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-5a4149e8090e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mlossrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             print('Train Epoch: {} iloader:{} [{}/{} ({:.0f}%)] Loss:{:.6f}: , ({:.3f} sec/step)'.format(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLalgorithm/mnistPyTorch.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
