{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:08:49.842821Z",
     "start_time": "2018-05-31T13:08:47.487192Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Training script for the WaveNet network on the VCTK corpus.\n",
    "\n",
    "This script trains a network with the WaveNet using data from the VCTK corpus,\n",
    "which can be freely downloaded at the following site (~10 GB):\n",
    "http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "from wavenet import WaveNetModel, AudioReader, optimizer_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:08:49.859072Z",
     "start_time": "2018-05-31T13:08:49.845017Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DATA_DIRECTORY = './VCTK-Corpus'\n",
    "LOGDIR_ROOT = './logdir'\n",
    "CHECKPOINT_EVERY = 50\n",
    "NUM_STEPS = int(1e5)\n",
    "LEARNING_RATE = 1e-3\n",
    "WAVENET_PARAMS = './wavenet_params.json'\n",
    "STARTED_DATESTRING = \"{0:%Y-%m-%dT%H-%M-%S}\".format(datetime.now())\n",
    "SAMPLE_SIZE = 100000\n",
    "L2_REGULARIZATION_STRENGTH = 0\n",
    "#SILENCE_THRESHOLD = 0.3\n",
    "SILENCE_THRESHOLD = 0\n",
    "EPSILON = 0.001\n",
    "MOMENTUM = 0.9\n",
    "MAX_TO_KEEP = 5\n",
    "METADATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:08:49.960568Z",
     "start_time": "2018-05-31T13:08:49.862020Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    def _str_to_bool(s):\n",
    "        \"\"\"Convert string to bool (in argparse context).\"\"\"\n",
    "        if s.lower() not in ['true', 'false']:\n",
    "            raise ValueError('Argument needs to be a '\n",
    "                             'boolean, got {}'.format(s))\n",
    "        return {'true': True, 'false': False}[s.lower()]\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='WaveNet example network')\n",
    "    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE,\n",
    "                        help='How many wav files to process at once. Default: ' + str(BATCH_SIZE) + '.')\n",
    "    parser.add_argument('--data_dir', type=str, default=DATA_DIRECTORY,\n",
    "                        help='The directory containing the VCTK corpus.')\n",
    "    parser.add_argument('--store_metadata', type=bool, default=METADATA,\n",
    "                        help='Whether to store advanced debugging information '\n",
    "                        '(execution time, memory consumption) for use with '\n",
    "                        'TensorBoard. Default: ' + str(METADATA) + '.')\n",
    "    parser.add_argument('--logdir', type=str, default=None,\n",
    "                        help='Directory in which to store the logging '\n",
    "                        'information for TensorBoard. '\n",
    "                        'If the model already exists, it will restore '\n",
    "                        'the state and will continue training. '\n",
    "                        'Cannot use with --logdir_root and --restore_from.')\n",
    "    parser.add_argument('--logdir_root', type=str, default=None,\n",
    "                        help='Root directory to place the logging '\n",
    "                        'output and generated model. These are stored '\n",
    "                        'under the dated subdirectory of --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--restore_from', type=str, default=None,\n",
    "                        help='Directory in which to restore the model from. '\n",
    "                        'This creates the new model under the dated directory '\n",
    "                        'in --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--checkpoint_every', type=int,\n",
    "                        default=CHECKPOINT_EVERY,\n",
    "                        help='How many steps to save each checkpoint after. Default: ' + str(CHECKPOINT_EVERY) + '.')\n",
    "    parser.add_argument('--num_steps', type=int, default=NUM_STEPS,\n",
    "                        help='Number of training steps. Default: ' + str(NUM_STEPS) + '.')\n",
    "    parser.add_argument('--learning_rate', type=float, default=LEARNING_RATE,\n",
    "                        help='Learning rate for training. Default: ' + str(LEARNING_RATE) + '.')\n",
    "    parser.add_argument('--wavenet_params', type=str, default=WAVENET_PARAMS,\n",
    "                        help='JSON file with the network parameters. Default: ' + WAVENET_PARAMS + '.')\n",
    "    parser.add_argument('--sample_size', type=int, default=SAMPLE_SIZE,\n",
    "                        help='Concatenate and cut audio samples to this many '\n",
    "                        'samples. Default: ' + str(SAMPLE_SIZE) + '.')\n",
    "    parser.add_argument('--l2_regularization_strength', type=float,\n",
    "                        default=L2_REGULARIZATION_STRENGTH,\n",
    "                        help='Coefficient in the L2 regularization. '\n",
    "                        'Default: False')\n",
    "    parser.add_argument('--silence_threshold', type=float,\n",
    "                        default=SILENCE_THRESHOLD,\n",
    "                        help='Volume threshold below which to trim the start '\n",
    "                        'and the end from the training set samples. Default: ' + str(SILENCE_THRESHOLD) + '.')\n",
    "    parser.add_argument('--optimizer', type=str, default='adam',\n",
    "                        choices=optimizer_factory.keys(),\n",
    "                        help='Select the optimizer specified by this option. Default: adam.')\n",
    "    parser.add_argument('--momentum', type=float,\n",
    "                        default=MOMENTUM, help='Specify the momentum to be '\n",
    "                        'used by sgd or rmsprop optimizer. Ignored by the '\n",
    "                        'adam optimizer. Default: ' + str(MOMENTUM) + '.')\n",
    "    parser.add_argument('--histograms', type=_str_to_bool, default=False,\n",
    "                        help='Whether to store histogram summaries. Default: False')\n",
    "    parser.add_argument('--gc_channels', type=int, default=None,\n",
    "                        help='Number of global condition channels. Default: None. Expecting: Int')\n",
    "    parser.add_argument('--max_checkpoints', type=int, default=MAX_TO_KEEP,\n",
    "                        help='Maximum amount of checkpoints that will be kept alive. Default: '\n",
    "                             + str(MAX_TO_KEEP) + '.')\n",
    "    return parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:08:49.974107Z",
     "start_time": "2018-05-31T13:08:49.962535Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:08:49.998662Z",
     "start_time": "2018-05-31T13:08:49.976717Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(saver, sess, logdir):\n",
    "    print(\"Trying to restore saved checkpoints from {} ...\".format(logdir),\n",
    "          end=\"\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(logdir)\n",
    "    if ckpt:\n",
    "        print(\"  Checkpoint found: {}\".format(ckpt.model_checkpoint_path))\n",
    "        global_step = int(ckpt.model_checkpoint_path\n",
    "                          .split('/')[-1]\n",
    "                          .split('-')[-1])\n",
    "        print(\"  Global step was: {}\".format(global_step))\n",
    "        print(\"  Restoring...\", end=\"\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\" Done.\")\n",
    "        return global_step\n",
    "    else:\n",
    "        print(\" No checkpoint found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:08:50.044970Z",
     "start_time": "2018-05-31T13:08:50.001693Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_default_logdir(logdir_root):\n",
    "    logdir = os.path.join(logdir_root, 'train', STARTED_DATESTRING)\n",
    "    return logdir\n",
    "\n",
    "\n",
    "def validate_directories(args):\n",
    "    \"\"\"Validate and arrange directory related arguments.\"\"\"\n",
    "\n",
    "    # Validation\n",
    "    if args.logdir and args.logdir_root:\n",
    "        raise ValueError(\"--logdir and --logdir_root cannot be \"\n",
    "                         \"specified at the same time.\")\n",
    "\n",
    "    if args.logdir and args.restore_from:\n",
    "        raise ValueError(\n",
    "            \"--logdir and --restore_from cannot be specified at the same \"\n",
    "            \"time. This is to keep your previous model from unexpected \"\n",
    "            \"overwrites.\\n\"\n",
    "            \"Use --logdir_root to specify the root of the directory which \"\n",
    "            \"will be automatically created with current date and time, or use \"\n",
    "            \"only --logdir to just continue the training from the last \"\n",
    "            \"checkpoint.\")\n",
    "\n",
    "    # Arrangement\n",
    "    logdir_root = args.logdir_root\n",
    "    if logdir_root is None:\n",
    "        logdir_root = LOGDIR_ROOT\n",
    "\n",
    "    logdir = args.logdir\n",
    "    if logdir is None:\n",
    "        logdir = get_default_logdir(logdir_root)\n",
    "        print('Using default logdir: {}'.format(logdir))\n",
    "\n",
    "    restore_from = args.restore_from\n",
    "    if restore_from is None:\n",
    "        # args.logdir and args.restore_from are exclusive,\n",
    "        # so it is guaranteed the logdir here is newly created.\n",
    "        restore_from = logdir\n",
    "\n",
    "    return {\n",
    "        'logdir': logdir,\n",
    "        'logdir_root': args.logdir_root,\n",
    "        'restore_from': restore_from\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:14:58.749029Z",
     "start_time": "2018-05-31T13:08:50.048093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default logdir: ./logdir/train/2018-05-31T21-08-49\n",
      "Tensor(\"wavenet_1/dilated_stack/layer1/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer1/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer2/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer2/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer3/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer3/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer4/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer4/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer5/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer5/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer6/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer6/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer7/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer7/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer8/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer8/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer9/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer9/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer11/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer11/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer12/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer12/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer13/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer13/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer14/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer14/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer15/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer15/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer16/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer16/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer17/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer17/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer18/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer18/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer19/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer19/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer21/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer21/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer22/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer22/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer23/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer23/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer24/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer24/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer25/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer25/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer26/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer26/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer27/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer27/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer28/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer28/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer29/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer29/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer31/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer31/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer32/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer32/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer33/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer33/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer34/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer34/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer35/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer35/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer36/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer36/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer37/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer37/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer38/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer38/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer39/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer39/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer41/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer41/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer42/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer42/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer43/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer43/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"wavenet_1/dilated_stack/layer44/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer44/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer45/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer45/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer46/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer46/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer47/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer47/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer48/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer48/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer49/causal_conv/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "Tensor(\"wavenet_1/dilated_stack/layer49/causal_conv_1/conv1d/Squeeze:0\", shape=(?, ?, 32), dtype=float32)\n",
      "WARNING:tensorflow:From /home/coder.chenshicheng/WaveNetSeparateAudio/wavenet/model.py:662: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Trying to restore saved checkpoints from ./logdir/train/2018-05-31T21-08-49 ... No checkpoint found.\n",
      "files length: 44257\n",
      "step 0 - loss = 5.686, (19.707 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T21-08-49 ... Done.\n",
      "step 1 - loss = 5.627, (3.361 sec/step)\n",
      "step 2 - loss = 5.562, (4.250 sec/step)\n",
      "step 3 - loss = 5.468, (4.205 sec/step)\n",
      "step 4 - loss = 5.393, (2.962 sec/step)\n",
      "step 5 - loss = 5.484, (3.448 sec/step)\n",
      "step 6 - loss = 5.217, (3.913 sec/step)\n",
      "step 7 - loss = 5.141, (2.995 sec/step)\n",
      "step 8 - loss = 5.228, (2.218 sec/step)\n",
      "step 9 - loss = 5.282, (2.976 sec/step)\n",
      "step 10 - loss = 4.892, (1.872 sec/step)\n",
      "step 11 - loss = 5.076, (3.437 sec/step)\n",
      "step 12 - loss = 4.871, (3.183 sec/step)\n",
      "step 13 - loss = 5.038, (3.100 sec/step)\n",
      "step 14 - loss = 4.678, (3.971 sec/step)\n",
      "step 15 - loss = 5.130, (4.037 sec/step)\n",
      "step 16 - loss = 5.167, (2.758 sec/step)\n",
      "step 17 - loss = 5.023, (3.069 sec/step)\n",
      "step 18 - loss = 5.114, (3.033 sec/step)\n",
      "step 19 - loss = 4.314, (1.961 sec/step)\n",
      "step 20 - loss = 5.168, (1.907 sec/step)\n",
      "step 21 - loss = 4.541, (3.737 sec/step)\n",
      "step 22 - loss = 4.527, (2.412 sec/step)\n",
      "step 23 - loss = 4.435, (6.152 sec/step)\n",
      "step 24 - loss = 4.836, (1.998 sec/step)\n",
      "step 25 - loss = 4.523, (1.772 sec/step)\n",
      "step 26 - loss = 4.804, (2.392 sec/step)\n",
      "step 27 - loss = 4.443, (3.224 sec/step)\n",
      "step 28 - loss = 4.239, (2.104 sec/step)\n",
      "step 29 - loss = 4.583, (1.951 sec/step)\n",
      "step 30 - loss = 4.259, (1.647 sec/step)\n",
      "step 31 - loss = 4.505, (3.822 sec/step)\n",
      "step 32 - loss = 4.877, (2.030 sec/step)\n",
      "step 33 - loss = 4.217, (2.134 sec/step)\n",
      "step 34 - loss = 4.765, (1.647 sec/step)\n",
      "step 35 - loss = 4.069, (2.265 sec/step)\n",
      "step 36 - loss = 3.752, (3.084 sec/step)\n",
      "step 37 - loss = 4.257, (4.359 sec/step)\n",
      "step 38 - loss = 2.984, (3.071 sec/step)\n",
      "step 39 - loss = 4.494, (3.203 sec/step)\n",
      "step 40 - loss = 3.726, (3.075 sec/step)\n",
      "step 41 - loss = 3.108, (6.395 sec/step)\n",
      "step 42 - loss = 3.678, (2.972 sec/step)\n",
      "step 43 - loss = 3.584, (3.558 sec/step)\n",
      "step 44 - loss = 3.436, (1.996 sec/step)\n",
      "step 45 - loss = 3.385, (2.667 sec/step)\n",
      "step 46 - loss = 3.989, (1.756 sec/step)\n",
      "step 47 - loss = 3.788, (2.421 sec/step)\n",
      "step 48 - loss = 4.035, (2.450 sec/step)\n",
      "step 49 - loss = 3.898, (2.337 sec/step)\n",
      "step 50 - loss = 3.830, (3.541 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T21-08-49 ... Done.\n",
      "step 51 - loss = 3.528, (2.375 sec/step)\n",
      "step 52 - loss = 3.762, (2.043 sec/step)\n",
      "step 53 - loss = 3.430, (3.261 sec/step)\n",
      "step 54 - loss = 3.934, (1.802 sec/step)\n",
      "step 55 - loss = 3.695, (1.698 sec/step)\n",
      "step 56 - loss = 4.023, (3.171 sec/step)\n",
      "step 57 - loss = 3.826, (2.685 sec/step)\n",
      "step 58 - loss = 3.063, (2.094 sec/step)\n",
      "step 59 - loss = 4.011, (2.125 sec/step)\n",
      "step 60 - loss = 3.181, (2.551 sec/step)\n",
      "step 61 - loss = 4.163, (2.177 sec/step)\n",
      "step 62 - loss = 4.186, (2.086 sec/step)\n",
      "step 63 - loss = 3.334, (1.544 sec/step)\n",
      "step 64 - loss = 4.166, (2.483 sec/step)\n",
      "step 65 - loss = 3.376, (1.881 sec/step)\n",
      "step 66 - loss = 2.924, (1.872 sec/step)\n",
      "step 67 - loss = 3.649, (1.806 sec/step)\n",
      "step 68 - loss = 3.433, (3.178 sec/step)\n",
      "step 69 - loss = 3.939, (2.675 sec/step)\n",
      "step 70 - loss = 3.801, (1.756 sec/step)\n",
      "step 71 - loss = 3.298, (1.945 sec/step)\n",
      "step 72 - loss = 2.715, (2.029 sec/step)\n",
      "step 73 - loss = 3.308, (2.971 sec/step)\n",
      "step 74 - loss = 3.224, (2.515 sec/step)\n",
      "step 75 - loss = 3.676, (2.254 sec/step)\n",
      "step 76 - loss = 3.430, (2.369 sec/step)\n",
      "step 77 - loss = 3.508, (1.785 sec/step)\n",
      "step 78 - loss = 3.993, (1.876 sec/step)\n",
      "step 79 - loss = 3.431, (1.711 sec/step)\n",
      "step 80 - loss = 3.561, (2.297 sec/step)\n",
      "step 81 - loss = 3.208, (4.134 sec/step)\n",
      "step 82 - loss = 3.113, (2.637 sec/step)\n",
      "step 83 - loss = 2.669, (3.305 sec/step)\n",
      "step 84 - loss = 2.974, (3.417 sec/step)\n",
      "step 85 - loss = 3.162, (1.360 sec/step)\n",
      "step 86 - loss = 2.571, (3.951 sec/step)\n",
      "step 87 - loss = 3.294, (1.733 sec/step)\n",
      "step 88 - loss = 2.433, (3.222 sec/step)\n",
      "step 89 - loss = 3.111, (2.505 sec/step)\n",
      "step 90 - loss = 2.712, (2.746 sec/step)\n",
      "step 91 - loss = 3.365, (3.723 sec/step)\n",
      "step 92 - loss = 3.282, (1.999 sec/step)\n",
      "step 93 - loss = 3.569, (2.607 sec/step)\n",
      "step 94 - loss = 3.200, (2.080 sec/step)\n",
      "step 95 - loss = 2.758, (2.069 sec/step)\n",
      "step 96 - loss = 3.199, (2.224 sec/step)\n",
      "step 97 - loss = 2.190, (2.245 sec/step)\n",
      "step 98 - loss = 2.694, (1.615 sec/step)\n",
      "step 99 - loss = 3.062, (4.939 sec/step)\n",
      "step 100 - loss = 3.208, (1.114 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T21-08-49 ... Done.\n",
      "step 101 - loss = 3.370, (1.644 sec/step)\n",
      "step 102 - loss = 2.761, (1.618 sec/step)\n",
      "step 103 - loss = 2.930, (1.591 sec/step)\n",
      "step 104 - loss = 3.115, (2.981 sec/step)\n",
      "step 105 - loss = 2.932, (2.558 sec/step)\n",
      "step 106 - loss = 2.298, (1.628 sec/step)\n",
      "step 107 - loss = 3.275, (2.740 sec/step)\n",
      "step 108 - loss = 1.858, (1.427 sec/step)\n",
      "step 109 - loss = 3.030, (1.899 sec/step)\n",
      "step 110 - loss = 2.435, (3.264 sec/step)\n",
      "step 111 - loss = 3.371, (2.466 sec/step)\n",
      "step 112 - loss = 3.605, (2.838 sec/step)\n",
      "step 113 - loss = 2.799, (2.545 sec/step)\n",
      "\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T21-08-49 ..."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1a523db76be0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlast_saved_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-2bd450753b9a>\u001b[0m in \u001b[0;36msave\u001b[0;34m(saver, sess, logdir, step)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' Done.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1726\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1727\u001b[0m           self.export_meta_graph(\n\u001b[0;32m-> 1728\u001b[0;31m               meta_graph_filename, strip_default_attrs=strip_default_attrs)\n\u001b[0m\u001b[1;32m   1729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mexport_meta_graph\u001b[0;34m(self, filename, collection_list, as_text, export_scope, clear_devices, clear_extraneous_savers, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     return export_meta_graph(\n\u001b[1;32m   1765\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m         \u001b[0mgraph_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1767\u001b[0m         \u001b[0msaver_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m         \u001b[0mcollection_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollection_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \"\"\"\n\u001b[1;32m   3227\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3228\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3229\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   3170\u001b[0m           \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3171\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphDef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3172\u001b[0;31m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3173\u001b[0m         \u001b[0;31m# Strip the experimental library field iff it's empty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = get_arguments()\n",
    "\n",
    "try:\n",
    "    directories = validate_directories(args)\n",
    "except ValueError as e:\n",
    "    print(\"Some arguments are wrong:\")\n",
    "    print(str(e))\n",
    "\n",
    "logdir = directories['logdir']\n",
    "restore_from = directories['restore_from']\n",
    "\n",
    "# Even if we restored the model, we will treat it as new training\n",
    "# if the trained model is written into an arbitrary location.\n",
    "is_overwritten_training = logdir != restore_from\n",
    "\n",
    "with open(args.wavenet_params, 'r') as f:\n",
    "    wavenet_params = json.load(f)\n",
    "\n",
    "# Create coordinator.\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "# Load raw waveform from VCTK corpus.\n",
    "with tf.name_scope('create_inputs'):\n",
    "    # Allow silence trimming to be skipped by specifying a threshold near\n",
    "    # zero.\n",
    "    silence_threshold = args.silence_threshold if args.silence_threshold > \\\n",
    "                                                  EPSILON else None\n",
    "    gc_enabled = args.gc_channels is not None\n",
    "    reader = AudioReader(\n",
    "        args.data_dir,\n",
    "        coord,\n",
    "        sample_rate=wavenet_params['sample_rate'],\n",
    "        gc_enabled=gc_enabled,\n",
    "        receptive_field=WaveNetModel.calculate_receptive_field(wavenet_params[\"filter_width\"],\n",
    "                                                               wavenet_params[\"dilations\"],\n",
    "                                                               wavenet_params[\"scalar_input\"],\n",
    "                                                               wavenet_params[\"initial_filter_width\"]),\n",
    "        sample_size=args.sample_size,\n",
    "        silence_threshold=silence_threshold)\n",
    "    audio_batch = reader.dequeue(args.batch_size)\n",
    "    if gc_enabled:\n",
    "        gc_id_batch = reader.dequeue_gc(args.batch_size)\n",
    "    else:\n",
    "        gc_id_batch = None\n",
    "\n",
    "# Create network.\n",
    "net = WaveNetModel(\n",
    "    batch_size=args.batch_size,\n",
    "    dilations=wavenet_params[\"dilations\"],\n",
    "    filter_width=wavenet_params[\"filter_width\"],\n",
    "    residual_channels=wavenet_params[\"residual_channels\"],\n",
    "    dilation_channels=wavenet_params[\"dilation_channels\"],\n",
    "    skip_channels=wavenet_params[\"skip_channels\"],\n",
    "    quantization_channels=wavenet_params[\"quantization_channels\"],\n",
    "    use_biases=wavenet_params[\"use_biases\"],\n",
    "    scalar_input=wavenet_params[\"scalar_input\"],\n",
    "    initial_filter_width=wavenet_params[\"initial_filter_width\"],\n",
    "    histograms=args.histograms,\n",
    "    global_condition_channels=args.gc_channels,\n",
    "    global_condition_cardinality=reader.gc_category_cardinality)\n",
    "\n",
    "if args.l2_regularization_strength == 0:\n",
    "    args.l2_regularization_strength = None\n",
    "loss = net.loss(input_batch=audio_batch,\n",
    "                global_condition_batch=gc_id_batch,\n",
    "                l2_regularization_strength=args.l2_regularization_strength)\n",
    "optimizer = optimizer_factory[args.optimizer](\n",
    "                learning_rate=args.learning_rate,\n",
    "                momentum=args.momentum)\n",
    "trainable = tf.trainable_variables()\n",
    "optim = optimizer.minimize(loss, var_list=trainable)\n",
    "\n",
    "# Set up logging for TensorBoard.\n",
    "writer = tf.summary.FileWriter(logdir)\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "run_metadata = tf.RunMetadata()\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "# Set up session\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Saver for storing checkpoints of the model.\n",
    "saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=args.max_checkpoints)\n",
    "\n",
    "try:\n",
    "    saved_global_step = load(saver, sess, restore_from)\n",
    "    if is_overwritten_training or saved_global_step is None:\n",
    "        # The first training step will be saved_global_step + 1,\n",
    "        # therefore we put -1 here for new or overwritten trainings.\n",
    "        saved_global_step = -1\n",
    "\n",
    "except:\n",
    "    print(\"Something went wrong while restoring checkpoint. \"\n",
    "          \"We will terminate training to avoid accidentally overwriting \"\n",
    "          \"the previous model.\")\n",
    "    raise\n",
    "\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "reader.start_threads(sess)\n",
    "\n",
    "step = None\n",
    "last_saved_step = saved_global_step\n",
    "try:\n",
    "    for step in range(saved_global_step + 1, args.num_steps):\n",
    "        start_time = time.time()\n",
    "        if args.store_metadata and step % 50 == 0:\n",
    "            # Slow run that stores extra information for debugging.\n",
    "            print('Storing metadata')\n",
    "            run_options = tf.RunOptions(\n",
    "                trace_level=tf.RunOptions.FULL_TRACE)\n",
    "            summary, loss_value, _ = sess.run(\n",
    "                [summaries, loss, optim],\n",
    "                options=run_options,\n",
    "                run_metadata=run_metadata)\n",
    "            writer.add_summary(summary, step)\n",
    "            writer.add_run_metadata(run_metadata,\n",
    "                                    'step_{:04d}'.format(step))\n",
    "            tl = timeline.Timeline(run_metadata.step_stats)\n",
    "            timeline_path = os.path.join(logdir, 'timeline.trace')\n",
    "            with open(timeline_path, 'w') as f:\n",
    "                f.write(tl.generate_chrome_trace_format(show_memory=True))\n",
    "        else:\n",
    "            summary, loss_value, _ = sess.run([summaries, loss, optim])\n",
    "            writer.add_summary(summary, step)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        print('step {:d} - loss = {:.3f}, ({:.3f} sec/step)'\n",
    "              .format(step, loss_value, duration))\n",
    "\n",
    "        if step % args.checkpoint_every == 0:\n",
    "            save(saver, sess, logdir, step)\n",
    "            last_saved_step = step\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Introduce a line break after ^C is displayed so save message\n",
    "    # is on its own line.\n",
    "    print()\n",
    "finally:\n",
    "    if step > last_saved_step:\n",
    "        save(saver, sess, logdir, step)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
