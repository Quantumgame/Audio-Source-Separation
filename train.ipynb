{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T02:54:40.005806Z",
     "start_time": "2018-05-31T02:54:39.992287Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Training script for the WaveNet network on the VCTK corpus.\n",
    "\n",
    "This script trains a network with the WaveNet using data from the VCTK corpus,\n",
    "which can be freely downloaded at the following site (~10 GB):\n",
    "http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "from wavenet import WaveNetModel, AudioReader, optimizer_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T02:54:40.516700Z",
     "start_time": "2018-05-31T02:54:40.499918Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "DATA_DIRECTORY = './VCTK-Corpus'\n",
    "LOGDIR_ROOT = './logdir'\n",
    "CHECKPOINT_EVERY = 50\n",
    "NUM_STEPS = int(1e5)\n",
    "LEARNING_RATE = 1e-3\n",
    "WAVENET_PARAMS = './wavenet_params.json'\n",
    "STARTED_DATESTRING = \"{0:%Y-%m-%dT%H-%M-%S}\".format(datetime.now())\n",
    "SAMPLE_SIZE = 100000\n",
    "L2_REGULARIZATION_STRENGTH = 0\n",
    "#SILENCE_THRESHOLD = 0.3\n",
    "SILENCE_THRESHOLD = 0\n",
    "EPSILON = 0.001\n",
    "MOMENTUM = 0.9\n",
    "MAX_TO_KEEP = 5\n",
    "METADATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T02:54:40.990094Z",
     "start_time": "2018-05-31T02:54:40.907424Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    def _str_to_bool(s):\n",
    "        \"\"\"Convert string to bool (in argparse context).\"\"\"\n",
    "        if s.lower() not in ['true', 'false']:\n",
    "            raise ValueError('Argument needs to be a '\n",
    "                             'boolean, got {}'.format(s))\n",
    "        return {'true': True, 'false': False}[s.lower()]\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='WaveNet example network')\n",
    "    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE,\n",
    "                        help='How many wav files to process at once. Default: ' + str(BATCH_SIZE) + '.')\n",
    "    parser.add_argument('--data_dir', type=str, default=DATA_DIRECTORY,\n",
    "                        help='The directory containing the VCTK corpus.')\n",
    "    parser.add_argument('--store_metadata', type=bool, default=METADATA,\n",
    "                        help='Whether to store advanced debugging information '\n",
    "                        '(execution time, memory consumption) for use with '\n",
    "                        'TensorBoard. Default: ' + str(METADATA) + '.')\n",
    "    parser.add_argument('--logdir', type=str, default=None,\n",
    "                        help='Directory in which to store the logging '\n",
    "                        'information for TensorBoard. '\n",
    "                        'If the model already exists, it will restore '\n",
    "                        'the state and will continue training. '\n",
    "                        'Cannot use with --logdir_root and --restore_from.')\n",
    "    parser.add_argument('--logdir_root', type=str, default=None,\n",
    "                        help='Root directory to place the logging '\n",
    "                        'output and generated model. These are stored '\n",
    "                        'under the dated subdirectory of --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--restore_from', type=str, default=None,\n",
    "                        help='Directory in which to restore the model from. '\n",
    "                        'This creates the new model under the dated directory '\n",
    "                        'in --logdir_root. '\n",
    "                        'Cannot use with --logdir.')\n",
    "    parser.add_argument('--checkpoint_every', type=int,\n",
    "                        default=CHECKPOINT_EVERY,\n",
    "                        help='How many steps to save each checkpoint after. Default: ' + str(CHECKPOINT_EVERY) + '.')\n",
    "    parser.add_argument('--num_steps', type=int, default=NUM_STEPS,\n",
    "                        help='Number of training steps. Default: ' + str(NUM_STEPS) + '.')\n",
    "    parser.add_argument('--learning_rate', type=float, default=LEARNING_RATE,\n",
    "                        help='Learning rate for training. Default: ' + str(LEARNING_RATE) + '.')\n",
    "    parser.add_argument('--wavenet_params', type=str, default=WAVENET_PARAMS,\n",
    "                        help='JSON file with the network parameters. Default: ' + WAVENET_PARAMS + '.')\n",
    "    parser.add_argument('--sample_size', type=int, default=SAMPLE_SIZE,\n",
    "                        help='Concatenate and cut audio samples to this many '\n",
    "                        'samples. Default: ' + str(SAMPLE_SIZE) + '.')\n",
    "    parser.add_argument('--l2_regularization_strength', type=float,\n",
    "                        default=L2_REGULARIZATION_STRENGTH,\n",
    "                        help='Coefficient in the L2 regularization. '\n",
    "                        'Default: False')\n",
    "    parser.add_argument('--silence_threshold', type=float,\n",
    "                        default=SILENCE_THRESHOLD,\n",
    "                        help='Volume threshold below which to trim the start '\n",
    "                        'and the end from the training set samples. Default: ' + str(SILENCE_THRESHOLD) + '.')\n",
    "    parser.add_argument('--optimizer', type=str, default='adam',\n",
    "                        choices=optimizer_factory.keys(),\n",
    "                        help='Select the optimizer specified by this option. Default: adam.')\n",
    "    parser.add_argument('--momentum', type=float,\n",
    "                        default=MOMENTUM, help='Specify the momentum to be '\n",
    "                        'used by sgd or rmsprop optimizer. Ignored by the '\n",
    "                        'adam optimizer. Default: ' + str(MOMENTUM) + '.')\n",
    "    parser.add_argument('--histograms', type=_str_to_bool, default=False,\n",
    "                        help='Whether to store histogram summaries. Default: False')\n",
    "    parser.add_argument('--gc_channels', type=int, default=None,\n",
    "                        help='Number of global condition channels. Default: None. Expecting: Int')\n",
    "    parser.add_argument('--max_checkpoints', type=int, default=MAX_TO_KEEP,\n",
    "                        help='Maximum amount of checkpoints that will be kept alive. Default: '\n",
    "                             + str(MAX_TO_KEEP) + '.')\n",
    "    return parser.parse_args([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T02:54:42.078110Z",
     "start_time": "2018-05-31T02:54:42.063078Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save(saver, sess, logdir, step):\n",
    "    model_name = 'model.ckpt'\n",
    "    checkpoint_path = os.path.join(logdir, model_name)\n",
    "    print('Storing checkpoint to {} ...'.format(logdir), end=\"\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if not os.path.exists(logdir):\n",
    "        os.makedirs(logdir)\n",
    "\n",
    "    saver.save(sess, checkpoint_path, global_step=step)\n",
    "    print(' Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T02:54:42.465266Z",
     "start_time": "2018-05-31T02:54:42.442989Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load(saver, sess, logdir):\n",
    "    print(\"Trying to restore saved checkpoints from {} ...\".format(logdir),\n",
    "          end=\"\")\n",
    "\n",
    "    ckpt = tf.train.get_checkpoint_state(logdir)\n",
    "    if ckpt:\n",
    "        print(\"  Checkpoint found: {}\".format(ckpt.model_checkpoint_path))\n",
    "        global_step = int(ckpt.model_checkpoint_path\n",
    "                          .split('/')[-1]\n",
    "                          .split('-')[-1])\n",
    "        print(\"  Global step was: {}\".format(global_step))\n",
    "        print(\"  Restoring...\", end=\"\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\" Done.\")\n",
    "        return global_step\n",
    "    else:\n",
    "        print(\" No checkpoint found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T02:54:42.925592Z",
     "start_time": "2018-05-31T02:54:42.884767Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_default_logdir(logdir_root):\n",
    "    logdir = os.path.join(logdir_root, 'train', STARTED_DATESTRING)\n",
    "    return logdir\n",
    "\n",
    "\n",
    "def validate_directories(args):\n",
    "    \"\"\"Validate and arrange directory related arguments.\"\"\"\n",
    "\n",
    "    # Validation\n",
    "    if args.logdir and args.logdir_root:\n",
    "        raise ValueError(\"--logdir and --logdir_root cannot be \"\n",
    "                         \"specified at the same time.\")\n",
    "\n",
    "    if args.logdir and args.restore_from:\n",
    "        raise ValueError(\n",
    "            \"--logdir and --restore_from cannot be specified at the same \"\n",
    "            \"time. This is to keep your previous model from unexpected \"\n",
    "            \"overwrites.\\n\"\n",
    "            \"Use --logdir_root to specify the root of the directory which \"\n",
    "            \"will be automatically created with current date and time, or use \"\n",
    "            \"only --logdir to just continue the training from the last \"\n",
    "            \"checkpoint.\")\n",
    "\n",
    "    # Arrangement\n",
    "    logdir_root = args.logdir_root\n",
    "    if logdir_root is None:\n",
    "        logdir_root = LOGDIR_ROOT\n",
    "\n",
    "    logdir = args.logdir\n",
    "    if logdir is None:\n",
    "        logdir = get_default_logdir(logdir_root)\n",
    "        print('Using default logdir: {}'.format(logdir))\n",
    "\n",
    "    restore_from = args.restore_from\n",
    "    if restore_from is None:\n",
    "        # args.logdir and args.restore_from are exclusive,\n",
    "        # so it is guaranteed the logdir here is newly created.\n",
    "        restore_from = logdir\n",
    "\n",
    "    return {\n",
    "        'logdir': logdir,\n",
    "        'logdir_root': args.logdir_root,\n",
    "        'restore_from': restore_from\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-05-31T02:54:43.392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default logdir: ./logdir/train/2018-05-31T10-54-40\n",
      "WARNING:tensorflow:From /home/coder.chenshicheng/WaveNetSeparateAudio/wavenet/model.py:662: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Trying to restore saved checkpoints from ./logdir/train/2018-05-31T10-54-40 ... No checkpoint found.\n",
      "files length: 44257\n",
      "step 0 - loss = 5.661, (17.984 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1 - loss = 5.589, (3.403 sec/step)\n",
      "step 2 - loss = 5.498, (3.220 sec/step)\n",
      "step 3 - loss = 5.493, (3.605 sec/step)\n",
      "step 4 - loss = 5.399, (3.675 sec/step)\n",
      "step 5 - loss = 5.312, (1.936 sec/step)\n",
      "step 6 - loss = 5.277, (3.636 sec/step)\n",
      "step 7 - loss = 5.186, (3.772 sec/step)\n",
      "step 8 - loss = 5.509, (4.324 sec/step)\n",
      "step 9 - loss = 5.239, (4.686 sec/step)\n",
      "step 10 - loss = 5.144, (2.501 sec/step)\n",
      "step 11 - loss = 4.987, (2.861 sec/step)\n",
      "step 12 - loss = 4.952, (2.903 sec/step)\n",
      "step 13 - loss = 4.970, (2.990 sec/step)\n",
      "step 14 - loss = 5.041, (3.451 sec/step)\n",
      "step 15 - loss = 4.925, (2.029 sec/step)\n",
      "step 16 - loss = 4.856, (1.851 sec/step)\n",
      "step 17 - loss = 5.042, (3.975 sec/step)\n",
      "step 18 - loss = 4.857, (3.234 sec/step)\n",
      "step 19 - loss = 4.951, (2.766 sec/step)\n",
      "step 20 - loss = 5.120, (1.711 sec/step)\n",
      "step 21 - loss = 4.896, (1.835 sec/step)\n",
      "step 22 - loss = 4.763, (2.178 sec/step)\n",
      "step 23 - loss = 5.071, (2.562 sec/step)\n",
      "step 24 - loss = 4.567, (1.586 sec/step)\n",
      "step 25 - loss = 4.928, (1.750 sec/step)\n",
      "step 26 - loss = 5.020, (2.479 sec/step)\n",
      "step 27 - loss = 4.813, (4.970 sec/step)\n",
      "step 28 - loss = 4.915, (2.289 sec/step)\n",
      "step 29 - loss = 3.969, (1.616 sec/step)\n",
      "step 30 - loss = 4.501, (1.538 sec/step)\n",
      "step 31 - loss = 4.389, (2.325 sec/step)\n",
      "step 32 - loss = 4.188, (4.316 sec/step)\n",
      "step 33 - loss = 3.779, (3.955 sec/step)\n",
      "step 34 - loss = 4.138, (2.951 sec/step)\n",
      "step 35 - loss = 3.753, (3.008 sec/step)\n",
      "step 36 - loss = 4.135, (2.227 sec/step)\n",
      "step 37 - loss = 3.576, (2.431 sec/step)\n",
      "step 38 - loss = 4.336, (2.716 sec/step)\n",
      "step 39 - loss = 3.748, (3.623 sec/step)\n",
      "step 40 - loss = 4.273, (2.389 sec/step)\n",
      "step 41 - loss = 3.786, (2.003 sec/step)\n",
      "step 42 - loss = 3.303, (2.363 sec/step)\n",
      "step 43 - loss = 3.939, (2.623 sec/step)\n",
      "step 44 - loss = 3.904, (3.411 sec/step)\n",
      "step 45 - loss = 3.560, (1.571 sec/step)\n",
      "step 46 - loss = 3.849, (1.524 sec/step)\n",
      "step 47 - loss = 3.075, (1.636 sec/step)\n",
      "step 48 - loss = 3.638, (2.344 sec/step)\n",
      "step 49 - loss = 3.782, (1.815 sec/step)\n",
      "step 50 - loss = 4.232, (2.483 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 51 - loss = 2.025, (2.446 sec/step)\n",
      "step 52 - loss = 3.749, (4.239 sec/step)\n",
      "step 53 - loss = 3.957, (2.150 sec/step)\n",
      "step 54 - loss = 3.499, (2.482 sec/step)\n",
      "step 55 - loss = 1.674, (3.968 sec/step)\n",
      "step 56 - loss = 4.269, (2.542 sec/step)\n",
      "step 57 - loss = 4.023, (1.919 sec/step)\n",
      "step 58 - loss = 3.447, (2.455 sec/step)\n",
      "step 59 - loss = 2.985, (2.119 sec/step)\n",
      "step 60 - loss = 2.928, (3.423 sec/step)\n",
      "step 61 - loss = 3.712, (3.254 sec/step)\n",
      "step 62 - loss = 3.080, (1.497 sec/step)\n",
      "step 63 - loss = 3.667, (1.746 sec/step)\n",
      "step 64 - loss = 3.553, (4.753 sec/step)\n",
      "step 65 - loss = 3.125, (2.605 sec/step)\n",
      "step 66 - loss = 3.356, (1.968 sec/step)\n",
      "step 67 - loss = 4.085, (2.191 sec/step)\n",
      "step 68 - loss = 3.683, (2.361 sec/step)\n",
      "step 69 - loss = 4.151, (2.143 sec/step)\n",
      "step 70 - loss = 3.098, (1.910 sec/step)\n",
      "step 71 - loss = 3.134, (1.919 sec/step)\n",
      "step 72 - loss = 3.439, (2.180 sec/step)\n",
      "step 73 - loss = 4.037, (2.109 sec/step)\n",
      "step 74 - loss = 3.252, (1.946 sec/step)\n",
      "step 75 - loss = 3.205, (2.501 sec/step)\n",
      "step 76 - loss = 3.004, (2.149 sec/step)\n",
      "step 77 - loss = 2.328, (3.463 sec/step)\n",
      "step 78 - loss = 3.663, (1.840 sec/step)\n",
      "step 79 - loss = 3.362, (2.295 sec/step)\n",
      "step 80 - loss = 3.447, (3.330 sec/step)\n",
      "step 81 - loss = 3.542, (1.636 sec/step)\n",
      "step 82 - loss = 3.063, (2.341 sec/step)\n",
      "step 83 - loss = 2.885, (1.685 sec/step)\n",
      "step 84 - loss = 3.931, (3.786 sec/step)\n",
      "step 85 - loss = 2.716, (1.697 sec/step)\n",
      "step 86 - loss = 3.497, (2.077 sec/step)\n",
      "step 87 - loss = 2.931, (2.171 sec/step)\n",
      "step 88 - loss = 2.736, (1.710 sec/step)\n",
      "step 89 - loss = 2.993, (1.675 sec/step)\n",
      "step 90 - loss = 3.227, (1.915 sec/step)\n",
      "step 91 - loss = 3.428, (2.334 sec/step)\n",
      "step 92 - loss = 2.641, (1.617 sec/step)\n",
      "step 93 - loss = 2.060, (2.272 sec/step)\n",
      "step 94 - loss = 2.396, (2.495 sec/step)\n",
      "step 95 - loss = 3.123, (1.871 sec/step)\n",
      "step 96 - loss = 3.094, (2.814 sec/step)\n",
      "step 97 - loss = 3.386, (1.774 sec/step)\n",
      "step 98 - loss = 2.389, (5.933 sec/step)\n",
      "step 99 - loss = 3.006, (1.774 sec/step)\n",
      "step 100 - loss = 2.844, (3.083 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 101 - loss = 2.944, (1.115 sec/step)\n",
      "step 102 - loss = 3.345, (2.585 sec/step)\n",
      "step 103 - loss = 3.996, (2.604 sec/step)\n",
      "step 104 - loss = 3.608, (2.218 sec/step)\n",
      "step 105 - loss = 2.882, (2.223 sec/step)\n",
      "step 106 - loss = 2.780, (0.764 sec/step)\n",
      "step 107 - loss = 3.586, (2.554 sec/step)\n",
      "step 108 - loss = 2.554, (3.237 sec/step)\n",
      "step 109 - loss = 3.105, (2.435 sec/step)\n",
      "step 110 - loss = 3.126, (2.485 sec/step)\n",
      "step 111 - loss = 1.343, (1.036 sec/step)\n",
      "step 112 - loss = 3.046, (1.842 sec/step)\n",
      "step 113 - loss = 2.478, (1.781 sec/step)\n",
      "step 114 - loss = 2.776, (1.967 sec/step)\n",
      "step 115 - loss = 3.348, (1.873 sec/step)\n",
      "step 116 - loss = 3.094, (2.958 sec/step)\n",
      "step 117 - loss = 2.846, (2.075 sec/step)\n",
      "step 118 - loss = 3.249, (3.494 sec/step)\n",
      "step 119 - loss = 2.948, (1.606 sec/step)\n",
      "step 120 - loss = 2.885, (2.872 sec/step)\n",
      "step 121 - loss = 3.328, (2.484 sec/step)\n",
      "step 122 - loss = 2.136, (1.646 sec/step)\n",
      "step 123 - loss = 2.776, (2.416 sec/step)\n",
      "step 124 - loss = 2.629, (1.788 sec/step)\n",
      "step 125 - loss = 2.486, (4.504 sec/step)\n",
      "step 126 - loss = 2.430, (1.551 sec/step)\n",
      "step 127 - loss = 2.662, (2.486 sec/step)\n",
      "step 128 - loss = 2.154, (3.435 sec/step)\n",
      "step 129 - loss = 2.911, (2.359 sec/step)\n",
      "step 130 - loss = 3.223, (2.484 sec/step)\n",
      "step 131 - loss = 3.416, (4.661 sec/step)\n",
      "step 132 - loss = 3.007, (2.880 sec/step)\n",
      "step 133 - loss = 1.865, (2.624 sec/step)\n",
      "step 134 - loss = 2.651, (6.007 sec/step)\n",
      "step 135 - loss = 2.114, (1.368 sec/step)\n",
      "step 136 - loss = 2.728, (2.302 sec/step)\n",
      "step 137 - loss = 2.905, (2.147 sec/step)\n",
      "step 138 - loss = 2.864, (1.562 sec/step)\n",
      "step 139 - loss = 2.491, (1.341 sec/step)\n",
      "step 140 - loss = 2.040, (2.098 sec/step)\n",
      "step 141 - loss = 1.956, (1.649 sec/step)\n",
      "step 142 - loss = 2.688, (3.191 sec/step)\n",
      "step 143 - loss = 2.630, (2.034 sec/step)\n",
      "step 144 - loss = 2.630, (1.956 sec/step)\n",
      "step 145 - loss = 2.578, (1.352 sec/step)\n",
      "step 146 - loss = 1.443, (5.013 sec/step)\n",
      "step 147 - loss = 2.199, (1.754 sec/step)\n",
      "step 148 - loss = 2.189, (2.742 sec/step)\n",
      "step 149 - loss = 2.338, (2.413 sec/step)\n",
      "step 150 - loss = 2.510, (1.713 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 151 - loss = 2.395, (1.659 sec/step)\n",
      "step 152 - loss = 1.976, (2.487 sec/step)\n",
      "step 153 - loss = 2.993, (2.093 sec/step)\n",
      "step 154 - loss = 2.530, (0.987 sec/step)\n",
      "step 155 - loss = 2.148, (2.647 sec/step)\n",
      "step 156 - loss = 2.048, (1.545 sec/step)\n",
      "step 157 - loss = 2.988, (1.736 sec/step)\n",
      "step 158 - loss = 2.684, (2.471 sec/step)\n",
      "step 159 - loss = 2.789, (1.679 sec/step)\n",
      "step 160 - loss = 2.842, (1.608 sec/step)\n",
      "step 161 - loss = 1.991, (2.823 sec/step)\n",
      "step 162 - loss = 2.050, (2.335 sec/step)\n",
      "step 163 - loss = 2.341, (1.756 sec/step)\n",
      "step 164 - loss = 3.309, (1.803 sec/step)\n",
      "step 165 - loss = 2.331, (1.633 sec/step)\n",
      "step 166 - loss = 3.334, (1.660 sec/step)\n",
      "step 167 - loss = 3.000, (2.040 sec/step)\n",
      "step 168 - loss = 2.683, (1.555 sec/step)\n",
      "step 169 - loss = 2.720, (2.485 sec/step)\n",
      "step 170 - loss = 3.518, (1.710 sec/step)\n",
      "step 171 - loss = 2.671, (1.968 sec/step)\n",
      "step 172 - loss = 2.680, (1.929 sec/step)\n",
      "step 173 - loss = 2.483, (1.826 sec/step)\n",
      "step 174 - loss = 2.192, (1.568 sec/step)\n",
      "step 175 - loss = 3.386, (2.486 sec/step)\n",
      "step 176 - loss = 3.500, (3.153 sec/step)\n",
      "step 177 - loss = 2.790, (1.589 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 178 - loss = 2.796, (2.508 sec/step)\n",
      "step 179 - loss = 2.209, (1.559 sec/step)\n",
      "step 180 - loss = 2.670, (1.560 sec/step)\n",
      "step 181 - loss = 2.155, (2.435 sec/step)\n",
      "step 182 - loss = 2.402, (2.651 sec/step)\n",
      "step 183 - loss = 2.503, (1.479 sec/step)\n",
      "step 184 - loss = 2.465, (2.372 sec/step)\n",
      "step 185 - loss = 2.860, (1.443 sec/step)\n",
      "step 186 - loss = 2.023, (3.556 sec/step)\n",
      "step 187 - loss = 2.114, (1.693 sec/step)\n",
      "step 188 - loss = 2.238, (1.933 sec/step)\n",
      "step 189 - loss = 3.029, (3.501 sec/step)\n",
      "step 190 - loss = 2.113, (3.246 sec/step)\n",
      "step 191 - loss = 2.445, (1.723 sec/step)\n",
      "step 192 - loss = 2.332, (1.854 sec/step)\n",
      "step 193 - loss = 2.765, (2.029 sec/step)\n",
      "step 194 - loss = 2.538, (1.665 sec/step)\n",
      "step 195 - loss = 2.749, (1.798 sec/step)\n",
      "step 196 - loss = 3.512, (3.293 sec/step)\n",
      "step 197 - loss = 2.932, (1.488 sec/step)\n",
      "step 198 - loss = 2.217, (2.409 sec/step)\n",
      "step 199 - loss = 2.394, (1.654 sec/step)\n",
      "step 200 - loss = 2.488, (2.968 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 201 - loss = 2.347, (2.067 sec/step)\n",
      "step 202 - loss = 2.680, (1.843 sec/step)\n",
      "step 203 - loss = 2.563, (2.487 sec/step)\n",
      "step 204 - loss = 1.046, (2.720 sec/step)\n",
      "step 205 - loss = 2.610, (2.036 sec/step)\n",
      "step 206 - loss = 2.818, (1.874 sec/step)\n",
      "step 207 - loss = 2.234, (2.888 sec/step)\n",
      "step 208 - loss = 1.951, (2.608 sec/step)\n",
      "step 209 - loss = 2.256, (1.375 sec/step)\n",
      "step 210 - loss = 2.062, (2.718 sec/step)\n",
      "step 211 - loss = 2.320, (2.104 sec/step)\n",
      "step 212 - loss = 2.359, (1.341 sec/step)\n",
      "step 213 - loss = 2.407, (1.790 sec/step)\n",
      "step 214 - loss = 2.407, (2.126 sec/step)\n",
      "step 215 - loss = 2.602, (1.961 sec/step)\n",
      "step 216 - loss = 2.946, (2.212 sec/step)\n",
      "step 217 - loss = 2.056, (1.944 sec/step)\n",
      "step 218 - loss = 2.788, (1.837 sec/step)\n",
      "step 219 - loss = 2.328, (2.296 sec/step)\n",
      "step 220 - loss = 1.725, (3.643 sec/step)\n",
      "step 221 - loss = 2.900, (3.833 sec/step)\n",
      "step 222 - loss = 2.229, (2.388 sec/step)\n",
      "step 223 - loss = 2.163, (2.592 sec/step)\n",
      "step 224 - loss = 1.817, (1.765 sec/step)\n",
      "step 225 - loss = 2.518, (2.105 sec/step)\n",
      "step 226 - loss = 2.940, (2.455 sec/step)\n",
      "step 227 - loss = 2.597, (1.997 sec/step)\n",
      "step 228 - loss = 1.677, (4.490 sec/step)\n",
      "step 229 - loss = 2.283, (1.761 sec/step)\n",
      "step 230 - loss = 2.306, (1.691 sec/step)\n",
      "step 231 - loss = 2.346, (2.997 sec/step)\n",
      "step 232 - loss = 2.402, (2.295 sec/step)\n",
      "step 233 - loss = 2.027, (1.634 sec/step)\n",
      "step 234 - loss = 2.806, (2.110 sec/step)\n",
      "step 235 - loss = 2.333, (1.523 sec/step)\n",
      "step 236 - loss = 2.996, (2.812 sec/step)\n",
      "step 237 - loss = 2.509, (2.359 sec/step)\n",
      "step 238 - loss = 2.700, (2.681 sec/step)\n",
      "step 239 - loss = 2.964, (1.712 sec/step)\n",
      "step 240 - loss = 2.856, (2.745 sec/step)\n",
      "step 241 - loss = 1.976, (1.616 sec/step)\n",
      "step 242 - loss = 2.424, (1.742 sec/step)\n",
      "step 243 - loss = 2.175, (1.947 sec/step)\n",
      "step 244 - loss = 2.082, (1.637 sec/step)\n",
      "step 245 - loss = 2.513, (1.566 sec/step)\n",
      "step 246 - loss = 2.255, (2.486 sec/step)\n",
      "step 247 - loss = 1.137, (1.476 sec/step)\n",
      "step 248 - loss = 2.640, (1.693 sec/step)\n",
      "step 249 - loss = 2.446, (2.140 sec/step)\n",
      "step 250 - loss = 2.284, (1.644 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 251 - loss = 2.570, (2.484 sec/step)\n",
      "step 252 - loss = 1.150, (1.581 sec/step)\n",
      "step 253 - loss = 2.243, (1.820 sec/step)\n",
      "step 254 - loss = 1.929, (1.580 sec/step)\n",
      "step 255 - loss = 2.874, (2.720 sec/step)\n",
      "step 256 - loss = 2.441, (1.721 sec/step)\n",
      "step 257 - loss = 2.546, (2.386 sec/step)\n",
      "step 258 - loss = 2.327, (2.205 sec/step)\n",
      "step 259 - loss = 2.218, (3.953 sec/step)\n",
      "step 260 - loss = 2.379, (2.188 sec/step)\n",
      "step 261 - loss = 2.742, (2.032 sec/step)\n",
      "step 262 - loss = 2.558, (1.393 sec/step)\n",
      "step 263 - loss = 2.702, (1.215 sec/step)\n",
      "step 264 - loss = 2.198, (1.333 sec/step)\n",
      "step 265 - loss = 2.171, (3.300 sec/step)\n",
      "step 266 - loss = 2.538, (1.387 sec/step)\n",
      "step 267 - loss = 2.348, (1.912 sec/step)\n",
      "step 268 - loss = 1.727, (1.725 sec/step)\n",
      "step 269 - loss = 1.920, (1.553 sec/step)\n",
      "step 270 - loss = 2.602, (1.919 sec/step)\n",
      "step 271 - loss = 1.885, (1.468 sec/step)\n",
      "step 272 - loss = 2.727, (3.011 sec/step)\n",
      "step 273 - loss = 2.037, (1.715 sec/step)\n",
      "step 274 - loss = 1.954, (0.999 sec/step)\n",
      "step 275 - loss = 1.806, (1.494 sec/step)\n",
      "step 276 - loss = 2.129, (5.515 sec/step)\n",
      "step 277 - loss = 1.775, (2.259 sec/step)\n",
      "step 278 - loss = 1.875, (2.484 sec/step)\n",
      "step 279 - loss = 0.676, (1.333 sec/step)\n",
      "step 280 - loss = 2.151, (1.351 sec/step)\n",
      "step 281 - loss = 2.967, (2.682 sec/step)\n",
      "step 282 - loss = 2.555, (2.358 sec/step)\n",
      "step 283 - loss = 2.280, (2.217 sec/step)\n",
      "step 284 - loss = 1.770, (2.859 sec/step)\n",
      "step 285 - loss = 2.600, (2.748 sec/step)\n",
      "step 286 - loss = 1.985, (1.961 sec/step)\n",
      "step 287 - loss = 2.161, (1.401 sec/step)\n",
      "step 288 - loss = 2.655, (2.679 sec/step)\n",
      "step 289 - loss = 2.700, (1.162 sec/step)\n",
      "step 290 - loss = 2.415, (2.343 sec/step)\n",
      "step 291 - loss = 2.076, (1.541 sec/step)\n",
      "step 292 - loss = 1.810, (1.386 sec/step)\n",
      "step 293 - loss = 1.927, (1.587 sec/step)\n",
      "step 294 - loss = 2.498, (2.581 sec/step)\n",
      "step 295 - loss = 2.329, (3.380 sec/step)\n",
      "step 296 - loss = 2.000, (2.255 sec/step)\n",
      "step 297 - loss = 2.900, (2.412 sec/step)\n",
      "step 298 - loss = 2.149, (1.472 sec/step)\n",
      "step 299 - loss = 3.076, (1.576 sec/step)\n",
      "step 300 - loss = 1.416, (3.302 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 301 - loss = 2.743, (2.607 sec/step)\n",
      "step 302 - loss = 2.191, (2.264 sec/step)\n",
      "step 303 - loss = 2.245, (1.274 sec/step)\n",
      "step 304 - loss = 2.971, (3.745 sec/step)\n",
      "step 305 - loss = 2.773, (2.225 sec/step)\n",
      "step 306 - loss = 2.121, (2.252 sec/step)\n",
      "step 307 - loss = 2.233, (1.953 sec/step)\n",
      "step 308 - loss = 2.747, (2.869 sec/step)\n",
      "step 309 - loss = 2.242, (1.528 sec/step)\n",
      "step 310 - loss = 1.531, (2.388 sec/step)\n",
      "step 311 - loss = 2.051, (2.485 sec/step)\n",
      "step 312 - loss = 1.379, (3.145 sec/step)\n",
      "step 313 - loss = 2.038, (1.469 sec/step)\n",
      "step 314 - loss = 2.216, (2.574 sec/step)\n",
      "step 315 - loss = 1.814, (2.060 sec/step)\n",
      "step 316 - loss = 1.899, (1.213 sec/step)\n",
      "step 317 - loss = 2.426, (1.462 sec/step)\n",
      "step 318 - loss = 2.606, (1.688 sec/step)\n",
      "step 319 - loss = 1.910, (2.235 sec/step)\n",
      "step 320 - loss = 2.412, (1.561 sec/step)\n",
      "step 321 - loss = 1.388, (1.701 sec/step)\n",
      "step 322 - loss = 2.215, (3.422 sec/step)\n",
      "step 323 - loss = 2.243, (1.905 sec/step)\n",
      "step 324 - loss = 2.066, (2.483 sec/step)\n",
      "step 325 - loss = 2.409, (2.133 sec/step)\n",
      "step 326 - loss = 2.620, (2.496 sec/step)\n",
      "step 327 - loss = 1.833, (1.842 sec/step)\n",
      "step 328 - loss = 2.392, (1.979 sec/step)\n",
      "step 329 - loss = 1.206, (1.583 sec/step)\n",
      "step 330 - loss = 2.407, (2.118 sec/step)\n",
      "step 331 - loss = 2.155, (1.646 sec/step)\n",
      "step 332 - loss = 3.150, (2.483 sec/step)\n",
      "step 333 - loss = 2.219, (2.461 sec/step)\n",
      "step 334 - loss = 2.260, (1.291 sec/step)\n",
      "step 335 - loss = 2.480, (2.286 sec/step)\n",
      "step 336 - loss = 2.865, (2.487 sec/step)\n",
      "step 337 - loss = 0.721, (1.210 sec/step)\n",
      "step 338 - loss = 2.383, (1.954 sec/step)\n",
      "step 339 - loss = 2.076, (1.578 sec/step)\n",
      "step 340 - loss = 2.032, (1.747 sec/step)\n",
      "step 341 - loss = 2.539, (1.353 sec/step)\n",
      "step 342 - loss = 2.238, (2.560 sec/step)\n",
      "step 343 - loss = 2.371, (1.613 sec/step)\n",
      "step 344 - loss = 2.280, (2.199 sec/step)\n",
      "step 345 - loss = 1.782, (1.976 sec/step)\n",
      "step 346 - loss = 3.024, (2.485 sec/step)\n",
      "step 347 - loss = 1.007, (0.672 sec/step)\n",
      "step 348 - loss = 2.284, (1.507 sec/step)\n",
      "step 349 - loss = 2.440, (2.121 sec/step)\n",
      "step 350 - loss = 1.588, (2.198 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 351 - loss = 1.830, (1.423 sec/step)\n",
      "step 352 - loss = 1.507, (2.547 sec/step)\n",
      "step 353 - loss = 2.635, (1.812 sec/step)\n",
      "step 354 - loss = 2.499, (1.948 sec/step)\n",
      "step 355 - loss = 1.926, (2.283 sec/step)\n",
      "step 356 - loss = 2.197, (1.233 sec/step)\n",
      "step 357 - loss = 2.226, (3.444 sec/step)\n",
      "step 358 - loss = 2.133, (1.935 sec/step)\n",
      "step 359 - loss = 1.947, (1.507 sec/step)\n",
      "step 360 - loss = 2.583, (2.410 sec/step)\n",
      "step 361 - loss = 2.302, (1.069 sec/step)\n",
      "step 362 - loss = 2.209, (2.458 sec/step)\n",
      "step 363 - loss = 2.101, (2.175 sec/step)\n",
      "step 364 - loss = 2.184, (1.421 sec/step)\n",
      "step 365 - loss = 2.983, (2.485 sec/step)\n",
      "step 366 - loss = 0.893, (0.911 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 367 - loss = 2.422, (1.508 sec/step)\n",
      "step 368 - loss = 1.911, (1.968 sec/step)\n",
      "step 369 - loss = 2.327, (1.626 sec/step)\n",
      "step 370 - loss = 2.359, (2.534 sec/step)\n",
      "step 371 - loss = 2.344, (1.851 sec/step)\n",
      "step 372 - loss = 2.037, (2.106 sec/step)\n",
      "step 373 - loss = 2.306, (1.424 sec/step)\n",
      "step 374 - loss = 1.783, (2.489 sec/step)\n",
      "step 375 - loss = 2.366, (1.572 sec/step)\n",
      "step 376 - loss = 2.254, (1.775 sec/step)\n",
      "step 377 - loss = 2.094, (1.602 sec/step)\n",
      "step 378 - loss = 1.680, (1.314 sec/step)\n",
      "step 379 - loss = 2.253, (1.558 sec/step)\n",
      "step 380 - loss = 1.635, (1.850 sec/step)\n",
      "step 381 - loss = 2.461, (2.006 sec/step)\n",
      "step 382 - loss = 1.680, (2.513 sec/step)\n",
      "step 383 - loss = 1.495, (2.096 sec/step)\n",
      "step 384 - loss = 1.629, (2.958 sec/step)\n",
      "step 385 - loss = 0.657, (2.525 sec/step)\n",
      "step 386 - loss = 2.721, (2.201 sec/step)\n",
      "step 387 - loss = 2.032, (1.961 sec/step)\n",
      "step 388 - loss = 1.681, (1.985 sec/step)\n",
      "step 389 - loss = 2.218, (1.842 sec/step)\n",
      "step 390 - loss = 2.398, (2.163 sec/step)\n",
      "step 391 - loss = 2.373, (1.498 sec/step)\n",
      "step 392 - loss = 2.568, (2.215 sec/step)\n",
      "step 393 - loss = 1.655, (1.341 sec/step)\n",
      "step 394 - loss = 1.776, (2.216 sec/step)\n",
      "step 395 - loss = 2.268, (1.785 sec/step)\n",
      "step 396 - loss = 2.583, (2.483 sec/step)\n",
      "step 397 - loss = 1.443, (4.514 sec/step)\n",
      "step 398 - loss = 1.700, (1.864 sec/step)\n",
      "step 399 - loss = 1.683, (1.892 sec/step)\n",
      "step 400 - loss = 2.455, (1.608 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 401 - loss = 1.968, (2.088 sec/step)\n",
      "step 402 - loss = 2.042, (2.538 sec/step)\n",
      "step 403 - loss = 2.761, (2.139 sec/step)\n",
      "step 404 - loss = 1.788, (1.427 sec/step)\n",
      "step 405 - loss = 2.249, (2.683 sec/step)\n",
      "step 406 - loss = 2.492, (1.260 sec/step)\n",
      "step 407 - loss = 2.634, (1.779 sec/step)\n",
      "step 408 - loss = 2.700, (2.484 sec/step)\n",
      "step 409 - loss = 1.942, (3.135 sec/step)\n",
      "step 410 - loss = 2.107, (1.487 sec/step)\n",
      "step 411 - loss = 2.443, (2.195 sec/step)\n",
      "step 412 - loss = 2.135, (1.566 sec/step)\n",
      "step 413 - loss = 2.279, (1.924 sec/step)\n",
      "step 414 - loss = 2.143, (1.768 sec/step)\n",
      "step 415 - loss = 2.063, (2.070 sec/step)\n",
      "step 416 - loss = 2.189, (1.550 sec/step)\n",
      "step 417 - loss = 1.641, (1.381 sec/step)\n",
      "step 418 - loss = 2.144, (1.099 sec/step)\n",
      "step 419 - loss = 2.060, (2.208 sec/step)\n",
      "step 420 - loss = 2.177, (1.561 sec/step)\n",
      "step 421 - loss = 2.234, (1.787 sec/step)\n",
      "step 422 - loss = 2.061, (1.556 sec/step)\n",
      "step 423 - loss = 2.159, (1.690 sec/step)\n",
      "step 424 - loss = 2.443, (2.594 sec/step)\n",
      "step 425 - loss = 2.207, (2.248 sec/step)\n",
      "step 426 - loss = 2.072, (1.896 sec/step)\n",
      "step 427 - loss = 2.164, (1.524 sec/step)\n",
      "step 428 - loss = 1.771, (2.556 sec/step)\n",
      "step 429 - loss = 1.497, (1.521 sec/step)\n",
      "step 430 - loss = 2.153, (2.862 sec/step)\n",
      "step 431 - loss = 2.189, (2.271 sec/step)\n",
      "step 432 - loss = 1.950, (1.161 sec/step)\n",
      "step 433 - loss = 2.423, (2.340 sec/step)\n",
      "step 434 - loss = 1.946, (1.669 sec/step)\n",
      "step 435 - loss = 2.559, (2.240 sec/step)\n",
      "step 436 - loss = 2.771, (2.484 sec/step)\n",
      "step 437 - loss = 0.791, (0.645 sec/step)\n",
      "step 438 - loss = 2.485, (2.485 sec/step)\n",
      "step 439 - loss = 0.718, (1.790 sec/step)\n",
      "step 440 - loss = 2.289, (2.938 sec/step)\n",
      "step 441 - loss = 2.435, (1.092 sec/step)\n",
      "step 442 - loss = 1.537, (2.080 sec/step)\n",
      "step 443 - loss = 2.294, (1.605 sec/step)\n",
      "step 444 - loss = 2.807, (1.048 sec/step)\n",
      "step 445 - loss = 2.046, (1.527 sec/step)\n",
      "step 446 - loss = 2.306, (1.486 sec/step)\n",
      "step 447 - loss = 2.137, (1.560 sec/step)\n",
      "step 448 - loss = 1.651, (1.421 sec/step)\n",
      "step 449 - loss = 2.500, (1.452 sec/step)\n",
      "step 450 - loss = 2.146, (1.691 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 451 - loss = 2.039, (1.920 sec/step)\n",
      "step 452 - loss = 2.047, (2.780 sec/step)\n",
      "step 453 - loss = 1.512, (3.048 sec/step)\n",
      "step 454 - loss = 2.470, (1.894 sec/step)\n",
      "step 455 - loss = 2.150, (1.938 sec/step)\n",
      "step 456 - loss = 2.020, (1.474 sec/step)\n",
      "step 457 - loss = 2.441, (1.725 sec/step)\n",
      "step 458 - loss = 2.196, (2.466 sec/step)\n",
      "step 459 - loss = 2.068, (1.975 sec/step)\n",
      "step 460 - loss = 2.122, (1.381 sec/step)\n",
      "step 461 - loss = 2.467, (2.484 sec/step)\n",
      "step 462 - loss = 2.305, (1.253 sec/step)\n",
      "step 463 - loss = 2.456, (2.153 sec/step)\n",
      "step 464 - loss = 2.329, (2.982 sec/step)\n",
      "step 465 - loss = 2.565, (3.364 sec/step)\n",
      "step 466 - loss = 1.945, (1.440 sec/step)\n",
      "step 467 - loss = 2.443, (1.624 sec/step)\n",
      "step 468 - loss = 2.076, (1.539 sec/step)\n",
      "step 469 - loss = 2.130, (1.523 sec/step)\n",
      "step 470 - loss = 1.702, (3.189 sec/step)\n",
      "step 471 - loss = 1.826, (2.173 sec/step)\n",
      "step 472 - loss = 1.944, (2.858 sec/step)\n",
      "step 473 - loss = 1.990, (1.415 sec/step)\n",
      "step 474 - loss = 1.865, (4.162 sec/step)\n",
      "step 475 - loss = 1.721, (1.813 sec/step)\n",
      "step 476 - loss = 2.085, (1.193 sec/step)\n",
      "step 477 - loss = 2.382, (3.259 sec/step)\n",
      "step 478 - loss = 2.444, (1.771 sec/step)\n",
      "step 479 - loss = 2.042, (1.573 sec/step)\n",
      "step 480 - loss = 1.962, (0.905 sec/step)\n",
      "step 481 - loss = 2.716, (2.020 sec/step)\n",
      "step 482 - loss = 2.161, (2.602 sec/step)\n",
      "step 483 - loss = 2.099, (0.915 sec/step)\n",
      "step 484 - loss = 2.079, (1.687 sec/step)\n",
      "step 485 - loss = 1.859, (3.459 sec/step)\n",
      "step 486 - loss = 1.579, (1.759 sec/step)\n",
      "step 487 - loss = 1.888, (1.113 sec/step)\n",
      "step 488 - loss = 2.022, (3.183 sec/step)\n",
      "step 489 - loss = 2.526, (1.180 sec/step)\n",
      "step 490 - loss = 1.946, (1.603 sec/step)\n",
      "step 491 - loss = 2.249, (1.894 sec/step)\n",
      "step 492 - loss = 1.719, (1.423 sec/step)\n",
      "step 493 - loss = 2.598, (3.258 sec/step)\n",
      "step 494 - loss = 2.125, (1.522 sec/step)\n",
      "step 495 - loss = 2.790, (2.007 sec/step)\n",
      "step 496 - loss = 1.885, (1.929 sec/step)\n",
      "step 497 - loss = 2.292, (1.254 sec/step)\n",
      "step 498 - loss = 2.007, (2.330 sec/step)\n",
      "step 499 - loss = 2.083, (1.477 sec/step)\n",
      "step 500 - loss = 1.899, (2.327 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 501 - loss = 1.838, (1.857 sec/step)\n",
      "step 502 - loss = 2.102, (1.947 sec/step)\n",
      "step 503 - loss = 2.046, (2.420 sec/step)\n",
      "step 504 - loss = 2.270, (1.034 sec/step)\n",
      "step 505 - loss = 2.202, (2.147 sec/step)\n",
      "step 506 - loss = 2.175, (1.769 sec/step)\n",
      "step 507 - loss = 2.135, (1.615 sec/step)\n",
      "step 508 - loss = 2.276, (1.487 sec/step)\n",
      "step 509 - loss = 2.273, (2.473 sec/step)\n",
      "step 510 - loss = 2.190, (2.382 sec/step)\n",
      "step 511 - loss = 1.848, (1.701 sec/step)\n",
      "step 512 - loss = 1.928, (1.945 sec/step)\n",
      "step 513 - loss = 2.021, (3.091 sec/step)\n",
      "step 514 - loss = 2.059, (2.006 sec/step)\n",
      "step 515 - loss = 2.171, (2.802 sec/step)\n",
      "step 516 - loss = 1.780, (2.257 sec/step)\n",
      "step 517 - loss = 1.854, (1.436 sec/step)\n",
      "step 518 - loss = 2.052, (1.195 sec/step)\n",
      "step 519 - loss = 1.605, (2.488 sec/step)\n",
      "step 520 - loss = 1.580, (1.544 sec/step)\n",
      "step 521 - loss = 1.687, (1.767 sec/step)\n",
      "step 522 - loss = 1.958, (1.292 sec/step)\n",
      "step 523 - loss = 1.854, (3.873 sec/step)\n",
      "step 524 - loss = 2.745, (2.619 sec/step)\n",
      "step 525 - loss = 1.259, (1.327 sec/step)\n",
      "step 526 - loss = 2.158, (1.754 sec/step)\n",
      "step 527 - loss = 2.292, (2.485 sec/step)\n",
      "step 528 - loss = 0.638, (0.953 sec/step)\n",
      "step 529 - loss = 1.893, (2.861 sec/step)\n",
      "step 530 - loss = 3.039, (1.722 sec/step)\n",
      "step 531 - loss = 1.892, (1.523 sec/step)\n",
      "step 532 - loss = 2.299, (3.272 sec/step)\n",
      "step 533 - loss = 2.607, (1.868 sec/step)\n",
      "step 534 - loss = 2.931, (1.787 sec/step)\n",
      "step 535 - loss = 2.164, (2.654 sec/step)\n",
      "step 536 - loss = 1.902, (1.521 sec/step)\n",
      "step 537 - loss = 2.352, (1.803 sec/step)\n",
      "step 538 - loss = 2.139, (1.895 sec/step)\n",
      "step 539 - loss = 1.897, (1.490 sec/step)\n",
      "step 540 - loss = 2.171, (1.513 sec/step)\n",
      "step 541 - loss = 2.566, (2.343 sec/step)\n",
      "step 542 - loss = 2.006, (1.359 sec/step)\n",
      "step 543 - loss = 2.838, (1.981 sec/step)\n",
      "step 544 - loss = 2.158, (1.928 sec/step)\n",
      "step 545 - loss = 2.315, (2.188 sec/step)\n",
      "step 546 - loss = 2.428, (1.595 sec/step)\n",
      "step 547 - loss = 2.289, (1.123 sec/step)\n",
      "step 548 - loss = 2.134, (2.778 sec/step)\n",
      "step 549 - loss = 2.190, (1.965 sec/step)\n",
      "step 550 - loss = 2.527, (1.464 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 551 - loss = 2.680, (1.482 sec/step)\n",
      "step 552 - loss = 2.672, (2.607 sec/step)\n",
      "step 553 - loss = 2.544, (1.778 sec/step)\n",
      "step 554 - loss = 2.848, (2.070 sec/step)\n",
      "step 555 - loss = 1.865, (1.369 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 556 - loss = 2.201, (2.113 sec/step)\n",
      "step 557 - loss = 1.906, (1.223 sec/step)\n",
      "step 558 - loss = 2.263, (1.681 sec/step)\n",
      "step 559 - loss = 2.430, (1.603 sec/step)\n",
      "step 560 - loss = 2.311, (1.657 sec/step)\n",
      "step 561 - loss = 2.116, (1.969 sec/step)\n",
      "step 562 - loss = 2.103, (1.827 sec/step)\n",
      "step 563 - loss = 2.266, (2.418 sec/step)\n",
      "step 564 - loss = 1.591, (1.415 sec/step)\n",
      "step 565 - loss = 2.785, (1.923 sec/step)\n",
      "step 566 - loss = 2.534, (1.524 sec/step)\n",
      "step 567 - loss = 1.705, (2.333 sec/step)\n",
      "step 568 - loss = 2.168, (3.060 sec/step)\n",
      "step 569 - loss = 1.900, (1.963 sec/step)\n",
      "step 570 - loss = 1.925, (2.066 sec/step)\n",
      "step 571 - loss = 1.811, (4.623 sec/step)\n",
      "step 572 - loss = 2.050, (2.686 sec/step)\n",
      "step 573 - loss = 1.544, (1.647 sec/step)\n",
      "step 574 - loss = 1.941, (2.356 sec/step)\n",
      "step 575 - loss = 1.819, (1.960 sec/step)\n",
      "step 576 - loss = 2.187, (1.542 sec/step)\n",
      "step 577 - loss = 2.136, (2.988 sec/step)\n",
      "step 578 - loss = 2.263, (1.488 sec/step)\n",
      "step 579 - loss = 1.765, (2.629 sec/step)\n",
      "step 580 - loss = 2.147, (2.554 sec/step)\n",
      "step 581 - loss = 2.039, (2.087 sec/step)\n",
      "step 582 - loss = 1.519, (3.164 sec/step)\n",
      "step 583 - loss = 1.919, (1.279 sec/step)\n",
      "step 584 - loss = 2.004, (1.294 sec/step)\n",
      "step 585 - loss = 2.168, (2.489 sec/step)\n",
      "step 586 - loss = 1.342, (3.528 sec/step)\n",
      "step 587 - loss = 1.698, (1.249 sec/step)\n",
      "step 588 - loss = 1.835, (1.700 sec/step)\n",
      "step 589 - loss = 1.418, (4.026 sec/step)\n",
      "step 590 - loss = 2.071, (1.787 sec/step)\n",
      "step 591 - loss = 1.494, (1.097 sec/step)\n",
      "step 592 - loss = 1.473, (1.556 sec/step)\n",
      "step 593 - loss = 1.751, (1.382 sec/step)\n",
      "step 594 - loss = 1.686, (1.116 sec/step)\n",
      "step 595 - loss = 1.952, (2.090 sec/step)\n",
      "step 596 - loss = 2.745, (2.486 sec/step)\n",
      "step 597 - loss = 3.026, (2.565 sec/step)\n",
      "step 598 - loss = 2.019, (1.461 sec/step)\n",
      "step 599 - loss = 1.894, (1.467 sec/step)\n",
      "step 600 - loss = 2.014, (1.435 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 601 - loss = 2.283, (1.753 sec/step)\n",
      "step 602 - loss = 2.086, (1.348 sec/step)\n",
      "step 603 - loss = 2.888, (2.725 sec/step)\n",
      "step 604 - loss = 1.760, (1.843 sec/step)\n",
      "step 605 - loss = 1.579, (1.412 sec/step)\n",
      "step 606 - loss = 2.229, (1.879 sec/step)\n",
      "step 607 - loss = 2.344, (1.985 sec/step)\n",
      "step 608 - loss = 2.238, (3.351 sec/step)\n",
      "step 609 - loss = 2.033, (2.997 sec/step)\n",
      "step 610 - loss = 2.396, (1.828 sec/step)\n",
      "step 611 - loss = 1.532, (1.245 sec/step)\n",
      "step 612 - loss = 1.960, (1.916 sec/step)\n",
      "step 613 - loss = 2.277, (2.868 sec/step)\n",
      "step 614 - loss = 2.519, (2.047 sec/step)\n",
      "step 615 - loss = 2.328, (1.739 sec/step)\n",
      "step 616 - loss = 2.180, (1.304 sec/step)\n",
      "step 617 - loss = 1.934, (3.322 sec/step)\n",
      "step 618 - loss = 2.047, (1.475 sec/step)\n",
      "step 619 - loss = 2.298, (2.483 sec/step)\n",
      "step 620 - loss = 0.630, (0.544 sec/step)\n",
      "step 621 - loss = 1.819, (1.096 sec/step)\n",
      "step 622 - loss = 2.162, (3.192 sec/step)\n",
      "step 623 - loss = 2.497, (1.828 sec/step)\n",
      "step 624 - loss = 2.133, (2.759 sec/step)\n",
      "step 625 - loss = 2.058, (1.322 sec/step)\n",
      "step 626 - loss = 1.739, (1.849 sec/step)\n",
      "step 627 - loss = 1.804, (1.801 sec/step)\n",
      "step 628 - loss = 2.447, (2.486 sec/step)\n",
      "step 629 - loss = 2.264, (2.144 sec/step)\n",
      "step 630 - loss = 2.071, (2.164 sec/step)\n",
      "step 631 - loss = 2.196, (1.591 sec/step)\n",
      "step 632 - loss = 2.226, (2.493 sec/step)\n",
      "step 633 - loss = 1.454, (1.872 sec/step)\n",
      "step 634 - loss = 2.007, (1.481 sec/step)\n",
      "step 635 - loss = 2.010, (2.838 sec/step)\n",
      "step 636 - loss = 2.154, (2.634 sec/step)\n",
      "step 637 - loss = 2.075, (1.360 sec/step)\n",
      "step 638 - loss = 2.695, (1.920 sec/step)\n",
      "step 639 - loss = 2.307, (1.881 sec/step)\n",
      "step 640 - loss = 2.053, (1.882 sec/step)\n",
      "step 641 - loss = 1.588, (1.354 sec/step)\n",
      "step 642 - loss = 2.289, (1.450 sec/step)\n",
      "step 643 - loss = 1.988, (2.036 sec/step)\n",
      "step 644 - loss = 2.408, (1.784 sec/step)\n",
      "step 645 - loss = 2.298, (2.886 sec/step)\n",
      "step 646 - loss = 2.090, (2.042 sec/step)\n",
      "step 647 - loss = 2.396, (1.229 sec/step)\n",
      "step 648 - loss = 2.158, (1.859 sec/step)\n",
      "step 649 - loss = 2.600, (3.016 sec/step)\n",
      "step 650 - loss = 2.093, (0.960 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 651 - loss = 1.724, (3.576 sec/step)\n",
      "step 652 - loss = 2.124, (1.450 sec/step)\n",
      "step 653 - loss = 2.461, (1.847 sec/step)\n",
      "step 654 - loss = 2.011, (2.177 sec/step)\n",
      "step 655 - loss = 2.321, (1.967 sec/step)\n",
      "step 656 - loss = 2.656, (2.390 sec/step)\n",
      "step 657 - loss = 2.376, (1.272 sec/step)\n",
      "step 658 - loss = 1.891, (1.694 sec/step)\n",
      "step 659 - loss = 2.475, (1.638 sec/step)\n",
      "step 660 - loss = 1.581, (1.214 sec/step)\n",
      "step 661 - loss = 2.281, (2.035 sec/step)\n",
      "step 662 - loss = 1.355, (2.056 sec/step)\n",
      "step 663 - loss = 1.989, (1.117 sec/step)\n",
      "step 664 - loss = 2.117, (0.885 sec/step)\n",
      "step 665 - loss = 1.845, (2.941 sec/step)\n",
      "step 666 - loss = 2.705, (2.486 sec/step)\n",
      "step 667 - loss = 2.114, (2.211 sec/step)\n",
      "step 668 - loss = 2.414, (1.991 sec/step)\n",
      "step 669 - loss = 1.339, (1.890 sec/step)\n",
      "step 670 - loss = 2.246, (2.287 sec/step)\n",
      "step 671 - loss = 2.061, (2.529 sec/step)\n",
      "step 672 - loss = 2.244, (1.348 sec/step)\n",
      "step 673 - loss = 2.389, (2.313 sec/step)\n",
      "step 674 - loss = 1.953, (1.980 sec/step)\n",
      "step 675 - loss = 2.418, (2.381 sec/step)\n",
      "step 676 - loss = 1.947, (1.165 sec/step)\n",
      "step 677 - loss = 2.618, (2.054 sec/step)\n",
      "step 678 - loss = 2.283, (1.518 sec/step)\n",
      "step 679 - loss = 2.661, (2.507 sec/step)\n",
      "step 680 - loss = 2.154, (2.864 sec/step)\n",
      "step 681 - loss = 1.869, (1.575 sec/step)\n",
      "step 682 - loss = 2.316, (2.318 sec/step)\n",
      "step 683 - loss = 2.019, (2.265 sec/step)\n",
      "step 684 - loss = 2.177, (1.352 sec/step)\n",
      "step 685 - loss = 1.611, (1.479 sec/step)\n",
      "step 686 - loss = 2.229, (2.613 sec/step)\n",
      "step 687 - loss = 1.954, (3.088 sec/step)\n",
      "step 688 - loss = 2.492, (3.561 sec/step)\n",
      "step 689 - loss = 2.114, (3.538 sec/step)\n",
      "step 690 - loss = 1.540, (1.337 sec/step)\n",
      "step 691 - loss = 1.809, (2.523 sec/step)\n",
      "step 692 - loss = 2.004, (3.186 sec/step)\n",
      "step 693 - loss = 1.848, (2.931 sec/step)\n",
      "step 694 - loss = 2.386, (0.882 sec/step)\n",
      "step 695 - loss = 2.208, (2.460 sec/step)\n",
      "step 696 - loss = 1.883, (2.954 sec/step)\n",
      "step 697 - loss = 2.336, (2.384 sec/step)\n",
      "step 698 - loss = 2.359, (1.709 sec/step)\n",
      "step 699 - loss = 1.979, (1.668 sec/step)\n",
      "step 700 - loss = 2.107, (3.352 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 701 - loss = 2.218, (1.787 sec/step)\n",
      "step 702 - loss = 1.703, (2.205 sec/step)\n",
      "step 703 - loss = 2.509, (2.258 sec/step)\n",
      "step 704 - loss = 1.889, (1.747 sec/step)\n",
      "step 705 - loss = 1.552, (2.325 sec/step)\n",
      "step 706 - loss = 2.540, (2.292 sec/step)\n",
      "step 707 - loss = 1.777, (1.307 sec/step)\n",
      "step 708 - loss = 1.889, (1.980 sec/step)\n",
      "step 709 - loss = 2.327, (1.494 sec/step)\n",
      "step 710 - loss = 2.236, (2.527 sec/step)\n",
      "step 711 - loss = 1.785, (1.286 sec/step)\n",
      "step 712 - loss = 1.671, (2.573 sec/step)\n",
      "step 713 - loss = 2.329, (1.938 sec/step)\n",
      "step 714 - loss = 1.968, (1.406 sec/step)\n",
      "step 715 - loss = 2.100, (2.059 sec/step)\n",
      "step 716 - loss = 1.697, (1.590 sec/step)\n",
      "step 717 - loss = 2.115, (1.576 sec/step)\n",
      "step 718 - loss = 2.396, (2.064 sec/step)\n",
      "step 719 - loss = 2.452, (2.180 sec/step)\n",
      "step 720 - loss = 2.535, (1.017 sec/step)\n",
      "step 721 - loss = 1.857, (1.431 sec/step)\n",
      "step 722 - loss = 1.478, (1.947 sec/step)\n",
      "step 723 - loss = 1.682, (2.484 sec/step)\n",
      "step 724 - loss = 0.600, (3.113 sec/step)\n",
      "step 725 - loss = 1.879, (1.473 sec/step)\n",
      "step 726 - loss = 2.339, (1.888 sec/step)\n",
      "step 727 - loss = 2.359, (2.318 sec/step)\n",
      "step 728 - loss = 1.890, (1.666 sec/step)\n",
      "step 729 - loss = 2.105, (3.062 sec/step)\n",
      "step 730 - loss = 1.848, (1.549 sec/step)\n",
      "step 731 - loss = 2.477, (1.969 sec/step)\n",
      "step 732 - loss = 2.596, (2.486 sec/step)\n",
      "step 733 - loss = 1.895, (1.674 sec/step)\n",
      "step 734 - loss = 2.267, (1.830 sec/step)\n",
      "step 735 - loss = 1.960, (1.589 sec/step)\n",
      "step 736 - loss = 2.065, (2.175 sec/step)\n",
      "step 737 - loss = 2.460, (2.634 sec/step)\n",
      "step 738 - loss = 1.522, (1.676 sec/step)\n",
      "step 739 - loss = 2.594, (1.498 sec/step)\n",
      "step 740 - loss = 2.636, (1.588 sec/step)\n",
      "step 741 - loss = 1.955, (2.604 sec/step)\n",
      "step 742 - loss = 1.756, (1.871 sec/step)\n",
      "step 743 - loss = 2.145, (1.437 sec/step)\n",
      "step 744 - loss = 1.816, (2.166 sec/step)\n",
      "step 745 - loss = 2.148, (2.828 sec/step)\n",
      "step 746 - loss = 2.550, (2.188 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 747 - loss = 2.645, (1.531 sec/step)\n",
      "step 748 - loss = 2.033, (2.486 sec/step)\n",
      "step 749 - loss = 0.703, (3.323 sec/step)\n",
      "step 750 - loss = 1.944, (1.694 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 751 - loss = 2.459, (1.981 sec/step)\n",
      "step 752 - loss = 1.898, (1.917 sec/step)\n",
      "step 753 - loss = 1.839, (0.927 sec/step)\n",
      "step 754 - loss = 2.147, (1.680 sec/step)\n",
      "step 755 - loss = 2.238, (2.573 sec/step)\n",
      "step 756 - loss = 2.732, (1.877 sec/step)\n",
      "step 757 - loss = 2.639, (2.482 sec/step)\n",
      "step 758 - loss = 1.974, (1.877 sec/step)\n",
      "step 759 - loss = 2.591, (2.153 sec/step)\n",
      "step 760 - loss = 1.989, (2.323 sec/step)\n",
      "step 761 - loss = 1.542, (0.881 sec/step)\n",
      "step 762 - loss = 2.359, (2.484 sec/step)\n",
      "step 763 - loss = 2.741, (2.340 sec/step)\n",
      "step 764 - loss = 2.569, (2.312 sec/step)\n",
      "step 765 - loss = 2.053, (1.637 sec/step)\n",
      "step 766 - loss = 1.988, (1.103 sec/step)\n",
      "step 767 - loss = 2.422, (1.809 sec/step)\n",
      "step 768 - loss = 1.364, (3.793 sec/step)\n",
      "step 769 - loss = 2.043, (2.024 sec/step)\n",
      "step 770 - loss = 2.278, (1.863 sec/step)\n",
      "step 771 - loss = 2.244, (1.521 sec/step)\n",
      "step 772 - loss = 1.267, (1.442 sec/step)\n",
      "step 773 - loss = 2.089, (2.483 sec/step)\n",
      "step 774 - loss = 2.493, (1.509 sec/step)\n",
      "step 775 - loss = 2.293, (2.966 sec/step)\n",
      "step 776 - loss = 1.989, (1.329 sec/step)\n",
      "step 777 - loss = 1.593, (2.131 sec/step)\n",
      "step 778 - loss = 1.482, (2.973 sec/step)\n",
      "step 779 - loss = 1.772, (1.383 sec/step)\n",
      "step 780 - loss = 2.002, (1.907 sec/step)\n",
      "step 781 - loss = 2.471, (0.988 sec/step)\n",
      "step 782 - loss = 2.363, (1.382 sec/step)\n",
      "step 783 - loss = 1.635, (2.633 sec/step)\n",
      "step 784 - loss = 2.064, (1.557 sec/step)\n",
      "step 785 - loss = 1.852, (2.234 sec/step)\n",
      "step 786 - loss = 1.445, (2.875 sec/step)\n",
      "step 787 - loss = 1.745, (2.237 sec/step)\n",
      "step 788 - loss = 1.755, (1.482 sec/step)\n",
      "step 789 - loss = 1.929, (2.279 sec/step)\n",
      "step 790 - loss = 2.171, (1.514 sec/step)\n",
      "step 791 - loss = 2.033, (1.646 sec/step)\n",
      "step 792 - loss = 2.144, (3.164 sec/step)\n",
      "step 793 - loss = 2.078, (1.870 sec/step)\n",
      "step 794 - loss = 2.082, (2.029 sec/step)\n",
      "step 795 - loss = 1.827, (2.262 sec/step)\n",
      "step 796 - loss = 2.070, (1.247 sec/step)\n",
      "step 797 - loss = 1.825, (1.526 sec/step)\n",
      "step 798 - loss = 1.948, (1.622 sec/step)\n",
      "step 799 - loss = 1.967, (1.789 sec/step)\n",
      "step 800 - loss = 2.100, (2.093 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 801 - loss = 1.572, (2.860 sec/step)\n",
      "step 802 - loss = 2.101, (2.963 sec/step)\n",
      "step 803 - loss = 1.833, (2.408 sec/step)\n",
      "step 804 - loss = 1.652, (2.295 sec/step)\n",
      "step 805 - loss = 2.741, (2.369 sec/step)\n",
      "step 806 - loss = 1.608, (2.361 sec/step)\n",
      "step 807 - loss = 2.057, (1.427 sec/step)\n",
      "step 808 - loss = 3.026, (1.743 sec/step)\n",
      "step 809 - loss = 2.230, (1.321 sec/step)\n",
      "step 810 - loss = 2.099, (1.408 sec/step)\n",
      "step 811 - loss = 2.096, (3.175 sec/step)\n",
      "step 812 - loss = 2.390, (1.912 sec/step)\n",
      "step 813 - loss = 1.779, (2.444 sec/step)\n",
      "step 814 - loss = 1.695, (1.806 sec/step)\n",
      "step 815 - loss = 1.790, (1.260 sec/step)\n",
      "step 816 - loss = 1.771, (1.898 sec/step)\n",
      "step 817 - loss = 1.636, (2.245 sec/step)\n",
      "step 818 - loss = 1.715, (1.245 sec/step)\n",
      "step 819 - loss = 2.397, (2.486 sec/step)\n",
      "step 820 - loss = 3.692, (2.315 sec/step)\n",
      "step 821 - loss = 1.533, (1.266 sec/step)\n",
      "step 822 - loss = 2.296, (2.488 sec/step)\n",
      "step 823 - loss = 2.061, (2.330 sec/step)\n",
      "step 824 - loss = 2.441, (1.552 sec/step)\n",
      "step 825 - loss = 2.023, (3.145 sec/step)\n",
      "step 826 - loss = 1.615, (1.386 sec/step)\n",
      "step 827 - loss = 1.448, (2.742 sec/step)\n",
      "step 828 - loss = 1.446, (2.483 sec/step)\n",
      "step 829 - loss = 2.390, (3.301 sec/step)\n",
      "step 830 - loss = 2.267, (2.512 sec/step)\n",
      "step 831 - loss = 1.976, (2.888 sec/step)\n",
      "step 832 - loss = 2.284, (0.980 sec/step)\n",
      "step 833 - loss = 2.569, (1.541 sec/step)\n",
      "step 834 - loss = 1.893, (2.049 sec/step)\n",
      "step 835 - loss = 2.260, (1.216 sec/step)\n",
      "step 836 - loss = 2.304, (1.355 sec/step)\n",
      "step 837 - loss = 2.154, (1.835 sec/step)\n",
      "step 838 - loss = 2.030, (2.121 sec/step)\n",
      "step 839 - loss = 1.973, (2.145 sec/step)\n",
      "step 840 - loss = 2.504, (2.329 sec/step)\n",
      "step 841 - loss = 2.450, (1.572 sec/step)\n",
      "step 842 - loss = 1.883, (1.579 sec/step)\n",
      "step 843 - loss = 2.388, (2.799 sec/step)\n",
      "step 844 - loss = 2.236, (2.177 sec/step)\n",
      "step 845 - loss = 2.739, (2.485 sec/step)\n",
      "step 846 - loss = 1.134, (2.620 sec/step)\n",
      "step 847 - loss = 2.263, (2.294 sec/step)\n",
      "step 848 - loss = 2.041, (1.512 sec/step)\n",
      "step 849 - loss = 1.664, (2.095 sec/step)\n",
      "step 850 - loss = 2.146, (3.052 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 851 - loss = 2.598, (2.522 sec/step)\n",
      "step 852 - loss = 2.204, (2.430 sec/step)\n",
      "step 853 - loss = 2.257, (2.035 sec/step)\n",
      "step 854 - loss = 2.105, (1.257 sec/step)\n",
      "step 855 - loss = 1.815, (1.350 sec/step)\n",
      "step 856 - loss = 1.947, (2.125 sec/step)\n",
      "step 857 - loss = 1.899, (2.173 sec/step)\n",
      "step 858 - loss = 1.744, (1.302 sec/step)\n",
      "step 859 - loss = 2.114, (2.631 sec/step)\n",
      "step 860 - loss = 1.899, (3.211 sec/step)\n",
      "step 861 - loss = 2.114, (3.699 sec/step)\n",
      "step 862 - loss = 1.575, (1.814 sec/step)\n",
      "step 863 - loss = 1.746, (1.927 sec/step)\n",
      "step 864 - loss = 1.945, (1.313 sec/step)\n",
      "step 865 - loss = 2.521, (4.177 sec/step)\n",
      "step 866 - loss = 2.007, (1.202 sec/step)\n",
      "step 867 - loss = 2.293, (2.786 sec/step)\n",
      "step 868 - loss = 1.994, (1.473 sec/step)\n",
      "step 869 - loss = 2.830, (2.219 sec/step)\n",
      "step 870 - loss = 2.312, (1.466 sec/step)\n",
      "step 871 - loss = 1.817, (3.214 sec/step)\n",
      "step 872 - loss = 2.063, (2.186 sec/step)\n",
      "step 873 - loss = 1.593, (1.562 sec/step)\n",
      "step 874 - loss = 2.127, (1.571 sec/step)\n",
      "step 875 - loss = 1.460, (1.702 sec/step)\n",
      "step 876 - loss = 2.061, (1.729 sec/step)\n",
      "step 877 - loss = 1.980, (2.004 sec/step)\n",
      "step 878 - loss = 1.627, (1.180 sec/step)\n",
      "step 879 - loss = 2.387, (2.127 sec/step)\n",
      "step 880 - loss = 1.549, (1.352 sec/step)\n",
      "step 881 - loss = 2.371, (2.303 sec/step)\n",
      "step 882 - loss = 1.633, (2.487 sec/step)\n",
      "step 883 - loss = 0.549, (1.366 sec/step)\n",
      "step 884 - loss = 2.140, (1.385 sec/step)\n",
      "step 885 - loss = 1.192, (3.026 sec/step)\n",
      "step 886 - loss = 2.546, (2.207 sec/step)\n",
      "step 887 - loss = 2.042, (2.071 sec/step)\n",
      "step 888 - loss = 2.064, (2.952 sec/step)\n",
      "step 889 - loss = 2.015, (1.608 sec/step)\n",
      "step 890 - loss = 2.423, (1.435 sec/step)\n",
      "step 891 - loss = 2.264, (1.562 sec/step)\n",
      "step 892 - loss = 1.577, (1.523 sec/step)\n",
      "step 893 - loss = 2.140, (1.383 sec/step)\n",
      "step 894 - loss = 2.190, (1.481 sec/step)\n",
      "step 895 - loss = 2.003, (2.101 sec/step)\n",
      "step 896 - loss = 1.761, (1.495 sec/step)\n",
      "step 897 - loss = 1.775, (3.158 sec/step)\n",
      "step 898 - loss = 1.780, (1.265 sec/step)\n",
      "step 899 - loss = 2.425, (1.974 sec/step)\n",
      "step 900 - loss = 2.223, (1.771 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 901 - loss = 2.590, (1.870 sec/step)\n",
      "step 902 - loss = 2.209, (1.231 sec/step)\n",
      "step 903 - loss = 2.085, (1.596 sec/step)\n",
      "step 904 - loss = 2.119, (1.247 sec/step)\n",
      "step 905 - loss = 2.057, (0.829 sec/step)\n",
      "step 906 - loss = 1.942, (3.106 sec/step)\n",
      "step 907 - loss = 2.185, (2.141 sec/step)\n",
      "step 908 - loss = 1.256, (3.080 sec/step)\n",
      "step 909 - loss = 2.152, (2.135 sec/step)\n",
      "step 910 - loss = 2.261, (2.233 sec/step)\n",
      "step 911 - loss = 1.563, (0.909 sec/step)\n",
      "step 912 - loss = 1.813, (2.552 sec/step)\n",
      "step 913 - loss = 1.761, (2.064 sec/step)\n",
      "step 914 - loss = 2.693, (1.869 sec/step)\n",
      "step 915 - loss = 1.458, (2.481 sec/step)\n",
      "step 916 - loss = 1.939, (1.347 sec/step)\n",
      "step 917 - loss = 2.550, (1.424 sec/step)\n",
      "step 918 - loss = 2.182, (1.868 sec/step)\n",
      "step 919 - loss = 1.441, (2.284 sec/step)\n",
      "step 920 - loss = 2.326, (2.477 sec/step)\n",
      "step 921 - loss = 1.555, (0.970 sec/step)\n",
      "step 922 - loss = 2.289, (1.109 sec/step)\n",
      "step 923 - loss = 1.661, (2.258 sec/step)\n",
      "step 924 - loss = 1.925, (1.918 sec/step)\n",
      "step 925 - loss = 1.555, (2.485 sec/step)\n",
      "step 926 - loss = 0.876, (1.545 sec/step)\n",
      "step 927 - loss = 2.386, (1.613 sec/step)\n",
      "step 928 - loss = 1.639, (2.631 sec/step)\n",
      "step 929 - loss = 2.360, (3.456 sec/step)\n",
      "step 930 - loss = 1.711, (1.765 sec/step)\n",
      "step 931 - loss = 2.258, (1.286 sec/step)\n",
      "step 932 - loss = 2.306, (2.275 sec/step)\n",
      "step 933 - loss = 1.585, (2.909 sec/step)\n",
      "step 934 - loss = 1.952, (1.213 sec/step)\n",
      "step 935 - loss = 2.277, (2.385 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 936 - loss = 1.350, (1.781 sec/step)\n",
      "step 937 - loss = 2.080, (1.432 sec/step)\n",
      "step 938 - loss = 2.302, (1.980 sec/step)\n",
      "step 939 - loss = 2.147, (1.691 sec/step)\n",
      "step 940 - loss = 1.719, (1.569 sec/step)\n",
      "step 941 - loss = 2.283, (2.486 sec/step)\n",
      "step 942 - loss = 2.666, (3.684 sec/step)\n",
      "step 943 - loss = 1.885, (1.913 sec/step)\n",
      "step 944 - loss = 1.706, (1.778 sec/step)\n",
      "step 945 - loss = 1.530, (1.914 sec/step)\n",
      "step 946 - loss = 2.441, (1.545 sec/step)\n",
      "step 947 - loss = 2.726, (1.405 sec/step)\n",
      "step 948 - loss = 1.609, (2.656 sec/step)\n",
      "step 949 - loss = 1.952, (1.538 sec/step)\n",
      "step 950 - loss = 1.963, (1.573 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 951 - loss = 1.361, (2.924 sec/step)\n",
      "step 952 - loss = 1.852, (1.231 sec/step)\n",
      "step 953 - loss = 1.510, (2.696 sec/step)\n",
      "step 954 - loss = 2.292, (3.012 sec/step)\n",
      "step 955 - loss = 1.727, (2.985 sec/step)\n",
      "step 956 - loss = 2.399, (2.957 sec/step)\n",
      "step 957 - loss = 1.648, (1.280 sec/step)\n",
      "step 958 - loss = 1.930, (1.322 sec/step)\n",
      "step 959 - loss = 2.414, (0.986 sec/step)\n",
      "step 960 - loss = 1.837, (1.128 sec/step)\n",
      "step 961 - loss = 2.444, (1.721 sec/step)\n",
      "step 962 - loss = 1.995, (1.870 sec/step)\n",
      "step 963 - loss = 1.980, (1.405 sec/step)\n",
      "step 964 - loss = 1.567, (1.296 sec/step)\n",
      "step 965 - loss = 1.959, (1.764 sec/step)\n",
      "step 966 - loss = 2.136, (1.590 sec/step)\n",
      "step 967 - loss = 1.867, (0.942 sec/step)\n",
      "step 968 - loss = 2.102, (1.030 sec/step)\n",
      "step 969 - loss = 2.372, (1.259 sec/step)\n",
      "step 970 - loss = 2.636, (2.172 sec/step)\n",
      "step 971 - loss = 2.652, (2.370 sec/step)\n",
      "step 972 - loss = 1.809, (1.756 sec/step)\n",
      "step 973 - loss = 2.483, (2.113 sec/step)\n",
      "step 974 - loss = 2.286, (2.923 sec/step)\n",
      "step 975 - loss = 2.353, (2.138 sec/step)\n",
      "step 976 - loss = 1.617, (1.921 sec/step)\n",
      "step 977 - loss = 1.856, (3.072 sec/step)\n",
      "step 978 - loss = 2.153, (1.020 sec/step)\n",
      "step 979 - loss = 2.293, (1.631 sec/step)\n",
      "step 980 - loss = 2.255, (1.792 sec/step)\n",
      "step 981 - loss = 2.199, (2.283 sec/step)\n",
      "step 982 - loss = 1.491, (2.166 sec/step)\n",
      "step 983 - loss = 2.315, (2.094 sec/step)\n",
      "step 984 - loss = 1.938, (1.389 sec/step)\n",
      "step 985 - loss = 2.378, (2.345 sec/step)\n",
      "step 986 - loss = 2.138, (1.087 sec/step)\n",
      "step 987 - loss = 2.344, (1.883 sec/step)\n",
      "step 988 - loss = 1.947, (1.350 sec/step)\n",
      "step 989 - loss = 1.663, (1.662 sec/step)\n",
      "step 990 - loss = 1.874, (1.210 sec/step)\n",
      "step 991 - loss = 1.833, (2.614 sec/step)\n",
      "step 992 - loss = 2.489, (2.266 sec/step)\n",
      "step 993 - loss = 2.031, (1.486 sec/step)\n",
      "step 994 - loss = 2.295, (1.846 sec/step)\n",
      "step 995 - loss = 1.819, (2.689 sec/step)\n",
      "step 996 - loss = 2.089, (1.902 sec/step)\n",
      "step 997 - loss = 1.839, (1.342 sec/step)\n",
      "step 998 - loss = 1.766, (1.809 sec/step)\n",
      "step 999 - loss = 1.584, (1.430 sec/step)\n",
      "step 1000 - loss = 1.923, (1.357 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1001 - loss = 1.999, (2.386 sec/step)\n",
      "step 1002 - loss = 1.623, (1.571 sec/step)\n",
      "step 1003 - loss = 1.738, (2.196 sec/step)\n",
      "step 1004 - loss = 2.267, (2.300 sec/step)\n",
      "step 1005 - loss = 2.433, (1.507 sec/step)\n",
      "step 1006 - loss = 1.511, (1.660 sec/step)\n",
      "step 1007 - loss = 2.143, (1.058 sec/step)\n",
      "step 1008 - loss = 2.160, (1.631 sec/step)\n",
      "step 1009 - loss = 2.082, (3.091 sec/step)\n",
      "step 1010 - loss = 2.432, (1.410 sec/step)\n",
      "step 1011 - loss = 1.818, (1.760 sec/step)\n",
      "step 1012 - loss = 2.223, (3.099 sec/step)\n",
      "step 1013 - loss = 1.618, (1.152 sec/step)\n",
      "step 1014 - loss = 2.113, (1.176 sec/step)\n",
      "step 1015 - loss = 2.037, (2.374 sec/step)\n",
      "step 1016 - loss = 1.753, (1.517 sec/step)\n",
      "step 1017 - loss = 1.940, (0.925 sec/step)\n",
      "step 1018 - loss = 1.789, (1.618 sec/step)\n",
      "step 1019 - loss = 2.432, (3.006 sec/step)\n",
      "step 1020 - loss = 1.775, (2.271 sec/step)\n",
      "step 1021 - loss = 2.185, (2.125 sec/step)\n",
      "step 1022 - loss = 1.563, (1.559 sec/step)\n",
      "step 1023 - loss = 2.064, (1.746 sec/step)\n",
      "step 1024 - loss = 1.601, (1.393 sec/step)\n",
      "step 1025 - loss = 1.842, (1.486 sec/step)\n",
      "step 1026 - loss = 1.374, (1.271 sec/step)\n",
      "step 1027 - loss = 1.545, (1.005 sec/step)\n",
      "step 1028 - loss = 1.502, (1.886 sec/step)\n",
      "step 1029 - loss = 2.133, (2.771 sec/step)\n",
      "step 1030 - loss = 1.585, (1.445 sec/step)\n",
      "step 1031 - loss = 2.609, (2.022 sec/step)\n",
      "step 1032 - loss = 1.544, (2.443 sec/step)\n",
      "step 1033 - loss = 2.278, (3.050 sec/step)\n",
      "step 1034 - loss = 2.240, (1.361 sec/step)\n",
      "step 1035 - loss = 2.274, (2.483 sec/step)\n",
      "step 1036 - loss = 1.628, (1.370 sec/step)\n",
      "step 1037 - loss = 2.074, (1.600 sec/step)\n",
      "step 1038 - loss = 2.494, (1.633 sec/step)\n",
      "step 1039 - loss = 2.252, (1.340 sec/step)\n",
      "step 1040 - loss = 2.102, (2.097 sec/step)\n",
      "step 1041 - loss = 2.038, (1.165 sec/step)\n",
      "step 1042 - loss = 2.314, (2.485 sec/step)\n",
      "step 1043 - loss = 1.624, (1.496 sec/step)\n",
      "step 1044 - loss = 2.002, (1.769 sec/step)\n",
      "step 1045 - loss = 2.138, (1.402 sec/step)\n",
      "step 1046 - loss = 1.473, (2.000 sec/step)\n",
      "step 1047 - loss = 2.367, (2.363 sec/step)\n",
      "step 1048 - loss = 1.562, (2.864 sec/step)\n",
      "step 1049 - loss = 1.974, (3.019 sec/step)\n",
      "step 1050 - loss = 1.749, (2.220 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1051 - loss = 1.695, (1.671 sec/step)\n",
      "step 1052 - loss = 1.995, (1.924 sec/step)\n",
      "step 1053 - loss = 1.867, (1.483 sec/step)\n",
      "step 1054 - loss = 1.809, (1.881 sec/step)\n",
      "step 1055 - loss = 1.225, (1.391 sec/step)\n",
      "step 1056 - loss = 2.540, (1.657 sec/step)\n",
      "step 1057 - loss = 2.114, (1.953 sec/step)\n",
      "step 1058 - loss = 1.919, (2.390 sec/step)\n",
      "step 1059 - loss = 2.125, (1.729 sec/step)\n",
      "step 1060 - loss = 2.449, (1.226 sec/step)\n",
      "step 1061 - loss = 1.839, (1.864 sec/step)\n",
      "step 1062 - loss = 2.011, (1.573 sec/step)\n",
      "step 1063 - loss = 1.778, (1.837 sec/step)\n",
      "step 1064 - loss = 1.747, (1.361 sec/step)\n",
      "step 1065 - loss = 2.009, (1.730 sec/step)\n",
      "step 1066 - loss = 2.027, (2.508 sec/step)\n",
      "step 1067 - loss = 0.670, (0.719 sec/step)\n",
      "step 1068 - loss = 2.408, (1.443 sec/step)\n",
      "step 1069 - loss = 2.357, (1.678 sec/step)\n",
      "step 1070 - loss = 1.889, (1.901 sec/step)\n",
      "step 1071 - loss = 2.041, (1.399 sec/step)\n",
      "step 1072 - loss = 1.732, (1.536 sec/step)\n",
      "step 1073 - loss = 1.915, (1.927 sec/step)\n",
      "step 1074 - loss = 2.435, (2.944 sec/step)\n",
      "step 1075 - loss = 2.119, (1.385 sec/step)\n",
      "step 1076 - loss = 1.601, (1.683 sec/step)\n",
      "step 1077 - loss = 2.576, (1.359 sec/step)\n",
      "step 1078 - loss = 2.324, (1.487 sec/step)\n",
      "step 1079 - loss = 1.737, (1.273 sec/step)\n",
      "step 1080 - loss = 1.997, (1.419 sec/step)\n",
      "step 1081 - loss = 2.018, (1.343 sec/step)\n",
      "step 1082 - loss = 2.392, (1.112 sec/step)\n",
      "step 1083 - loss = 1.650, (1.351 sec/step)\n",
      "step 1084 - loss = 1.516, (1.018 sec/step)\n",
      "step 1085 - loss = 2.276, (1.683 sec/step)\n",
      "step 1086 - loss = 1.997, (1.902 sec/step)\n",
      "step 1087 - loss = 2.801, (2.053 sec/step)\n",
      "step 1088 - loss = 1.704, (0.969 sec/step)\n",
      "step 1089 - loss = 2.022, (1.223 sec/step)\n",
      "step 1090 - loss = 2.055, (2.642 sec/step)\n",
      "step 1091 - loss = 1.962, (1.837 sec/step)\n",
      "step 1092 - loss = 1.844, (1.540 sec/step)\n",
      "step 1093 - loss = 1.834, (3.765 sec/step)\n",
      "step 1094 - loss = 1.547, (2.885 sec/step)\n",
      "step 1095 - loss = 1.972, (1.516 sec/step)\n",
      "step 1096 - loss = 2.486, (1.372 sec/step)\n",
      "step 1097 - loss = 2.551, (2.025 sec/step)\n",
      "step 1098 - loss = 2.482, (4.150 sec/step)\n",
      "step 1099 - loss = 1.429, (3.290 sec/step)\n",
      "step 1100 - loss = 1.798, (1.234 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1101 - loss = 2.284, (1.844 sec/step)\n",
      "step 1102 - loss = 1.723, (2.850 sec/step)\n",
      "step 1103 - loss = 2.061, (1.586 sec/step)\n",
      "step 1104 - loss = 1.838, (2.784 sec/step)\n",
      "step 1105 - loss = 2.538, (3.282 sec/step)\n",
      "step 1106 - loss = 2.002, (2.564 sec/step)\n",
      "step 1107 - loss = 1.546, (2.537 sec/step)\n",
      "step 1108 - loss = 2.564, (2.262 sec/step)\n",
      "step 1109 - loss = 2.537, (1.934 sec/step)\n",
      "step 1110 - loss = 2.193, (1.054 sec/step)\n",
      "step 1111 - loss = 2.329, (2.062 sec/step)\n",
      "step 1112 - loss = 1.896, (3.259 sec/step)\n",
      "step 1113 - loss = 1.900, (1.075 sec/step)\n",
      "step 1114 - loss = 2.129, (1.146 sec/step)\n",
      "step 1115 - loss = 2.015, (2.337 sec/step)\n",
      "step 1116 - loss = 2.014, (1.348 sec/step)\n",
      "step 1117 - loss = 2.513, (1.722 sec/step)\n",
      "step 1118 - loss = 1.900, (2.527 sec/step)\n",
      "step 1119 - loss = 2.464, (1.204 sec/step)\n",
      "step 1120 - loss = 1.705, (0.933 sec/step)\n",
      "step 1121 - loss = 1.680, (3.159 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1122 - loss = 2.174, (1.494 sec/step)\n",
      "step 1123 - loss = 1.584, (2.087 sec/step)\n",
      "step 1124 - loss = 1.509, (1.359 sec/step)\n",
      "step 1125 - loss = 1.799, (1.790 sec/step)\n",
      "step 1126 - loss = 1.592, (1.331 sec/step)\n",
      "step 1127 - loss = 1.751, (1.649 sec/step)\n",
      "step 1128 - loss = 2.279, (1.655 sec/step)\n",
      "step 1129 - loss = 1.607, (1.711 sec/step)\n",
      "step 1130 - loss = 2.269, (1.697 sec/step)\n",
      "step 1131 - loss = 1.841, (1.135 sec/step)\n",
      "step 1132 - loss = 1.842, (1.294 sec/step)\n",
      "step 1133 - loss = 2.249, (1.561 sec/step)\n",
      "step 1134 - loss = 1.661, (1.916 sec/step)\n",
      "step 1135 - loss = 1.917, (1.433 sec/step)\n",
      "step 1136 - loss = 2.194, (2.486 sec/step)\n",
      "step 1137 - loss = 1.790, (2.197 sec/step)\n",
      "step 1138 - loss = 2.266, (1.246 sec/step)\n",
      "step 1139 - loss = 2.041, (1.201 sec/step)\n",
      "step 1140 - loss = 2.332, (1.493 sec/step)\n",
      "step 1141 - loss = 2.461, (1.809 sec/step)\n",
      "step 1142 - loss = 2.338, (1.392 sec/step)\n",
      "step 1143 - loss = 1.579, (1.649 sec/step)\n",
      "step 1144 - loss = 1.658, (1.171 sec/step)\n",
      "step 1145 - loss = 2.322, (1.572 sec/step)\n",
      "step 1146 - loss = 1.900, (1.513 sec/step)\n",
      "step 1147 - loss = 1.792, (1.428 sec/step)\n",
      "step 1148 - loss = 2.085, (2.695 sec/step)\n",
      "step 1149 - loss = 1.889, (2.015 sec/step)\n",
      "step 1150 - loss = 1.900, (1.281 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1151 - loss = 2.776, (2.482 sec/step)\n",
      "step 1152 - loss = 2.429, (1.750 sec/step)\n",
      "step 1153 - loss = 1.551, (1.134 sec/step)\n",
      "step 1154 - loss = 1.928, (1.669 sec/step)\n",
      "step 1155 - loss = 2.465, (3.851 sec/step)\n",
      "step 1156 - loss = 1.704, (1.520 sec/step)\n",
      "step 1157 - loss = 2.099, (1.282 sec/step)\n",
      "step 1158 - loss = 2.019, (1.682 sec/step)\n",
      "step 1159 - loss = 2.296, (2.747 sec/step)\n",
      "step 1160 - loss = 2.076, (2.795 sec/step)\n",
      "step 1161 - loss = 1.167, (2.165 sec/step)\n",
      "step 1162 - loss = 2.369, (1.246 sec/step)\n",
      "step 1163 - loss = 1.730, (1.752 sec/step)\n",
      "step 1164 - loss = 2.198, (2.695 sec/step)\n",
      "step 1165 - loss = 2.030, (2.485 sec/step)\n",
      "step 1166 - loss = 1.131, (1.727 sec/step)\n",
      "step 1167 - loss = 1.963, (3.181 sec/step)\n",
      "step 1168 - loss = 2.064, (1.172 sec/step)\n",
      "step 1169 - loss = 2.164, (1.406 sec/step)\n",
      "step 1170 - loss = 2.100, (1.445 sec/step)\n",
      "step 1171 - loss = 2.379, (1.970 sec/step)\n",
      "step 1172 - loss = 1.594, (1.790 sec/step)\n",
      "step 1173 - loss = 1.928, (2.217 sec/step)\n",
      "step 1174 - loss = 1.241, (1.091 sec/step)\n",
      "step 1175 - loss = 2.233, (1.556 sec/step)\n",
      "step 1176 - loss = 2.386, (1.590 sec/step)\n",
      "step 1177 - loss = 1.997, (1.325 sec/step)\n",
      "step 1178 - loss = 2.476, (1.770 sec/step)\n",
      "step 1179 - loss = 2.149, (1.440 sec/step)\n",
      "step 1180 - loss = 2.448, (1.326 sec/step)\n",
      "step 1181 - loss = 2.057, (1.284 sec/step)\n",
      "step 1182 - loss = 2.024, (1.616 sec/step)\n",
      "step 1183 - loss = 2.282, (1.298 sec/step)\n",
      "step 1184 - loss = 2.398, (1.526 sec/step)\n",
      "step 1185 - loss = 1.976, (1.781 sec/step)\n",
      "step 1186 - loss = 1.999, (1.158 sec/step)\n",
      "step 1187 - loss = 2.072, (1.649 sec/step)\n",
      "step 1188 - loss = 2.415, (2.343 sec/step)\n",
      "step 1189 - loss = 2.608, (1.408 sec/step)\n",
      "step 1190 - loss = 2.562, (1.509 sec/step)\n",
      "step 1191 - loss = 1.947, (1.742 sec/step)\n",
      "step 1192 - loss = 2.750, (1.919 sec/step)\n",
      "step 1193 - loss = 1.905, (2.754 sec/step)\n",
      "step 1194 - loss = 1.873, (1.930 sec/step)\n",
      "step 1195 - loss = 2.014, (2.665 sec/step)\n",
      "step 1196 - loss = 1.374, (1.591 sec/step)\n",
      "step 1197 - loss = 1.807, (2.568 sec/step)\n",
      "step 1198 - loss = 2.175, (1.358 sec/step)\n",
      "step 1199 - loss = 2.014, (2.847 sec/step)\n",
      "step 1200 - loss = 1.744, (1.629 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1201 - loss = 1.630, (2.196 sec/step)\n",
      "step 1202 - loss = 2.197, (1.445 sec/step)\n",
      "step 1203 - loss = 2.007, (1.833 sec/step)\n",
      "step 1204 - loss = 1.633, (2.033 sec/step)\n",
      "step 1205 - loss = 2.569, (1.970 sec/step)\n",
      "step 1206 - loss = 2.051, (2.981 sec/step)\n",
      "step 1207 - loss = 2.179, (1.850 sec/step)\n",
      "step 1208 - loss = 2.089, (2.733 sec/step)\n",
      "step 1209 - loss = 2.439, (1.147 sec/step)\n",
      "step 1210 - loss = 1.600, (1.053 sec/step)\n",
      "step 1211 - loss = 2.184, (1.624 sec/step)\n",
      "step 1212 - loss = 2.281, (1.477 sec/step)\n",
      "step 1213 - loss = 1.507, (3.500 sec/step)\n",
      "step 1214 - loss = 2.317, (2.536 sec/step)\n",
      "step 1215 - loss = 2.268, (2.611 sec/step)\n",
      "step 1216 - loss = 1.828, (1.760 sec/step)\n",
      "step 1217 - loss = 2.391, (1.374 sec/step)\n",
      "step 1218 - loss = 1.670, (1.573 sec/step)\n",
      "step 1219 - loss = 2.256, (2.487 sec/step)\n",
      "step 1220 - loss = 2.302, (2.879 sec/step)\n",
      "step 1221 - loss = 1.725, (1.605 sec/step)\n",
      "step 1222 - loss = 2.249, (1.204 sec/step)\n",
      "step 1223 - loss = 1.767, (2.593 sec/step)\n",
      "step 1224 - loss = 2.315, (1.507 sec/step)\n",
      "step 1225 - loss = 2.164, (1.442 sec/step)\n",
      "step 1226 - loss = 1.862, (1.474 sec/step)\n",
      "step 1227 - loss = 1.705, (3.064 sec/step)\n",
      "step 1228 - loss = 2.532, (2.812 sec/step)\n",
      "step 1229 - loss = 1.568, (1.425 sec/step)\n",
      "step 1230 - loss = 2.258, (1.185 sec/step)\n",
      "step 1231 - loss = 2.240, (1.940 sec/step)\n",
      "step 1232 - loss = 2.421, (1.068 sec/step)\n",
      "step 1233 - loss = 2.121, (2.219 sec/step)\n",
      "step 1234 - loss = 1.554, (2.178 sec/step)\n",
      "step 1235 - loss = 2.175, (2.919 sec/step)\n",
      "step 1236 - loss = 2.493, (2.638 sec/step)\n",
      "step 1237 - loss = 2.013, (2.978 sec/step)\n",
      "step 1238 - loss = 1.958, (1.396 sec/step)\n",
      "step 1239 - loss = 1.640, (2.018 sec/step)\n",
      "step 1240 - loss = 2.238, (1.762 sec/step)\n",
      "step 1241 - loss = 2.240, (2.082 sec/step)\n",
      "step 1242 - loss = 1.549, (2.397 sec/step)\n",
      "step 1243 - loss = 2.399, (1.498 sec/step)\n",
      "step 1244 - loss = 2.287, (1.589 sec/step)\n",
      "step 1245 - loss = 2.331, (1.210 sec/step)\n",
      "step 1246 - loss = 2.289, (2.075 sec/step)\n",
      "step 1247 - loss = 2.519, (1.538 sec/step)\n",
      "step 1248 - loss = 2.432, (1.671 sec/step)\n",
      "step 1249 - loss = 1.944, (1.465 sec/step)\n",
      "step 1250 - loss = 1.798, (1.561 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1251 - loss = 1.769, (1.935 sec/step)\n",
      "step 1252 - loss = 1.970, (1.610 sec/step)\n",
      "step 1253 - loss = 2.113, (3.039 sec/step)\n",
      "step 1254 - loss = 1.924, (1.747 sec/step)\n",
      "step 1255 - loss = 2.710, (1.717 sec/step)\n",
      "step 1256 - loss = 2.395, (1.628 sec/step)\n",
      "step 1257 - loss = 1.995, (1.310 sec/step)\n",
      "step 1258 - loss = 1.798, (3.790 sec/step)\n",
      "step 1259 - loss = 1.744, (2.788 sec/step)\n",
      "step 1260 - loss = 1.344, (0.955 sec/step)\n",
      "step 1261 - loss = 1.706, (1.450 sec/step)\n",
      "step 1262 - loss = 2.333, (1.526 sec/step)\n",
      "step 1263 - loss = 2.104, (1.401 sec/step)\n",
      "step 1264 - loss = 1.498, (1.474 sec/step)\n",
      "step 1265 - loss = 1.703, (1.652 sec/step)\n",
      "step 1266 - loss = 1.714, (1.309 sec/step)\n",
      "step 1267 - loss = 1.804, (2.813 sec/step)\n",
      "step 1268 - loss = 1.810, (2.015 sec/step)\n",
      "step 1269 - loss = 2.279, (1.519 sec/step)\n",
      "step 1270 - loss = 2.244, (1.660 sec/step)\n",
      "step 1271 - loss = 2.277, (2.002 sec/step)\n",
      "step 1272 - loss = 2.030, (1.448 sec/step)\n",
      "step 1273 - loss = 2.046, (1.401 sec/step)\n",
      "step 1274 - loss = 1.407, (1.746 sec/step)\n",
      "step 1275 - loss = 1.789, (1.984 sec/step)\n",
      "step 1276 - loss = 2.114, (3.409 sec/step)\n",
      "step 1277 - loss = 1.213, (1.903 sec/step)\n",
      "step 1278 - loss = 2.005, (2.513 sec/step)\n",
      "step 1279 - loss = 1.788, (1.736 sec/step)\n",
      "step 1280 - loss = 2.101, (1.815 sec/step)\n",
      "step 1281 - loss = 1.604, (2.038 sec/step)\n",
      "step 1282 - loss = 2.203, (1.491 sec/step)\n",
      "step 1283 - loss = 1.887, (1.631 sec/step)\n",
      "step 1284 - loss = 1.880, (1.882 sec/step)\n",
      "step 1285 - loss = 2.490, (3.029 sec/step)\n",
      "step 1286 - loss = 2.404, (1.538 sec/step)\n",
      "step 1287 - loss = 1.659, (3.131 sec/step)\n",
      "step 1288 - loss = 1.746, (3.209 sec/step)\n",
      "step 1289 - loss = 1.840, (1.179 sec/step)\n",
      "step 1290 - loss = 2.171, (2.169 sec/step)\n",
      "step 1291 - loss = 1.758, (1.502 sec/step)\n",
      "step 1292 - loss = 1.333, (1.485 sec/step)\n",
      "step 1293 - loss = 3.115, (2.486 sec/step)\n",
      "step 1294 - loss = 2.474, (2.900 sec/step)\n",
      "step 1295 - loss = 1.297, (2.265 sec/step)\n",
      "step 1296 - loss = 1.956, (2.569 sec/step)\n",
      "step 1297 - loss = 1.740, (1.367 sec/step)\n",
      "step 1298 - loss = 2.439, (2.274 sec/step)\n",
      "step 1299 - loss = 1.513, (3.147 sec/step)\n",
      "step 1300 - loss = 1.660, (0.969 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1301 - loss = 2.302, (2.306 sec/step)\n",
      "step 1302 - loss = 2.309, (1.339 sec/step)\n",
      "step 1303 - loss = 1.593, (1.642 sec/step)\n",
      "step 1304 - loss = 2.413, (2.485 sec/step)\n",
      "step 1305 - loss = 2.722, (3.561 sec/step)\n",
      "step 1306 - loss = 2.101, (2.485 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1307 - loss = 2.616, (2.246 sec/step)\n",
      "step 1308 - loss = 2.377, (1.910 sec/step)\n",
      "step 1309 - loss = 2.026, (1.983 sec/step)\n",
      "step 1310 - loss = 1.723, (1.319 sec/step)\n",
      "step 1311 - loss = 2.035, (1.151 sec/step)\n",
      "step 1312 - loss = 1.816, (1.353 sec/step)\n",
      "step 1313 - loss = 1.756, (1.341 sec/step)\n",
      "step 1314 - loss = 2.270, (1.297 sec/step)\n",
      "step 1315 - loss = 1.594, (1.843 sec/step)\n",
      "step 1316 - loss = 2.372, (2.077 sec/step)\n",
      "step 1317 - loss = 2.304, (2.484 sec/step)\n",
      "step 1318 - loss = 2.539, (2.483 sec/step)\n",
      "step 1319 - loss = 2.399, (0.929 sec/step)\n",
      "step 1320 - loss = 2.302, (1.402 sec/step)\n",
      "step 1321 - loss = 2.021, (1.464 sec/step)\n",
      "step 1322 - loss = 2.329, (1.868 sec/step)\n",
      "step 1323 - loss = 1.866, (1.304 sec/step)\n",
      "step 1324 - loss = 2.043, (1.658 sec/step)\n",
      "step 1325 - loss = 2.408, (1.743 sec/step)\n",
      "step 1326 - loss = 1.865, (2.077 sec/step)\n",
      "step 1327 - loss = 1.853, (1.428 sec/step)\n",
      "step 1328 - loss = 2.312, (1.822 sec/step)\n",
      "step 1329 - loss = 1.870, (3.707 sec/step)\n",
      "step 1330 - loss = 2.170, (1.860 sec/step)\n",
      "step 1331 - loss = 1.986, (3.296 sec/step)\n",
      "step 1332 - loss = 2.116, (2.366 sec/step)\n",
      "step 1333 - loss = 2.678, (1.828 sec/step)\n",
      "step 1334 - loss = 2.031, (2.519 sec/step)\n",
      "step 1335 - loss = 2.408, (1.790 sec/step)\n",
      "step 1336 - loss = 1.819, (2.160 sec/step)\n",
      "step 1337 - loss = 1.808, (1.666 sec/step)\n",
      "step 1338 - loss = 1.711, (3.057 sec/step)\n",
      "step 1339 - loss = 2.328, (1.296 sec/step)\n",
      "step 1340 - loss = 2.376, (1.439 sec/step)\n",
      "step 1341 - loss = 2.324, (2.976 sec/step)\n",
      "step 1342 - loss = 1.430, (2.762 sec/step)\n",
      "step 1343 - loss = 1.925, (2.664 sec/step)\n",
      "step 1344 - loss = 1.840, (2.111 sec/step)\n",
      "step 1345 - loss = 2.324, (2.022 sec/step)\n",
      "step 1346 - loss = 2.230, (1.435 sec/step)\n",
      "step 1347 - loss = 2.010, (1.765 sec/step)\n",
      "step 1348 - loss = 1.690, (2.488 sec/step)\n",
      "step 1349 - loss = 0.603, (2.617 sec/step)\n",
      "step 1350 - loss = 1.425, (2.673 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1351 - loss = 2.055, (2.273 sec/step)\n",
      "step 1352 - loss = 2.244, (3.025 sec/step)\n",
      "step 1353 - loss = 2.451, (2.484 sec/step)\n",
      "step 1354 - loss = 2.391, (3.683 sec/step)\n",
      "step 1355 - loss = 1.629, (1.627 sec/step)\n",
      "step 1356 - loss = 1.803, (1.878 sec/step)\n",
      "step 1357 - loss = 2.059, (2.633 sec/step)\n",
      "step 1358 - loss = 1.616, (2.333 sec/step)\n",
      "step 1359 - loss = 2.004, (1.314 sec/step)\n",
      "step 1360 - loss = 2.269, (3.067 sec/step)\n",
      "step 1361 - loss = 2.190, (2.952 sec/step)\n",
      "step 1362 - loss = 2.120, (1.460 sec/step)\n",
      "step 1363 - loss = 2.207, (2.280 sec/step)\n",
      "step 1364 - loss = 2.162, (2.081 sec/step)\n",
      "step 1365 - loss = 1.785, (1.192 sec/step)\n",
      "step 1366 - loss = 1.670, (1.628 sec/step)\n",
      "step 1367 - loss = 2.679, (2.880 sec/step)\n",
      "step 1368 - loss = 1.838, (1.408 sec/step)\n",
      "step 1369 - loss = 2.599, (1.855 sec/step)\n",
      "step 1370 - loss = 1.561, (1.016 sec/step)\n",
      "step 1371 - loss = 1.413, (1.329 sec/step)\n",
      "step 1372 - loss = 2.641, (2.363 sec/step)\n",
      "step 1373 - loss = 2.011, (1.360 sec/step)\n",
      "step 1374 - loss = 1.546, (2.943 sec/step)\n",
      "step 1375 - loss = 2.114, (1.777 sec/step)\n",
      "step 1376 - loss = 1.913, (2.046 sec/step)\n",
      "step 1377 - loss = 1.826, (1.551 sec/step)\n",
      "step 1378 - loss = 2.349, (1.400 sec/step)\n",
      "step 1379 - loss = 1.518, (1.267 sec/step)\n",
      "step 1380 - loss = 1.999, (1.679 sec/step)\n",
      "step 1381 - loss = 1.520, (1.522 sec/step)\n",
      "step 1382 - loss = 1.557, (1.941 sec/step)\n",
      "step 1383 - loss = 1.850, (2.099 sec/step)\n",
      "step 1384 - loss = 1.695, (0.961 sec/step)\n",
      "step 1385 - loss = 1.592, (1.258 sec/step)\n",
      "step 1386 - loss = 1.987, (0.939 sec/step)\n",
      "step 1387 - loss = 2.449, (1.394 sec/step)\n",
      "step 1388 - loss = 1.562, (1.370 sec/step)\n",
      "step 1389 - loss = 2.273, (1.507 sec/step)\n",
      "step 1390 - loss = 1.948, (1.280 sec/step)\n",
      "step 1391 - loss = 1.595, (1.525 sec/step)\n",
      "step 1392 - loss = 2.103, (2.096 sec/step)\n",
      "step 1393 - loss = 2.074, (2.316 sec/step)\n",
      "step 1394 - loss = 2.026, (1.890 sec/step)\n",
      "step 1395 - loss = 2.414, (1.437 sec/step)\n",
      "step 1396 - loss = 1.628, (3.079 sec/step)\n",
      "step 1397 - loss = 1.799, (1.505 sec/step)\n",
      "step 1398 - loss = 1.892, (1.823 sec/step)\n",
      "step 1399 - loss = 1.466, (3.261 sec/step)\n",
      "step 1400 - loss = 2.351, (1.390 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1401 - loss = 1.802, (2.568 sec/step)\n",
      "step 1402 - loss = 2.079, (2.670 sec/step)\n",
      "step 1403 - loss = 2.497, (2.063 sec/step)\n",
      "step 1404 - loss = 1.500, (3.230 sec/step)\n",
      "step 1405 - loss = 1.957, (0.866 sec/step)\n",
      "step 1406 - loss = 2.193, (2.184 sec/step)\n",
      "step 1407 - loss = 2.042, (1.386 sec/step)\n",
      "step 1408 - loss = 1.564, (1.347 sec/step)\n",
      "step 1409 - loss = 1.379, (2.961 sec/step)\n",
      "step 1410 - loss = 2.219, (1.294 sec/step)\n",
      "step 1411 - loss = 2.261, (1.234 sec/step)\n",
      "step 1412 - loss = 2.527, (1.522 sec/step)\n",
      "step 1413 - loss = 1.796, (1.914 sec/step)\n",
      "step 1414 - loss = 1.922, (1.296 sec/step)\n",
      "step 1415 - loss = 1.950, (1.552 sec/step)\n",
      "step 1416 - loss = 1.816, (1.424 sec/step)\n",
      "step 1417 - loss = 2.173, (2.309 sec/step)\n",
      "step 1418 - loss = 1.431, (2.136 sec/step)\n",
      "step 1419 - loss = 1.859, (1.297 sec/step)\n",
      "step 1420 - loss = 1.870, (2.917 sec/step)\n",
      "step 1421 - loss = 2.149, (1.331 sec/step)\n",
      "step 1422 - loss = 1.804, (1.902 sec/step)\n",
      "step 1423 - loss = 2.389, (1.267 sec/step)\n",
      "step 1424 - loss = 1.548, (1.170 sec/step)\n",
      "step 1425 - loss = 2.153, (1.553 sec/step)\n",
      "step 1426 - loss = 1.651, (2.196 sec/step)\n",
      "step 1427 - loss = 1.651, (2.679 sec/step)\n",
      "step 1428 - loss = 2.365, (2.436 sec/step)\n",
      "step 1429 - loss = 2.089, (1.981 sec/step)\n",
      "step 1430 - loss = 2.686, (2.027 sec/step)\n",
      "step 1431 - loss = 2.044, (1.945 sec/step)\n",
      "step 1432 - loss = 2.522, (2.322 sec/step)\n",
      "step 1433 - loss = 1.984, (1.381 sec/step)\n",
      "step 1434 - loss = 2.213, (1.345 sec/step)\n",
      "step 1435 - loss = 2.086, (3.242 sec/step)\n",
      "step 1436 - loss = 2.165, (1.673 sec/step)\n",
      "step 1437 - loss = 2.189, (2.250 sec/step)\n",
      "step 1438 - loss = 2.094, (2.012 sec/step)\n",
      "step 1439 - loss = 2.181, (1.536 sec/step)\n",
      "step 1440 - loss = 1.841, (2.543 sec/step)\n",
      "step 1441 - loss = 1.862, (1.439 sec/step)\n",
      "step 1442 - loss = 1.430, (1.352 sec/step)\n",
      "step 1443 - loss = 1.955, (2.167 sec/step)\n",
      "step 1444 - loss = 1.851, (1.435 sec/step)\n",
      "step 1445 - loss = 1.834, (1.108 sec/step)\n",
      "step 1446 - loss = 1.330, (1.949 sec/step)\n",
      "step 1447 - loss = 2.453, (1.650 sec/step)\n",
      "step 1448 - loss = 1.535, (1.391 sec/step)\n",
      "step 1449 - loss = 2.303, (2.008 sec/step)\n",
      "step 1450 - loss = 2.365, (2.460 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1451 - loss = 1.544, (1.501 sec/step)\n",
      "step 1452 - loss = 2.506, (2.522 sec/step)\n",
      "step 1453 - loss = 2.074, (3.074 sec/step)\n",
      "step 1454 - loss = 2.006, (1.720 sec/step)\n",
      "step 1455 - loss = 1.660, (2.075 sec/step)\n",
      "step 1456 - loss = 2.419, (1.280 sec/step)\n",
      "step 1457 - loss = 2.102, (1.113 sec/step)\n",
      "step 1458 - loss = 1.988, (1.807 sec/step)\n",
      "step 1459 - loss = 2.070, (1.384 sec/step)\n",
      "step 1460 - loss = 1.372, (2.579 sec/step)\n",
      "step 1461 - loss = 2.198, (2.081 sec/step)\n",
      "step 1462 - loss = 1.879, (2.492 sec/step)\n",
      "step 1463 - loss = 1.569, (1.605 sec/step)\n",
      "step 1464 - loss = 2.253, (1.709 sec/step)\n",
      "step 1465 - loss = 2.041, (2.185 sec/step)\n",
      "step 1466 - loss = 2.684, (2.484 sec/step)\n",
      "step 1467 - loss = 2.866, (1.757 sec/step)\n",
      "step 1468 - loss = 2.028, (1.666 sec/step)\n",
      "step 1469 - loss = 2.865, (1.163 sec/step)\n",
      "step 1470 - loss = 2.287, (2.050 sec/step)\n",
      "step 1471 - loss = 1.520, (2.261 sec/step)\n",
      "step 1472 - loss = 1.954, (1.127 sec/step)\n",
      "step 1473 - loss = 1.544, (1.354 sec/step)\n",
      "step 1474 - loss = 2.219, (1.210 sec/step)\n",
      "step 1475 - loss = 1.955, (2.262 sec/step)\n",
      "step 1476 - loss = 2.834, (3.010 sec/step)\n",
      "step 1477 - loss = 1.728, (1.526 sec/step)\n",
      "step 1478 - loss = 1.685, (1.724 sec/step)\n",
      "step 1479 - loss = 1.892, (1.190 sec/step)\n",
      "step 1480 - loss = 1.732, (1.214 sec/step)\n",
      "step 1481 - loss = 1.936, (1.607 sec/step)\n",
      "step 1482 - loss = 2.137, (2.073 sec/step)\n",
      "step 1483 - loss = 1.879, (1.238 sec/step)\n",
      "step 1484 - loss = 2.263, (1.577 sec/step)\n",
      "step 1485 - loss = 2.748, (1.376 sec/step)\n",
      "step 1486 - loss = 1.872, (2.488 sec/step)\n",
      "step 1487 - loss = 1.814, (2.934 sec/step)\n",
      "step 1488 - loss = 1.787, (2.005 sec/step)\n",
      "step 1489 - loss = 1.895, (2.062 sec/step)\n",
      "step 1490 - loss = 1.226, (2.487 sec/step)\n",
      "step 1491 - loss = 0.518, (1.005 sec/step)\n",
      "step 1492 - loss = 1.867, (1.164 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1493 - loss = 1.510, (1.553 sec/step)\n",
      "step 1494 - loss = 2.451, (1.357 sec/step)\n",
      "step 1495 - loss = 2.234, (1.131 sec/step)\n",
      "step 1496 - loss = 2.014, (1.894 sec/step)\n",
      "step 1497 - loss = 2.466, (1.227 sec/step)\n",
      "step 1498 - loss = 2.275, (1.722 sec/step)\n",
      "step 1499 - loss = 1.757, (2.092 sec/step)\n",
      "step 1500 - loss = 1.989, (1.878 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1501 - loss = 2.042, (1.781 sec/step)\n",
      "step 1502 - loss = 2.435, (1.272 sec/step)\n",
      "step 1503 - loss = 1.464, (2.784 sec/step)\n",
      "step 1504 - loss = 1.934, (2.517 sec/step)\n",
      "step 1505 - loss = 1.434, (1.279 sec/step)\n",
      "step 1506 - loss = 1.948, (1.526 sec/step)\n",
      "step 1507 - loss = 1.579, (2.924 sec/step)\n",
      "step 1508 - loss = 1.671, (1.678 sec/step)\n",
      "step 1509 - loss = 2.042, (1.302 sec/step)\n",
      "step 1510 - loss = 1.967, (1.694 sec/step)\n",
      "step 1511 - loss = 1.618, (1.556 sec/step)\n",
      "step 1512 - loss = 2.219, (2.058 sec/step)\n",
      "step 1513 - loss = 2.527, (0.925 sec/step)\n",
      "step 1514 - loss = 1.573, (1.657 sec/step)\n",
      "step 1515 - loss = 1.837, (3.666 sec/step)\n",
      "step 1516 - loss = 2.269, (2.485 sec/step)\n",
      "step 1517 - loss = 0.773, (4.792 sec/step)\n",
      "step 1518 - loss = 2.240, (1.843 sec/step)\n",
      "step 1519 - loss = 1.748, (2.272 sec/step)\n",
      "step 1520 - loss = 1.962, (1.625 sec/step)\n",
      "step 1521 - loss = 2.067, (1.731 sec/step)\n",
      "step 1522 - loss = 1.643, (1.433 sec/step)\n",
      "step 1523 - loss = 2.605, (2.484 sec/step)\n",
      "step 1524 - loss = 1.772, (2.249 sec/step)\n",
      "step 1525 - loss = 2.189, (1.439 sec/step)\n",
      "step 1526 - loss = 2.310, (2.484 sec/step)\n",
      "step 1527 - loss = 1.225, (1.481 sec/step)\n",
      "step 1528 - loss = 2.175, (2.422 sec/step)\n",
      "step 1529 - loss = 2.725, (1.601 sec/step)\n",
      "step 1530 - loss = 2.553, (1.052 sec/step)\n",
      "step 1531 - loss = 2.362, (1.753 sec/step)\n",
      "step 1532 - loss = 1.354, (1.706 sec/step)\n",
      "step 1533 - loss = 1.897, (2.714 sec/step)\n",
      "step 1534 - loss = 2.209, (2.577 sec/step)\n",
      "step 1535 - loss = 2.059, (1.478 sec/step)\n",
      "step 1536 - loss = 3.241, (3.047 sec/step)\n",
      "step 1537 - loss = 2.073, (1.014 sec/step)\n",
      "step 1538 - loss = 2.142, (1.070 sec/step)\n",
      "step 1539 - loss = 1.896, (1.836 sec/step)\n",
      "step 1540 - loss = 2.788, (2.637 sec/step)\n",
      "step 1541 - loss = 2.083, (2.127 sec/step)\n",
      "step 1542 - loss = 2.325, (1.378 sec/step)\n",
      "step 1543 - loss = 2.168, (1.593 sec/step)\n",
      "step 1544 - loss = 1.995, (2.124 sec/step)\n",
      "step 1545 - loss = 2.293, (2.121 sec/step)\n",
      "step 1546 - loss = 2.540, (1.696 sec/step)\n",
      "step 1547 - loss = 2.047, (2.082 sec/step)\n",
      "step 1548 - loss = 2.420, (1.390 sec/step)\n",
      "step 1549 - loss = 1.936, (2.484 sec/step)\n",
      "step 1550 - loss = 0.746, (0.595 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1551 - loss = 2.422, (1.410 sec/step)\n",
      "step 1552 - loss = 2.335, (2.188 sec/step)\n",
      "step 1553 - loss = 2.213, (1.393 sec/step)\n",
      "step 1554 - loss = 2.183, (2.207 sec/step)\n",
      "step 1555 - loss = 2.219, (1.402 sec/step)\n",
      "step 1556 - loss = 1.622, (2.423 sec/step)\n",
      "step 1557 - loss = 2.279, (1.156 sec/step)\n",
      "step 1558 - loss = 1.941, (1.242 sec/step)\n",
      "step 1559 - loss = 1.729, (1.693 sec/step)\n",
      "step 1560 - loss = 2.059, (2.415 sec/step)\n",
      "step 1561 - loss = 1.510, (0.980 sec/step)\n",
      "step 1562 - loss = 1.816, (1.765 sec/step)\n",
      "step 1563 - loss = 2.212, (1.532 sec/step)\n",
      "step 1564 - loss = 1.600, (1.756 sec/step)\n",
      "step 1565 - loss = 2.000, (1.759 sec/step)\n",
      "step 1566 - loss = 1.747, (2.888 sec/step)\n",
      "step 1567 - loss = 2.609, (1.265 sec/step)\n",
      "step 1568 - loss = 1.831, (3.090 sec/step)\n",
      "step 1569 - loss = 1.970, (2.118 sec/step)\n",
      "step 1570 - loss = 2.097, (1.422 sec/step)\n",
      "step 1571 - loss = 1.505, (1.622 sec/step)\n",
      "step 1572 - loss = 1.646, (1.573 sec/step)\n",
      "step 1573 - loss = 2.365, (1.263 sec/step)\n",
      "step 1574 - loss = 1.961, (1.442 sec/step)\n",
      "step 1575 - loss = 2.230, (1.429 sec/step)\n",
      "step 1576 - loss = 2.140, (2.108 sec/step)\n",
      "step 1577 - loss = 1.870, (1.820 sec/step)\n",
      "step 1578 - loss = 2.404, (2.136 sec/step)\n",
      "step 1579 - loss = 1.907, (1.846 sec/step)\n",
      "step 1580 - loss = 1.599, (1.540 sec/step)\n",
      "step 1581 - loss = 2.054, (1.646 sec/step)\n",
      "step 1582 - loss = 2.241, (2.336 sec/step)\n",
      "step 1583 - loss = 1.959, (1.175 sec/step)\n",
      "step 1584 - loss = 2.945, (1.949 sec/step)\n",
      "step 1585 - loss = 2.185, (1.242 sec/step)\n",
      "step 1586 - loss = 1.954, (1.112 sec/step)\n",
      "step 1587 - loss = 1.796, (1.481 sec/step)\n",
      "step 1588 - loss = 1.576, (1.613 sec/step)\n",
      "step 1589 - loss = 2.034, (1.151 sec/step)\n",
      "step 1590 - loss = 2.120, (1.841 sec/step)\n",
      "step 1591 - loss = 1.654, (2.964 sec/step)\n",
      "step 1592 - loss = 2.039, (1.679 sec/step)\n",
      "step 1593 - loss = 1.848, (2.128 sec/step)\n",
      "step 1594 - loss = 2.063, (1.100 sec/step)\n",
      "step 1595 - loss = 1.705, (1.371 sec/step)\n",
      "step 1596 - loss = 1.540, (1.907 sec/step)\n",
      "step 1597 - loss = 2.921, (1.513 sec/step)\n",
      "step 1598 - loss = 1.883, (1.199 sec/step)\n",
      "step 1599 - loss = 1.566, (1.276 sec/step)\n",
      "step 1600 - loss = 2.510, (3.508 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1601 - loss = 2.233, (1.359 sec/step)\n",
      "step 1602 - loss = 2.388, (1.932 sec/step)\n",
      "step 1603 - loss = 1.823, (1.633 sec/step)\n",
      "step 1604 - loss = 1.814, (1.751 sec/step)\n",
      "step 1605 - loss = 2.128, (1.753 sec/step)\n",
      "step 1606 - loss = 1.972, (2.267 sec/step)\n",
      "step 1607 - loss = 2.457, (2.331 sec/step)\n",
      "step 1608 - loss = 1.557, (2.066 sec/step)\n",
      "step 1609 - loss = 1.652, (1.529 sec/step)\n",
      "step 1610 - loss = 1.437, (1.305 sec/step)\n",
      "step 1611 - loss = 1.913, (1.713 sec/step)\n",
      "step 1612 - loss = 1.953, (1.264 sec/step)\n",
      "step 1613 - loss = 1.862, (2.217 sec/step)\n",
      "step 1614 - loss = 1.730, (1.471 sec/step)\n",
      "step 1615 - loss = 1.988, (1.578 sec/step)\n",
      "step 1616 - loss = 2.545, (1.147 sec/step)\n",
      "step 1617 - loss = 2.217, (1.469 sec/step)\n",
      "step 1618 - loss = 2.139, (1.620 sec/step)\n",
      "step 1619 - loss = 1.769, (1.653 sec/step)\n",
      "step 1620 - loss = 2.317, (1.678 sec/step)\n",
      "step 1621 - loss = 2.378, (1.970 sec/step)\n",
      "step 1622 - loss = 2.310, (1.607 sec/step)\n",
      "step 1623 - loss = 1.804, (1.391 sec/step)\n",
      "step 1624 - loss = 1.941, (1.213 sec/step)\n",
      "step 1625 - loss = 1.590, (3.058 sec/step)\n",
      "step 1626 - loss = 1.747, (1.305 sec/step)\n",
      "step 1627 - loss = 2.279, (1.572 sec/step)\n",
      "step 1628 - loss = 2.367, (1.270 sec/step)\n",
      "step 1629 - loss = 2.082, (2.008 sec/step)\n",
      "step 1630 - loss = 1.981, (2.014 sec/step)\n",
      "step 1631 - loss = 1.890, (0.971 sec/step)\n",
      "step 1632 - loss = 2.438, (3.075 sec/step)\n",
      "step 1633 - loss = 1.802, (1.306 sec/step)\n",
      "step 1634 - loss = 1.588, (1.590 sec/step)\n",
      "step 1635 - loss = 1.343, (1.534 sec/step)\n",
      "step 1636 - loss = 2.296, (1.481 sec/step)\n",
      "step 1637 - loss = 2.248, (1.637 sec/step)\n",
      "step 1638 - loss = 1.834, (1.696 sec/step)\n",
      "step 1639 - loss = 1.852, (2.153 sec/step)\n",
      "step 1640 - loss = 1.898, (1.973 sec/step)\n",
      "step 1641 - loss = 1.821, (1.896 sec/step)\n",
      "step 1642 - loss = 1.643, (2.749 sec/step)\n",
      "step 1643 - loss = 2.194, (1.212 sec/step)\n",
      "step 1644 - loss = 2.093, (1.596 sec/step)\n",
      "step 1645 - loss = 1.668, (1.659 sec/step)\n",
      "step 1646 - loss = 2.240, (1.968 sec/step)\n",
      "step 1647 - loss = 2.159, (1.295 sec/step)\n",
      "step 1648 - loss = 2.290, (1.271 sec/step)\n",
      "step 1649 - loss = 2.066, (1.246 sec/step)\n",
      "step 1650 - loss = 2.313, (1.216 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1651 - loss = 1.572, (2.295 sec/step)\n",
      "step 1652 - loss = 1.882, (1.315 sec/step)\n",
      "step 1653 - loss = 1.644, (1.242 sec/step)\n",
      "step 1654 - loss = 2.010, (2.611 sec/step)\n",
      "step 1655 - loss = 1.499, (2.435 sec/step)\n",
      "step 1656 - loss = 2.201, (2.514 sec/step)\n",
      "step 1657 - loss = 1.996, (1.785 sec/step)\n",
      "step 1658 - loss = 2.134, (1.676 sec/step)\n",
      "step 1659 - loss = 1.671, (1.357 sec/step)\n",
      "step 1660 - loss = 1.681, (2.548 sec/step)\n",
      "step 1661 - loss = 2.124, (1.392 sec/step)\n",
      "step 1662 - loss = 1.820, (2.410 sec/step)\n",
      "step 1663 - loss = 1.894, (2.816 sec/step)\n",
      "step 1664 - loss = 2.113, (2.829 sec/step)\n",
      "step 1665 - loss = 2.286, (3.190 sec/step)\n",
      "step 1666 - loss = 2.369, (1.931 sec/step)\n",
      "step 1667 - loss = 1.852, (1.230 sec/step)\n",
      "step 1668 - loss = 2.070, (1.794 sec/step)\n",
      "step 1669 - loss = 1.650, (1.274 sec/step)\n",
      "step 1670 - loss = 1.726, (1.200 sec/step)\n",
      "step 1671 - loss = 1.955, (1.468 sec/step)\n",
      "step 1672 - loss = 2.046, (2.486 sec/step)\n",
      "step 1673 - loss = 2.794, (3.005 sec/step)\n",
      "step 1674 - loss = 1.452, (3.177 sec/step)\n",
      "step 1675 - loss = 2.087, (2.591 sec/step)\n",
      "step 1676 - loss = 1.357, (1.950 sec/step)\n",
      "step 1677 - loss = 1.967, (1.851 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1678 - loss = 2.039, (2.484 sec/step)\n",
      "step 1679 - loss = 1.949, (1.841 sec/step)\n",
      "step 1680 - loss = 2.132, (1.099 sec/step)\n",
      "step 1681 - loss = 2.177, (1.905 sec/step)\n",
      "step 1682 - loss = 1.898, (1.640 sec/step)\n",
      "step 1683 - loss = 1.706, (1.869 sec/step)\n",
      "step 1684 - loss = 1.808, (1.406 sec/step)\n",
      "step 1685 - loss = 2.137, (1.249 sec/step)\n",
      "step 1686 - loss = 2.004, (2.786 sec/step)\n",
      "step 1687 - loss = 1.555, (2.119 sec/step)\n",
      "step 1688 - loss = 2.431, (1.576 sec/step)\n",
      "step 1689 - loss = 2.041, (1.457 sec/step)\n",
      "step 1690 - loss = 1.420, (1.214 sec/step)\n",
      "step 1691 - loss = 2.171, (1.519 sec/step)\n",
      "step 1692 - loss = 1.915, (2.173 sec/step)\n",
      "step 1693 - loss = 1.552, (2.580 sec/step)\n",
      "step 1694 - loss = 1.599, (1.579 sec/step)\n",
      "step 1695 - loss = 1.759, (1.367 sec/step)\n",
      "step 1696 - loss = 1.934, (1.733 sec/step)\n",
      "step 1697 - loss = 2.317, (2.252 sec/step)\n",
      "step 1698 - loss = 2.022, (1.574 sec/step)\n",
      "step 1699 - loss = 1.599, (1.737 sec/step)\n",
      "step 1700 - loss = 1.860, (2.907 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1701 - loss = 1.866, (2.460 sec/step)\n",
      "step 1702 - loss = 2.129, (2.892 sec/step)\n",
      "step 1703 - loss = 1.874, (1.904 sec/step)\n",
      "step 1704 - loss = 1.676, (1.398 sec/step)\n",
      "step 1705 - loss = 1.462, (1.601 sec/step)\n",
      "step 1706 - loss = 1.936, (1.554 sec/step)\n",
      "step 1707 - loss = 1.383, (1.065 sec/step)\n",
      "step 1708 - loss = 2.379, (2.485 sec/step)\n",
      "step 1709 - loss = 2.709, (2.480 sec/step)\n",
      "step 1710 - loss = 1.596, (1.403 sec/step)\n",
      "step 1711 - loss = 1.587, (1.417 sec/step)\n",
      "step 1712 - loss = 2.027, (1.411 sec/step)\n",
      "step 1713 - loss = 1.776, (1.785 sec/step)\n",
      "step 1714 - loss = 2.090, (3.391 sec/step)\n",
      "step 1715 - loss = 2.007, (2.740 sec/step)\n",
      "step 1716 - loss = 1.798, (1.342 sec/step)\n",
      "step 1717 - loss = 1.503, (1.351 sec/step)\n",
      "step 1718 - loss = 1.966, (1.143 sec/step)\n",
      "step 1719 - loss = 2.364, (2.156 sec/step)\n",
      "step 1720 - loss = 2.513, (1.558 sec/step)\n",
      "step 1721 - loss = 1.974, (1.859 sec/step)\n",
      "step 1722 - loss = 1.692, (3.084 sec/step)\n",
      "step 1723 - loss = 2.421, (3.449 sec/step)\n",
      "step 1724 - loss = 2.211, (1.359 sec/step)\n",
      "step 1725 - loss = 1.770, (1.168 sec/step)\n",
      "step 1726 - loss = 1.264, (1.672 sec/step)\n",
      "step 1727 - loss = 1.755, (2.255 sec/step)\n",
      "step 1728 - loss = 2.208, (1.773 sec/step)\n",
      "step 1729 - loss = 1.647, (1.162 sec/step)\n",
      "step 1730 - loss = 1.562, (1.176 sec/step)\n",
      "step 1731 - loss = 1.418, (1.423 sec/step)\n",
      "step 1732 - loss = 2.579, (1.728 sec/step)\n",
      "step 1733 - loss = 1.720, (2.197 sec/step)\n",
      "step 1734 - loss = 1.699, (1.393 sec/step)\n",
      "step 1735 - loss = 1.602, (2.023 sec/step)\n",
      "step 1736 - loss = 2.047, (2.770 sec/step)\n",
      "step 1737 - loss = 1.906, (1.563 sec/step)\n",
      "step 1738 - loss = 1.650, (1.256 sec/step)\n",
      "step 1739 - loss = 1.981, (2.473 sec/step)\n",
      "step 1740 - loss = 1.686, (3.013 sec/step)\n",
      "step 1741 - loss = 1.774, (1.703 sec/step)\n",
      "step 1742 - loss = 2.199, (1.035 sec/step)\n",
      "step 1743 - loss = 1.475, (2.936 sec/step)\n",
      "step 1744 - loss = 2.160, (2.772 sec/step)\n",
      "step 1745 - loss = 2.150, (1.088 sec/step)\n",
      "step 1746 - loss = 1.420, (3.013 sec/step)\n",
      "step 1747 - loss = 2.205, (2.053 sec/step)\n",
      "step 1748 - loss = 2.683, (1.438 sec/step)\n",
      "step 1749 - loss = 2.175, (1.307 sec/step)\n",
      "step 1750 - loss = 1.916, (1.367 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1751 - loss = 2.280, (2.483 sec/step)\n",
      "step 1752 - loss = 1.004, (2.852 sec/step)\n",
      "step 1753 - loss = 2.384, (1.382 sec/step)\n",
      "step 1754 - loss = 1.822, (1.280 sec/step)\n",
      "step 1755 - loss = 1.966, (1.205 sec/step)\n",
      "step 1756 - loss = 1.768, (1.769 sec/step)\n",
      "step 1757 - loss = 2.532, (1.799 sec/step)\n",
      "step 1758 - loss = 1.872, (2.206 sec/step)\n",
      "step 1759 - loss = 1.736, (1.346 sec/step)\n",
      "step 1760 - loss = 1.598, (1.445 sec/step)\n",
      "step 1761 - loss = 2.176, (2.415 sec/step)\n",
      "step 1762 - loss = 1.368, (1.753 sec/step)\n",
      "step 1763 - loss = 2.097, (1.209 sec/step)\n",
      "step 1764 - loss = 1.982, (1.085 sec/step)\n",
      "step 1765 - loss = 1.792, (1.149 sec/step)\n",
      "step 1766 - loss = 1.876, (1.394 sec/step)\n",
      "step 1767 - loss = 1.841, (1.581 sec/step)\n",
      "step 1768 - loss = 2.509, (2.114 sec/step)\n",
      "step 1769 - loss = 1.733, (0.951 sec/step)\n",
      "step 1770 - loss = 2.149, (2.122 sec/step)\n",
      "step 1771 - loss = 1.614, (1.496 sec/step)\n",
      "step 1772 - loss = 1.896, (1.308 sec/step)\n",
      "step 1773 - loss = 1.461, (1.711 sec/step)\n",
      "step 1774 - loss = 1.570, (1.518 sec/step)\n",
      "step 1775 - loss = 1.664, (2.275 sec/step)\n",
      "step 1776 - loss = 2.311, (1.052 sec/step)\n",
      "step 1777 - loss = 1.625, (1.527 sec/step)\n",
      "step 1778 - loss = 1.951, (1.678 sec/step)\n",
      "step 1779 - loss = 2.517, (1.608 sec/step)\n",
      "step 1780 - loss = 1.862, (1.946 sec/step)\n",
      "step 1781 - loss = 1.730, (1.200 sec/step)\n",
      "step 1782 - loss = 1.938, (2.887 sec/step)\n",
      "step 1783 - loss = 1.964, (1.179 sec/step)\n",
      "step 1784 - loss = 2.210, (1.151 sec/step)\n",
      "step 1785 - loss = 2.113, (1.046 sec/step)\n",
      "step 1786 - loss = 1.340, (1.852 sec/step)\n",
      "step 1787 - loss = 1.830, (1.722 sec/step)\n",
      "step 1788 - loss = 1.540, (1.703 sec/step)\n",
      "step 1789 - loss = 1.888, (1.460 sec/step)\n",
      "step 1790 - loss = 1.779, (1.296 sec/step)\n",
      "step 1791 - loss = 1.529, (1.129 sec/step)\n",
      "step 1792 - loss = 2.013, (1.427 sec/step)\n",
      "step 1793 - loss = 1.774, (1.610 sec/step)\n",
      "step 1794 - loss = 2.768, (2.587 sec/step)\n",
      "step 1795 - loss = 2.130, (1.462 sec/step)\n",
      "step 1796 - loss = 1.746, (1.381 sec/step)\n",
      "step 1797 - loss = 1.578, (1.128 sec/step)\n",
      "step 1798 - loss = 2.090, (2.827 sec/step)\n",
      "step 1799 - loss = 2.186, (1.308 sec/step)\n",
      "step 1800 - loss = 1.968, (1.307 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1801 - loss = 1.824, (1.853 sec/step)\n",
      "step 1802 - loss = 2.385, (2.485 sec/step)\n",
      "step 1803 - loss = 2.635, (2.319 sec/step)\n",
      "step 1804 - loss = 2.319, (2.686 sec/step)\n",
      "step 1805 - loss = 1.951, (1.228 sec/step)\n",
      "step 1806 - loss = 1.897, (2.866 sec/step)\n",
      "step 1807 - loss = 1.674, (1.019 sec/step)\n",
      "step 1808 - loss = 2.030, (1.995 sec/step)\n",
      "step 1809 - loss = 1.726, (2.653 sec/step)\n",
      "step 1810 - loss = 2.266, (1.293 sec/step)\n",
      "step 1811 - loss = 2.593, (1.817 sec/step)\n",
      "step 1812 - loss = 2.135, (1.828 sec/step)\n",
      "step 1813 - loss = 2.106, (1.693 sec/step)\n",
      "step 1814 - loss = 2.190, (3.004 sec/step)\n",
      "step 1815 - loss = 1.836, (1.202 sec/step)\n",
      "step 1816 - loss = 1.981, (1.214 sec/step)\n",
      "step 1817 - loss = 1.269, (1.191 sec/step)\n",
      "step 1818 - loss = 2.247, (0.955 sec/step)\n",
      "step 1819 - loss = 1.223, (1.382 sec/step)\n",
      "step 1820 - loss = 2.268, (1.755 sec/step)\n",
      "step 1821 - loss = 1.000, (1.697 sec/step)\n",
      "step 1822 - loss = 1.882, (1.790 sec/step)\n",
      "step 1823 - loss = 2.306, (1.439 sec/step)\n",
      "step 1824 - loss = 2.217, (3.687 sec/step)\n",
      "step 1825 - loss = 2.290, (1.941 sec/step)\n",
      "step 1826 - loss = 1.758, (1.229 sec/step)\n",
      "step 1827 - loss = 1.890, (1.732 sec/step)\n",
      "step 1828 - loss = 2.493, (2.486 sec/step)\n",
      "step 1829 - loss = 1.791, (1.061 sec/step)\n",
      "step 1830 - loss = 1.636, (1.212 sec/step)\n",
      "step 1831 - loss = 1.892, (1.838 sec/step)\n",
      "step 1832 - loss = 2.328, (1.175 sec/step)\n",
      "step 1833 - loss = 1.906, (2.116 sec/step)\n",
      "step 1834 - loss = 2.462, (1.928 sec/step)\n",
      "step 1835 - loss = 1.870, (1.069 sec/step)\n",
      "step 1836 - loss = 1.229, (1.337 sec/step)\n",
      "step 1837 - loss = 1.441, (2.483 sec/step)\n",
      "step 1838 - loss = 1.795, (1.118 sec/step)\n",
      "step 1839 - loss = 2.293, (1.624 sec/step)\n",
      "step 1840 - loss = 1.943, (1.419 sec/step)\n",
      "step 1841 - loss = 1.593, (1.268 sec/step)\n",
      "step 1842 - loss = 2.628, (2.224 sec/step)\n",
      "step 1843 - loss = 2.312, (2.512 sec/step)\n",
      "step 1844 - loss = 2.451, (1.844 sec/step)\n",
      "step 1845 - loss = 2.140, (1.791 sec/step)\n",
      "step 1846 - loss = 2.065, (1.945 sec/step)\n",
      "step 1847 - loss = 2.315, (2.153 sec/step)\n",
      "step 1848 - loss = 0.955, (2.223 sec/step)\n",
      "step 1849 - loss = 1.910, (2.938 sec/step)\n",
      "step 1850 - loss = 1.933, (2.761 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1851 - loss = 2.089, (2.853 sec/step)\n",
      "step 1852 - loss = 2.504, (1.241 sec/step)\n",
      "step 1853 - loss = 1.388, (1.243 sec/step)\n",
      "step 1854 - loss = 1.940, (2.474 sec/step)\n",
      "step 1855 - loss = 2.178, (1.961 sec/step)\n",
      "step 1856 - loss = 2.545, (1.462 sec/step)\n",
      "step 1857 - loss = 1.411, (2.089 sec/step)\n",
      "step 1858 - loss = 2.128, (3.502 sec/step)\n",
      "step 1859 - loss = 1.506, (1.592 sec/step)\n",
      "step 1860 - loss = 2.639, (2.146 sec/step)\n",
      "step 1861 - loss = 2.522, (1.291 sec/step)\n",
      "step 1862 - loss = 2.071, (1.614 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1863 - loss = 1.692, (1.443 sec/step)\n",
      "step 1864 - loss = 1.345, (2.372 sec/step)\n",
      "step 1865 - loss = 1.506, (1.424 sec/step)\n",
      "step 1866 - loss = 1.394, (1.292 sec/step)\n",
      "step 1867 - loss = 2.116, (1.582 sec/step)\n",
      "step 1868 - loss = 2.370, (1.693 sec/step)\n",
      "step 1869 - loss = 2.164, (1.476 sec/step)\n",
      "step 1870 - loss = 1.529, (2.031 sec/step)\n",
      "step 1871 - loss = 2.120, (2.042 sec/step)\n",
      "step 1872 - loss = 1.714, (2.063 sec/step)\n",
      "step 1873 - loss = 1.605, (2.383 sec/step)\n",
      "step 1874 - loss = 1.701, (1.534 sec/step)\n",
      "step 1875 - loss = 1.959, (2.810 sec/step)\n",
      "step 1876 - loss = 1.660, (1.887 sec/step)\n",
      "step 1877 - loss = 2.365, (2.403 sec/step)\n",
      "step 1878 - loss = 2.104, (1.794 sec/step)\n",
      "step 1879 - loss = 2.107, (1.422 sec/step)\n",
      "step 1880 - loss = 2.157, (2.463 sec/step)\n",
      "step 1881 - loss = 2.352, (1.238 sec/step)\n",
      "step 1882 - loss = 1.992, (1.694 sec/step)\n",
      "step 1883 - loss = 2.164, (1.359 sec/step)\n",
      "step 1884 - loss = 1.715, (1.502 sec/step)\n",
      "step 1885 - loss = 1.396, (3.000 sec/step)\n",
      "step 1886 - loss = 2.048, (2.553 sec/step)\n",
      "step 1887 - loss = 1.449, (2.614 sec/step)\n",
      "step 1888 - loss = 1.968, (1.321 sec/step)\n",
      "step 1889 - loss = 2.098, (1.312 sec/step)\n",
      "step 1890 - loss = 2.466, (1.511 sec/step)\n",
      "step 1891 - loss = 2.216, (1.541 sec/step)\n",
      "step 1892 - loss = 1.123, (1.557 sec/step)\n",
      "step 1893 - loss = 2.380, (1.858 sec/step)\n",
      "step 1894 - loss = 2.233, (1.974 sec/step)\n",
      "step 1895 - loss = 2.000, (2.583 sec/step)\n",
      "step 1896 - loss = 1.785, (1.891 sec/step)\n",
      "step 1897 - loss = 1.122, (2.482 sec/step)\n",
      "step 1898 - loss = 1.450, (3.022 sec/step)\n",
      "step 1899 - loss = 1.971, (1.855 sec/step)\n",
      "step 1900 - loss = 2.338, (1.150 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1901 - loss = 2.270, (1.506 sec/step)\n",
      "step 1902 - loss = 2.156, (1.484 sec/step)\n",
      "step 1903 - loss = 1.747, (2.309 sec/step)\n",
      "step 1904 - loss = 1.911, (1.803 sec/step)\n",
      "step 1905 - loss = 1.617, (1.440 sec/step)\n",
      "step 1906 - loss = 2.311, (1.283 sec/step)\n",
      "step 1907 - loss = 1.586, (1.545 sec/step)\n",
      "step 1908 - loss = 1.857, (1.334 sec/step)\n",
      "step 1909 - loss = 2.242, (1.364 sec/step)\n",
      "step 1910 - loss = 2.381, (3.022 sec/step)\n",
      "step 1911 - loss = 1.931, (3.285 sec/step)\n",
      "step 1912 - loss = 1.670, (1.115 sec/step)\n",
      "step 1913 - loss = 2.310, (1.560 sec/step)\n",
      "step 1914 - loss = 1.897, (2.144 sec/step)\n",
      "step 1915 - loss = 1.862, (2.060 sec/step)\n",
      "step 1916 - loss = 2.075, (2.130 sec/step)\n",
      "step 1917 - loss = 1.575, (2.485 sec/step)\n",
      "step 1918 - loss = 1.691, (1.839 sec/step)\n",
      "step 1919 - loss = 1.590, (2.225 sec/step)\n",
      "step 1920 - loss = 1.760, (1.581 sec/step)\n",
      "step 1921 - loss = 2.025, (1.208 sec/step)\n",
      "step 1922 - loss = 1.691, (2.785 sec/step)\n",
      "step 1923 - loss = 1.533, (1.503 sec/step)\n",
      "step 1924 - loss = 2.221, (2.986 sec/step)\n",
      "step 1925 - loss = 2.499, (1.627 sec/step)\n",
      "step 1926 - loss = 1.399, (2.935 sec/step)\n",
      "step 1927 - loss = 2.510, (2.486 sec/step)\n",
      "step 1928 - loss = 1.744, (2.693 sec/step)\n",
      "step 1929 - loss = 2.151, (1.441 sec/step)\n",
      "step 1930 - loss = 2.069, (2.370 sec/step)\n",
      "step 1931 - loss = 2.146, (1.029 sec/step)\n",
      "step 1932 - loss = 1.799, (1.313 sec/step)\n",
      "step 1933 - loss = 1.968, (1.708 sec/step)\n",
      "step 1934 - loss = 1.553, (1.715 sec/step)\n",
      "step 1935 - loss = 2.123, (1.017 sec/step)\n",
      "step 1936 - loss = 1.647, (1.019 sec/step)\n",
      "step 1937 - loss = 2.519, (2.563 sec/step)\n",
      "step 1938 - loss = 1.199, (1.915 sec/step)\n",
      "step 1939 - loss = 2.407, (1.286 sec/step)\n",
      "step 1940 - loss = 1.796, (0.867 sec/step)\n",
      "step 1941 - loss = 1.590, (1.654 sec/step)\n",
      "step 1942 - loss = 2.017, (1.209 sec/step)\n",
      "step 1943 - loss = 2.248, (1.439 sec/step)\n",
      "step 1944 - loss = 1.552, (1.054 sec/step)\n",
      "step 1945 - loss = 1.946, (1.391 sec/step)\n",
      "step 1946 - loss = 2.468, (2.484 sec/step)\n",
      "step 1947 - loss = 2.453, (2.455 sec/step)\n",
      "step 1948 - loss = 1.750, (1.027 sec/step)\n",
      "step 1949 - loss = 2.062, (1.151 sec/step)\n",
      "step 1950 - loss = 2.107, (1.249 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 1951 - loss = 2.328, (1.225 sec/step)\n",
      "step 1952 - loss = 1.564, (1.889 sec/step)\n",
      "step 1953 - loss = 1.985, (1.424 sec/step)\n",
      "step 1954 - loss = 1.404, (0.999 sec/step)\n",
      "step 1955 - loss = 2.635, (1.392 sec/step)\n",
      "step 1956 - loss = 1.618, (1.424 sec/step)\n",
      "step 1957 - loss = 1.686, (1.457 sec/step)\n",
      "step 1958 - loss = 1.864, (2.156 sec/step)\n",
      "step 1959 - loss = 2.120, (1.374 sec/step)\n",
      "step 1960 - loss = 1.913, (1.179 sec/step)\n",
      "step 1961 - loss = 1.696, (1.827 sec/step)\n",
      "step 1962 - loss = 1.805, (1.876 sec/step)\n",
      "step 1963 - loss = 2.456, (2.246 sec/step)\n",
      "step 1964 - loss = 2.558, (1.395 sec/step)\n",
      "step 1965 - loss = 1.622, (1.506 sec/step)\n",
      "step 1966 - loss = 1.954, (1.562 sec/step)\n",
      "step 1967 - loss = 2.068, (1.955 sec/step)\n",
      "step 1968 - loss = 2.084, (1.382 sec/step)\n",
      "step 1969 - loss = 1.863, (1.526 sec/step)\n",
      "step 1970 - loss = 2.426, (1.662 sec/step)\n",
      "step 1971 - loss = 1.438, (1.518 sec/step)\n",
      "step 1972 - loss = 2.026, (1.249 sec/step)\n",
      "step 1973 - loss = 1.945, (1.531 sec/step)\n",
      "step 1974 - loss = 1.772, (1.315 sec/step)\n",
      "step 1975 - loss = 1.586, (1.460 sec/step)\n",
      "step 1976 - loss = 1.714, (1.921 sec/step)\n",
      "step 1977 - loss = 1.694, (1.745 sec/step)\n",
      "step 1978 - loss = 2.098, (2.068 sec/step)\n",
      "step 1979 - loss = 2.284, (1.686 sec/step)\n",
      "step 1980 - loss = 1.876, (1.283 sec/step)\n",
      "step 1981 - loss = 1.687, (3.038 sec/step)\n",
      "step 1982 - loss = 1.578, (2.866 sec/step)\n",
      "step 1983 - loss = 2.242, (1.649 sec/step)\n",
      "step 1984 - loss = 1.747, (1.331 sec/step)\n",
      "step 1985 - loss = 1.698, (2.115 sec/step)\n",
      "step 1986 - loss = 1.298, (1.935 sec/step)\n",
      "step 1987 - loss = 2.472, (2.662 sec/step)\n",
      "step 1988 - loss = 1.755, (2.199 sec/step)\n",
      "step 1989 - loss = 2.358, (1.733 sec/step)\n",
      "step 1990 - loss = 1.583, (1.776 sec/step)\n",
      "step 1991 - loss = 1.971, (2.485 sec/step)\n",
      "step 1992 - loss = 1.867, (2.698 sec/step)\n",
      "step 1993 - loss = 1.471, (1.272 sec/step)\n",
      "step 1994 - loss = 1.941, (1.459 sec/step)\n",
      "step 1995 - loss = 2.380, (3.018 sec/step)\n",
      "step 1996 - loss = 1.936, (1.865 sec/step)\n",
      "step 1997 - loss = 2.029, (2.942 sec/step)\n",
      "step 1998 - loss = 1.688, (2.395 sec/step)\n",
      "step 1999 - loss = 1.758, (1.260 sec/step)\n",
      "step 2000 - loss = 2.025, (1.347 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2001 - loss = 2.130, (2.486 sec/step)\n",
      "step 2002 - loss = 1.554, (2.864 sec/step)\n",
      "step 2003 - loss = 2.002, (1.132 sec/step)\n",
      "step 2004 - loss = 2.108, (0.967 sec/step)\n",
      "step 2005 - loss = 1.690, (1.772 sec/step)\n",
      "step 2006 - loss = 1.724, (1.655 sec/step)\n",
      "step 2007 - loss = 2.037, (1.274 sec/step)\n",
      "step 2008 - loss = 2.114, (1.855 sec/step)\n",
      "step 2009 - loss = 1.991, (1.355 sec/step)\n",
      "step 2010 - loss = 1.784, (1.295 sec/step)\n",
      "step 2011 - loss = 1.776, (1.489 sec/step)\n",
      "step 2012 - loss = 1.709, (2.866 sec/step)\n",
      "step 2013 - loss = 1.865, (2.826 sec/step)\n",
      "step 2014 - loss = 2.427, (2.984 sec/step)\n",
      "step 2015 - loss = 1.592, (1.867 sec/step)\n",
      "step 2016 - loss = 2.053, (1.646 sec/step)\n",
      "step 2017 - loss = 2.011, (1.760 sec/step)\n",
      "step 2018 - loss = 1.801, (1.095 sec/step)\n",
      "step 2019 - loss = 1.581, (1.015 sec/step)\n",
      "step 2020 - loss = 1.792, (1.992 sec/step)\n",
      "step 2021 - loss = 2.510, (2.781 sec/step)\n",
      "step 2022 - loss = 1.799, (1.105 sec/step)\n",
      "step 2023 - loss = 1.955, (2.027 sec/step)\n",
      "step 2024 - loss = 1.636, (2.678 sec/step)\n",
      "step 2025 - loss = 2.174, (1.246 sec/step)\n",
      "step 2026 - loss = 1.942, (2.931 sec/step)\n",
      "step 2027 - loss = 1.920, (1.374 sec/step)\n",
      "step 2028 - loss = 1.777, (2.781 sec/step)\n",
      "step 2029 - loss = 1.712, (1.423 sec/step)\n",
      "step 2030 - loss = 1.378, (1.508 sec/step)\n",
      "step 2031 - loss = 1.647, (1.344 sec/step)\n",
      "step 2032 - loss = 1.997, (1.436 sec/step)\n",
      "step 2033 - loss = 1.487, (2.685 sec/step)\n",
      "step 2034 - loss = 1.688, (1.410 sec/step)\n",
      "step 2035 - loss = 1.531, (1.333 sec/step)\n",
      "step 2036 - loss = 1.472, (1.454 sec/step)\n",
      "step 2037 - loss = 2.134, (1.279 sec/step)\n",
      "step 2038 - loss = 2.071, (2.408 sec/step)\n",
      "step 2039 - loss = 2.181, (3.235 sec/step)\n",
      "step 2040 - loss = 1.586, (1.157 sec/step)\n",
      "step 2041 - loss = 2.335, (1.755 sec/step)\n",
      "step 2042 - loss = 2.378, (3.604 sec/step)\n",
      "step 2043 - loss = 2.167, (1.470 sec/step)\n",
      "step 2044 - loss = 1.420, (1.218 sec/step)\n",
      "step 2045 - loss = 1.953, (2.022 sec/step)\n",
      "step 2046 - loss = 2.112, (2.077 sec/step)\n",
      "step 2047 - loss = 1.757, (1.259 sec/step)\n",
      "step 2048 - loss = 2.307, (2.237 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2049 - loss = 1.437, (1.476 sec/step)\n",
      "step 2050 - loss = 2.449, (1.695 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2051 - loss = 2.147, (1.247 sec/step)\n",
      "step 2052 - loss = 1.767, (2.478 sec/step)\n",
      "step 2053 - loss = 2.863, (1.852 sec/step)\n",
      "step 2054 - loss = 1.476, (1.067 sec/step)\n",
      "step 2055 - loss = 2.221, (1.493 sec/step)\n",
      "step 2056 - loss = 2.668, (1.246 sec/step)\n",
      "step 2057 - loss = 2.540, (2.482 sec/step)\n",
      "step 2058 - loss = 2.878, (1.160 sec/step)\n",
      "step 2059 - loss = 2.224, (1.921 sec/step)\n",
      "step 2060 - loss = 1.741, (1.894 sec/step)\n",
      "step 2061 - loss = 2.556, (2.483 sec/step)\n",
      "step 2062 - loss = 0.643, (2.659 sec/step)\n",
      "step 2063 - loss = 2.027, (2.501 sec/step)\n",
      "step 2064 - loss = 1.519, (2.067 sec/step)\n",
      "step 2065 - loss = 2.161, (1.258 sec/step)\n",
      "step 2066 - loss = 2.230, (1.971 sec/step)\n",
      "step 2067 - loss = 1.902, (1.227 sec/step)\n",
      "step 2068 - loss = 3.197, (1.387 sec/step)\n",
      "step 2069 - loss = 2.014, (0.856 sec/step)\n",
      "step 2070 - loss = 1.832, (1.701 sec/step)\n",
      "step 2071 - loss = 2.020, (1.932 sec/step)\n",
      "step 2072 - loss = 2.060, (1.569 sec/step)\n",
      "step 2073 - loss = 2.039, (2.484 sec/step)\n",
      "step 2074 - loss = 1.888, (2.409 sec/step)\n",
      "step 2075 - loss = 2.186, (2.525 sec/step)\n",
      "step 2076 - loss = 1.727, (2.196 sec/step)\n",
      "step 2077 - loss = 1.913, (1.541 sec/step)\n",
      "step 2078 - loss = 1.831, (3.073 sec/step)\n",
      "step 2079 - loss = 2.244, (1.493 sec/step)\n",
      "step 2080 - loss = 1.957, (1.783 sec/step)\n",
      "step 2081 - loss = 1.665, (2.094 sec/step)\n",
      "step 2082 - loss = 1.664, (1.088 sec/step)\n",
      "step 2083 - loss = 2.397, (2.430 sec/step)\n",
      "step 2084 - loss = 2.324, (2.293 sec/step)\n",
      "step 2085 - loss = 2.298, (2.535 sec/step)\n",
      "step 2086 - loss = 1.275, (2.002 sec/step)\n",
      "step 2087 - loss = 1.841, (2.003 sec/step)\n",
      "step 2088 - loss = 2.592, (2.485 sec/step)\n",
      "step 2089 - loss = 2.068, (2.957 sec/step)\n",
      "step 2090 - loss = 1.396, (2.007 sec/step)\n",
      "step 2091 - loss = 1.952, (1.541 sec/step)\n",
      "step 2092 - loss = 2.348, (2.556 sec/step)\n",
      "step 2093 - loss = 1.828, (2.432 sec/step)\n",
      "step 2094 - loss = 2.123, (1.296 sec/step)\n",
      "step 2095 - loss = 2.437, (3.201 sec/step)\n",
      "step 2096 - loss = 2.426, (1.387 sec/step)\n",
      "step 2097 - loss = 1.817, (2.155 sec/step)\n",
      "step 2098 - loss = 2.090, (1.035 sec/step)\n",
      "step 2099 - loss = 2.203, (1.629 sec/step)\n",
      "step 2100 - loss = 1.991, (2.626 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2101 - loss = 1.913, (1.637 sec/step)\n",
      "step 2102 - loss = 2.207, (1.295 sec/step)\n",
      "step 2103 - loss = 1.885, (2.785 sec/step)\n",
      "step 2104 - loss = 1.997, (1.395 sec/step)\n",
      "step 2105 - loss = 2.154, (2.762 sec/step)\n",
      "step 2106 - loss = 2.296, (1.608 sec/step)\n",
      "step 2107 - loss = 2.077, (1.406 sec/step)\n",
      "step 2108 - loss = 1.782, (1.384 sec/step)\n",
      "step 2109 - loss = 2.274, (1.620 sec/step)\n",
      "step 2110 - loss = 2.022, (0.971 sec/step)\n",
      "step 2111 - loss = 1.771, (2.182 sec/step)\n",
      "step 2112 - loss = 2.247, (1.707 sec/step)\n",
      "step 2113 - loss = 2.086, (1.273 sec/step)\n",
      "step 2114 - loss = 2.406, (2.509 sec/step)\n",
      "step 2115 - loss = 2.043, (2.005 sec/step)\n",
      "step 2116 - loss = 1.709, (2.059 sec/step)\n",
      "step 2117 - loss = 2.419, (2.483 sec/step)\n",
      "step 2118 - loss = 2.032, (2.794 sec/step)\n",
      "step 2119 - loss = 1.434, (1.401 sec/step)\n",
      "step 2120 - loss = 1.607, (1.541 sec/step)\n",
      "step 2121 - loss = 1.944, (1.801 sec/step)\n",
      "step 2122 - loss = 2.339, (1.764 sec/step)\n",
      "step 2123 - loss = 1.901, (2.384 sec/step)\n",
      "step 2124 - loss = 2.018, (2.440 sec/step)\n",
      "step 2125 - loss = 1.674, (2.116 sec/step)\n",
      "step 2126 - loss = 2.239, (1.549 sec/step)\n",
      "step 2127 - loss = 1.990, (1.358 sec/step)\n",
      "step 2128 - loss = 2.179, (1.363 sec/step)\n",
      "step 2129 - loss = 1.836, (2.094 sec/step)\n",
      "step 2130 - loss = 2.671, (1.653 sec/step)\n",
      "step 2131 - loss = 2.174, (1.287 sec/step)\n",
      "step 2132 - loss = 2.041, (2.235 sec/step)\n",
      "step 2133 - loss = 2.460, (1.299 sec/step)\n",
      "step 2134 - loss = 2.104, (1.455 sec/step)\n",
      "step 2135 - loss = 1.640, (1.730 sec/step)\n",
      "step 2136 - loss = 1.941, (1.050 sec/step)\n",
      "step 2137 - loss = 1.756, (1.126 sec/step)\n",
      "step 2138 - loss = 2.234, (1.635 sec/step)\n",
      "step 2139 - loss = 2.133, (1.665 sec/step)\n",
      "step 2140 - loss = 1.561, (1.006 sec/step)\n",
      "step 2141 - loss = 1.873, (1.282 sec/step)\n",
      "step 2142 - loss = 1.970, (1.792 sec/step)\n",
      "step 2143 - loss = 2.146, (3.159 sec/step)\n",
      "step 2144 - loss = 1.592, (1.189 sec/step)\n",
      "step 2145 - loss = 1.790, (1.769 sec/step)\n",
      "step 2146 - loss = 2.159, (2.618 sec/step)\n",
      "step 2147 - loss = 1.930, (1.165 sec/step)\n",
      "step 2148 - loss = 1.271, (2.615 sec/step)\n",
      "step 2149 - loss = 2.208, (1.410 sec/step)\n",
      "step 2150 - loss = 2.038, (1.601 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2151 - loss = 2.000, (1.446 sec/step)\n",
      "step 2152 - loss = 2.488, (1.544 sec/step)\n",
      "step 2153 - loss = 2.125, (1.272 sec/step)\n",
      "step 2154 - loss = 1.479, (1.338 sec/step)\n",
      "step 2155 - loss = 2.015, (1.068 sec/step)\n",
      "step 2156 - loss = 1.658, (1.729 sec/step)\n",
      "step 2157 - loss = 1.833, (1.089 sec/step)\n",
      "step 2158 - loss = 1.398, (1.253 sec/step)\n",
      "step 2159 - loss = 2.333, (2.359 sec/step)\n",
      "step 2160 - loss = 2.198, (1.451 sec/step)\n",
      "step 2161 - loss = 2.069, (1.929 sec/step)\n",
      "step 2162 - loss = 2.384, (1.255 sec/step)\n",
      "step 2163 - loss = 1.825, (1.336 sec/step)\n",
      "step 2164 - loss = 1.873, (1.202 sec/step)\n",
      "step 2165 - loss = 2.165, (1.275 sec/step)\n",
      "step 2166 - loss = 2.201, (1.330 sec/step)\n",
      "step 2167 - loss = 2.145, (1.556 sec/step)\n",
      "step 2168 - loss = 1.977, (1.420 sec/step)\n",
      "step 2169 - loss = 2.076, (2.483 sec/step)\n",
      "step 2170 - loss = 0.896, (1.716 sec/step)\n",
      "step 2171 - loss = 2.845, (1.069 sec/step)\n",
      "step 2172 - loss = 1.329, (1.953 sec/step)\n",
      "step 2173 - loss = 1.540, (1.251 sec/step)\n",
      "step 2174 - loss = 2.074, (0.789 sec/step)\n",
      "step 2175 - loss = 2.110, (0.864 sec/step)\n",
      "step 2176 - loss = 1.582, (1.462 sec/step)\n",
      "step 2177 - loss = 1.778, (2.723 sec/step)\n",
      "step 2178 - loss = 2.359, (2.488 sec/step)\n",
      "step 2179 - loss = 1.844, (1.423 sec/step)\n",
      "step 2180 - loss = 2.594, (2.791 sec/step)\n",
      "step 2181 - loss = 1.529, (1.927 sec/step)\n",
      "step 2182 - loss = 2.352, (2.485 sec/step)\n",
      "step 2183 - loss = 2.139, (1.722 sec/step)\n",
      "step 2184 - loss = 2.068, (2.026 sec/step)\n",
      "step 2185 - loss = 2.197, (1.111 sec/step)\n",
      "step 2186 - loss = 2.035, (1.878 sec/step)\n",
      "step 2187 - loss = 2.370, (1.482 sec/step)\n",
      "step 2188 - loss = 2.026, (1.272 sec/step)\n",
      "step 2189 - loss = 1.673, (1.821 sec/step)\n",
      "step 2190 - loss = 1.612, (2.295 sec/step)\n",
      "step 2191 - loss = 1.995, (1.776 sec/step)\n",
      "step 2192 - loss = 2.431, (2.099 sec/step)\n",
      "step 2193 - loss = 2.197, (1.319 sec/step)\n",
      "step 2194 - loss = 1.775, (1.307 sec/step)\n",
      "step 2195 - loss = 2.011, (1.668 sec/step)\n",
      "step 2196 - loss = 1.830, (1.533 sec/step)\n",
      "step 2197 - loss = 1.710, (2.089 sec/step)\n",
      "step 2198 - loss = 2.173, (1.203 sec/step)\n",
      "step 2199 - loss = 2.366, (1.887 sec/step)\n",
      "step 2200 - loss = 1.911, (1.197 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2201 - loss = 1.652, (2.488 sec/step)\n",
      "step 2202 - loss = 0.850, (3.452 sec/step)\n",
      "step 2203 - loss = 1.492, (0.969 sec/step)\n",
      "step 2204 - loss = 1.561, (2.312 sec/step)\n",
      "step 2205 - loss = 1.476, (2.978 sec/step)\n",
      "step 2206 - loss = 1.848, (1.384 sec/step)\n",
      "step 2207 - loss = 2.231, (2.486 sec/step)\n",
      "step 2208 - loss = 1.843, (1.240 sec/step)\n",
      "step 2209 - loss = 2.092, (1.745 sec/step)\n",
      "step 2210 - loss = 2.099, (1.214 sec/step)\n",
      "step 2211 - loss = 2.426, (1.516 sec/step)\n",
      "step 2212 - loss = 2.007, (1.702 sec/step)\n",
      "step 2213 - loss = 1.542, (0.940 sec/step)\n",
      "step 2214 - loss = 2.138, (1.206 sec/step)\n",
      "step 2215 - loss = 1.825, (2.866 sec/step)\n",
      "step 2216 - loss = 1.690, (2.003 sec/step)\n",
      "step 2217 - loss = 1.606, (2.485 sec/step)\n",
      "step 2218 - loss = 0.584, (1.921 sec/step)\n",
      "step 2219 - loss = 2.096, (2.491 sec/step)\n",
      "step 2220 - loss = 1.466, (1.201 sec/step)\n",
      "step 2221 - loss = 1.871, (2.047 sec/step)\n",
      "step 2222 - loss = 1.993, (1.592 sec/step)\n",
      "step 2223 - loss = 2.060, (2.134 sec/step)\n",
      "step 2224 - loss = 2.290, (2.449 sec/step)\n",
      "step 2225 - loss = 2.646, (1.641 sec/step)\n",
      "step 2226 - loss = 1.614, (1.181 sec/step)\n",
      "step 2227 - loss = 2.007, (1.001 sec/step)\n",
      "step 2228 - loss = 1.793, (1.766 sec/step)\n",
      "step 2229 - loss = 2.109, (1.319 sec/step)\n",
      "step 2230 - loss = 2.362, (1.853 sec/step)\n",
      "step 2231 - loss = 1.703, (1.367 sec/step)\n",
      "step 2232 - loss = 1.725, (1.100 sec/step)\n",
      "step 2233 - loss = 1.966, (0.938 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2234 - loss = 1.955, (1.291 sec/step)\n",
      "step 2235 - loss = 2.239, (2.536 sec/step)\n",
      "step 2236 - loss = 1.948, (2.181 sec/step)\n",
      "step 2237 - loss = 1.899, (2.625 sec/step)\n",
      "step 2238 - loss = 1.819, (3.077 sec/step)\n",
      "step 2239 - loss = 2.204, (1.277 sec/step)\n",
      "step 2240 - loss = 1.687, (2.484 sec/step)\n",
      "step 2241 - loss = 1.391, (1.201 sec/step)\n",
      "step 2242 - loss = 1.991, (2.905 sec/step)\n",
      "step 2243 - loss = 1.510, (1.311 sec/step)\n",
      "step 2244 - loss = 2.227, (1.283 sec/step)\n",
      "step 2245 - loss = 1.882, (1.358 sec/step)\n",
      "step 2246 - loss = 1.635, (0.962 sec/step)\n",
      "step 2247 - loss = 1.525, (1.503 sec/step)\n",
      "step 2248 - loss = 1.780, (1.494 sec/step)\n",
      "step 2249 - loss = 2.376, (2.039 sec/step)\n",
      "step 2250 - loss = 2.041, (2.699 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2251 - loss = 1.960, (1.636 sec/step)\n",
      "step 2252 - loss = 1.901, (1.667 sec/step)\n",
      "step 2253 - loss = 1.768, (1.588 sec/step)\n",
      "step 2254 - loss = 2.724, (2.485 sec/step)\n",
      "step 2255 - loss = 2.261, (2.808 sec/step)\n",
      "step 2256 - loss = 1.786, (1.780 sec/step)\n",
      "step 2257 - loss = 1.983, (1.117 sec/step)\n",
      "step 2258 - loss = 1.463, (1.258 sec/step)\n",
      "step 2259 - loss = 1.910, (1.825 sec/step)\n",
      "step 2260 - loss = 1.709, (2.946 sec/step)\n",
      "step 2261 - loss = 1.744, (1.458 sec/step)\n",
      "step 2262 - loss = 2.109, (1.392 sec/step)\n",
      "step 2263 - loss = 2.095, (1.607 sec/step)\n",
      "step 2264 - loss = 1.538, (2.263 sec/step)\n",
      "step 2265 - loss = 1.891, (1.844 sec/step)\n",
      "step 2266 - loss = 2.004, (1.713 sec/step)\n",
      "step 2267 - loss = 1.527, (0.990 sec/step)\n",
      "step 2268 - loss = 1.620, (1.346 sec/step)\n",
      "step 2269 - loss = 2.386, (2.411 sec/step)\n",
      "step 2270 - loss = 1.487, (2.320 sec/step)\n",
      "step 2271 - loss = 1.956, (3.235 sec/step)\n",
      "step 2272 - loss = 1.653, (1.380 sec/step)\n",
      "step 2273 - loss = 2.261, (1.823 sec/step)\n",
      "step 2274 - loss = 1.928, (0.939 sec/step)\n",
      "step 2275 - loss = 1.971, (1.000 sec/step)\n",
      "step 2276 - loss = 1.545, (1.762 sec/step)\n",
      "step 2277 - loss = 2.635, (1.780 sec/step)\n",
      "step 2278 - loss = 1.382, (1.260 sec/step)\n",
      "step 2279 - loss = 2.342, (1.599 sec/step)\n",
      "step 2280 - loss = 1.334, (2.781 sec/step)\n",
      "step 2281 - loss = 2.287, (1.066 sec/step)\n",
      "step 2282 - loss = 2.094, (2.864 sec/step)\n",
      "step 2283 - loss = 1.896, (1.467 sec/step)\n",
      "step 2284 - loss = 2.262, (1.290 sec/step)\n",
      "step 2285 - loss = 2.200, (1.532 sec/step)\n",
      "step 2286 - loss = 2.273, (1.713 sec/step)\n",
      "step 2287 - loss = 2.065, (1.065 sec/step)\n",
      "step 2288 - loss = 1.819, (1.256 sec/step)\n",
      "step 2289 - loss = 2.284, (1.957 sec/step)\n",
      "step 2290 - loss = 1.483, (2.719 sec/step)\n",
      "step 2291 - loss = 2.489, (1.490 sec/step)\n",
      "step 2292 - loss = 1.616, (1.866 sec/step)\n",
      "step 2293 - loss = 2.006, (1.148 sec/step)\n",
      "step 2294 - loss = 2.164, (2.702 sec/step)\n",
      "step 2295 - loss = 2.084, (2.077 sec/step)\n",
      "step 2296 - loss = 1.626, (2.795 sec/step)\n",
      "step 2297 - loss = 1.664, (0.891 sec/step)\n",
      "step 2298 - loss = 1.929, (2.484 sec/step)\n",
      "step 2299 - loss = 2.280, (2.282 sec/step)\n",
      "step 2300 - loss = 2.586, (1.212 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2301 - loss = 1.644, (1.227 sec/step)\n",
      "step 2302 - loss = 1.810, (1.859 sec/step)\n",
      "step 2303 - loss = 1.826, (2.425 sec/step)\n",
      "step 2304 - loss = 2.129, (1.536 sec/step)\n",
      "step 2305 - loss = 2.318, (2.040 sec/step)\n",
      "step 2306 - loss = 2.417, (1.248 sec/step)\n",
      "step 2307 - loss = 1.837, (1.305 sec/step)\n",
      "step 2308 - loss = 1.673, (2.023 sec/step)\n",
      "step 2309 - loss = 1.937, (1.364 sec/step)\n",
      "step 2310 - loss = 1.652, (1.496 sec/step)\n",
      "step 2311 - loss = 1.524, (2.593 sec/step)\n",
      "step 2312 - loss = 1.761, (1.327 sec/step)\n",
      "step 2313 - loss = 2.045, (1.402 sec/step)\n",
      "step 2314 - loss = 2.269, (2.447 sec/step)\n",
      "step 2315 - loss = 1.442, (1.284 sec/step)\n",
      "step 2316 - loss = 1.789, (1.316 sec/step)\n",
      "step 2317 - loss = 2.078, (2.544 sec/step)\n",
      "step 2318 - loss = 1.538, (1.214 sec/step)\n",
      "step 2319 - loss = 1.540, (1.412 sec/step)\n",
      "step 2320 - loss = 2.059, (1.510 sec/step)\n",
      "step 2321 - loss = 1.809, (3.003 sec/step)\n",
      "step 2322 - loss = 2.111, (2.108 sec/step)\n",
      "step 2323 - loss = 2.385, (1.407 sec/step)\n",
      "step 2324 - loss = 1.942, (1.428 sec/step)\n",
      "step 2325 - loss = 1.814, (2.528 sec/step)\n",
      "step 2326 - loss = 1.884, (2.018 sec/step)\n",
      "step 2327 - loss = 2.277, (1.509 sec/step)\n",
      "step 2328 - loss = 1.604, (1.182 sec/step)\n",
      "step 2329 - loss = 2.118, (1.431 sec/step)\n",
      "step 2330 - loss = 2.586, (1.855 sec/step)\n",
      "step 2331 - loss = 1.593, (2.594 sec/step)\n",
      "step 2332 - loss = 1.761, (1.623 sec/step)\n",
      "step 2333 - loss = 1.414, (1.198 sec/step)\n",
      "step 2334 - loss = 2.204, (1.637 sec/step)\n",
      "step 2335 - loss = 1.290, (1.350 sec/step)\n",
      "step 2336 - loss = 2.080, (0.941 sec/step)\n",
      "step 2337 - loss = 2.245, (3.106 sec/step)\n",
      "step 2338 - loss = 1.796, (2.839 sec/step)\n",
      "step 2339 - loss = 1.530, (1.589 sec/step)\n",
      "step 2340 - loss = 1.551, (1.540 sec/step)\n",
      "step 2341 - loss = 1.437, (1.310 sec/step)\n",
      "step 2342 - loss = 1.906, (3.159 sec/step)\n",
      "step 2343 - loss = 1.816, (1.573 sec/step)\n",
      "step 2344 - loss = 1.561, (1.310 sec/step)\n",
      "step 2345 - loss = 2.178, (1.697 sec/step)\n",
      "step 2346 - loss = 2.333, (2.107 sec/step)\n",
      "step 2347 - loss = 1.943, (2.030 sec/step)\n",
      "step 2348 - loss = 2.190, (2.950 sec/step)\n",
      "step 2349 - loss = 1.892, (1.320 sec/step)\n",
      "step 2350 - loss = 1.466, (1.877 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2351 - loss = 1.693, (2.486 sec/step)\n",
      "step 2352 - loss = 0.693, (1.211 sec/step)\n",
      "step 2353 - loss = 1.974, (0.952 sec/step)\n",
      "step 2354 - loss = 1.794, (1.662 sec/step)\n",
      "step 2355 - loss = 1.437, (2.116 sec/step)\n",
      "step 2356 - loss = 1.738, (1.034 sec/step)\n",
      "step 2357 - loss = 1.396, (1.401 sec/step)\n",
      "step 2358 - loss = 1.559, (2.991 sec/step)\n",
      "step 2359 - loss = 2.282, (1.520 sec/step)\n",
      "step 2360 - loss = 1.741, (3.757 sec/step)\n",
      "step 2361 - loss = 2.198, (1.582 sec/step)\n",
      "step 2362 - loss = 1.647, (1.377 sec/step)\n",
      "step 2363 - loss = 2.284, (2.217 sec/step)\n",
      "step 2364 - loss = 2.000, (1.275 sec/step)\n",
      "step 2365 - loss = 1.853, (1.839 sec/step)\n",
      "step 2366 - loss = 2.019, (1.104 sec/step)\n",
      "step 2367 - loss = 1.823, (1.208 sec/step)\n",
      "step 2368 - loss = 1.700, (1.177 sec/step)\n",
      "step 2369 - loss = 1.217, (1.328 sec/step)\n",
      "step 2370 - loss = 2.473, (2.483 sec/step)\n",
      "step 2371 - loss = 2.211, (2.543 sec/step)\n",
      "step 2372 - loss = 2.428, (2.483 sec/step)\n",
      "step 2373 - loss = 2.496, (2.283 sec/step)\n",
      "step 2374 - loss = 1.871, (1.727 sec/step)\n",
      "step 2375 - loss = 2.331, (1.757 sec/step)\n",
      "step 2376 - loss = 2.042, (2.068 sec/step)\n",
      "step 2377 - loss = 2.103, (0.985 sec/step)\n",
      "step 2378 - loss = 1.923, (1.683 sec/step)\n",
      "step 2379 - loss = 1.723, (1.585 sec/step)\n",
      "step 2380 - loss = 1.945, (1.419 sec/step)\n",
      "step 2381 - loss = 1.692, (1.906 sec/step)\n",
      "step 2382 - loss = 1.504, (1.160 sec/step)\n",
      "step 2383 - loss = 2.437, (2.485 sec/step)\n",
      "step 2384 - loss = 2.718, (1.945 sec/step)\n",
      "step 2385 - loss = 1.764, (1.205 sec/step)\n",
      "step 2386 - loss = 1.681, (0.804 sec/step)\n",
      "step 2387 - loss = 1.611, (1.308 sec/step)\n",
      "step 2388 - loss = 1.980, (2.359 sec/step)\n",
      "step 2389 - loss = 1.977, (1.525 sec/step)\n",
      "step 2390 - loss = 2.374, (1.749 sec/step)\n",
      "step 2391 - loss = 2.527, (1.068 sec/step)\n",
      "step 2392 - loss = 1.975, (1.592 sec/step)\n",
      "step 2393 - loss = 1.597, (2.485 sec/step)\n",
      "step 2394 - loss = 1.757, (5.986 sec/step)\n",
      "step 2395 - loss = 2.148, (1.308 sec/step)\n",
      "step 2396 - loss = 2.419, (2.484 sec/step)\n",
      "step 2397 - loss = 1.721, (0.230 sec/step)\n",
      "step 2398 - loss = 1.859, (0.984 sec/step)\n",
      "step 2399 - loss = 1.806, (2.003 sec/step)\n",
      "step 2400 - loss = 2.123, (2.009 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2401 - loss = 2.044, (2.989 sec/step)\n",
      "step 2402 - loss = 1.727, (1.280 sec/step)\n",
      "step 2403 - loss = 2.090, (1.771 sec/step)\n",
      "step 2404 - loss = 1.877, (2.000 sec/step)\n",
      "step 2405 - loss = 1.436, (1.427 sec/step)\n",
      "step 2406 - loss = 1.713, (0.847 sec/step)\n",
      "step 2407 - loss = 1.808, (1.282 sec/step)\n",
      "step 2408 - loss = 1.788, (1.000 sec/step)\n",
      "step 2409 - loss = 2.109, (1.680 sec/step)\n",
      "step 2410 - loss = 1.760, (0.662 sec/step)\n",
      "step 2411 - loss = 1.301, (1.693 sec/step)\n",
      "step 2412 - loss = 2.417, (2.487 sec/step)\n",
      "step 2413 - loss = 0.757, (1.793 sec/step)\n",
      "step 2414 - loss = 1.851, (1.464 sec/step)\n",
      "step 2415 - loss = 2.016, (1.742 sec/step)\n",
      "step 2416 - loss = 2.356, (1.526 sec/step)\n",
      "step 2417 - loss = 2.304, (1.782 sec/step)\n",
      "step 2418 - loss = 1.713, (1.847 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2419 - loss = 2.163, (2.486 sec/step)\n",
      "step 2420 - loss = 1.907, (2.923 sec/step)\n",
      "step 2421 - loss = 1.968, (1.245 sec/step)\n",
      "step 2422 - loss = 2.005, (0.793 sec/step)\n",
      "step 2423 - loss = 1.523, (1.687 sec/step)\n",
      "step 2424 - loss = 1.950, (1.244 sec/step)\n",
      "step 2425 - loss = 2.097, (1.214 sec/step)\n",
      "step 2426 - loss = 1.579, (1.101 sec/step)\n",
      "step 2427 - loss = 1.326, (1.687 sec/step)\n",
      "step 2428 - loss = 1.702, (1.977 sec/step)\n",
      "step 2429 - loss = 1.567, (2.450 sec/step)\n",
      "step 2430 - loss = 2.375, (1.755 sec/step)\n",
      "step 2431 - loss = 1.782, (1.602 sec/step)\n",
      "step 2432 - loss = 1.768, (1.213 sec/step)\n",
      "step 2433 - loss = 2.228, (1.228 sec/step)\n",
      "step 2434 - loss = 1.821, (1.196 sec/step)\n",
      "step 2435 - loss = 2.144, (1.439 sec/step)\n",
      "step 2436 - loss = 2.247, (2.703 sec/step)\n",
      "step 2437 - loss = 1.556, (1.256 sec/step)\n",
      "step 2438 - loss = 2.134, (1.150 sec/step)\n",
      "step 2439 - loss = 1.883, (1.443 sec/step)\n",
      "step 2440 - loss = 2.086, (1.358 sec/step)\n",
      "step 2441 - loss = 2.027, (1.392 sec/step)\n",
      "step 2442 - loss = 2.132, (1.541 sec/step)\n",
      "step 2443 - loss = 1.575, (1.018 sec/step)\n",
      "step 2444 - loss = 2.501, (2.486 sec/step)\n",
      "step 2445 - loss = 1.044, (0.554 sec/step)\n",
      "step 2446 - loss = 2.282, (1.139 sec/step)\n",
      "step 2447 - loss = 1.828, (2.612 sec/step)\n",
      "step 2448 - loss = 2.338, (2.518 sec/step)\n",
      "step 2449 - loss = 1.972, (1.196 sec/step)\n",
      "step 2450 - loss = 2.169, (1.428 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2451 - loss = 2.171, (2.130 sec/step)\n",
      "step 2452 - loss = 1.628, (1.675 sec/step)\n",
      "step 2453 - loss = 2.133, (1.249 sec/step)\n",
      "step 2454 - loss = 1.779, (3.400 sec/step)\n",
      "step 2455 - loss = 1.492, (1.745 sec/step)\n",
      "step 2456 - loss = 2.127, (1.725 sec/step)\n",
      "step 2457 - loss = 2.222, (1.390 sec/step)\n",
      "step 2458 - loss = 1.699, (1.861 sec/step)\n",
      "step 2459 - loss = 1.833, (1.736 sec/step)\n",
      "step 2460 - loss = 2.165, (2.029 sec/step)\n",
      "step 2461 - loss = 1.663, (2.299 sec/step)\n",
      "step 2462 - loss = 1.864, (2.733 sec/step)\n",
      "step 2463 - loss = 1.863, (1.826 sec/step)\n",
      "step 2464 - loss = 2.227, (2.420 sec/step)\n",
      "step 2465 - loss = 1.398, (1.113 sec/step)\n",
      "step 2466 - loss = 2.331, (2.394 sec/step)\n",
      "step 2467 - loss = 1.827, (3.084 sec/step)\n",
      "step 2468 - loss = 1.959, (2.836 sec/step)\n",
      "step 2469 - loss = 2.200, (1.032 sec/step)\n",
      "step 2470 - loss = 2.249, (1.388 sec/step)\n",
      "step 2471 - loss = 2.421, (2.198 sec/step)\n",
      "step 2472 - loss = 1.938, (2.134 sec/step)\n",
      "step 2473 - loss = 2.402, (2.347 sec/step)\n",
      "step 2474 - loss = 1.887, (1.733 sec/step)\n",
      "step 2475 - loss = 2.318, (1.703 sec/step)\n",
      "step 2476 - loss = 1.112, (2.121 sec/step)\n",
      "step 2477 - loss = 2.365, (1.714 sec/step)\n",
      "step 2478 - loss = 2.646, (1.883 sec/step)\n",
      "step 2479 - loss = 1.977, (1.520 sec/step)\n",
      "step 2480 - loss = 1.978, (3.113 sec/step)\n",
      "step 2481 - loss = 2.055, (1.198 sec/step)\n",
      "step 2482 - loss = 2.583, (1.431 sec/step)\n",
      "step 2483 - loss = 1.728, (1.405 sec/step)\n",
      "step 2484 - loss = 2.147, (2.336 sec/step)\n",
      "step 2485 - loss = 1.647, (1.948 sec/step)\n",
      "step 2486 - loss = 1.495, (1.244 sec/step)\n",
      "step 2487 - loss = 2.033, (1.775 sec/step)\n",
      "step 2488 - loss = 2.323, (1.703 sec/step)\n",
      "step 2489 - loss = 2.002, (1.658 sec/step)\n",
      "step 2490 - loss = 1.358, (1.479 sec/step)\n",
      "step 2491 - loss = 1.766, (2.304 sec/step)\n",
      "step 2492 - loss = 2.017, (1.700 sec/step)\n",
      "step 2493 - loss = 1.684, (1.639 sec/step)\n",
      "step 2494 - loss = 1.684, (1.709 sec/step)\n",
      "step 2495 - loss = 1.917, (1.844 sec/step)\n",
      "step 2496 - loss = 2.187, (1.423 sec/step)\n",
      "step 2497 - loss = 1.566, (1.747 sec/step)\n",
      "step 2498 - loss = 2.391, (1.652 sec/step)\n",
      "step 2499 - loss = 2.166, (1.386 sec/step)\n",
      "step 2500 - loss = 1.514, (0.952 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2501 - loss = 1.430, (2.486 sec/step)\n",
      "step 2502 - loss = 0.947, (1.317 sec/step)\n",
      "step 2503 - loss = 1.686, (1.437 sec/step)\n",
      "step 2504 - loss = 2.052, (0.793 sec/step)\n",
      "step 2505 - loss = 1.862, (1.521 sec/step)\n",
      "step 2506 - loss = 1.091, (2.483 sec/step)\n",
      "step 2507 - loss = 0.489, (1.967 sec/step)\n",
      "step 2508 - loss = 2.116, (1.934 sec/step)\n",
      "step 2509 - loss = 2.073, (1.845 sec/step)\n",
      "step 2510 - loss = 2.444, (1.903 sec/step)\n",
      "step 2511 - loss = 1.882, (1.290 sec/step)\n",
      "step 2512 - loss = 2.583, (1.679 sec/step)\n",
      "step 2513 - loss = 1.849, (1.189 sec/step)\n",
      "step 2514 - loss = 1.411, (1.404 sec/step)\n",
      "step 2515 - loss = 2.101, (1.975 sec/step)\n",
      "step 2516 - loss = 1.639, (1.245 sec/step)\n",
      "step 2517 - loss = 2.304, (1.955 sec/step)\n",
      "step 2518 - loss = 1.595, (0.942 sec/step)\n",
      "step 2519 - loss = 1.587, (1.261 sec/step)\n",
      "step 2520 - loss = 1.618, (1.100 sec/step)\n",
      "step 2521 - loss = 1.626, (1.820 sec/step)\n",
      "step 2522 - loss = 1.828, (1.558 sec/step)\n",
      "step 2523 - loss = 1.956, (2.485 sec/step)\n",
      "step 2524 - loss = 1.839, (1.762 sec/step)\n",
      "step 2525 - loss = 1.719, (2.132 sec/step)\n",
      "step 2526 - loss = 2.741, (2.487 sec/step)\n",
      "step 2527 - loss = 2.524, (2.808 sec/step)\n",
      "step 2528 - loss = 2.129, (2.193 sec/step)\n",
      "step 2529 - loss = 1.672, (1.226 sec/step)\n",
      "step 2530 - loss = 2.115, (2.046 sec/step)\n",
      "step 2531 - loss = 2.300, (3.197 sec/step)\n",
      "step 2532 - loss = 2.746, (1.883 sec/step)\n",
      "step 2533 - loss = 2.007, (1.446 sec/step)\n",
      "step 2534 - loss = 2.133, (2.485 sec/step)\n",
      "step 2535 - loss = 1.346, (1.222 sec/step)\n",
      "step 2536 - loss = 1.363, (1.361 sec/step)\n",
      "step 2537 - loss = 1.953, (2.486 sec/step)\n",
      "step 2538 - loss = 2.386, (1.559 sec/step)\n",
      "step 2539 - loss = 2.694, (2.486 sec/step)\n",
      "step 2540 - loss = 1.698, (2.271 sec/step)\n",
      "step 2541 - loss = 1.633, (2.800 sec/step)\n",
      "step 2542 - loss = 1.981, (2.073 sec/step)\n",
      "step 2543 - loss = 1.381, (2.318 sec/step)\n",
      "step 2544 - loss = 2.028, (1.480 sec/step)\n",
      "step 2545 - loss = 2.081, (1.541 sec/step)\n",
      "step 2546 - loss = 2.031, (2.135 sec/step)\n",
      "step 2547 - loss = 2.066, (1.523 sec/step)\n",
      "step 2548 - loss = 1.641, (1.819 sec/step)\n",
      "step 2549 - loss = 1.995, (2.855 sec/step)\n",
      "step 2550 - loss = 1.528, (1.291 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2551 - loss = 1.452, (2.112 sec/step)\n",
      "step 2552 - loss = 1.896, (0.806 sec/step)\n",
      "step 2553 - loss = 2.351, (1.911 sec/step)\n",
      "step 2554 - loss = 2.316, (0.942 sec/step)\n",
      "step 2555 - loss = 1.997, (1.312 sec/step)\n",
      "step 2556 - loss = 1.469, (0.821 sec/step)\n",
      "step 2557 - loss = 1.970, (1.359 sec/step)\n",
      "step 2558 - loss = 1.766, (2.488 sec/step)\n",
      "step 2559 - loss = 2.100, (1.223 sec/step)\n",
      "step 2560 - loss = 1.799, (1.210 sec/step)\n",
      "step 2561 - loss = 1.380, (1.807 sec/step)\n",
      "step 2562 - loss = 1.780, (1.504 sec/step)\n",
      "step 2563 - loss = 1.875, (2.007 sec/step)\n",
      "step 2564 - loss = 1.835, (1.635 sec/step)\n",
      "step 2565 - loss = 1.399, (1.474 sec/step)\n",
      "step 2566 - loss = 1.749, (1.096 sec/step)\n",
      "step 2567 - loss = 2.052, (1.166 sec/step)\n",
      "step 2568 - loss = 2.082, (2.832 sec/step)\n",
      "step 2569 - loss = 1.776, (2.027 sec/step)\n",
      "step 2570 - loss = 1.421, (1.511 sec/step)\n",
      "step 2571 - loss = 2.201, (1.872 sec/step)\n",
      "step 2572 - loss = 1.589, (2.148 sec/step)\n",
      "step 2573 - loss = 2.383, (0.951 sec/step)\n",
      "step 2574 - loss = 1.520, (3.034 sec/step)\n",
      "step 2575 - loss = 1.814, (1.449 sec/step)\n",
      "step 2576 - loss = 1.405, (2.771 sec/step)\n",
      "step 2577 - loss = 1.792, (2.484 sec/step)\n",
      "step 2578 - loss = 2.330, (2.022 sec/step)\n",
      "step 2579 - loss = 1.601, (1.509 sec/step)\n",
      "step 2580 - loss = 1.975, (2.485 sec/step)\n",
      "step 2581 - loss = 1.969, (1.491 sec/step)\n",
      "step 2582 - loss = 2.323, (0.985 sec/step)\n",
      "step 2583 - loss = 2.342, (2.302 sec/step)\n",
      "step 2584 - loss = 1.396, (2.095 sec/step)\n",
      "step 2585 - loss = 2.130, (1.798 sec/step)\n",
      "step 2586 - loss = 1.703, (1.335 sec/step)\n",
      "step 2587 - loss = 1.605, (2.482 sec/step)\n",
      "step 2588 - loss = 0.709, (0.965 sec/step)\n",
      "step 2589 - loss = 1.801, (3.161 sec/step)\n",
      "step 2590 - loss = 2.431, (1.327 sec/step)\n",
      "step 2591 - loss = 1.669, (1.181 sec/step)\n",
      "step 2592 - loss = 2.324, (1.751 sec/step)\n",
      "step 2593 - loss = 1.819, (1.409 sec/step)\n",
      "step 2594 - loss = 1.429, (1.435 sec/step)\n",
      "step 2595 - loss = 1.877, (1.772 sec/step)\n",
      "step 2596 - loss = 2.051, (0.924 sec/step)\n",
      "step 2597 - loss = 2.081, (1.338 sec/step)\n",
      "step 2598 - loss = 1.337, (1.956 sec/step)\n",
      "step 2599 - loss = 1.600, (2.741 sec/step)\n",
      "step 2600 - loss = 1.848, (1.372 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2601 - loss = 2.197, (1.754 sec/step)\n",
      "step 2602 - loss = 2.331, (2.975 sec/step)\n",
      "step 2603 - loss = 2.391, (1.751 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2604 - loss = 1.949, (2.402 sec/step)\n",
      "step 2605 - loss = 1.941, (1.746 sec/step)\n",
      "step 2606 - loss = 1.903, (1.014 sec/step)\n",
      "step 2607 - loss = 1.467, (0.894 sec/step)\n",
      "step 2608 - loss = 1.934, (1.533 sec/step)\n",
      "step 2609 - loss = 2.426, (3.303 sec/step)\n",
      "step 2610 - loss = 1.806, (1.723 sec/step)\n",
      "step 2611 - loss = 1.104, (2.472 sec/step)\n",
      "step 2612 - loss = 2.109, (2.989 sec/step)\n",
      "step 2613 - loss = 1.647, (1.232 sec/step)\n",
      "step 2614 - loss = 1.494, (1.223 sec/step)\n",
      "step 2615 - loss = 1.662, (1.030 sec/step)\n",
      "step 2616 - loss = 1.605, (1.635 sec/step)\n",
      "step 2617 - loss = 1.796, (1.262 sec/step)\n",
      "step 2618 - loss = 2.079, (1.579 sec/step)\n",
      "step 2619 - loss = 2.082, (2.276 sec/step)\n",
      "step 2620 - loss = 1.925, (1.127 sec/step)\n",
      "step 2621 - loss = 1.528, (2.484 sec/step)\n",
      "step 2622 - loss = 1.224, (2.499 sec/step)\n",
      "step 2623 - loss = 1.891, (1.146 sec/step)\n",
      "step 2624 - loss = 2.243, (1.413 sec/step)\n",
      "step 2625 - loss = 1.425, (1.317 sec/step)\n",
      "step 2626 - loss = 1.473, (1.952 sec/step)\n",
      "step 2627 - loss = 2.102, (2.487 sec/step)\n",
      "step 2628 - loss = 2.070, (2.695 sec/step)\n",
      "step 2629 - loss = 1.670, (1.644 sec/step)\n",
      "step 2630 - loss = 1.468, (1.458 sec/step)\n",
      "step 2631 - loss = 1.585, (2.718 sec/step)\n",
      "step 2632 - loss = 2.248, (1.901 sec/step)\n",
      "step 2633 - loss = 1.889, (1.146 sec/step)\n",
      "step 2634 - loss = 1.847, (2.063 sec/step)\n",
      "step 2635 - loss = 2.506, (1.276 sec/step)\n",
      "step 2636 - loss = 1.827, (1.195 sec/step)\n",
      "step 2637 - loss = 1.775, (1.092 sec/step)\n",
      "step 2638 - loss = 2.382, (1.947 sec/step)\n",
      "step 2639 - loss = 1.425, (2.601 sec/step)\n",
      "step 2640 - loss = 1.952, (1.187 sec/step)\n",
      "step 2641 - loss = 1.711, (1.642 sec/step)\n",
      "step 2642 - loss = 2.005, (2.261 sec/step)\n",
      "step 2643 - loss = 2.024, (1.053 sec/step)\n",
      "step 2644 - loss = 1.934, (1.180 sec/step)\n",
      "step 2645 - loss = 2.503, (1.834 sec/step)\n",
      "step 2646 - loss = 2.044, (1.195 sec/step)\n",
      "step 2647 - loss = 2.049, (2.203 sec/step)\n",
      "step 2648 - loss = 2.063, (1.756 sec/step)\n",
      "step 2649 - loss = 2.213, (1.865 sec/step)\n",
      "step 2650 - loss = 1.942, (2.215 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2651 - loss = 1.989, (1.685 sec/step)\n",
      "step 2652 - loss = 1.679, (2.059 sec/step)\n",
      "step 2653 - loss = 2.007, (1.133 sec/step)\n",
      "step 2654 - loss = 1.999, (1.460 sec/step)\n",
      "step 2655 - loss = 1.724, (1.543 sec/step)\n",
      "step 2656 - loss = 2.336, (1.353 sec/step)\n",
      "step 2657 - loss = 2.136, (2.248 sec/step)\n",
      "step 2658 - loss = 1.892, (2.357 sec/step)\n",
      "step 2659 - loss = 1.870, (1.936 sec/step)\n",
      "step 2660 - loss = 1.541, (1.214 sec/step)\n",
      "step 2661 - loss = 1.541, (1.189 sec/step)\n",
      "step 2662 - loss = 1.923, (1.424 sec/step)\n",
      "step 2663 - loss = 1.653, (2.758 sec/step)\n",
      "step 2664 - loss = 1.748, (1.242 sec/step)\n",
      "step 2665 - loss = 2.004, (2.401 sec/step)\n",
      "step 2666 - loss = 1.518, (1.203 sec/step)\n",
      "step 2667 - loss = 1.548, (2.001 sec/step)\n",
      "step 2668 - loss = 2.171, (1.898 sec/step)\n",
      "step 2669 - loss = 1.259, (2.723 sec/step)\n",
      "step 2670 - loss = 1.479, (2.175 sec/step)\n",
      "step 2671 - loss = 2.162, (1.550 sec/step)\n",
      "step 2672 - loss = 1.904, (1.654 sec/step)\n",
      "step 2673 - loss = 1.953, (1.284 sec/step)\n",
      "step 2674 - loss = 2.248, (2.496 sec/step)\n",
      "step 2675 - loss = 2.467, (2.490 sec/step)\n",
      "step 2676 - loss = 2.374, (0.152 sec/step)\n",
      "step 2677 - loss = 2.367, (3.557 sec/step)\n",
      "step 2678 - loss = 2.151, (1.346 sec/step)\n",
      "step 2679 - loss = 2.059, (3.723 sec/step)\n",
      "step 2680 - loss = 2.475, (2.486 sec/step)\n",
      "step 2681 - loss = 2.552, (2.783 sec/step)\n",
      "step 2682 - loss = 2.300, (1.230 sec/step)\n",
      "step 2683 - loss = 1.666, (3.309 sec/step)\n",
      "step 2684 - loss = 1.126, (1.345 sec/step)\n",
      "step 2685 - loss = 1.736, (2.160 sec/step)\n",
      "step 2686 - loss = 1.992, (1.102 sec/step)\n",
      "step 2687 - loss = 1.921, (1.222 sec/step)\n",
      "step 2688 - loss = 0.992, (1.212 sec/step)\n",
      "step 2689 - loss = 2.335, (2.011 sec/step)\n",
      "step 2690 - loss = 2.300, (1.241 sec/step)\n",
      "step 2691 - loss = 2.213, (1.605 sec/step)\n",
      "step 2692 - loss = 1.981, (3.623 sec/step)\n",
      "step 2693 - loss = 1.836, (1.128 sec/step)\n",
      "step 2694 - loss = 2.149, (2.565 sec/step)\n",
      "step 2695 - loss = 1.708, (1.284 sec/step)\n",
      "step 2696 - loss = 2.278, (2.540 sec/step)\n",
      "step 2697 - loss = 2.115, (1.534 sec/step)\n",
      "step 2698 - loss = 1.647, (1.202 sec/step)\n",
      "step 2699 - loss = 1.811, (2.055 sec/step)\n",
      "step 2700 - loss = 1.691, (0.869 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2701 - loss = 1.870, (1.438 sec/step)\n",
      "step 2702 - loss = 2.008, (2.403 sec/step)\n",
      "step 2703 - loss = 1.837, (1.406 sec/step)\n",
      "step 2704 - loss = 2.172, (1.470 sec/step)\n",
      "step 2705 - loss = 1.661, (1.347 sec/step)\n",
      "step 2706 - loss = 1.514, (2.324 sec/step)\n",
      "step 2707 - loss = 1.666, (3.275 sec/step)\n",
      "step 2708 - loss = 2.225, (1.300 sec/step)\n",
      "step 2709 - loss = 2.055, (1.675 sec/step)\n",
      "step 2710 - loss = 1.669, (1.227 sec/step)\n",
      "step 2711 - loss = 2.162, (1.420 sec/step)\n",
      "step 2712 - loss = 1.591, (2.371 sec/step)\n",
      "step 2713 - loss = 2.563, (1.546 sec/step)\n",
      "step 2714 - loss = 2.461, (2.915 sec/step)\n",
      "step 2715 - loss = 2.514, (1.250 sec/step)\n",
      "step 2716 - loss = 1.307, (1.888 sec/step)\n",
      "step 2717 - loss = 2.332, (1.574 sec/step)\n",
      "step 2718 - loss = 1.779, (1.480 sec/step)\n",
      "step 2719 - loss = 0.599, (2.484 sec/step)\n",
      "step 2720 - loss = 2.147, (2.523 sec/step)\n",
      "step 2721 - loss = 2.539, (1.925 sec/step)\n",
      "step 2722 - loss = 2.048, (1.212 sec/step)\n",
      "step 2723 - loss = 1.846, (1.829 sec/step)\n",
      "step 2724 - loss = 1.993, (2.669 sec/step)\n",
      "step 2725 - loss = 1.921, (1.786 sec/step)\n",
      "step 2726 - loss = 1.655, (1.706 sec/step)\n",
      "step 2727 - loss = 1.511, (1.206 sec/step)\n",
      "step 2728 - loss = 1.582, (1.127 sec/step)\n",
      "step 2729 - loss = 1.726, (1.311 sec/step)\n",
      "step 2730 - loss = 2.448, (2.391 sec/step)\n",
      "step 2731 - loss = 1.351, (1.466 sec/step)\n",
      "step 2732 - loss = 1.425, (1.755 sec/step)\n",
      "step 2733 - loss = 2.107, (1.915 sec/step)\n",
      "step 2734 - loss = 1.991, (1.305 sec/step)\n",
      "step 2735 - loss = 1.805, (1.805 sec/step)\n",
      "step 2736 - loss = 1.881, (1.384 sec/step)\n",
      "step 2737 - loss = 1.822, (1.388 sec/step)\n",
      "step 2738 - loss = 2.187, (1.975 sec/step)\n",
      "step 2739 - loss = 2.344, (1.702 sec/step)\n",
      "step 2740 - loss = 1.923, (2.098 sec/step)\n",
      "step 2741 - loss = 2.035, (1.862 sec/step)\n",
      "step 2742 - loss = 2.027, (1.162 sec/step)\n",
      "step 2743 - loss = 1.515, (1.114 sec/step)\n",
      "step 2744 - loss = 1.904, (1.292 sec/step)\n",
      "step 2745 - loss = 1.912, (2.118 sec/step)\n",
      "step 2746 - loss = 1.250, (2.542 sec/step)\n",
      "step 2747 - loss = 1.990, (1.200 sec/step)\n",
      "step 2748 - loss = 2.264, (1.845 sec/step)\n",
      "step 2749 - loss = 1.888, (3.173 sec/step)\n",
      "step 2750 - loss = 1.841, (1.676 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2751 - loss = 2.160, (1.460 sec/step)\n",
      "step 2752 - loss = 2.071, (1.258 sec/step)\n",
      "step 2753 - loss = 2.513, (2.483 sec/step)\n",
      "step 2754 - loss = 1.954, (2.914 sec/step)\n",
      "step 2755 - loss = 2.317, (1.761 sec/step)\n",
      "step 2756 - loss = 1.872, (1.441 sec/step)\n",
      "step 2757 - loss = 2.109, (2.163 sec/step)\n",
      "step 2758 - loss = 2.085, (1.460 sec/step)\n",
      "step 2759 - loss = 1.810, (1.056 sec/step)\n",
      "step 2760 - loss = 2.742, (1.472 sec/step)\n",
      "step 2761 - loss = 1.537, (1.012 sec/step)\n",
      "step 2762 - loss = 2.375, (2.484 sec/step)\n",
      "step 2763 - loss = 2.229, (2.374 sec/step)\n",
      "step 2764 - loss = 2.182, (1.314 sec/step)\n",
      "step 2765 - loss = 2.686, (2.485 sec/step)\n",
      "step 2766 - loss = 3.488, (2.637 sec/step)\n",
      "step 2767 - loss = 1.968, (1.804 sec/step)\n",
      "step 2768 - loss = 2.185, (1.390 sec/step)\n",
      "step 2769 - loss = 1.650, (2.429 sec/step)\n",
      "step 2770 - loss = 2.147, (1.942 sec/step)\n",
      "step 2771 - loss = 2.337, (1.470 sec/step)\n",
      "step 2772 - loss = 1.832, (1.286 sec/step)\n",
      "step 2773 - loss = 1.607, (1.147 sec/step)\n",
      "step 2774 - loss = 2.193, (2.026 sec/step)\n",
      "step 2775 - loss = 2.174, (2.562 sec/step)\n",
      "step 2776 - loss = 1.720, (1.634 sec/step)\n",
      "step 2777 - loss = 2.324, (2.033 sec/step)\n",
      "step 2778 - loss = 2.165, (1.492 sec/step)\n",
      "step 2779 - loss = 1.838, (2.780 sec/step)\n",
      "step 2780 - loss = 2.325, (1.271 sec/step)\n",
      "step 2781 - loss = 2.239, (2.397 sec/step)\n",
      "step 2782 - loss = 1.745, (1.826 sec/step)\n",
      "step 2783 - loss = 1.872, (1.174 sec/step)\n",
      "step 2784 - loss = 2.443, (3.407 sec/step)\n",
      "step 2785 - loss = 1.727, (2.680 sec/step)\n",
      "step 2786 - loss = 2.309, (2.033 sec/step)\n",
      "step 2787 - loss = 2.064, (2.059 sec/step)\n",
      "step 2788 - loss = 2.146, (1.150 sec/step)\n",
      "step 2789 - loss = 1.987, (2.089 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2790 - loss = 1.909, (1.243 sec/step)\n",
      "step 2791 - loss = 1.953, (1.667 sec/step)\n",
      "step 2792 - loss = 1.886, (1.643 sec/step)\n",
      "step 2793 - loss = 1.960, (3.145 sec/step)\n",
      "step 2794 - loss = 2.089, (1.889 sec/step)\n",
      "step 2795 - loss = 1.960, (1.027 sec/step)\n",
      "step 2796 - loss = 2.059, (1.014 sec/step)\n",
      "step 2797 - loss = 1.542, (3.114 sec/step)\n",
      "step 2798 - loss = 2.007, (1.504 sec/step)\n",
      "step 2799 - loss = 2.071, (1.283 sec/step)\n",
      "step 2800 - loss = 1.761, (3.196 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2801 - loss = 2.112, (0.896 sec/step)\n",
      "step 2802 - loss = 1.840, (2.328 sec/step)\n",
      "step 2803 - loss = 1.650, (2.527 sec/step)\n",
      "step 2804 - loss = 1.947, (1.166 sec/step)\n",
      "step 2805 - loss = 2.004, (1.018 sec/step)\n",
      "step 2806 - loss = 1.767, (1.014 sec/step)\n",
      "step 2807 - loss = 1.416, (3.501 sec/step)\n",
      "step 2808 - loss = 1.958, (1.588 sec/step)\n",
      "step 2809 - loss = 1.841, (2.181 sec/step)\n",
      "step 2810 - loss = 2.024, (1.535 sec/step)\n",
      "step 2811 - loss = 1.589, (1.544 sec/step)\n",
      "step 2812 - loss = 1.671, (2.044 sec/step)\n",
      "step 2813 - loss = 2.367, (2.000 sec/step)\n",
      "step 2814 - loss = 2.069, (1.257 sec/step)\n",
      "step 2815 - loss = 2.061, (1.772 sec/step)\n",
      "step 2816 - loss = 1.969, (1.172 sec/step)\n",
      "step 2817 - loss = 2.083, (1.236 sec/step)\n",
      "step 2818 - loss = 2.055, (1.344 sec/step)\n",
      "step 2819 - loss = 1.992, (1.518 sec/step)\n",
      "step 2820 - loss = 1.788, (1.630 sec/step)\n",
      "step 2821 - loss = 2.091, (1.567 sec/step)\n",
      "step 2822 - loss = 1.609, (1.841 sec/step)\n",
      "step 2823 - loss = 1.726, (2.180 sec/step)\n",
      "step 2824 - loss = 2.154, (0.808 sec/step)\n",
      "step 2825 - loss = 1.406, (0.909 sec/step)\n",
      "step 2826 - loss = 2.490, (2.485 sec/step)\n",
      "step 2827 - loss = 2.526, (1.503 sec/step)\n",
      "step 2828 - loss = 1.865, (1.612 sec/step)\n",
      "step 2829 - loss = 1.766, (1.735 sec/step)\n",
      "step 2830 - loss = 2.176, (1.943 sec/step)\n",
      "step 2831 - loss = 2.160, (1.564 sec/step)\n",
      "step 2832 - loss = 1.476, (1.246 sec/step)\n",
      "step 2833 - loss = 2.147, (2.485 sec/step)\n",
      "step 2834 - loss = 0.646, (1.535 sec/step)\n",
      "step 2835 - loss = 1.949, (2.392 sec/step)\n",
      "step 2836 - loss = 1.442, (1.883 sec/step)\n",
      "step 2837 - loss = 2.277, (1.361 sec/step)\n",
      "step 2838 - loss = 1.859, (1.357 sec/step)\n",
      "step 2839 - loss = 1.079, (1.239 sec/step)\n",
      "step 2840 - loss = 1.731, (1.130 sec/step)\n",
      "step 2841 - loss = 2.351, (1.736 sec/step)\n",
      "step 2842 - loss = 1.739, (1.758 sec/step)\n",
      "step 2843 - loss = 1.913, (1.132 sec/step)\n",
      "step 2844 - loss = 1.649, (1.222 sec/step)\n",
      "step 2845 - loss = 1.763, (1.404 sec/step)\n",
      "step 2846 - loss = 1.645, (2.595 sec/step)\n",
      "step 2847 - loss = 2.157, (1.619 sec/step)\n",
      "step 2848 - loss = 2.342, (2.836 sec/step)\n",
      "step 2849 - loss = 1.932, (1.659 sec/step)\n",
      "step 2850 - loss = 2.135, (1.233 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2851 - loss = 2.152, (2.191 sec/step)\n",
      "step 2852 - loss = 1.952, (1.159 sec/step)\n",
      "step 2853 - loss = 1.823, (1.406 sec/step)\n",
      "step 2854 - loss = 1.925, (1.514 sec/step)\n",
      "step 2855 - loss = 2.624, (1.244 sec/step)\n",
      "step 2856 - loss = 2.477, (1.406 sec/step)\n",
      "step 2857 - loss = 1.581, (2.574 sec/step)\n",
      "step 2858 - loss = 1.798, (1.625 sec/step)\n",
      "step 2859 - loss = 1.637, (1.616 sec/step)\n",
      "step 2860 - loss = 1.975, (1.791 sec/step)\n",
      "step 2861 - loss = 2.008, (3.220 sec/step)\n",
      "step 2862 - loss = 1.739, (3.299 sec/step)\n",
      "step 2863 - loss = 1.857, (1.272 sec/step)\n",
      "step 2864 - loss = 2.194, (1.034 sec/step)\n",
      "step 2865 - loss = 1.791, (2.911 sec/step)\n",
      "step 2866 - loss = 1.011, (1.884 sec/step)\n",
      "step 2867 - loss = 1.549, (2.487 sec/step)\n",
      "step 2868 - loss = 0.786, (0.981 sec/step)\n",
      "step 2869 - loss = 2.218, (2.467 sec/step)\n",
      "step 2870 - loss = 2.140, (1.683 sec/step)\n",
      "step 2871 - loss = 2.455, (2.562 sec/step)\n",
      "step 2872 - loss = 1.704, (2.740 sec/step)\n",
      "step 2873 - loss = 1.687, (1.822 sec/step)\n",
      "step 2874 - loss = 1.590, (1.607 sec/step)\n",
      "step 2875 - loss = 2.108, (1.250 sec/step)\n",
      "step 2876 - loss = 1.741, (1.493 sec/step)\n",
      "step 2877 - loss = 2.001, (1.159 sec/step)\n",
      "step 2878 - loss = 1.842, (0.937 sec/step)\n",
      "step 2879 - loss = 2.606, (2.737 sec/step)\n",
      "step 2880 - loss = 2.232, (1.240 sec/step)\n",
      "step 2881 - loss = 1.886, (1.145 sec/step)\n",
      "step 2882 - loss = 2.198, (1.231 sec/step)\n",
      "step 2883 - loss = 2.029, (0.989 sec/step)\n",
      "step 2884 - loss = 1.611, (1.840 sec/step)\n",
      "step 2885 - loss = 2.030, (1.615 sec/step)\n",
      "step 2886 - loss = 1.513, (1.401 sec/step)\n",
      "step 2887 - loss = 1.558, (1.854 sec/step)\n",
      "step 2888 - loss = 2.073, (1.372 sec/step)\n",
      "step 2889 - loss = 2.009, (1.355 sec/step)\n",
      "step 2890 - loss = 1.968, (1.408 sec/step)\n",
      "step 2891 - loss = 1.875, (1.409 sec/step)\n",
      "step 2892 - loss = 2.219, (0.949 sec/step)\n",
      "step 2893 - loss = 2.468, (1.761 sec/step)\n",
      "step 2894 - loss = 1.957, (2.824 sec/step)\n",
      "step 2895 - loss = 1.827, (1.051 sec/step)\n",
      "step 2896 - loss = 1.801, (1.094 sec/step)\n",
      "step 2897 - loss = 2.253, (1.221 sec/step)\n",
      "step 2898 - loss = 1.652, (1.334 sec/step)\n",
      "step 2899 - loss = 2.050, (2.659 sec/step)\n",
      "step 2900 - loss = 1.944, (1.670 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2901 - loss = 1.647, (1.302 sec/step)\n",
      "step 2902 - loss = 1.784, (1.623 sec/step)\n",
      "step 2903 - loss = 1.908, (1.468 sec/step)\n",
      "step 2904 - loss = 1.846, (1.919 sec/step)\n",
      "step 2905 - loss = 1.308, (2.880 sec/step)\n",
      "step 2906 - loss = 1.468, (1.632 sec/step)\n",
      "step 2907 - loss = 1.742, (2.306 sec/step)\n",
      "step 2908 - loss = 2.064, (1.383 sec/step)\n",
      "step 2909 - loss = 2.169, (1.214 sec/step)\n",
      "step 2910 - loss = 1.664, (1.293 sec/step)\n",
      "step 2911 - loss = 1.921, (1.243 sec/step)\n",
      "step 2912 - loss = 1.671, (1.457 sec/step)\n",
      "step 2913 - loss = 1.979, (1.855 sec/step)\n",
      "step 2914 - loss = 1.177, (2.486 sec/step)\n",
      "step 2915 - loss = 0.655, (0.919 sec/step)\n",
      "step 2916 - loss = 1.810, (0.999 sec/step)\n",
      "step 2917 - loss = 2.166, (1.035 sec/step)\n",
      "step 2918 - loss = 1.577, (1.892 sec/step)\n",
      "step 2919 - loss = 2.039, (2.461 sec/step)\n",
      "step 2920 - loss = 1.730, (1.245 sec/step)\n",
      "step 2921 - loss = 1.919, (1.761 sec/step)\n",
      "step 2922 - loss = 2.162, (2.719 sec/step)\n",
      "step 2923 - loss = 1.840, (1.159 sec/step)\n",
      "step 2924 - loss = 2.092, (1.386 sec/step)\n",
      "step 2925 - loss = 1.641, (1.308 sec/step)\n",
      "step 2926 - loss = 2.323, (1.423 sec/step)\n",
      "step 2927 - loss = 1.648, (1.148 sec/step)\n",
      "step 2928 - loss = 2.483, (1.159 sec/step)\n",
      "step 2929 - loss = 2.237, (1.902 sec/step)\n",
      "step 2930 - loss = 1.659, (3.242 sec/step)\n",
      "step 2931 - loss = 2.239, (1.148 sec/step)\n",
      "step 2932 - loss = 2.211, (1.707 sec/step)\n",
      "step 2933 - loss = 1.222, (2.775 sec/step)\n",
      "step 2934 - loss = 1.902, (1.662 sec/step)\n",
      "step 2935 - loss = 1.620, (2.383 sec/step)\n",
      "step 2936 - loss = 2.565, (3.478 sec/step)\n",
      "step 2937 - loss = 2.080, (1.200 sec/step)\n",
      "step 2938 - loss = 1.818, (2.284 sec/step)\n",
      "step 2939 - loss = 2.514, (1.357 sec/step)\n",
      "step 2940 - loss = 1.999, (2.169 sec/step)\n",
      "step 2941 - loss = 1.418, (1.128 sec/step)\n",
      "step 2942 - loss = 2.220, (1.894 sec/step)\n",
      "step 2943 - loss = 1.804, (1.426 sec/step)\n",
      "step 2944 - loss = 2.183, (1.607 sec/step)\n",
      "step 2945 - loss = 1.096, (1.588 sec/step)\n",
      "step 2946 - loss = 1.625, (2.214 sec/step)\n",
      "step 2947 - loss = 2.222, (2.023 sec/step)\n",
      "step 2948 - loss = 1.835, (1.345 sec/step)\n",
      "step 2949 - loss = 2.234, (1.686 sec/step)\n",
      "step 2950 - loss = 1.787, (2.484 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 2951 - loss = 1.481, (1.918 sec/step)\n",
      "step 2952 - loss = 1.783, (2.054 sec/step)\n",
      "step 2953 - loss = 1.953, (0.964 sec/step)\n",
      "step 2954 - loss = 1.696, (1.411 sec/step)\n",
      "step 2955 - loss = 1.672, (1.361 sec/step)\n",
      "step 2956 - loss = 1.953, (1.894 sec/step)\n",
      "step 2957 - loss = 1.483, (0.970 sec/step)\n",
      "step 2958 - loss = 1.970, (1.385 sec/step)\n",
      "step 2959 - loss = 2.205, (1.272 sec/step)\n",
      "step 2960 - loss = 1.772, (3.202 sec/step)\n",
      "step 2961 - loss = 1.606, (2.657 sec/step)\n",
      "step 2962 - loss = 1.871, (2.020 sec/step)\n",
      "step 2963 - loss = 1.821, (1.448 sec/step)\n",
      "step 2964 - loss = 2.149, (1.203 sec/step)\n",
      "step 2965 - loss = 1.943, (2.487 sec/step)\n",
      "step 2966 - loss = 1.624, (1.738 sec/step)\n",
      "step 2967 - loss = 1.572, (1.297 sec/step)\n",
      "step 2968 - loss = 1.672, (1.243 sec/step)\n",
      "step 2969 - loss = 1.600, (1.427 sec/step)\n",
      "step 2970 - loss = 1.863, (1.258 sec/step)\n",
      "step 2971 - loss = 2.363, (2.128 sec/step)\n",
      "step 2972 - loss = 1.876, (1.445 sec/step)\n",
      "step 2973 - loss = 1.667, (1.198 sec/step)\n",
      "step 2974 - loss = 2.338, (1.834 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2975 - loss = 2.056, (1.461 sec/step)\n",
      "step 2976 - loss = 1.942, (2.383 sec/step)\n",
      "step 2977 - loss = 1.670, (2.161 sec/step)\n",
      "step 2978 - loss = 2.136, (1.458 sec/step)\n",
      "step 2979 - loss = 1.477, (1.168 sec/step)\n",
      "step 2980 - loss = 1.515, (1.202 sec/step)\n",
      "step 2981 - loss = 1.952, (1.496 sec/step)\n",
      "step 2982 - loss = 2.364, (2.000 sec/step)\n",
      "step 2983 - loss = 2.062, (3.434 sec/step)\n",
      "step 2984 - loss = 1.888, (1.469 sec/step)\n",
      "step 2985 - loss = 1.349, (1.784 sec/step)\n",
      "step 2986 - loss = 2.297, (1.298 sec/step)\n",
      "step 2987 - loss = 2.307, (2.702 sec/step)\n",
      "step 2988 - loss = 1.777, (2.723 sec/step)\n",
      "step 2989 - loss = 1.823, (2.100 sec/step)\n",
      "step 2990 - loss = 1.656, (2.947 sec/step)\n",
      "step 2991 - loss = 1.939, (1.936 sec/step)\n",
      "step 2992 - loss = 1.817, (2.778 sec/step)\n",
      "step 2993 - loss = 1.750, (1.567 sec/step)\n",
      "step 2994 - loss = 2.288, (2.372 sec/step)\n",
      "step 2995 - loss = 2.477, (1.627 sec/step)\n",
      "step 2996 - loss = 2.379, (2.701 sec/step)\n",
      "step 2997 - loss = 1.757, (1.466 sec/step)\n",
      "step 2998 - loss = 1.720, (1.609 sec/step)\n",
      "step 2999 - loss = 2.075, (2.740 sec/step)\n",
      "step 3000 - loss = 1.616, (2.233 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3001 - loss = 2.132, (2.530 sec/step)\n",
      "step 3002 - loss = 2.393, (2.162 sec/step)\n",
      "step 3003 - loss = 2.550, (1.958 sec/step)\n",
      "step 3004 - loss = 1.690, (1.175 sec/step)\n",
      "step 3005 - loss = 1.933, (0.744 sec/step)\n",
      "step 3006 - loss = 1.658, (1.156 sec/step)\n",
      "step 3007 - loss = 2.263, (1.722 sec/step)\n",
      "step 3008 - loss = 1.838, (1.641 sec/step)\n",
      "step 3009 - loss = 1.935, (1.196 sec/step)\n",
      "step 3010 - loss = 1.910, (0.936 sec/step)\n",
      "step 3011 - loss = 1.962, (2.405 sec/step)\n",
      "step 3012 - loss = 1.589, (0.856 sec/step)\n",
      "step 3013 - loss = 1.815, (1.019 sec/step)\n",
      "step 3014 - loss = 1.547, (2.913 sec/step)\n",
      "step 3015 - loss = 1.559, (1.634 sec/step)\n",
      "step 3016 - loss = 1.681, (1.001 sec/step)\n",
      "step 3017 - loss = 1.784, (2.981 sec/step)\n",
      "step 3018 - loss = 2.355, (1.819 sec/step)\n",
      "step 3019 - loss = 2.054, (1.516 sec/step)\n",
      "step 3020 - loss = 1.867, (1.880 sec/step)\n",
      "step 3021 - loss = 1.402, (2.029 sec/step)\n",
      "step 3022 - loss = 1.318, (2.341 sec/step)\n",
      "step 3023 - loss = 1.765, (0.918 sec/step)\n",
      "step 3024 - loss = 1.708, (1.131 sec/step)\n",
      "step 3025 - loss = 1.499, (1.344 sec/step)\n",
      "step 3026 - loss = 1.560, (1.786 sec/step)\n",
      "step 3027 - loss = 2.067, (1.552 sec/step)\n",
      "step 3028 - loss = 1.902, (1.247 sec/step)\n",
      "step 3029 - loss = 1.917, (1.617 sec/step)\n",
      "step 3030 - loss = 1.581, (2.192 sec/step)\n",
      "step 3031 - loss = 1.827, (1.906 sec/step)\n",
      "step 3032 - loss = 2.342, (1.359 sec/step)\n",
      "step 3033 - loss = 2.148, (1.558 sec/step)\n",
      "step 3034 - loss = 1.631, (1.409 sec/step)\n",
      "step 3035 - loss = 1.769, (1.113 sec/step)\n",
      "step 3036 - loss = 1.880, (1.347 sec/step)\n",
      "step 3037 - loss = 1.363, (1.065 sec/step)\n",
      "step 3038 - loss = 1.831, (1.172 sec/step)\n",
      "step 3039 - loss = 2.421, (1.372 sec/step)\n",
      "step 3040 - loss = 2.415, (1.439 sec/step)\n",
      "step 3041 - loss = 1.790, (1.100 sec/step)\n",
      "step 3042 - loss = 1.311, (2.062 sec/step)\n",
      "step 3043 - loss = 1.778, (1.571 sec/step)\n",
      "step 3044 - loss = 1.763, (1.522 sec/step)\n",
      "step 3045 - loss = 1.549, (1.630 sec/step)\n",
      "step 3046 - loss = 2.029, (1.111 sec/step)\n",
      "step 3047 - loss = 1.926, (1.410 sec/step)\n",
      "step 3048 - loss = 2.039, (1.348 sec/step)\n",
      "step 3049 - loss = 1.645, (2.522 sec/step)\n",
      "step 3050 - loss = 1.427, (1.115 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3051 - loss = 1.437, (2.073 sec/step)\n",
      "step 3052 - loss = 2.426, (2.248 sec/step)\n",
      "step 3053 - loss = 1.804, (2.439 sec/step)\n",
      "step 3054 - loss = 1.558, (1.881 sec/step)\n",
      "step 3055 - loss = 1.523, (1.257 sec/step)\n",
      "step 3056 - loss = 1.896, (1.159 sec/step)\n",
      "step 3057 - loss = 1.681, (2.585 sec/step)\n",
      "step 3058 - loss = 2.218, (2.203 sec/step)\n",
      "step 3059 - loss = 2.084, (1.508 sec/step)\n",
      "step 3060 - loss = 2.302, (1.512 sec/step)\n",
      "step 3061 - loss = 1.698, (1.512 sec/step)\n",
      "step 3062 - loss = 1.914, (1.318 sec/step)\n",
      "step 3063 - loss = 2.429, (2.484 sec/step)\n",
      "step 3064 - loss = 1.846, (0.883 sec/step)\n",
      "step 3065 - loss = 1.770, (1.393 sec/step)\n",
      "step 3066 - loss = 1.860, (1.673 sec/step)\n",
      "step 3067 - loss = 1.664, (1.307 sec/step)\n",
      "step 3068 - loss = 1.559, (2.759 sec/step)\n",
      "step 3069 - loss = 2.005, (2.477 sec/step)\n",
      "step 3070 - loss = 1.862, (1.395 sec/step)\n",
      "step 3071 - loss = 1.601, (1.953 sec/step)\n",
      "step 3072 - loss = 2.214, (1.114 sec/step)\n",
      "step 3073 - loss = 1.730, (1.404 sec/step)\n",
      "step 3074 - loss = 2.146, (1.675 sec/step)\n",
      "step 3075 - loss = 2.188, (2.600 sec/step)\n",
      "step 3076 - loss = 2.185, (0.924 sec/step)\n",
      "step 3077 - loss = 1.833, (1.455 sec/step)\n",
      "step 3078 - loss = 1.711, (2.964 sec/step)\n",
      "step 3079 - loss = 2.168, (1.520 sec/step)\n",
      "step 3080 - loss = 2.203, (2.715 sec/step)\n",
      "step 3081 - loss = 1.898, (1.662 sec/step)\n",
      "step 3082 - loss = 2.015, (1.738 sec/step)\n",
      "step 3083 - loss = 1.615, (3.289 sec/step)\n",
      "step 3084 - loss = 1.842, (1.096 sec/step)\n",
      "step 3085 - loss = 1.930, (0.968 sec/step)\n",
      "step 3086 - loss = 2.248, (1.959 sec/step)\n",
      "step 3087 - loss = 2.288, (0.987 sec/step)\n",
      "step 3088 - loss = 2.285, (1.288 sec/step)\n",
      "step 3089 - loss = 1.964, (2.510 sec/step)\n",
      "step 3090 - loss = 2.194, (1.130 sec/step)\n",
      "step 3091 - loss = 1.682, (1.358 sec/step)\n",
      "step 3092 - loss = 2.072, (2.098 sec/step)\n",
      "step 3093 - loss = 1.800, (1.585 sec/step)\n",
      "step 3094 - loss = 1.986, (1.459 sec/step)\n",
      "step 3095 - loss = 1.873, (1.111 sec/step)\n",
      "step 3096 - loss = 2.155, (1.765 sec/step)\n",
      "step 3097 - loss = 1.644, (1.879 sec/step)\n",
      "step 3098 - loss = 2.071, (1.553 sec/step)\n",
      "step 3099 - loss = 2.218, (1.407 sec/step)\n",
      "step 3100 - loss = 1.237, (0.941 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3101 - loss = 1.547, (1.508 sec/step)\n",
      "step 3102 - loss = 1.685, (2.856 sec/step)\n",
      "step 3103 - loss = 2.053, (1.797 sec/step)\n",
      "step 3104 - loss = 1.832, (2.488 sec/step)\n",
      "step 3105 - loss = 0.732, (2.203 sec/step)\n",
      "step 3106 - loss = 1.983, (1.343 sec/step)\n",
      "step 3107 - loss = 1.174, (1.522 sec/step)\n",
      "step 3108 - loss = 1.612, (2.070 sec/step)\n",
      "step 3109 - loss = 1.465, (2.835 sec/step)\n",
      "step 3110 - loss = 1.824, (1.248 sec/step)\n",
      "step 3111 - loss = 1.936, (1.115 sec/step)\n",
      "step 3112 - loss = 2.257, (1.319 sec/step)\n",
      "step 3113 - loss = 1.982, (1.396 sec/step)\n",
      "step 3114 - loss = 2.137, (1.980 sec/step)\n",
      "step 3115 - loss = 2.027, (1.533 sec/step)\n",
      "step 3116 - loss = 2.073, (3.287 sec/step)\n",
      "step 3117 - loss = 1.540, (1.447 sec/step)\n",
      "step 3118 - loss = 1.388, (1.565 sec/step)\n",
      "step 3119 - loss = 2.160, (1.027 sec/step)\n",
      "step 3120 - loss = 2.243, (1.268 sec/step)\n",
      "step 3121 - loss = 1.851, (2.476 sec/step)\n",
      "step 3122 - loss = 2.044, (1.092 sec/step)\n",
      "step 3123 - loss = 1.238, (1.864 sec/step)\n",
      "step 3124 - loss = 1.762, (1.317 sec/step)\n",
      "step 3125 - loss = 1.937, (1.785 sec/step)\n",
      "step 3126 - loss = 2.501, (1.098 sec/step)\n",
      "step 3127 - loss = 2.069, (1.474 sec/step)\n",
      "step 3128 - loss = 1.889, (2.484 sec/step)\n",
      "step 3129 - loss = 0.641, (1.117 sec/step)\n",
      "step 3130 - loss = 2.282, (2.161 sec/step)\n",
      "step 3131 - loss = 1.300, (2.485 sec/step)\n",
      "step 3132 - loss = 0.589, (1.219 sec/step)\n",
      "step 3133 - loss = 1.886, (1.158 sec/step)\n",
      "step 3134 - loss = 2.659, (2.248 sec/step)\n",
      "step 3135 - loss = 1.561, (1.095 sec/step)\n",
      "step 3136 - loss = 1.901, (1.434 sec/step)\n",
      "step 3137 - loss = 1.875, (1.482 sec/step)\n",
      "step 3138 - loss = 1.991, (2.439 sec/step)\n",
      "step 3139 - loss = 2.431, (1.357 sec/step)\n",
      "step 3140 - loss = 1.801, (1.192 sec/step)\n",
      "step 3141 - loss = 2.037, (2.229 sec/step)\n",
      "step 3142 - loss = 2.037, (1.326 sec/step)\n",
      "step 3143 - loss = 2.308, (1.575 sec/step)\n",
      "step 3144 - loss = 2.217, (2.484 sec/step)\n",
      "step 3145 - loss = 1.446, (2.348 sec/step)\n",
      "step 3146 - loss = 1.661, (1.019 sec/step)\n",
      "step 3147 - loss = 1.843, (3.028 sec/step)\n",
      "step 3148 - loss = 1.659, (1.396 sec/step)\n",
      "step 3149 - loss = 1.518, (1.744 sec/step)\n",
      "step 3150 - loss = 1.825, (1.479 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3151 - loss = 2.031, (1.420 sec/step)\n",
      "step 3152 - loss = 2.124, (3.388 sec/step)\n",
      "step 3153 - loss = 1.404, (1.573 sec/step)\n",
      "step 3154 - loss = 2.017, (1.180 sec/step)\n",
      "step 3155 - loss = 2.413, (2.483 sec/step)\n",
      "step 3156 - loss = 2.329, (2.733 sec/step)\n",
      "step 3157 - loss = 1.889, (0.969 sec/step)\n",
      "step 3158 - loss = 1.983, (2.622 sec/step)\n",
      "step 3159 - loss = 1.591, (1.796 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3160 - loss = 1.780, (1.410 sec/step)\n",
      "step 3161 - loss = 1.814, (1.145 sec/step)\n",
      "step 3162 - loss = 1.278, (1.009 sec/step)\n",
      "step 3163 - loss = 1.713, (1.361 sec/step)\n",
      "step 3164 - loss = 2.177, (1.634 sec/step)\n",
      "step 3165 - loss = 1.892, (1.562 sec/step)\n",
      "step 3166 - loss = 1.987, (2.381 sec/step)\n",
      "step 3167 - loss = 1.852, (1.882 sec/step)\n",
      "step 3168 - loss = 2.609, (2.015 sec/step)\n",
      "step 3169 - loss = 1.908, (1.323 sec/step)\n",
      "step 3170 - loss = 1.911, (1.347 sec/step)\n",
      "step 3171 - loss = 2.122, (1.508 sec/step)\n",
      "step 3172 - loss = 1.439, (1.335 sec/step)\n",
      "step 3173 - loss = 1.714, (1.453 sec/step)\n",
      "step 3174 - loss = 1.475, (1.301 sec/step)\n",
      "step 3175 - loss = 1.960, (1.244 sec/step)\n",
      "step 3176 - loss = 2.344, (1.280 sec/step)\n",
      "step 3177 - loss = 2.286, (2.268 sec/step)\n",
      "step 3178 - loss = 1.771, (1.209 sec/step)\n",
      "step 3179 - loss = 1.831, (2.144 sec/step)\n",
      "step 3180 - loss = 1.791, (2.484 sec/step)\n",
      "step 3181 - loss = 0.415, (2.907 sec/step)\n",
      "step 3182 - loss = 2.065, (2.454 sec/step)\n",
      "step 3183 - loss = 1.819, (1.249 sec/step)\n",
      "step 3184 - loss = 1.695, (1.680 sec/step)\n",
      "step 3185 - loss = 2.411, (2.054 sec/step)\n",
      "step 3186 - loss = 2.490, (1.150 sec/step)\n",
      "step 3187 - loss = 1.459, (1.971 sec/step)\n",
      "step 3188 - loss = 1.612, (1.282 sec/step)\n",
      "step 3189 - loss = 2.063, (0.838 sec/step)\n",
      "step 3190 - loss = 2.365, (1.446 sec/step)\n",
      "step 3191 - loss = 1.788, (2.161 sec/step)\n",
      "step 3192 - loss = 1.362, (2.539 sec/step)\n",
      "step 3193 - loss = 1.729, (1.927 sec/step)\n",
      "step 3194 - loss = 2.424, (2.564 sec/step)\n",
      "step 3195 - loss = 1.764, (0.913 sec/step)\n",
      "step 3196 - loss = 2.403, (2.215 sec/step)\n",
      "step 3197 - loss = 2.014, (1.521 sec/step)\n",
      "step 3198 - loss = 1.558, (1.673 sec/step)\n",
      "step 3199 - loss = 1.719, (2.630 sec/step)\n",
      "step 3200 - loss = 1.486, (1.873 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3201 - loss = 1.860, (1.748 sec/step)\n",
      "step 3202 - loss = 1.919, (1.789 sec/step)\n",
      "step 3203 - loss = 1.591, (1.314 sec/step)\n",
      "step 3204 - loss = 1.974, (0.926 sec/step)\n",
      "step 3205 - loss = 2.118, (1.912 sec/step)\n",
      "step 3206 - loss = 1.602, (1.280 sec/step)\n",
      "step 3207 - loss = 2.246, (1.903 sec/step)\n",
      "step 3208 - loss = 2.218, (2.689 sec/step)\n",
      "step 3209 - loss = 2.198, (2.208 sec/step)\n",
      "step 3210 - loss = 1.670, (1.641 sec/step)\n",
      "step 3211 - loss = 1.507, (1.691 sec/step)\n",
      "step 3212 - loss = 2.306, (1.539 sec/step)\n",
      "step 3213 - loss = 1.935, (1.257 sec/step)\n",
      "step 3214 - loss = 2.213, (1.697 sec/step)\n",
      "step 3215 - loss = 2.326, (1.676 sec/step)\n",
      "step 3216 - loss = 1.718, (0.709 sec/step)\n",
      "step 3217 - loss = 1.819, (1.088 sec/step)\n",
      "step 3218 - loss = 2.037, (1.649 sec/step)\n",
      "step 3219 - loss = 1.467, (1.345 sec/step)\n",
      "step 3220 - loss = 2.366, (1.882 sec/step)\n",
      "step 3221 - loss = 1.811, (1.750 sec/step)\n",
      "step 3222 - loss = 1.665, (2.700 sec/step)\n",
      "step 3223 - loss = 1.835, (1.033 sec/step)\n",
      "step 3224 - loss = 1.674, (1.616 sec/step)\n",
      "step 3225 - loss = 2.343, (1.576 sec/step)\n",
      "step 3226 - loss = 1.590, (0.980 sec/step)\n",
      "step 3227 - loss = 2.495, (1.762 sec/step)\n",
      "step 3228 - loss = 1.782, (1.304 sec/step)\n",
      "step 3229 - loss = 1.983, (1.600 sec/step)\n",
      "step 3230 - loss = 1.986, (1.819 sec/step)\n",
      "step 3231 - loss = 1.797, (2.486 sec/step)\n",
      "step 3232 - loss = 0.427, (0.695 sec/step)\n",
      "step 3233 - loss = 2.684, (2.485 sec/step)\n",
      "step 3234 - loss = 2.738, (2.034 sec/step)\n",
      "step 3235 - loss = 1.371, (1.280 sec/step)\n",
      "step 3236 - loss = 2.094, (1.422 sec/step)\n",
      "step 3237 - loss = 1.842, (1.357 sec/step)\n",
      "step 3238 - loss = 2.031, (1.158 sec/step)\n",
      "step 3239 - loss = 2.009, (1.802 sec/step)\n",
      "step 3240 - loss = 1.931, (2.764 sec/step)\n",
      "step 3241 - loss = 1.747, (1.471 sec/step)\n",
      "step 3242 - loss = 1.516, (0.956 sec/step)\n",
      "step 3243 - loss = 2.141, (0.960 sec/step)\n",
      "step 3244 - loss = 2.566, (1.131 sec/step)\n",
      "step 3245 - loss = 1.554, (2.123 sec/step)\n",
      "step 3246 - loss = 1.934, (1.887 sec/step)\n",
      "step 3247 - loss = 2.222, (1.422 sec/step)\n",
      "step 3248 - loss = 2.332, (1.545 sec/step)\n",
      "step 3249 - loss = 1.732, (1.392 sec/step)\n",
      "step 3250 - loss = 2.420, (2.484 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3251 - loss = 1.794, (2.683 sec/step)\n",
      "step 3252 - loss = 1.516, (1.163 sec/step)\n",
      "step 3253 - loss = 1.649, (1.635 sec/step)\n",
      "step 3254 - loss = 2.206, (1.201 sec/step)\n",
      "step 3255 - loss = 2.014, (1.131 sec/step)\n",
      "step 3256 - loss = 1.856, (2.745 sec/step)\n",
      "step 3257 - loss = 1.788, (1.393 sec/step)\n",
      "step 3258 - loss = 2.021, (1.417 sec/step)\n",
      "step 3259 - loss = 2.090, (1.092 sec/step)\n",
      "step 3260 - loss = 2.512, (1.423 sec/step)\n",
      "step 3261 - loss = 2.341, (1.604 sec/step)\n",
      "step 3262 - loss = 1.943, (1.126 sec/step)\n",
      "step 3263 - loss = 2.202, (1.693 sec/step)\n",
      "step 3264 - loss = 1.627, (1.274 sec/step)\n",
      "step 3265 - loss = 2.178, (1.552 sec/step)\n",
      "step 3266 - loss = 1.807, (1.098 sec/step)\n",
      "step 3267 - loss = 2.355, (1.350 sec/step)\n",
      "step 3268 - loss = 1.721, (1.953 sec/step)\n",
      "step 3269 - loss = 1.963, (2.523 sec/step)\n",
      "step 3270 - loss = 2.187, (2.207 sec/step)\n",
      "step 3271 - loss = 1.832, (1.604 sec/step)\n",
      "step 3272 - loss = 1.974, (2.759 sec/step)\n",
      "step 3273 - loss = 1.604, (1.029 sec/step)\n",
      "step 3274 - loss = 1.823, (2.100 sec/step)\n",
      "step 3275 - loss = 1.881, (0.930 sec/step)\n",
      "step 3276 - loss = 2.022, (1.519 sec/step)\n",
      "step 3277 - loss = 1.380, (1.210 sec/step)\n",
      "step 3278 - loss = 2.145, (1.705 sec/step)\n",
      "step 3279 - loss = 1.999, (1.741 sec/step)\n",
      "step 3280 - loss = 1.800, (1.070 sec/step)\n",
      "step 3281 - loss = 2.235, (1.409 sec/step)\n",
      "step 3282 - loss = 2.222, (2.484 sec/step)\n",
      "step 3283 - loss = 1.442, (4.932 sec/step)\n",
      "step 3284 - loss = 1.677, (1.652 sec/step)\n",
      "step 3285 - loss = 1.312, (2.584 sec/step)\n",
      "step 3286 - loss = 1.829, (1.663 sec/step)\n",
      "step 3287 - loss = 2.327, (1.846 sec/step)\n",
      "step 3288 - loss = 1.754, (1.815 sec/step)\n",
      "step 3289 - loss = 1.999, (1.666 sec/step)\n",
      "step 3290 - loss = 2.035, (2.903 sec/step)\n",
      "step 3291 - loss = 2.247, (2.218 sec/step)\n",
      "step 3292 - loss = 1.769, (2.296 sec/step)\n",
      "step 3293 - loss = 1.974, (1.550 sec/step)\n",
      "step 3294 - loss = 2.002, (1.612 sec/step)\n",
      "step 3295 - loss = 1.894, (1.070 sec/step)\n",
      "step 3296 - loss = 1.962, (2.484 sec/step)\n",
      "step 3297 - loss = 1.671, (1.151 sec/step)\n",
      "step 3298 - loss = 1.604, (2.318 sec/step)\n",
      "step 3299 - loss = 1.865, (2.629 sec/step)\n",
      "step 3300 - loss = 1.323, (0.835 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3301 - loss = 1.660, (2.449 sec/step)\n",
      "step 3302 - loss = 2.271, (1.346 sec/step)\n",
      "step 3303 - loss = 1.982, (1.102 sec/step)\n",
      "step 3304 - loss = 2.273, (2.487 sec/step)\n",
      "step 3305 - loss = 0.866, (0.466 sec/step)\n",
      "step 3306 - loss = 1.514, (1.989 sec/step)\n",
      "step 3307 - loss = 2.405, (1.523 sec/step)\n",
      "step 3308 - loss = 2.013, (1.174 sec/step)\n",
      "step 3309 - loss = 1.684, (0.954 sec/step)\n",
      "step 3310 - loss = 1.538, (1.183 sec/step)\n",
      "step 3311 - loss = 2.091, (1.050 sec/step)\n",
      "step 3312 - loss = 2.132, (1.665 sec/step)\n",
      "step 3313 - loss = 2.033, (1.258 sec/step)\n",
      "step 3314 - loss = 1.998, (2.423 sec/step)\n",
      "step 3315 - loss = 1.897, (1.649 sec/step)\n",
      "step 3316 - loss = 2.147, (1.328 sec/step)\n",
      "step 3317 - loss = 2.112, (1.456 sec/step)\n",
      "step 3318 - loss = 1.831, (1.419 sec/step)\n",
      "step 3319 - loss = 2.436, (1.401 sec/step)\n",
      "step 3320 - loss = 1.992, (1.596 sec/step)\n",
      "step 3321 - loss = 1.707, (1.471 sec/step)\n",
      "step 3322 - loss = 1.754, (1.509 sec/step)\n",
      "step 3323 - loss = 1.827, (1.095 sec/step)\n",
      "step 3324 - loss = 1.577, (1.231 sec/step)\n",
      "step 3325 - loss = 1.765, (0.927 sec/step)\n",
      "step 3326 - loss = 1.922, (0.894 sec/step)\n",
      "step 3327 - loss = 2.038, (1.982 sec/step)\n",
      "step 3328 - loss = 1.587, (3.430 sec/step)\n",
      "step 3329 - loss = 1.679, (1.199 sec/step)\n",
      "step 3330 - loss = 1.509, (1.370 sec/step)\n",
      "step 3331 - loss = 1.648, (1.483 sec/step)\n",
      "step 3332 - loss = 1.778, (2.348 sec/step)\n",
      "step 3333 - loss = 1.639, (2.740 sec/step)\n",
      "step 3334 - loss = 2.051, (2.370 sec/step)\n",
      "step 3335 - loss = 2.197, (2.655 sec/step)\n",
      "step 3336 - loss = 1.607, (1.201 sec/step)\n",
      "step 3337 - loss = 1.806, (1.155 sec/step)\n",
      "step 3338 - loss = 2.491, (2.144 sec/step)\n",
      "step 3339 - loss = 2.214, (1.256 sec/step)\n",
      "step 3340 - loss = 1.851, (1.884 sec/step)\n",
      "step 3341 - loss = 2.249, (2.752 sec/step)\n",
      "step 3342 - loss = 1.314, (1.484 sec/step)\n",
      "step 3343 - loss = 1.300, (1.125 sec/step)\n",
      "step 3344 - loss = 1.660, (1.537 sec/step)\n",
      "step 3345 - loss = 2.164, (1.114 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3346 - loss = 1.743, (1.863 sec/step)\n",
      "step 3347 - loss = 2.392, (3.063 sec/step)\n",
      "step 3348 - loss = 1.882, (1.729 sec/step)\n",
      "step 3349 - loss = 2.004, (2.597 sec/step)\n",
      "step 3350 - loss = 1.778, (1.271 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3351 - loss = 2.186, (2.488 sec/step)\n",
      "step 3352 - loss = 2.106, (1.229 sec/step)\n",
      "step 3353 - loss = 1.444, (1.393 sec/step)\n",
      "step 3354 - loss = 2.141, (1.195 sec/step)\n",
      "step 3355 - loss = 1.967, (1.266 sec/step)\n",
      "step 3356 - loss = 1.966, (1.936 sec/step)\n",
      "step 3357 - loss = 2.146, (1.705 sec/step)\n",
      "step 3358 - loss = 1.585, (1.581 sec/step)\n",
      "step 3359 - loss = 1.920, (1.383 sec/step)\n",
      "step 3360 - loss = 1.757, (1.462 sec/step)\n",
      "step 3361 - loss = 1.856, (2.535 sec/step)\n",
      "step 3362 - loss = 1.794, (1.316 sec/step)\n",
      "step 3363 - loss = 1.976, (1.293 sec/step)\n",
      "step 3364 - loss = 2.088, (1.762 sec/step)\n",
      "step 3365 - loss = 1.721, (2.485 sec/step)\n",
      "step 3366 - loss = 2.096, (2.073 sec/step)\n",
      "step 3367 - loss = 1.910, (1.955 sec/step)\n",
      "step 3368 - loss = 1.755, (2.449 sec/step)\n",
      "step 3369 - loss = 2.297, (2.620 sec/step)\n",
      "step 3370 - loss = 1.502, (1.070 sec/step)\n",
      "step 3371 - loss = 1.667, (1.752 sec/step)\n",
      "step 3372 - loss = 1.874, (1.917 sec/step)\n",
      "step 3373 - loss = 2.304, (1.784 sec/step)\n",
      "step 3374 - loss = 1.488, (1.170 sec/step)\n",
      "step 3375 - loss = 1.628, (1.031 sec/step)\n",
      "step 3376 - loss = 1.486, (1.069 sec/step)\n",
      "step 3377 - loss = 1.907, (1.796 sec/step)\n",
      "step 3378 - loss = 2.566, (1.112 sec/step)\n",
      "step 3379 - loss = 2.232, (2.131 sec/step)\n",
      "step 3380 - loss = 2.336, (1.398 sec/step)\n",
      "step 3381 - loss = 1.576, (3.612 sec/step)\n",
      "step 3382 - loss = 1.559, (1.888 sec/step)\n",
      "step 3383 - loss = 1.975, (1.095 sec/step)\n",
      "step 3384 - loss = 1.764, (1.910 sec/step)\n",
      "step 3385 - loss = 2.073, (2.257 sec/step)\n",
      "step 3386 - loss = 2.217, (2.488 sec/step)\n",
      "step 3387 - loss = 2.014, (1.176 sec/step)\n",
      "step 3388 - loss = 1.529, (1.397 sec/step)\n",
      "step 3389 - loss = 2.303, (2.037 sec/step)\n",
      "step 3390 - loss = 2.150, (2.670 sec/step)\n",
      "step 3391 - loss = 1.432, (1.456 sec/step)\n",
      "step 3392 - loss = 1.806, (1.086 sec/step)\n",
      "step 3393 - loss = 1.757, (1.205 sec/step)\n",
      "step 3394 - loss = 1.880, (1.202 sec/step)\n",
      "step 3395 - loss = 1.878, (0.943 sec/step)\n",
      "step 3396 - loss = 2.346, (2.262 sec/step)\n",
      "step 3397 - loss = 1.843, (1.814 sec/step)\n",
      "step 3398 - loss = 2.537, (1.542 sec/step)\n",
      "step 3399 - loss = 1.956, (1.661 sec/step)\n",
      "step 3400 - loss = 1.447, (2.028 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3401 - loss = 1.804, (1.950 sec/step)\n",
      "step 3402 - loss = 1.918, (0.999 sec/step)\n",
      "step 3403 - loss = 1.562, (0.967 sec/step)\n",
      "step 3404 - loss = 2.004, (2.459 sec/step)\n",
      "step 3405 - loss = 1.486, (2.046 sec/step)\n",
      "step 3406 - loss = 1.936, (1.461 sec/step)\n",
      "step 3407 - loss = 1.940, (1.052 sec/step)\n",
      "step 3408 - loss = 1.266, (1.701 sec/step)\n",
      "step 3409 - loss = 1.641, (1.424 sec/step)\n",
      "step 3410 - loss = 1.562, (1.503 sec/step)\n",
      "step 3411 - loss = 2.215, (1.654 sec/step)\n",
      "step 3412 - loss = 1.656, (0.970 sec/step)\n",
      "step 3413 - loss = 2.013, (1.310 sec/step)\n",
      "step 3414 - loss = 2.178, (2.673 sec/step)\n",
      "step 3415 - loss = 1.978, (1.213 sec/step)\n",
      "step 3416 - loss = 2.568, (1.584 sec/step)\n",
      "step 3417 - loss = 2.169, (1.795 sec/step)\n",
      "step 3418 - loss = 1.321, (2.532 sec/step)\n",
      "step 3419 - loss = 1.500, (1.664 sec/step)\n",
      "step 3420 - loss = 2.113, (1.361 sec/step)\n",
      "step 3421 - loss = 1.653, (1.813 sec/step)\n",
      "step 3422 - loss = 1.976, (1.991 sec/step)\n",
      "step 3423 - loss = 1.972, (1.575 sec/step)\n",
      "step 3424 - loss = 2.031, (1.773 sec/step)\n",
      "step 3425 - loss = 1.650, (2.093 sec/step)\n",
      "step 3426 - loss = 1.908, (1.459 sec/step)\n",
      "step 3427 - loss = 2.106, (1.703 sec/step)\n",
      "step 3428 - loss = 2.254, (1.609 sec/step)\n",
      "step 3429 - loss = 1.859, (1.262 sec/step)\n",
      "step 3430 - loss = 1.778, (1.614 sec/step)\n",
      "step 3431 - loss = 2.129, (1.640 sec/step)\n",
      "step 3432 - loss = 1.770, (1.637 sec/step)\n",
      "step 3433 - loss = 2.073, (2.716 sec/step)\n",
      "step 3434 - loss = 2.019, (1.497 sec/step)\n",
      "step 3435 - loss = 2.132, (2.668 sec/step)\n",
      "step 3436 - loss = 1.885, (1.480 sec/step)\n",
      "step 3437 - loss = 1.116, (1.456 sec/step)\n",
      "step 3438 - loss = 1.637, (1.127 sec/step)\n",
      "step 3439 - loss = 1.641, (1.190 sec/step)\n",
      "step 3440 - loss = 1.967, (1.862 sec/step)\n",
      "step 3441 - loss = 2.442, (1.785 sec/step)\n",
      "step 3442 - loss = 1.568, (1.439 sec/step)\n",
      "step 3443 - loss = 2.062, (1.829 sec/step)\n",
      "step 3444 - loss = 1.430, (1.458 sec/step)\n",
      "step 3445 - loss = 1.961, (1.953 sec/step)\n",
      "step 3446 - loss = 2.180, (1.773 sec/step)\n",
      "step 3447 - loss = 1.861, (1.189 sec/step)\n",
      "step 3448 - loss = 2.020, (2.485 sec/step)\n",
      "step 3449 - loss = 0.962, (1.397 sec/step)\n",
      "step 3450 - loss = 1.608, (3.737 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3451 - loss = 2.051, (2.483 sec/step)\n",
      "step 3452 - loss = 1.861, (1.182 sec/step)\n",
      "step 3453 - loss = 1.506, (1.280 sec/step)\n",
      "step 3454 - loss = 1.418, (1.089 sec/step)\n",
      "step 3455 - loss = 2.169, (2.484 sec/step)\n",
      "step 3456 - loss = 2.778, (2.725 sec/step)\n",
      "step 3457 - loss = 1.789, (3.291 sec/step)\n",
      "step 3458 - loss = 2.020, (1.990 sec/step)\n",
      "step 3459 - loss = 1.950, (1.345 sec/step)\n",
      "step 3460 - loss = 2.148, (1.408 sec/step)\n",
      "step 3461 - loss = 1.728, (1.386 sec/step)\n",
      "step 3462 - loss = 1.845, (1.373 sec/step)\n",
      "step 3463 - loss = 1.712, (2.165 sec/step)\n",
      "step 3464 - loss = 1.760, (1.757 sec/step)\n",
      "step 3465 - loss = 1.852, (1.164 sec/step)\n",
      "step 3466 - loss = 2.009, (0.986 sec/step)\n",
      "step 3467 - loss = 1.720, (1.152 sec/step)\n",
      "step 3468 - loss = 1.761, (1.164 sec/step)\n",
      "step 3469 - loss = 1.818, (2.756 sec/step)\n",
      "step 3470 - loss = 2.343, (1.274 sec/step)\n",
      "step 3471 - loss = 1.531, (1.412 sec/step)\n",
      "step 3472 - loss = 1.503, (2.129 sec/step)\n",
      "step 3473 - loss = 1.847, (1.343 sec/step)\n",
      "step 3474 - loss = 2.390, (1.392 sec/step)\n",
      "step 3475 - loss = 2.008, (2.484 sec/step)\n",
      "step 3476 - loss = 2.086, (1.060 sec/step)\n",
      "step 3477 - loss = 1.845, (1.199 sec/step)\n",
      "step 3478 - loss = 2.564, (1.857 sec/step)\n",
      "step 3479 - loss = 1.750, (1.090 sec/step)\n",
      "step 3480 - loss = 1.844, (1.447 sec/step)\n",
      "step 3481 - loss = 1.539, (2.175 sec/step)\n",
      "step 3482 - loss = 1.579, (1.279 sec/step)\n",
      "step 3483 - loss = 2.279, (1.952 sec/step)\n",
      "step 3484 - loss = 2.169, (1.514 sec/step)\n",
      "step 3485 - loss = 1.718, (2.701 sec/step)\n",
      "step 3486 - loss = 1.650, (1.113 sec/step)\n",
      "step 3487 - loss = 2.117, (1.643 sec/step)\n",
      "step 3488 - loss = 2.050, (1.308 sec/step)\n",
      "step 3489 - loss = 1.908, (1.281 sec/step)\n",
      "step 3490 - loss = 2.037, (1.948 sec/step)\n",
      "step 3491 - loss = 1.525, (1.787 sec/step)\n",
      "step 3492 - loss = 1.895, (1.448 sec/step)\n",
      "step 3493 - loss = 1.720, (1.279 sec/step)\n",
      "step 3494 - loss = 1.972, (1.422 sec/step)\n",
      "step 3495 - loss = 2.029, (2.322 sec/step)\n",
      "step 3496 - loss = 1.348, (1.144 sec/step)\n",
      "step 3497 - loss = 1.888, (1.446 sec/step)\n",
      "step 3498 - loss = 2.169, (1.548 sec/step)\n",
      "step 3499 - loss = 1.783, (1.356 sec/step)\n",
      "step 3500 - loss = 2.277, (1.487 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3501 - loss = 1.669, (1.540 sec/step)\n",
      "step 3502 - loss = 2.428, (2.130 sec/step)\n",
      "step 3503 - loss = 2.265, (1.126 sec/step)\n",
      "step 3504 - loss = 1.884, (0.961 sec/step)\n",
      "step 3505 - loss = 1.894, (1.815 sec/step)\n",
      "step 3506 - loss = 1.662, (2.591 sec/step)\n",
      "step 3507 - loss = 1.353, (2.820 sec/step)\n",
      "step 3508 - loss = 2.087, (1.209 sec/step)\n",
      "step 3509 - loss = 1.749, (2.058 sec/step)\n",
      "step 3510 - loss = 2.400, (2.634 sec/step)\n",
      "step 3511 - loss = 1.457, (1.123 sec/step)\n",
      "step 3512 - loss = 1.484, (0.837 sec/step)\n",
      "step 3513 - loss = 2.071, (2.139 sec/step)\n",
      "step 3514 - loss = 1.671, (1.377 sec/step)\n",
      "step 3515 - loss = 1.770, (1.179 sec/step)\n",
      "step 3516 - loss = 2.342, (1.229 sec/step)\n",
      "step 3517 - loss = 2.338, (3.196 sec/step)\n",
      "step 3518 - loss = 2.420, (1.762 sec/step)\n",
      "step 3519 - loss = 1.440, (1.288 sec/step)\n",
      "step 3520 - loss = 1.863, (1.487 sec/step)\n",
      "step 3521 - loss = 1.464, (2.050 sec/step)\n",
      "step 3522 - loss = 1.817, (1.656 sec/step)\n",
      "step 3523 - loss = 1.833, (0.977 sec/step)\n",
      "step 3524 - loss = 1.438, (1.650 sec/step)\n",
      "step 3525 - loss = 1.945, (1.450 sec/step)\n",
      "step 3526 - loss = 2.090, (2.042 sec/step)\n",
      "step 3527 - loss = 1.729, (1.260 sec/step)\n",
      "step 3528 - loss = 1.226, (1.278 sec/step)\n",
      "step 3529 - loss = 1.984, (1.154 sec/step)\n",
      "step 3530 - loss = 2.490, (2.486 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3531 - loss = 2.291, (2.124 sec/step)\n",
      "step 3532 - loss = 2.059, (1.831 sec/step)\n",
      "step 3533 - loss = 2.530, (2.557 sec/step)\n",
      "step 3534 - loss = 2.148, (1.227 sec/step)\n",
      "step 3535 - loss = 1.999, (2.094 sec/step)\n",
      "step 3536 - loss = 1.728, (1.731 sec/step)\n",
      "step 3537 - loss = 2.207, (2.795 sec/step)\n",
      "step 3538 - loss = 1.817, (1.299 sec/step)\n",
      "step 3539 - loss = 1.552, (1.461 sec/step)\n",
      "step 3540 - loss = 2.593, (2.487 sec/step)\n",
      "step 3541 - loss = 2.553, (1.668 sec/step)\n",
      "step 3542 - loss = 1.836, (2.053 sec/step)\n",
      "step 3543 - loss = 1.864, (1.308 sec/step)\n",
      "step 3544 - loss = 1.612, (2.740 sec/step)\n",
      "step 3545 - loss = 1.927, (1.228 sec/step)\n",
      "step 3546 - loss = 2.088, (1.161 sec/step)\n",
      "step 3547 - loss = 1.798, (1.052 sec/step)\n",
      "step 3548 - loss = 2.315, (1.635 sec/step)\n",
      "step 3549 - loss = 2.252, (2.574 sec/step)\n",
      "step 3550 - loss = 2.147, (1.683 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3551 - loss = 2.297, (1.260 sec/step)\n",
      "step 3552 - loss = 2.006, (1.984 sec/step)\n",
      "step 3553 - loss = 1.631, (1.291 sec/step)\n",
      "step 3554 - loss = 2.085, (1.145 sec/step)\n",
      "step 3555 - loss = 1.716, (0.915 sec/step)\n",
      "step 3556 - loss = 1.712, (1.492 sec/step)\n",
      "step 3557 - loss = 2.117, (1.930 sec/step)\n",
      "step 3558 - loss = 2.032, (1.842 sec/step)\n",
      "step 3559 - loss = 1.903, (1.710 sec/step)\n",
      "step 3560 - loss = 1.514, (0.954 sec/step)\n",
      "step 3561 - loss = 1.926, (1.570 sec/step)\n",
      "step 3562 - loss = 1.559, (1.199 sec/step)\n",
      "step 3563 - loss = 2.236, (2.485 sec/step)\n",
      "step 3564 - loss = 0.568, (1.977 sec/step)\n",
      "step 3565 - loss = 1.778, (1.260 sec/step)\n",
      "step 3566 - loss = 2.081, (0.986 sec/step)\n",
      "step 3567 - loss = 1.184, (2.688 sec/step)\n",
      "step 3568 - loss = 1.954, (2.045 sec/step)\n",
      "step 3569 - loss = 2.156, (1.088 sec/step)\n",
      "step 3570 - loss = 1.931, (2.036 sec/step)\n",
      "step 3571 - loss = 2.103, (1.740 sec/step)\n",
      "step 3572 - loss = 2.293, (1.714 sec/step)\n",
      "step 3573 - loss = 1.418, (1.182 sec/step)\n",
      "step 3574 - loss = 1.984, (1.424 sec/step)\n",
      "step 3575 - loss = 1.796, (1.313 sec/step)\n",
      "step 3576 - loss = 1.972, (1.677 sec/step)\n",
      "step 3577 - loss = 1.939, (1.654 sec/step)\n",
      "step 3578 - loss = 2.354, (1.767 sec/step)\n",
      "step 3579 - loss = 1.957, (2.180 sec/step)\n",
      "step 3580 - loss = 1.444, (2.459 sec/step)\n",
      "step 3581 - loss = 1.939, (1.517 sec/step)\n",
      "step 3582 - loss = 1.229, (1.785 sec/step)\n",
      "step 3583 - loss = 2.004, (1.540 sec/step)\n",
      "step 3584 - loss = 2.320, (2.927 sec/step)\n",
      "step 3585 - loss = 2.116, (2.483 sec/step)\n",
      "step 3586 - loss = 1.080, (0.713 sec/step)\n",
      "step 3587 - loss = 1.820, (2.920 sec/step)\n",
      "step 3588 - loss = 1.719, (1.381 sec/step)\n",
      "step 3589 - loss = 2.419, (1.710 sec/step)\n",
      "step 3590 - loss = 1.647, (1.034 sec/step)\n",
      "step 3591 - loss = 1.821, (2.427 sec/step)\n",
      "step 3592 - loss = 2.076, (1.500 sec/step)\n",
      "step 3593 - loss = 2.010, (1.465 sec/step)\n",
      "step 3594 - loss = 2.163, (2.762 sec/step)\n",
      "step 3595 - loss = 2.425, (1.408 sec/step)\n",
      "step 3596 - loss = 2.340, (1.442 sec/step)\n",
      "step 3597 - loss = 1.697, (1.524 sec/step)\n",
      "step 3598 - loss = 1.740, (3.345 sec/step)\n",
      "step 3599 - loss = 1.628, (1.160 sec/step)\n",
      "step 3600 - loss = 1.387, (1.291 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3601 - loss = 1.706, (1.214 sec/step)\n",
      "step 3602 - loss = 1.719, (2.452 sec/step)\n",
      "step 3603 - loss = 2.220, (1.423 sec/step)\n",
      "step 3604 - loss = 1.667, (1.222 sec/step)\n",
      "step 3605 - loss = 1.551, (1.871 sec/step)\n",
      "step 3606 - loss = 2.162, (2.172 sec/step)\n",
      "step 3607 - loss = 1.729, (2.483 sec/step)\n",
      "step 3608 - loss = 0.584, (0.767 sec/step)\n",
      "step 3609 - loss = 1.525, (1.381 sec/step)\n",
      "step 3610 - loss = 1.717, (1.702 sec/step)\n",
      "step 3611 - loss = 1.845, (1.225 sec/step)\n",
      "step 3612 - loss = 1.361, (1.353 sec/step)\n",
      "step 3613 - loss = 1.112, (1.962 sec/step)\n",
      "step 3614 - loss = 1.953, (1.559 sec/step)\n",
      "step 3615 - loss = 1.795, (1.833 sec/step)\n",
      "step 3616 - loss = 1.194, (1.651 sec/step)\n",
      "step 3617 - loss = 1.930, (1.314 sec/step)\n",
      "step 3618 - loss = 1.878, (2.341 sec/step)\n",
      "step 3619 - loss = 2.448, (1.292 sec/step)\n",
      "step 3620 - loss = 2.464, (1.229 sec/step)\n",
      "step 3621 - loss = 2.105, (1.745 sec/step)\n",
      "step 3622 - loss = 1.833, (1.113 sec/step)\n",
      "step 3623 - loss = 1.650, (2.656 sec/step)\n",
      "step 3624 - loss = 1.805, (1.156 sec/step)\n",
      "step 3625 - loss = 1.400, (1.827 sec/step)\n",
      "step 3626 - loss = 1.696, (2.859 sec/step)\n",
      "step 3627 - loss = 1.617, (1.032 sec/step)\n",
      "step 3628 - loss = 2.045, (1.219 sec/step)\n",
      "step 3629 - loss = 2.475, (0.958 sec/step)\n",
      "step 3630 - loss = 2.422, (1.342 sec/step)\n",
      "step 3631 - loss = 1.999, (1.715 sec/step)\n",
      "step 3632 - loss = 1.506, (1.159 sec/step)\n",
      "step 3633 - loss = 1.879, (1.125 sec/step)\n",
      "step 3634 - loss = 2.140, (1.946 sec/step)\n",
      "step 3635 - loss = 1.881, (1.806 sec/step)\n",
      "step 3636 - loss = 1.971, (1.146 sec/step)\n",
      "step 3637 - loss = 2.296, (1.677 sec/step)\n",
      "step 3638 - loss = 1.880, (2.808 sec/step)\n",
      "step 3639 - loss = 1.592, (0.997 sec/step)\n",
      "step 3640 - loss = 1.638, (2.080 sec/step)\n",
      "step 3641 - loss = 1.957, (2.484 sec/step)\n",
      "step 3642 - loss = 0.875, (1.282 sec/step)\n",
      "step 3643 - loss = 2.014, (1.705 sec/step)\n",
      "step 3644 - loss = 1.994, (1.301 sec/step)\n",
      "step 3645 - loss = 1.885, (2.738 sec/step)\n",
      "step 3646 - loss = 1.518, (1.047 sec/step)\n",
      "step 3647 - loss = 1.993, (1.086 sec/step)\n",
      "step 3648 - loss = 2.161, (1.621 sec/step)\n",
      "step 3649 - loss = 1.871, (1.792 sec/step)\n",
      "step 3650 - loss = 2.398, (3.204 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3651 - loss = 1.951, (1.556 sec/step)\n",
      "step 3652 - loss = 2.253, (0.968 sec/step)\n",
      "step 3653 - loss = 2.720, (2.343 sec/step)\n",
      "step 3654 - loss = 1.889, (1.177 sec/step)\n",
      "step 3655 - loss = 2.385, (2.484 sec/step)\n",
      "step 3656 - loss = 0.651, (0.477 sec/step)\n",
      "step 3657 - loss = 1.821, (1.065 sec/step)\n",
      "step 3658 - loss = 1.526, (2.046 sec/step)\n",
      "step 3659 - loss = 1.422, (0.970 sec/step)\n",
      "step 3660 - loss = 1.540, (1.215 sec/step)\n",
      "step 3661 - loss = 2.284, (2.113 sec/step)\n",
      "step 3662 - loss = 1.886, (1.178 sec/step)\n",
      "step 3663 - loss = 2.022, (1.151 sec/step)\n",
      "step 3664 - loss = 1.704, (1.344 sec/step)\n",
      "step 3665 - loss = 2.082, (1.462 sec/step)\n",
      "step 3666 - loss = 2.304, (2.281 sec/step)\n",
      "step 3667 - loss = 2.288, (2.486 sec/step)\n",
      "step 3668 - loss = 2.371, (2.668 sec/step)\n",
      "step 3669 - loss = 1.984, (2.104 sec/step)\n",
      "step 3670 - loss = 2.099, (1.834 sec/step)\n",
      "step 3671 - loss = 1.580, (1.571 sec/step)\n",
      "step 3672 - loss = 2.565, (2.489 sec/step)\n",
      "step 3673 - loss = 1.947, (1.464 sec/step)\n",
      "step 3674 - loss = 1.866, (2.234 sec/step)\n",
      "step 3675 - loss = 2.356, (1.764 sec/step)\n",
      "step 3676 - loss = 1.641, (1.514 sec/step)\n",
      "step 3677 - loss = 1.949, (1.523 sec/step)\n",
      "step 3678 - loss = 2.381, (2.589 sec/step)\n",
      "step 3679 - loss = 1.527, (2.109 sec/step)\n",
      "step 3680 - loss = 1.735, (2.660 sec/step)\n",
      "step 3681 - loss = 2.228, (2.111 sec/step)\n",
      "step 3682 - loss = 1.743, (1.245 sec/step)\n",
      "step 3683 - loss = 1.926, (1.128 sec/step)\n",
      "step 3684 - loss = 2.478, (3.513 sec/step)\n",
      "step 3685 - loss = 1.367, (3.150 sec/step)\n",
      "step 3686 - loss = 1.877, (1.180 sec/step)\n",
      "step 3687 - loss = 1.435, (1.208 sec/step)\n",
      "step 3688 - loss = 1.596, (2.059 sec/step)\n",
      "step 3689 - loss = 2.232, (1.987 sec/step)\n",
      "step 3690 - loss = 2.179, (1.888 sec/step)\n",
      "step 3691 - loss = 1.644, (1.012 sec/step)\n",
      "step 3692 - loss = 2.012, (2.486 sec/step)\n",
      "step 3693 - loss = 0.678, (0.389 sec/step)\n",
      "step 3694 - loss = 1.197, (1.311 sec/step)\n",
      "step 3695 - loss = 1.780, (2.042 sec/step)\n",
      "step 3696 - loss = 2.173, (1.572 sec/step)\n",
      "step 3697 - loss = 2.422, (1.602 sec/step)\n",
      "step 3698 - loss = 1.536, (1.561 sec/step)\n",
      "step 3699 - loss = 1.868, (1.961 sec/step)\n",
      "step 3700 - loss = 1.522, (2.093 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3701 - loss = 1.690, (1.126 sec/step)\n",
      "step 3702 - loss = 1.835, (1.334 sec/step)\n",
      "step 3703 - loss = 2.087, (1.293 sec/step)\n",
      "step 3704 - loss = 2.066, (0.758 sec/step)\n",
      "step 3705 - loss = 2.189, (1.314 sec/step)\n",
      "step 3706 - loss = 1.455, (1.537 sec/step)\n",
      "step 3707 - loss = 2.169, (1.383 sec/step)\n",
      "step 3708 - loss = 1.565, (1.403 sec/step)\n",
      "step 3709 - loss = 1.556, (2.067 sec/step)\n",
      "step 3710 - loss = 1.880, (1.329 sec/step)\n",
      "step 3711 - loss = 1.681, (1.355 sec/step)\n",
      "step 3712 - loss = 1.300, (1.167 sec/step)\n",
      "step 3713 - loss = 1.411, (2.465 sec/step)\n",
      "step 3714 - loss = 2.301, (1.766 sec/step)\n",
      "step 3715 - loss = 2.063, (1.027 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3716 - loss = 2.121, (1.163 sec/step)\n",
      "step 3717 - loss = 1.791, (0.910 sec/step)\n",
      "step 3718 - loss = 1.616, (1.554 sec/step)\n",
      "step 3719 - loss = 2.423, (1.476 sec/step)\n",
      "step 3720 - loss = 1.945, (2.341 sec/step)\n",
      "step 3721 - loss = 2.332, (2.483 sec/step)\n",
      "step 3722 - loss = 2.697, (2.346 sec/step)\n",
      "step 3723 - loss = 1.662, (2.680 sec/step)\n",
      "step 3724 - loss = 2.144, (1.670 sec/step)\n",
      "step 3725 - loss = 1.044, (2.324 sec/step)\n",
      "step 3726 - loss = 1.662, (1.571 sec/step)\n",
      "step 3727 - loss = 1.468, (0.976 sec/step)\n",
      "step 3728 - loss = 1.822, (0.863 sec/step)\n",
      "step 3729 - loss = 1.971, (1.225 sec/step)\n",
      "step 3730 - loss = 2.070, (1.194 sec/step)\n",
      "step 3731 - loss = 2.245, (1.443 sec/step)\n",
      "step 3732 - loss = 1.631, (1.068 sec/step)\n",
      "step 3733 - loss = 2.452, (3.555 sec/step)\n",
      "step 3734 - loss = 1.356, (2.168 sec/step)\n",
      "step 3735 - loss = 2.079, (1.926 sec/step)\n",
      "step 3736 - loss = 1.937, (1.456 sec/step)\n",
      "step 3737 - loss = 2.254, (1.385 sec/step)\n",
      "step 3738 - loss = 2.040, (1.260 sec/step)\n",
      "step 3739 - loss = 1.882, (1.508 sec/step)\n",
      "step 3740 - loss = 2.279, (3.368 sec/step)\n",
      "step 3741 - loss = 1.515, (1.159 sec/step)\n",
      "step 3742 - loss = 2.185, (2.040 sec/step)\n",
      "step 3743 - loss = 1.708, (0.949 sec/step)\n",
      "step 3744 - loss = 2.051, (1.229 sec/step)\n",
      "step 3745 - loss = 2.317, (1.542 sec/step)\n",
      "step 3746 - loss = 1.441, (1.420 sec/step)\n",
      "step 3747 - loss = 1.998, (2.469 sec/step)\n",
      "step 3748 - loss = 1.175, (1.360 sec/step)\n",
      "step 3749 - loss = 1.699, (3.558 sec/step)\n",
      "step 3750 - loss = 2.187, (2.541 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3751 - loss = 1.151, (2.272 sec/step)\n",
      "step 3752 - loss = 1.475, (2.817 sec/step)\n",
      "step 3753 - loss = 2.118, (2.643 sec/step)\n",
      "step 3754 - loss = 2.278, (2.361 sec/step)\n",
      "step 3755 - loss = 2.473, (1.588 sec/step)\n",
      "step 3756 - loss = 1.467, (1.067 sec/step)\n",
      "step 3757 - loss = 2.004, (2.039 sec/step)\n",
      "step 3758 - loss = 2.441, (1.869 sec/step)\n",
      "step 3759 - loss = 2.472, (2.484 sec/step)\n",
      "step 3760 - loss = 1.202, (1.345 sec/step)\n",
      "step 3761 - loss = 2.001, (1.445 sec/step)\n",
      "step 3762 - loss = 1.971, (1.123 sec/step)\n",
      "step 3763 - loss = 2.008, (1.927 sec/step)\n",
      "step 3764 - loss = 2.009, (1.177 sec/step)\n",
      "step 3765 - loss = 2.239, (1.572 sec/step)\n",
      "step 3766 - loss = 1.543, (1.362 sec/step)\n",
      "step 3767 - loss = 1.709, (1.361 sec/step)\n",
      "step 3768 - loss = 2.147, (1.244 sec/step)\n",
      "step 3769 - loss = 1.866, (1.601 sec/step)\n",
      "step 3770 - loss = 2.070, (1.540 sec/step)\n",
      "step 3771 - loss = 1.876, (1.568 sec/step)\n",
      "step 3772 - loss = 2.314, (2.478 sec/step)\n",
      "step 3773 - loss = 2.512, (1.130 sec/step)\n",
      "step 3774 - loss = 1.316, (2.399 sec/step)\n",
      "step 3775 - loss = 1.879, (1.251 sec/step)\n",
      "step 3776 - loss = 1.764, (1.488 sec/step)\n",
      "step 3777 - loss = 1.747, (1.523 sec/step)\n",
      "step 3778 - loss = 1.680, (1.286 sec/step)\n",
      "step 3779 - loss = 1.781, (1.861 sec/step)\n",
      "step 3780 - loss = 2.227, (1.589 sec/step)\n",
      "step 3781 - loss = 2.227, (1.357 sec/step)\n",
      "step 3782 - loss = 2.352, (2.483 sec/step)\n",
      "step 3783 - loss = 0.706, (0.824 sec/step)\n",
      "step 3784 - loss = 2.123, (1.049 sec/step)\n",
      "step 3785 - loss = 1.954, (1.198 sec/step)\n",
      "step 3786 - loss = 2.143, (2.987 sec/step)\n",
      "step 3787 - loss = 1.731, (1.388 sec/step)\n",
      "step 3788 - loss = 2.060, (1.304 sec/step)\n",
      "step 3789 - loss = 1.960, (1.199 sec/step)\n",
      "step 3790 - loss = 1.856, (1.075 sec/step)\n",
      "step 3791 - loss = 1.961, (2.118 sec/step)\n",
      "step 3792 - loss = 1.905, (1.652 sec/step)\n",
      "step 3793 - loss = 1.692, (1.695 sec/step)\n",
      "step 3794 - loss = 1.931, (0.957 sec/step)\n",
      "step 3795 - loss = 1.386, (2.484 sec/step)\n",
      "step 3796 - loss = 0.732, (1.194 sec/step)\n",
      "step 3797 - loss = 1.952, (1.256 sec/step)\n",
      "step 3798 - loss = 1.593, (1.115 sec/step)\n",
      "step 3799 - loss = 2.043, (2.161 sec/step)\n",
      "step 3800 - loss = 1.553, (1.367 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3801 - loss = 1.786, (1.557 sec/step)\n",
      "step 3802 - loss = 1.857, (1.905 sec/step)\n",
      "step 3803 - loss = 2.206, (1.447 sec/step)\n",
      "step 3804 - loss = 2.127, (1.185 sec/step)\n",
      "step 3805 - loss = 2.308, (2.375 sec/step)\n",
      "step 3806 - loss = 2.295, (1.979 sec/step)\n",
      "step 3807 - loss = 1.981, (1.387 sec/step)\n",
      "step 3808 - loss = 1.750, (2.919 sec/step)\n",
      "step 3809 - loss = 1.801, (1.163 sec/step)\n",
      "step 3810 - loss = 1.934, (1.892 sec/step)\n",
      "step 3811 - loss = 1.252, (1.563 sec/step)\n",
      "step 3812 - loss = 2.014, (2.334 sec/step)\n",
      "step 3813 - loss = 1.611, (1.381 sec/step)\n",
      "step 3814 - loss = 2.126, (2.577 sec/step)\n",
      "step 3815 - loss = 1.861, (1.238 sec/step)\n",
      "step 3816 - loss = 1.201, (1.259 sec/step)\n",
      "step 3817 - loss = 2.064, (1.552 sec/step)\n",
      "step 3818 - loss = 1.784, (1.584 sec/step)\n",
      "step 3819 - loss = 2.251, (2.511 sec/step)\n",
      "step 3820 - loss = 1.640, (1.420 sec/step)\n",
      "step 3821 - loss = 1.528, (2.258 sec/step)\n",
      "step 3822 - loss = 1.885, (1.649 sec/step)\n",
      "step 3823 - loss = 1.955, (2.202 sec/step)\n",
      "step 3824 - loss = 1.701, (0.858 sec/step)\n",
      "step 3825 - loss = 2.496, (0.942 sec/step)\n",
      "step 3826 - loss = 1.633, (1.740 sec/step)\n",
      "step 3827 - loss = 1.960, (2.812 sec/step)\n",
      "step 3828 - loss = 1.514, (2.264 sec/step)\n",
      "step 3829 - loss = 1.831, (1.342 sec/step)\n",
      "step 3830 - loss = 2.237, (1.914 sec/step)\n",
      "step 3831 - loss = 1.710, (1.054 sec/step)\n",
      "step 3832 - loss = 1.887, (2.487 sec/step)\n",
      "step 3833 - loss = 1.496, (2.726 sec/step)\n",
      "step 3834 - loss = 2.046, (1.385 sec/step)\n",
      "step 3835 - loss = 1.414, (1.464 sec/step)\n",
      "step 3836 - loss = 2.727, (2.871 sec/step)\n",
      "step 3837 - loss = 2.174, (1.098 sec/step)\n",
      "step 3838 - loss = 1.597, (1.568 sec/step)\n",
      "step 3839 - loss = 2.236, (1.298 sec/step)\n",
      "step 3840 - loss = 1.430, (1.231 sec/step)\n",
      "step 3841 - loss = 1.687, (1.163 sec/step)\n",
      "step 3842 - loss = 1.747, (1.086 sec/step)\n",
      "step 3843 - loss = 1.614, (1.681 sec/step)\n",
      "step 3844 - loss = 1.439, (1.388 sec/step)\n",
      "step 3845 - loss = 2.119, (3.093 sec/step)\n",
      "step 3846 - loss = 2.456, (1.597 sec/step)\n",
      "step 3847 - loss = 1.802, (2.027 sec/step)\n",
      "step 3848 - loss = 2.259, (2.255 sec/step)\n",
      "step 3849 - loss = 1.855, (1.158 sec/step)\n",
      "step 3850 - loss = 1.780, (2.287 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3851 - loss = 1.453, (2.656 sec/step)\n",
      "step 3852 - loss = 1.331, (2.485 sec/step)\n",
      "step 3853 - loss = 0.715, (0.153 sec/step)\n",
      "step 3854 - loss = 2.824, (1.785 sec/step)\n",
      "step 3855 - loss = 1.237, (3.150 sec/step)\n",
      "step 3856 - loss = 2.319, (1.345 sec/step)\n",
      "step 3857 - loss = 1.554, (1.555 sec/step)\n",
      "step 3858 - loss = 1.820, (2.023 sec/step)\n",
      "step 3859 - loss = 2.140, (1.321 sec/step)\n",
      "step 3860 - loss = 2.145, (1.749 sec/step)\n",
      "step 3861 - loss = 1.890, (1.899 sec/step)\n",
      "step 3862 - loss = 1.627, (1.471 sec/step)\n",
      "step 3863 - loss = 1.830, (2.795 sec/step)\n",
      "step 3864 - loss = 1.489, (1.643 sec/step)\n",
      "step 3865 - loss = 2.477, (2.485 sec/step)\n",
      "step 3866 - loss = 2.327, (2.301 sec/step)\n",
      "step 3867 - loss = 1.574, (1.486 sec/step)\n",
      "step 3868 - loss = 1.765, (2.765 sec/step)\n",
      "step 3869 - loss = 2.012, (1.880 sec/step)\n",
      "step 3870 - loss = 2.334, (2.486 sec/step)\n",
      "step 3871 - loss = 0.549, (0.979 sec/step)\n",
      "step 3872 - loss = 2.589, (2.487 sec/step)\n",
      "step 3873 - loss = 1.080, (1.794 sec/step)\n",
      "step 3874 - loss = 2.324, (2.694 sec/step)\n",
      "step 3875 - loss = 1.840, (1.939 sec/step)\n",
      "step 3876 - loss = 2.047, (0.930 sec/step)\n",
      "step 3877 - loss = 1.634, (1.822 sec/step)\n",
      "step 3878 - loss = 1.445, (2.642 sec/step)\n",
      "step 3879 - loss = 2.714, (2.485 sec/step)\n",
      "step 3880 - loss = 1.950, (2.294 sec/step)\n",
      "step 3881 - loss = 2.051, (2.627 sec/step)\n",
      "step 3882 - loss = 1.916, (1.397 sec/step)\n",
      "step 3883 - loss = 2.065, (1.552 sec/step)\n",
      "step 3884 - loss = 2.046, (1.396 sec/step)\n",
      "step 3885 - loss = 2.197, (3.593 sec/step)\n",
      "step 3886 - loss = 1.698, (0.775 sec/step)\n",
      "step 3887 - loss = 1.699, (1.180 sec/step)\n",
      "step 3888 - loss = 1.701, (0.868 sec/step)\n",
      "step 3889 - loss = 1.614, (1.811 sec/step)\n",
      "step 3890 - loss = 1.299, (1.202 sec/step)\n",
      "step 3891 - loss = 1.718, (0.800 sec/step)\n",
      "step 3892 - loss = 1.277, (1.987 sec/step)\n",
      "step 3893 - loss = 2.212, (1.413 sec/step)\n",
      "step 3894 - loss = 1.490, (2.486 sec/step)\n",
      "step 3895 - loss = 2.733, (3.349 sec/step)\n",
      "step 3896 - loss = 1.559, (2.008 sec/step)\n",
      "step 3897 - loss = 1.228, (2.482 sec/step)\n",
      "step 3898 - loss = 0.674, (1.325 sec/step)\n",
      "step 3899 - loss = 2.869, (1.003 sec/step)\n",
      "step 3900 - loss = 2.311, (1.210 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3901 - loss = 1.228, (1.839 sec/step)\n",
      "step 3902 - loss = 1.563, (2.300 sec/step)\n",
      "step 3903 - loss = 2.179, (2.152 sec/step)\n",
      "step 3904 - loss = 2.172, (1.034 sec/step)\n",
      "step 3905 - loss = 1.812, (1.520 sec/step)\n",
      "step 3906 - loss = 2.028, (1.228 sec/step)\n",
      "step 3907 - loss = 1.956, (1.360 sec/step)\n",
      "step 3908 - loss = 1.695, (1.100 sec/step)\n",
      "step 3909 - loss = 2.333, (2.486 sec/step)\n",
      "step 3910 - loss = 2.966, (1.778 sec/step)\n",
      "step 3911 - loss = 1.234, (2.268 sec/step)\n",
      "step 3912 - loss = 2.238, (1.189 sec/step)\n",
      "step 3913 - loss = 1.585, (2.217 sec/step)\n",
      "step 3914 - loss = 1.638, (2.665 sec/step)\n",
      "step 3915 - loss = 1.868, (1.088 sec/step)\n",
      "step 3916 - loss = 2.366, (1.764 sec/step)\n",
      "step 3917 - loss = 2.042, (1.470 sec/step)\n",
      "step 3918 - loss = 1.705, (1.291 sec/step)\n",
      "step 3919 - loss = 1.761, (1.571 sec/step)\n",
      "step 3920 - loss = 1.572, (1.202 sec/step)\n",
      "step 3921 - loss = 1.531, (1.745 sec/step)\n",
      "step 3922 - loss = 1.806, (1.810 sec/step)\n",
      "step 3923 - loss = 1.398, (1.142 sec/step)\n",
      "step 3924 - loss = 2.033, (1.600 sec/step)\n",
      "step 3925 - loss = 1.520, (1.845 sec/step)\n",
      "step 3926 - loss = 1.927, (1.408 sec/step)\n",
      "step 3927 - loss = 1.236, (1.233 sec/step)\n",
      "step 3928 - loss = 2.089, (1.525 sec/step)\n",
      "step 3929 - loss = 1.745, (1.111 sec/step)\n",
      "step 3930 - loss = 2.192, (2.482 sec/step)\n",
      "step 3931 - loss = 1.207, (0.305 sec/step)\n",
      "step 3932 - loss = 2.082, (1.227 sec/step)\n",
      "step 3933 - loss = 1.926, (1.387 sec/step)\n",
      "step 3934 - loss = 2.081, (1.215 sec/step)\n",
      "step 3935 - loss = 2.329, (1.358 sec/step)\n",
      "step 3936 - loss = 2.382, (2.622 sec/step)\n",
      "step 3937 - loss = 1.592, (1.279 sec/step)\n",
      "step 3938 - loss = 2.508, (1.715 sec/step)\n",
      "step 3939 - loss = 1.536, (1.988 sec/step)\n",
      "step 3940 - loss = 2.415, (1.372 sec/step)\n",
      "step 3941 - loss = 2.103, (1.431 sec/step)\n",
      "step 3942 - loss = 1.748, (1.815 sec/step)\n",
      "step 3943 - loss = 1.963, (2.121 sec/step)\n",
      "step 3944 - loss = 1.898, (1.893 sec/step)\n",
      "step 3945 - loss = 2.602, (0.854 sec/step)\n",
      "step 3946 - loss = 2.678, (1.126 sec/step)\n",
      "step 3947 - loss = 2.264, (1.920 sec/step)\n",
      "step 3948 - loss = 1.880, (1.415 sec/step)\n",
      "step 3949 - loss = 2.154, (1.131 sec/step)\n",
      "step 3950 - loss = 1.818, (1.692 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 3951 - loss = 1.383, (2.483 sec/step)\n",
      "step 3952 - loss = 0.630, (2.658 sec/step)\n",
      "step 3953 - loss = 2.639, (1.196 sec/step)\n",
      "step 3954 - loss = 1.834, (1.394 sec/step)\n",
      "step 3955 - loss = 2.206, (1.598 sec/step)\n",
      "step 3956 - loss = 1.636, (2.698 sec/step)\n",
      "step 3957 - loss = 2.010, (2.487 sec/step)\n",
      "step 3958 - loss = 0.619, (0.157 sec/step)\n",
      "step 3959 - loss = 2.357, (1.634 sec/step)\n",
      "step 3960 - loss = 2.886, (0.989 sec/step)\n",
      "step 3961 - loss = 1.711, (1.963 sec/step)\n",
      "step 3962 - loss = 1.793, (2.005 sec/step)\n",
      "step 3963 - loss = 2.065, (1.128 sec/step)\n",
      "step 3964 - loss = 2.114, (0.794 sec/step)\n",
      "step 3965 - loss = 1.870, (1.520 sec/step)\n",
      "step 3966 - loss = 2.284, (2.485 sec/step)\n",
      "step 3967 - loss = 2.295, (2.044 sec/step)\n",
      "step 3968 - loss = 2.495, (2.222 sec/step)\n",
      "step 3969 - loss = 2.367, (2.488 sec/step)\n",
      "step 3970 - loss = 2.351, (2.486 sec/step)\n",
      "step 3971 - loss = 0.654, (2.673 sec/step)\n",
      "step 3972 - loss = 1.781, (1.401 sec/step)\n",
      "step 3973 - loss = 1.859, (1.684 sec/step)\n",
      "step 3974 - loss = 2.252, (2.115 sec/step)\n",
      "step 3975 - loss = 2.450, (2.326 sec/step)\n",
      "step 3976 - loss = 2.238, (0.866 sec/step)\n",
      "step 3977 - loss = 1.607, (1.889 sec/step)\n",
      "step 3978 - loss = 1.942, (1.909 sec/step)\n",
      "step 3979 - loss = 1.540, (1.245 sec/step)\n",
      "step 3980 - loss = 2.071, (1.820 sec/step)\n",
      "step 3981 - loss = 1.996, (1.642 sec/step)\n",
      "step 3982 - loss = 1.722, (1.680 sec/step)\n",
      "step 3983 - loss = 2.239, (1.325 sec/step)\n",
      "step 3984 - loss = 1.613, (1.226 sec/step)\n",
      "step 3985 - loss = 2.218, (1.282 sec/step)\n",
      "step 3986 - loss = 1.910, (1.413 sec/step)\n",
      "step 3987 - loss = 1.855, (2.066 sec/step)\n",
      "step 3988 - loss = 2.269, (3.099 sec/step)\n",
      "step 3989 - loss = 2.061, (2.487 sec/step)\n",
      "step 3990 - loss = 2.142, (0.884 sec/step)\n",
      "step 3991 - loss = 1.518, (1.823 sec/step)\n",
      "step 3992 - loss = 1.877, (1.657 sec/step)\n",
      "step 3993 - loss = 1.437, (1.495 sec/step)\n",
      "step 3994 - loss = 2.219, (1.385 sec/step)\n",
      "step 3995 - loss = 1.500, (1.115 sec/step)\n",
      "step 3996 - loss = 1.728, (0.937 sec/step)\n",
      "step 3997 - loss = 1.565, (0.998 sec/step)\n",
      "step 3998 - loss = 1.858, (2.123 sec/step)\n",
      "step 3999 - loss = 1.958, (2.604 sec/step)\n",
      "step 4000 - loss = 2.385, (1.535 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4001 - loss = 1.732, (1.440 sec/step)\n",
      "step 4002 - loss = 2.267, (2.213 sec/step)\n",
      "step 4003 - loss = 2.078, (1.780 sec/step)\n",
      "step 4004 - loss = 2.228, (0.925 sec/step)\n",
      "step 4005 - loss = 2.055, (1.229 sec/step)\n",
      "step 4006 - loss = 2.274, (1.550 sec/step)\n",
      "step 4007 - loss = 1.538, (2.182 sec/step)\n",
      "step 4008 - loss = 1.460, (3.392 sec/step)\n",
      "step 4009 - loss = 2.217, (1.520 sec/step)\n",
      "step 4010 - loss = 1.967, (2.638 sec/step)\n",
      "step 4011 - loss = 1.985, (2.109 sec/step)\n",
      "step 4012 - loss = 2.093, (1.650 sec/step)\n",
      "step 4013 - loss = 2.326, (1.000 sec/step)\n",
      "step 4014 - loss = 1.506, (1.525 sec/step)\n",
      "step 4015 - loss = 1.993, (2.005 sec/step)\n",
      "step 4016 - loss = 2.211, (1.342 sec/step)\n",
      "step 4017 - loss = 1.943, (1.273 sec/step)\n",
      "step 4018 - loss = 2.141, (2.545 sec/step)\n",
      "step 4019 - loss = 1.505, (1.710 sec/step)\n",
      "step 4020 - loss = 1.551, (2.484 sec/step)\n",
      "step 4021 - loss = 1.997, (2.113 sec/step)\n",
      "step 4022 - loss = 2.034, (1.012 sec/step)\n",
      "step 4023 - loss = 2.296, (1.568 sec/step)\n",
      "step 4024 - loss = 1.853, (1.440 sec/step)\n",
      "step 4025 - loss = 2.117, (1.389 sec/step)\n",
      "step 4026 - loss = 1.822, (1.794 sec/step)\n",
      "step 4027 - loss = 1.255, (2.811 sec/step)\n",
      "step 4028 - loss = 1.913, (1.865 sec/step)\n",
      "step 4029 - loss = 1.740, (0.895 sec/step)\n",
      "step 4030 - loss = 1.818, (3.273 sec/step)\n",
      "step 4031 - loss = 2.385, (1.352 sec/step)\n",
      "step 4032 - loss = 2.059, (1.011 sec/step)\n",
      "step 4033 - loss = 2.131, (1.097 sec/step)\n",
      "step 4034 - loss = 1.856, (2.648 sec/step)\n",
      "step 4035 - loss = 1.808, (1.113 sec/step)\n",
      "step 4036 - loss = 1.840, (3.323 sec/step)\n",
      "step 4037 - loss = 2.265, (3.158 sec/step)\n",
      "step 4038 - loss = 1.637, (1.128 sec/step)\n",
      "step 4039 - loss = 2.123, (1.178 sec/step)\n",
      "step 4040 - loss = 2.308, (2.702 sec/step)\n",
      "step 4041 - loss = 2.196, (1.332 sec/step)\n",
      "step 4042 - loss = 2.078, (1.228 sec/step)\n",
      "step 4043 - loss = 1.895, (1.131 sec/step)\n",
      "step 4044 - loss = 1.612, (1.033 sec/step)\n",
      "step 4045 - loss = 1.738, (2.787 sec/step)\n",
      "step 4046 - loss = 1.943, (1.229 sec/step)\n",
      "step 4047 - loss = 1.559, (1.488 sec/step)\n",
      "step 4048 - loss = 2.417, (2.053 sec/step)\n",
      "step 4049 - loss = 2.255, (1.254 sec/step)\n",
      "step 4050 - loss = 2.142, (1.273 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4051 - loss = 2.076, (2.011 sec/step)\n",
      "step 4052 - loss = 1.644, (1.706 sec/step)\n",
      "step 4053 - loss = 1.676, (1.017 sec/step)\n",
      "step 4054 - loss = 1.944, (1.406 sec/step)\n",
      "step 4055 - loss = 0.992, (1.609 sec/step)\n",
      "step 4056 - loss = 1.843, (1.471 sec/step)\n",
      "step 4057 - loss = 1.578, (1.115 sec/step)\n",
      "step 4058 - loss = 1.687, (1.234 sec/step)\n",
      "step 4059 - loss = 1.576, (1.506 sec/step)\n",
      "step 4060 - loss = 2.573, (2.304 sec/step)\n",
      "step 4061 - loss = 1.506, (1.907 sec/step)\n",
      "step 4062 - loss = 2.084, (1.153 sec/step)\n",
      "step 4063 - loss = 1.815, (1.610 sec/step)\n",
      "step 4064 - loss = 1.859, (1.522 sec/step)\n",
      "step 4065 - loss = 1.524, (1.685 sec/step)\n",
      "step 4066 - loss = 1.211, (1.304 sec/step)\n",
      "step 4067 - loss = 2.044, (1.391 sec/step)\n",
      "step 4068 - loss = 2.151, (1.198 sec/step)\n",
      "step 4069 - loss = 1.928, (1.544 sec/step)\n",
      "step 4070 - loss = 2.361, (2.491 sec/step)\n",
      "step 4071 - loss = 1.513, (1.387 sec/step)\n",
      "step 4072 - loss = 1.594, (2.052 sec/step)\n",
      "step 4073 - loss = 1.952, (1.391 sec/step)\n",
      "step 4074 - loss = 2.183, (0.971 sec/step)\n",
      "step 4075 - loss = 2.181, (1.951 sec/step)\n",
      "step 4076 - loss = 2.152, (2.140 sec/step)\n",
      "step 4077 - loss = 1.885, (2.787 sec/step)\n",
      "step 4078 - loss = 2.178, (1.229 sec/step)\n",
      "step 4079 - loss = 2.033, (1.576 sec/step)\n",
      "step 4080 - loss = 1.959, (0.989 sec/step)\n",
      "step 4081 - loss = 2.175, (2.648 sec/step)\n",
      "step 4082 - loss = 1.939, (1.328 sec/step)\n",
      "step 4083 - loss = 1.961, (0.986 sec/step)\n",
      "step 4084 - loss = 1.847, (2.628 sec/step)\n",
      "step 4085 - loss = 2.080, (1.235 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4086 - loss = 1.953, (2.259 sec/step)\n",
      "step 4087 - loss = 1.858, (1.414 sec/step)\n",
      "step 4088 - loss = 1.848, (1.145 sec/step)\n",
      "step 4089 - loss = 2.111, (1.516 sec/step)\n",
      "step 4090 - loss = 1.832, (1.762 sec/step)\n",
      "step 4091 - loss = 2.128, (1.160 sec/step)\n",
      "step 4092 - loss = 1.534, (2.320 sec/step)\n",
      "step 4093 - loss = 1.589, (1.016 sec/step)\n",
      "step 4094 - loss = 2.180, (1.601 sec/step)\n",
      "step 4095 - loss = 2.238, (2.084 sec/step)\n",
      "step 4096 - loss = 2.212, (1.315 sec/step)\n",
      "step 4097 - loss = 2.121, (1.149 sec/step)\n",
      "step 4098 - loss = 1.724, (1.679 sec/step)\n",
      "step 4099 - loss = 2.311, (1.208 sec/step)\n",
      "step 4100 - loss = 1.748, (1.440 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4101 - loss = 2.588, (2.485 sec/step)\n",
      "step 4102 - loss = 0.682, (1.159 sec/step)\n",
      "step 4103 - loss = 1.377, (1.274 sec/step)\n",
      "step 4104 - loss = 1.854, (1.314 sec/step)\n",
      "step 4105 - loss = 1.453, (1.633 sec/step)\n",
      "step 4106 - loss = 1.969, (2.484 sec/step)\n",
      "step 4107 - loss = 2.452, (2.485 sec/step)\n",
      "step 4108 - loss = 1.128, (1.481 sec/step)\n",
      "step 4109 - loss = 1.848, (2.578 sec/step)\n",
      "step 4110 - loss = 2.137, (1.633 sec/step)\n",
      "step 4111 - loss = 2.252, (0.838 sec/step)\n",
      "step 4112 - loss = 1.706, (1.247 sec/step)\n",
      "step 4113 - loss = 2.244, (2.189 sec/step)\n",
      "step 4114 - loss = 2.141, (1.426 sec/step)\n",
      "step 4115 - loss = 1.858, (2.769 sec/step)\n",
      "step 4116 - loss = 2.120, (1.441 sec/step)\n",
      "step 4117 - loss = 1.604, (1.178 sec/step)\n",
      "step 4118 - loss = 1.832, (1.494 sec/step)\n",
      "step 4119 - loss = 2.168, (1.482 sec/step)\n",
      "step 4120 - loss = 1.824, (1.205 sec/step)\n",
      "step 4121 - loss = 2.091, (1.302 sec/step)\n",
      "step 4122 - loss = 2.061, (1.929 sec/step)\n",
      "step 4123 - loss = 2.043, (2.381 sec/step)\n",
      "step 4124 - loss = 1.723, (1.947 sec/step)\n",
      "step 4125 - loss = 2.389, (1.965 sec/step)\n",
      "step 4126 - loss = 1.609, (1.000 sec/step)\n",
      "step 4127 - loss = 1.863, (1.646 sec/step)\n",
      "step 4128 - loss = 2.381, (1.804 sec/step)\n",
      "step 4129 - loss = 1.679, (2.749 sec/step)\n",
      "step 4130 - loss = 1.604, (1.209 sec/step)\n",
      "step 4131 - loss = 1.407, (2.512 sec/step)\n",
      "step 4132 - loss = 2.109, (0.927 sec/step)\n",
      "step 4133 - loss = 2.503, (2.484 sec/step)\n",
      "step 4134 - loss = 1.227, (0.918 sec/step)\n",
      "step 4135 - loss = 1.858, (1.584 sec/step)\n",
      "step 4136 - loss = 1.564, (1.634 sec/step)\n",
      "step 4137 - loss = 1.635, (1.478 sec/step)\n",
      "step 4138 - loss = 2.152, (1.088 sec/step)\n",
      "step 4139 - loss = 1.948, (2.485 sec/step)\n",
      "step 4140 - loss = 0.929, (0.397 sec/step)\n",
      "step 4141 - loss = 1.906, (2.022 sec/step)\n",
      "step 4142 - loss = 1.702, (1.150 sec/step)\n",
      "step 4143 - loss = 2.077, (2.818 sec/step)\n",
      "step 4144 - loss = 1.739, (1.359 sec/step)\n",
      "step 4145 - loss = 2.193, (2.060 sec/step)\n",
      "step 4146 - loss = 1.801, (1.593 sec/step)\n",
      "step 4147 - loss = 1.605, (1.946 sec/step)\n",
      "step 4148 - loss = 1.991, (2.781 sec/step)\n",
      "step 4149 - loss = 1.746, (1.893 sec/step)\n",
      "step 4150 - loss = 2.186, (2.752 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4151 - loss = 2.291, (2.483 sec/step)\n",
      "step 4152 - loss = 1.536, (2.710 sec/step)\n",
      "step 4153 - loss = 1.999, (1.177 sec/step)\n",
      "step 4154 - loss = 2.048, (1.321 sec/step)\n",
      "step 4155 - loss = 1.331, (2.091 sec/step)\n",
      "step 4156 - loss = 1.338, (1.251 sec/step)\n",
      "step 4157 - loss = 1.944, (0.917 sec/step)\n",
      "step 4158 - loss = 2.246, (1.387 sec/step)\n",
      "step 4159 - loss = 2.495, (2.516 sec/step)\n",
      "step 4160 - loss = 2.057, (2.093 sec/step)\n",
      "step 4161 - loss = 1.579, (1.929 sec/step)\n",
      "step 4162 - loss = 1.925, (1.431 sec/step)\n",
      "step 4163 - loss = 1.748, (1.261 sec/step)\n",
      "step 4164 - loss = 1.653, (1.481 sec/step)\n",
      "step 4165 - loss = 1.926, (1.509 sec/step)\n",
      "step 4166 - loss = 1.988, (1.456 sec/step)\n",
      "step 4167 - loss = 1.793, (1.301 sec/step)\n",
      "step 4168 - loss = 2.295, (2.484 sec/step)\n",
      "step 4169 - loss = 1.871, (1.471 sec/step)\n",
      "step 4170 - loss = 1.274, (1.458 sec/step)\n",
      "step 4171 - loss = 1.754, (1.198 sec/step)\n",
      "step 4172 - loss = 1.943, (1.278 sec/step)\n",
      "step 4173 - loss = 1.725, (1.232 sec/step)\n",
      "step 4174 - loss = 2.217, (1.941 sec/step)\n",
      "step 4175 - loss = 2.164, (1.558 sec/step)\n",
      "step 4176 - loss = 1.955, (1.069 sec/step)\n",
      "step 4177 - loss = 1.683, (3.287 sec/step)\n",
      "step 4178 - loss = 1.549, (1.523 sec/step)\n",
      "step 4179 - loss = 2.236, (1.356 sec/step)\n",
      "step 4180 - loss = 1.944, (1.644 sec/step)\n",
      "step 4181 - loss = 2.740, (1.630 sec/step)\n",
      "step 4182 - loss = 1.565, (1.774 sec/step)\n",
      "step 4183 - loss = 1.741, (1.366 sec/step)\n",
      "step 4184 - loss = 2.470, (2.486 sec/step)\n",
      "step 4185 - loss = 3.146, (2.682 sec/step)\n",
      "step 4186 - loss = 2.700, (1.511 sec/step)\n",
      "step 4187 - loss = 1.831, (2.463 sec/step)\n",
      "step 4188 - loss = 2.188, (0.909 sec/step)\n",
      "step 4189 - loss = 1.154, (1.496 sec/step)\n",
      "step 4190 - loss = 1.846, (2.468 sec/step)\n",
      "step 4191 - loss = 1.639, (1.716 sec/step)\n",
      "step 4192 - loss = 1.950, (1.343 sec/step)\n",
      "step 4193 - loss = 1.766, (1.275 sec/step)\n",
      "step 4194 - loss = 1.890, (1.821 sec/step)\n",
      "step 4195 - loss = 1.841, (2.347 sec/step)\n",
      "step 4196 - loss = 1.391, (1.585 sec/step)\n",
      "step 4197 - loss = 1.468, (0.858 sec/step)\n",
      "step 4198 - loss = 2.160, (1.593 sec/step)\n",
      "step 4199 - loss = 2.291, (2.019 sec/step)\n",
      "step 4200 - loss = 2.101, (1.209 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4201 - loss = 1.978, (2.432 sec/step)\n",
      "step 4202 - loss = 2.270, (1.535 sec/step)\n",
      "step 4203 - loss = 2.024, (1.391 sec/step)\n",
      "step 4204 - loss = 2.421, (2.389 sec/step)\n",
      "step 4205 - loss = 1.675, (1.235 sec/step)\n",
      "step 4206 - loss = 2.184, (1.800 sec/step)\n",
      "step 4207 - loss = 1.928, (1.051 sec/step)\n",
      "step 4208 - loss = 2.881, (2.484 sec/step)\n",
      "step 4209 - loss = 2.488, (1.687 sec/step)\n",
      "step 4210 - loss = 2.213, (2.549 sec/step)\n",
      "step 4211 - loss = 1.846, (1.200 sec/step)\n",
      "step 4212 - loss = 1.998, (1.267 sec/step)\n",
      "step 4213 - loss = 2.381, (2.485 sec/step)\n",
      "step 4214 - loss = 1.494, (1.594 sec/step)\n",
      "step 4215 - loss = 1.791, (1.445 sec/step)\n",
      "step 4216 - loss = 1.543, (1.870 sec/step)\n",
      "step 4217 - loss = 1.892, (2.333 sec/step)\n",
      "step 4218 - loss = 1.734, (1.316 sec/step)\n",
      "step 4219 - loss = 1.862, (1.518 sec/step)\n",
      "step 4220 - loss = 1.892, (1.396 sec/step)\n",
      "step 4221 - loss = 1.444, (1.476 sec/step)\n",
      "step 4222 - loss = 2.256, (1.762 sec/step)\n",
      "step 4223 - loss = 1.787, (1.724 sec/step)\n",
      "step 4224 - loss = 2.110, (1.227 sec/step)\n",
      "step 4225 - loss = 2.347, (1.269 sec/step)\n",
      "step 4226 - loss = 1.490, (1.444 sec/step)\n",
      "step 4227 - loss = 1.981, (1.988 sec/step)\n",
      "step 4228 - loss = 2.952, (1.731 sec/step)\n",
      "step 4229 - loss = 1.705, (1.517 sec/step)\n",
      "step 4230 - loss = 2.193, (1.579 sec/step)\n",
      "step 4231 - loss = 2.354, (1.609 sec/step)\n",
      "step 4232 - loss = 1.519, (1.327 sec/step)\n",
      "step 4233 - loss = 1.666, (2.248 sec/step)\n",
      "step 4234 - loss = 1.833, (1.408 sec/step)\n",
      "step 4235 - loss = 2.035, (1.442 sec/step)\n",
      "step 4236 - loss = 2.061, (2.729 sec/step)\n",
      "step 4237 - loss = 2.234, (3.101 sec/step)\n",
      "step 4238 - loss = 1.995, (1.692 sec/step)\n",
      "step 4239 - loss = 2.049, (1.350 sec/step)\n",
      "step 4240 - loss = 1.801, (2.434 sec/step)\n",
      "step 4241 - loss = 2.561, (1.245 sec/step)\n",
      "step 4242 - loss = 1.458, (1.141 sec/step)\n",
      "step 4243 - loss = 2.034, (2.335 sec/step)\n",
      "step 4244 - loss = 2.212, (1.557 sec/step)\n",
      "step 4245 - loss = 1.484, (1.200 sec/step)\n",
      "step 4246 - loss = 1.533, (1.048 sec/step)\n",
      "step 4247 - loss = 1.752, (1.353 sec/step)\n",
      "step 4248 - loss = 2.214, (1.919 sec/step)\n",
      "step 4249 - loss = 1.777, (1.311 sec/step)\n",
      "step 4250 - loss = 2.003, (1.373 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4251 - loss = 1.968, (1.537 sec/step)\n",
      "step 4252 - loss = 1.446, (1.426 sec/step)\n",
      "step 4253 - loss = 2.115, (1.834 sec/step)\n",
      "step 4254 - loss = 1.724, (1.285 sec/step)\n",
      "step 4255 - loss = 1.567, (1.086 sec/step)\n",
      "step 4256 - loss = 1.927, (1.180 sec/step)\n",
      "step 4257 - loss = 1.415, (2.880 sec/step)\n",
      "step 4258 - loss = 2.050, (0.983 sec/step)\n",
      "step 4259 - loss = 1.753, (1.497 sec/step)\n",
      "step 4260 - loss = 1.873, (1.233 sec/step)\n",
      "step 4261 - loss = 1.722, (1.633 sec/step)\n",
      "step 4262 - loss = 1.739, (1.254 sec/step)\n",
      "step 4263 - loss = 2.072, (3.154 sec/step)\n",
      "step 4264 - loss = 1.705, (0.941 sec/step)\n",
      "step 4265 - loss = 2.172, (2.194 sec/step)\n",
      "step 4266 - loss = 1.425, (1.154 sec/step)\n",
      "step 4267 - loss = 1.753, (2.201 sec/step)\n",
      "step 4268 - loss = 1.184, (1.154 sec/step)\n",
      "step 4269 - loss = 2.440, (1.723 sec/step)\n",
      "step 4270 - loss = 2.299, (1.333 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4271 - loss = 2.151, (1.739 sec/step)\n",
      "step 4272 - loss = 1.586, (1.810 sec/step)\n",
      "step 4273 - loss = 2.302, (1.541 sec/step)\n",
      "step 4274 - loss = 1.739, (1.385 sec/step)\n",
      "step 4275 - loss = 1.638, (1.710 sec/step)\n",
      "step 4276 - loss = 1.793, (1.158 sec/step)\n",
      "step 4277 - loss = 2.136, (1.321 sec/step)\n",
      "step 4278 - loss = 1.682, (1.410 sec/step)\n",
      "step 4279 - loss = 2.114, (1.314 sec/step)\n",
      "step 4280 - loss = 1.585, (1.442 sec/step)\n",
      "step 4281 - loss = 1.670, (1.279 sec/step)\n",
      "step 4282 - loss = 1.324, (1.575 sec/step)\n",
      "step 4283 - loss = 1.915, (1.378 sec/step)\n",
      "step 4284 - loss = 1.509, (2.236 sec/step)\n",
      "step 4285 - loss = 1.476, (1.202 sec/step)\n",
      "step 4286 - loss = 1.975, (1.391 sec/step)\n",
      "step 4287 - loss = 1.863, (1.048 sec/step)\n",
      "step 4288 - loss = 2.381, (2.156 sec/step)\n",
      "step 4289 - loss = 1.384, (1.148 sec/step)\n",
      "step 4290 - loss = 2.294, (2.487 sec/step)\n",
      "step 4291 - loss = 2.997, (1.454 sec/step)\n",
      "step 4292 - loss = 2.108, (1.362 sec/step)\n",
      "step 4293 - loss = 1.717, (1.348 sec/step)\n",
      "step 4294 - loss = 1.821, (1.635 sec/step)\n",
      "step 4295 - loss = 1.457, (2.497 sec/step)\n",
      "step 4296 - loss = 1.831, (1.045 sec/step)\n",
      "step 4297 - loss = 2.074, (1.124 sec/step)\n",
      "step 4298 - loss = 1.849, (1.002 sec/step)\n",
      "step 4299 - loss = 1.916, (1.642 sec/step)\n",
      "step 4300 - loss = 1.908, (1.261 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4301 - loss = 1.982, (1.526 sec/step)\n",
      "step 4302 - loss = 1.597, (1.877 sec/step)\n",
      "step 4303 - loss = 1.301, (1.414 sec/step)\n",
      "step 4304 - loss = 2.486, (1.834 sec/step)\n",
      "step 4305 - loss = 2.089, (1.832 sec/step)\n",
      "step 4306 - loss = 2.334, (1.412 sec/step)\n",
      "step 4307 - loss = 1.550, (1.973 sec/step)\n",
      "step 4308 - loss = 1.940, (1.727 sec/step)\n",
      "step 4309 - loss = 2.147, (1.395 sec/step)\n",
      "step 4310 - loss = 2.236, (2.269 sec/step)\n",
      "step 4311 - loss = 1.942, (1.382 sec/step)\n",
      "step 4312 - loss = 1.742, (2.730 sec/step)\n",
      "step 4313 - loss = 2.003, (0.856 sec/step)\n",
      "step 4314 - loss = 1.736, (1.154 sec/step)\n",
      "step 4315 - loss = 1.766, (2.763 sec/step)\n",
      "step 4316 - loss = 1.720, (2.662 sec/step)\n",
      "step 4317 - loss = 1.634, (1.262 sec/step)\n",
      "step 4318 - loss = 1.462, (2.129 sec/step)\n",
      "step 4319 - loss = 2.243, (2.741 sec/step)\n",
      "step 4320 - loss = 1.512, (0.856 sec/step)\n",
      "step 4321 - loss = 1.940, (1.482 sec/step)\n",
      "step 4322 - loss = 1.329, (2.670 sec/step)\n",
      "step 4323 - loss = 1.341, (1.173 sec/step)\n",
      "step 4324 - loss = 1.986, (2.097 sec/step)\n",
      "step 4325 - loss = 1.614, (1.230 sec/step)\n",
      "step 4326 - loss = 2.056, (1.111 sec/step)\n",
      "step 4327 - loss = 2.309, (1.334 sec/step)\n",
      "step 4328 - loss = 2.273, (2.484 sec/step)\n",
      "step 4329 - loss = 0.591, (1.158 sec/step)\n",
      "step 4330 - loss = 1.660, (1.384 sec/step)\n",
      "step 4331 - loss = 2.715, (2.146 sec/step)\n",
      "step 4332 - loss = 2.034, (1.728 sec/step)\n",
      "step 4333 - loss = 2.279, (2.481 sec/step)\n",
      "step 4334 - loss = 2.520, (2.586 sec/step)\n",
      "step 4335 - loss = 1.813, (1.804 sec/step)\n",
      "step 4336 - loss = 1.449, (1.181 sec/step)\n",
      "step 4337 - loss = 1.918, (1.343 sec/step)\n",
      "step 4338 - loss = 2.229, (1.182 sec/step)\n",
      "step 4339 - loss = 2.134, (2.099 sec/step)\n",
      "step 4340 - loss = 2.177, (1.652 sec/step)\n",
      "step 4341 - loss = 1.493, (1.582 sec/step)\n",
      "step 4342 - loss = 1.704, (1.016 sec/step)\n",
      "step 4343 - loss = 1.901, (2.779 sec/step)\n",
      "step 4344 - loss = 2.310, (0.970 sec/step)\n",
      "step 4345 - loss = 1.535, (1.193 sec/step)\n",
      "step 4346 - loss = 1.523, (1.441 sec/step)\n",
      "step 4347 - loss = 2.258, (1.181 sec/step)\n",
      "step 4348 - loss = 1.666, (2.075 sec/step)\n",
      "step 4349 - loss = 1.563, (2.435 sec/step)\n",
      "step 4350 - loss = 2.523, (1.576 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4351 - loss = 2.499, (1.700 sec/step)\n",
      "step 4352 - loss = 2.011, (2.686 sec/step)\n",
      "step 4353 - loss = 1.823, (1.349 sec/step)\n",
      "step 4354 - loss = 2.870, (2.486 sec/step)\n",
      "step 4355 - loss = 2.037, (2.582 sec/step)\n",
      "step 4356 - loss = 2.466, (2.487 sec/step)\n",
      "step 4357 - loss = 1.462, (1.252 sec/step)\n",
      "step 4358 - loss = 1.714, (1.814 sec/step)\n",
      "step 4359 - loss = 1.980, (1.688 sec/step)\n",
      "step 4360 - loss = 2.023, (1.494 sec/step)\n",
      "step 4361 - loss = 1.624, (1.394 sec/step)\n",
      "step 4362 - loss = 1.860, (1.311 sec/step)\n",
      "step 4363 - loss = 2.120, (1.000 sec/step)\n",
      "step 4364 - loss = 1.486, (1.678 sec/step)\n",
      "step 4365 - loss = 2.230, (1.080 sec/step)\n",
      "step 4366 - loss = 1.644, (1.104 sec/step)\n",
      "step 4367 - loss = 1.983, (2.048 sec/step)\n",
      "step 4368 - loss = 1.940, (1.382 sec/step)\n",
      "step 4369 - loss = 1.821, (1.160 sec/step)\n",
      "step 4370 - loss = 2.308, (2.042 sec/step)\n",
      "step 4371 - loss = 2.376, (1.690 sec/step)\n",
      "step 4372 - loss = 1.983, (1.100 sec/step)\n",
      "step 4373 - loss = 1.782, (0.963 sec/step)\n",
      "step 4374 - loss = 1.500, (1.018 sec/step)\n",
      "step 4375 - loss = 1.752, (2.267 sec/step)\n",
      "step 4376 - loss = 1.774, (1.476 sec/step)\n",
      "step 4377 - loss = 2.057, (3.409 sec/step)\n",
      "step 4378 - loss = 2.045, (2.435 sec/step)\n",
      "step 4379 - loss = 1.493, (1.947 sec/step)\n",
      "step 4380 - loss = 2.038, (2.052 sec/step)\n",
      "step 4381 - loss = 2.206, (1.569 sec/step)\n",
      "step 4382 - loss = 1.842, (1.149 sec/step)\n",
      "step 4383 - loss = 1.930, (1.319 sec/step)\n",
      "step 4384 - loss = 1.742, (2.167 sec/step)\n",
      "step 4385 - loss = 2.457, (1.208 sec/step)\n",
      "step 4386 - loss = 1.574, (2.565 sec/step)\n",
      "step 4387 - loss = 1.355, (2.487 sec/step)\n",
      "step 4388 - loss = 1.344, (2.598 sec/step)\n",
      "step 4389 - loss = 2.114, (3.288 sec/step)\n",
      "step 4390 - loss = 2.219, (2.775 sec/step)\n",
      "step 4391 - loss = 2.331, (1.989 sec/step)\n",
      "step 4392 - loss = 2.424, (3.673 sec/step)\n",
      "step 4393 - loss = 2.095, (1.294 sec/step)\n",
      "step 4394 - loss = 1.827, (0.864 sec/step)\n",
      "step 4395 - loss = 1.740, (1.069 sec/step)\n",
      "step 4396 - loss = 2.677, (2.144 sec/step)\n",
      "step 4397 - loss = 2.092, (2.113 sec/step)\n",
      "step 4398 - loss = 1.787, (1.479 sec/step)\n",
      "step 4399 - loss = 2.080, (1.211 sec/step)\n",
      "step 4400 - loss = 2.204, (1.422 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4401 - loss = 2.771, (2.468 sec/step)\n",
      "step 4402 - loss = 1.933, (0.910 sec/step)\n",
      "step 4403 - loss = 1.789, (1.307 sec/step)\n",
      "step 4404 - loss = 2.063, (2.006 sec/step)\n",
      "step 4405 - loss = 1.985, (1.180 sec/step)\n",
      "step 4406 - loss = 2.004, (1.649 sec/step)\n",
      "step 4407 - loss = 1.632, (1.120 sec/step)\n",
      "step 4408 - loss = 1.897, (1.267 sec/step)\n",
      "step 4409 - loss = 2.150, (1.088 sec/step)\n",
      "step 4410 - loss = 1.659, (1.278 sec/step)\n",
      "step 4411 - loss = 1.649, (1.220 sec/step)\n",
      "step 4412 - loss = 2.045, (1.280 sec/step)\n",
      "step 4413 - loss = 1.425, (1.049 sec/step)\n",
      "step 4414 - loss = 2.596, (1.679 sec/step)\n",
      "step 4415 - loss = 0.948, (1.033 sec/step)\n",
      "step 4416 - loss = 2.350, (1.262 sec/step)\n",
      "step 4417 - loss = 2.550, (1.896 sec/step)\n",
      "step 4418 - loss = 1.425, (2.562 sec/step)\n",
      "step 4419 - loss = 2.030, (1.177 sec/step)\n",
      "step 4420 - loss = 2.559, (2.484 sec/step)\n",
      "step 4421 - loss = 1.152, (2.506 sec/step)\n",
      "step 4422 - loss = 1.596, (1.501 sec/step)\n",
      "step 4423 - loss = 1.657, (1.304 sec/step)\n",
      "step 4424 - loss = 2.444, (1.574 sec/step)\n",
      "step 4425 - loss = 1.552, (1.958 sec/step)\n",
      "step 4426 - loss = 1.682, (1.650 sec/step)\n",
      "step 4427 - loss = 1.765, (2.762 sec/step)\n",
      "step 4428 - loss = 2.196, (1.132 sec/step)\n",
      "step 4429 - loss = 1.840, (0.870 sec/step)\n",
      "step 4430 - loss = 1.629, (1.273 sec/step)\n",
      "step 4431 - loss = 1.246, (2.821 sec/step)\n",
      "step 4432 - loss = 1.995, (1.085 sec/step)\n",
      "step 4433 - loss = 1.505, (1.016 sec/step)\n",
      "step 4434 - loss = 1.747, (2.485 sec/step)\n",
      "step 4435 - loss = 1.591, (1.313 sec/step)\n",
      "step 4436 - loss = 1.255, (1.805 sec/step)\n",
      "step 4437 - loss = 2.178, (1.314 sec/step)\n",
      "step 4438 - loss = 1.656, (1.475 sec/step)\n",
      "step 4439 - loss = 1.407, (0.971 sec/step)\n",
      "step 4440 - loss = 1.605, (2.685 sec/step)\n",
      "step 4441 - loss = 2.267, (1.247 sec/step)\n",
      "step 4442 - loss = 1.985, (1.628 sec/step)\n",
      "step 4443 - loss = 1.863, (1.400 sec/step)\n",
      "step 4444 - loss = 1.435, (2.298 sec/step)\n",
      "step 4445 - loss = 2.024, (1.151 sec/step)\n",
      "step 4446 - loss = 2.176, (1.263 sec/step)\n",
      "step 4447 - loss = 1.714, (1.038 sec/step)\n",
      "step 4448 - loss = 1.398, (1.374 sec/step)\n",
      "step 4449 - loss = 1.803, (1.932 sec/step)\n",
      "step 4450 - loss = 1.996, (1.090 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4451 - loss = 1.451, (2.179 sec/step)\n",
      "step 4452 - loss = 1.872, (1.458 sec/step)\n",
      "step 4453 - loss = 1.389, (2.531 sec/step)\n",
      "step 4454 - loss = 1.446, (0.915 sec/step)\n",
      "step 4455 - loss = 1.779, (1.287 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4456 - loss = 2.217, (2.485 sec/step)\n",
      "step 4457 - loss = 2.002, (1.835 sec/step)\n",
      "step 4458 - loss = 1.791, (1.525 sec/step)\n",
      "step 4459 - loss = 1.960, (1.129 sec/step)\n",
      "step 4460 - loss = 1.647, (2.308 sec/step)\n",
      "step 4461 - loss = 2.017, (2.456 sec/step)\n",
      "step 4462 - loss = 2.496, (2.188 sec/step)\n",
      "step 4463 - loss = 2.009, (1.086 sec/step)\n",
      "step 4464 - loss = 1.849, (1.887 sec/step)\n",
      "step 4465 - loss = 1.754, (1.590 sec/step)\n",
      "step 4466 - loss = 2.363, (1.791 sec/step)\n",
      "step 4467 - loss = 2.204, (1.274 sec/step)\n",
      "step 4468 - loss = 1.356, (2.310 sec/step)\n",
      "step 4469 - loss = 1.995, (1.295 sec/step)\n",
      "step 4470 - loss = 2.083, (2.483 sec/step)\n",
      "step 4471 - loss = 1.713, (2.733 sec/step)\n",
      "step 4472 - loss = 2.003, (0.995 sec/step)\n",
      "step 4473 - loss = 1.446, (1.361 sec/step)\n",
      "step 4474 - loss = 2.060, (1.294 sec/step)\n",
      "step 4475 - loss = 1.539, (1.543 sec/step)\n",
      "step 4476 - loss = 2.099, (1.053 sec/step)\n",
      "step 4477 - loss = 2.432, (1.945 sec/step)\n",
      "step 4478 - loss = 1.860, (1.221 sec/step)\n",
      "step 4479 - loss = 1.752, (1.311 sec/step)\n",
      "step 4480 - loss = 1.785, (2.571 sec/step)\n",
      "step 4481 - loss = 2.048, (1.759 sec/step)\n",
      "step 4482 - loss = 2.231, (1.393 sec/step)\n",
      "step 4483 - loss = 1.537, (0.959 sec/step)\n",
      "step 4484 - loss = 2.039, (1.409 sec/step)\n",
      "step 4485 - loss = 1.868, (1.314 sec/step)\n",
      "step 4486 - loss = 2.042, (0.924 sec/step)\n",
      "step 4487 - loss = 1.522, (1.727 sec/step)\n",
      "step 4488 - loss = 1.153, (1.054 sec/step)\n",
      "step 4489 - loss = 2.444, (1.118 sec/step)\n",
      "step 4490 - loss = 1.510, (2.488 sec/step)\n",
      "step 4491 - loss = 0.507, (1.371 sec/step)\n",
      "step 4492 - loss = 1.585, (2.844 sec/step)\n",
      "step 4493 - loss = 1.529, (2.749 sec/step)\n",
      "step 4494 - loss = 1.910, (1.246 sec/step)\n",
      "step 4495 - loss = 1.789, (1.852 sec/step)\n",
      "step 4496 - loss = 1.543, (2.406 sec/step)\n",
      "step 4497 - loss = 1.884, (2.460 sec/step)\n",
      "step 4498 - loss = 1.835, (1.049 sec/step)\n",
      "step 4499 - loss = 1.257, (1.727 sec/step)\n",
      "step 4500 - loss = 2.426, (1.652 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4501 - loss = 1.806, (1.340 sec/step)\n",
      "step 4502 - loss = 1.599, (1.866 sec/step)\n",
      "step 4503 - loss = 1.693, (1.161 sec/step)\n",
      "step 4504 - loss = 1.256, (2.735 sec/step)\n",
      "step 4505 - loss = 1.857, (1.000 sec/step)\n",
      "step 4506 - loss = 1.675, (1.557 sec/step)\n",
      "step 4507 - loss = 1.863, (0.956 sec/step)\n",
      "step 4508 - loss = 2.030, (0.958 sec/step)\n",
      "step 4509 - loss = 2.009, (2.343 sec/step)\n",
      "step 4510 - loss = 1.867, (1.355 sec/step)\n",
      "step 4511 - loss = 1.825, (1.046 sec/step)\n",
      "step 4512 - loss = 2.079, (2.743 sec/step)\n",
      "step 4513 - loss = 2.099, (1.069 sec/step)\n",
      "step 4514 - loss = 1.962, (1.131 sec/step)\n",
      "step 4515 - loss = 1.966, (1.390 sec/step)\n",
      "step 4516 - loss = 2.271, (2.486 sec/step)\n",
      "step 4517 - loss = 2.426, (1.272 sec/step)\n",
      "step 4518 - loss = 1.760, (1.447 sec/step)\n",
      "step 4519 - loss = 1.949, (1.075 sec/step)\n",
      "step 4520 - loss = 1.809, (1.845 sec/step)\n",
      "step 4521 - loss = 1.613, (1.658 sec/step)\n",
      "step 4522 - loss = 1.849, (1.878 sec/step)\n",
      "step 4523 - loss = 2.139, (1.785 sec/step)\n",
      "step 4524 - loss = 1.997, (0.954 sec/step)\n",
      "step 4525 - loss = 1.571, (1.212 sec/step)\n",
      "step 4526 - loss = 1.574, (1.111 sec/step)\n",
      "step 4527 - loss = 1.423, (1.347 sec/step)\n",
      "step 4528 - loss = 1.559, (1.243 sec/step)\n",
      "step 4529 - loss = 1.497, (1.519 sec/step)\n",
      "step 4530 - loss = 1.761, (3.392 sec/step)\n",
      "step 4531 - loss = 2.320, (2.484 sec/step)\n",
      "step 4532 - loss = 0.701, (0.197 sec/step)\n",
      "step 4533 - loss = 1.561, (1.074 sec/step)\n",
      "step 4534 - loss = 1.694, (1.334 sec/step)\n",
      "step 4535 - loss = 2.095, (1.605 sec/step)\n",
      "step 4536 - loss = 2.218, (1.517 sec/step)\n",
      "step 4537 - loss = 1.587, (1.279 sec/step)\n",
      "step 4538 - loss = 1.737, (1.556 sec/step)\n",
      "step 4539 - loss = 2.477, (2.485 sec/step)\n",
      "step 4540 - loss = 2.039, (2.741 sec/step)\n",
      "step 4541 - loss = 1.668, (1.114 sec/step)\n",
      "step 4542 - loss = 1.785, (0.927 sec/step)\n",
      "step 4543 - loss = 2.116, (1.489 sec/step)\n",
      "step 4544 - loss = 1.677, (1.035 sec/step)\n",
      "step 4545 - loss = 2.142, (1.489 sec/step)\n",
      "step 4546 - loss = 1.826, (1.357 sec/step)\n",
      "step 4547 - loss = 2.018, (1.278 sec/step)\n",
      "step 4548 - loss = 1.896, (1.104 sec/step)\n",
      "step 4549 - loss = 2.060, (2.948 sec/step)\n",
      "step 4550 - loss = 1.787, (1.232 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4551 - loss = 1.737, (1.410 sec/step)\n",
      "step 4552 - loss = 2.111, (1.148 sec/step)\n",
      "step 4553 - loss = 1.642, (1.391 sec/step)\n",
      "step 4554 - loss = 2.221, (1.862 sec/step)\n",
      "step 4555 - loss = 2.258, (1.200 sec/step)\n",
      "step 4556 - loss = 1.671, (1.392 sec/step)\n",
      "step 4557 - loss = 1.943, (1.986 sec/step)\n",
      "step 4558 - loss = 1.436, (2.579 sec/step)\n",
      "step 4559 - loss = 1.288, (2.544 sec/step)\n",
      "step 4560 - loss = 1.750, (1.193 sec/step)\n",
      "step 4561 - loss = 2.133, (1.097 sec/step)\n",
      "step 4562 - loss = 2.107, (1.493 sec/step)\n",
      "step 4563 - loss = 2.278, (1.699 sec/step)\n",
      "step 4564 - loss = 2.096, (1.108 sec/step)\n",
      "step 4565 - loss = 2.086, (1.052 sec/step)\n",
      "step 4566 - loss = 2.001, (1.130 sec/step)\n",
      "step 4567 - loss = 1.566, (1.578 sec/step)\n",
      "step 4568 - loss = 1.609, (1.446 sec/step)\n",
      "step 4569 - loss = 2.009, (1.314 sec/step)\n",
      "step 4570 - loss = 1.850, (0.911 sec/step)\n",
      "step 4571 - loss = 1.675, (1.596 sec/step)\n",
      "step 4572 - loss = 1.987, (1.630 sec/step)\n",
      "step 4573 - loss = 1.416, (1.391 sec/step)\n",
      "step 4574 - loss = 2.005, (2.230 sec/step)\n",
      "step 4575 - loss = 1.320, (1.315 sec/step)\n",
      "step 4576 - loss = 1.548, (2.947 sec/step)\n",
      "step 4577 - loss = 1.271, (2.115 sec/step)\n",
      "step 4578 - loss = 1.677, (1.003 sec/step)\n",
      "step 4579 - loss = 1.779, (1.212 sec/step)\n",
      "step 4580 - loss = 1.913, (1.279 sec/step)\n",
      "step 4581 - loss = 1.912, (1.564 sec/step)\n",
      "step 4582 - loss = 1.448, (1.299 sec/step)\n",
      "step 4583 - loss = 1.822, (1.290 sec/step)\n",
      "step 4584 - loss = 2.064, (1.404 sec/step)\n",
      "step 4585 - loss = 2.283, (1.176 sec/step)\n",
      "step 4586 - loss = 1.818, (1.716 sec/step)\n",
      "step 4587 - loss = 2.073, (2.215 sec/step)\n",
      "step 4588 - loss = 1.191, (1.069 sec/step)\n",
      "step 4589 - loss = 2.128, (2.210 sec/step)\n",
      "step 4590 - loss = 1.215, (1.411 sec/step)\n",
      "step 4591 - loss = 1.653, (1.099 sec/step)\n",
      "step 4592 - loss = 1.751, (0.954 sec/step)\n",
      "step 4593 - loss = 2.651, (1.280 sec/step)\n",
      "step 4594 - loss = 1.779, (2.143 sec/step)\n",
      "step 4595 - loss = 2.468, (1.987 sec/step)\n",
      "step 4596 - loss = 1.776, (2.006 sec/step)\n",
      "step 4597 - loss = 2.162, (2.416 sec/step)\n",
      "step 4598 - loss = 1.029, (1.538 sec/step)\n",
      "step 4599 - loss = 1.856, (0.893 sec/step)\n",
      "step 4600 - loss = 2.250, (1.837 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4601 - loss = 1.794, (1.113 sec/step)\n",
      "step 4602 - loss = 2.084, (3.101 sec/step)\n",
      "step 4603 - loss = 1.862, (2.407 sec/step)\n",
      "step 4604 - loss = 2.344, (1.230 sec/step)\n",
      "step 4605 - loss = 1.788, (1.483 sec/step)\n",
      "step 4606 - loss = 1.909, (1.093 sec/step)\n",
      "step 4607 - loss = 2.243, (1.112 sec/step)\n",
      "step 4608 - loss = 2.021, (1.348 sec/step)\n",
      "step 4609 - loss = 2.235, (2.835 sec/step)\n",
      "step 4610 - loss = 1.305, (2.609 sec/step)\n",
      "step 4611 - loss = 2.123, (1.116 sec/step)\n",
      "step 4612 - loss = 2.191, (1.128 sec/step)\n",
      "step 4613 - loss = 2.133, (2.149 sec/step)\n",
      "step 4614 - loss = 1.736, (2.192 sec/step)\n",
      "step 4615 - loss = 1.490, (1.183 sec/step)\n",
      "step 4616 - loss = 1.794, (1.051 sec/step)\n",
      "step 4617 - loss = 1.332, (2.471 sec/step)\n",
      "step 4618 - loss = 1.616, (1.407 sec/step)\n",
      "step 4619 - loss = 2.222, (1.508 sec/step)\n",
      "step 4620 - loss = 1.383, (1.086 sec/step)\n",
      "step 4621 - loss = 1.647, (2.436 sec/step)\n",
      "step 4622 - loss = 2.231, (1.179 sec/step)\n",
      "step 4623 - loss = 2.285, (1.360 sec/step)\n",
      "step 4624 - loss = 1.465, (1.267 sec/step)\n",
      "step 4625 - loss = 1.978, (1.447 sec/step)\n",
      "step 4626 - loss = 2.390, (1.754 sec/step)\n",
      "step 4627 - loss = 1.482, (0.957 sec/step)\n",
      "step 4628 - loss = 1.137, (1.132 sec/step)\n",
      "step 4629 - loss = 1.457, (1.129 sec/step)\n",
      "step 4630 - loss = 1.587, (1.262 sec/step)\n",
      "step 4631 - loss = 1.324, (1.163 sec/step)\n",
      "step 4632 - loss = 1.813, (1.627 sec/step)\n",
      "step 4633 - loss = 1.657, (1.101 sec/step)\n",
      "step 4634 - loss = 2.129, (1.745 sec/step)\n",
      "step 4635 - loss = 2.003, (1.575 sec/step)\n",
      "step 4636 - loss = 2.297, (2.487 sec/step)\n",
      "step 4637 - loss = 1.611, (1.081 sec/step)\n",
      "step 4638 - loss = 1.897, (2.355 sec/step)\n",
      "step 4639 - loss = 2.369, (2.488 sec/step)\n",
      "step 4640 - loss = 1.542, (2.425 sec/step)\n",
      "step 4641 - loss = 1.521, (1.358 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4642 - loss = 1.714, (1.315 sec/step)\n",
      "step 4643 - loss = 2.259, (2.452 sec/step)\n",
      "step 4644 - loss = 2.103, (1.448 sec/step)\n",
      "step 4645 - loss = 1.815, (1.708 sec/step)\n",
      "step 4646 - loss = 2.196, (1.127 sec/step)\n",
      "step 4647 - loss = 1.286, (1.327 sec/step)\n",
      "step 4648 - loss = 2.048, (1.274 sec/step)\n",
      "step 4649 - loss = 1.809, (1.682 sec/step)\n",
      "step 4650 - loss = 1.465, (1.531 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4651 - loss = 1.748, (1.033 sec/step)\n",
      "step 4652 - loss = 1.460, (0.988 sec/step)\n",
      "step 4653 - loss = 1.832, (1.629 sec/step)\n",
      "step 4654 - loss = 1.848, (1.223 sec/step)\n",
      "step 4655 - loss = 2.087, (1.213 sec/step)\n",
      "step 4656 - loss = 2.360, (1.296 sec/step)\n",
      "step 4657 - loss = 2.233, (1.901 sec/step)\n",
      "step 4658 - loss = 1.964, (1.169 sec/step)\n",
      "step 4659 - loss = 2.296, (1.319 sec/step)\n",
      "step 4660 - loss = 1.550, (1.160 sec/step)\n",
      "step 4661 - loss = 2.313, (1.515 sec/step)\n",
      "step 4662 - loss = 2.336, (1.067 sec/step)\n",
      "step 4663 - loss = 2.035, (1.397 sec/step)\n",
      "step 4664 - loss = 1.536, (1.754 sec/step)\n",
      "step 4665 - loss = 1.635, (1.201 sec/step)\n",
      "step 4666 - loss = 2.272, (1.446 sec/step)\n",
      "step 4667 - loss = 1.879, (2.486 sec/step)\n",
      "step 4668 - loss = 0.543, (0.772 sec/step)\n",
      "step 4669 - loss = 2.124, (1.781 sec/step)\n",
      "step 4670 - loss = 1.661, (1.894 sec/step)\n",
      "step 4671 - loss = 2.015, (1.417 sec/step)\n",
      "step 4672 - loss = 1.782, (1.178 sec/step)\n",
      "step 4673 - loss = 1.540, (0.906 sec/step)\n",
      "step 4674 - loss = 2.358, (1.170 sec/step)\n",
      "step 4675 - loss = 1.956, (2.052 sec/step)\n",
      "step 4676 - loss = 1.928, (2.035 sec/step)\n",
      "step 4677 - loss = 1.347, (1.104 sec/step)\n",
      "step 4678 - loss = 1.493, (1.170 sec/step)\n",
      "step 4679 - loss = 2.112, (2.602 sec/step)\n",
      "step 4680 - loss = 1.472, (1.004 sec/step)\n",
      "step 4681 - loss = 2.315, (1.116 sec/step)\n",
      "step 4682 - loss = 2.146, (2.038 sec/step)\n",
      "step 4683 - loss = 1.697, (1.908 sec/step)\n",
      "step 4684 - loss = 1.689, (1.440 sec/step)\n",
      "step 4685 - loss = 1.915, (1.829 sec/step)\n",
      "step 4686 - loss = 1.740, (2.449 sec/step)\n",
      "step 4687 - loss = 1.489, (1.328 sec/step)\n",
      "step 4688 - loss = 1.997, (1.891 sec/step)\n",
      "step 4689 - loss = 2.080, (1.584 sec/step)\n",
      "step 4690 - loss = 1.652, (1.221 sec/step)\n",
      "step 4691 - loss = 1.533, (1.181 sec/step)\n",
      "step 4692 - loss = 2.019, (1.827 sec/step)\n",
      "step 4693 - loss = 2.256, (1.519 sec/step)\n",
      "step 4694 - loss = 1.644, (1.178 sec/step)\n",
      "step 4695 - loss = 1.857, (1.970 sec/step)\n",
      "step 4696 - loss = 1.481, (2.152 sec/step)\n",
      "step 4697 - loss = 2.223, (2.375 sec/step)\n",
      "step 4698 - loss = 1.624, (1.667 sec/step)\n",
      "step 4699 - loss = 1.719, (1.614 sec/step)\n",
      "step 4700 - loss = 1.747, (1.277 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4701 - loss = 1.648, (2.205 sec/step)\n",
      "step 4702 - loss = 1.609, (1.230 sec/step)\n",
      "step 4703 - loss = 1.660, (1.608 sec/step)\n",
      "step 4704 - loss = 1.699, (1.275 sec/step)\n",
      "step 4705 - loss = 2.051, (1.354 sec/step)\n",
      "step 4706 - loss = 1.616, (1.750 sec/step)\n",
      "step 4707 - loss = 2.163, (1.830 sec/step)\n",
      "step 4708 - loss = 1.832, (1.096 sec/step)\n",
      "step 4709 - loss = 1.436, (1.308 sec/step)\n",
      "step 4710 - loss = 1.775, (1.128 sec/step)\n",
      "step 4711 - loss = 1.511, (3.633 sec/step)\n",
      "step 4712 - loss = 1.526, (1.244 sec/step)\n",
      "step 4713 - loss = 1.943, (1.332 sec/step)\n",
      "step 4714 - loss = 2.197, (1.637 sec/step)\n",
      "step 4715 - loss = 2.217, (2.224 sec/step)\n",
      "step 4716 - loss = 1.946, (3.492 sec/step)\n",
      "step 4717 - loss = 2.101, (2.476 sec/step)\n",
      "step 4718 - loss = 1.394, (1.146 sec/step)\n",
      "step 4719 - loss = 1.806, (2.843 sec/step)\n",
      "step 4720 - loss = 1.870, (1.493 sec/step)\n",
      "step 4721 - loss = 2.043, (1.257 sec/step)\n",
      "step 4722 - loss = 2.166, (1.505 sec/step)\n",
      "step 4723 - loss = 1.672, (2.776 sec/step)\n",
      "step 4724 - loss = 2.051, (1.310 sec/step)\n",
      "step 4725 - loss = 1.199, (1.115 sec/step)\n",
      "step 4726 - loss = 1.891, (1.077 sec/step)\n",
      "step 4727 - loss = 1.441, (1.461 sec/step)\n",
      "step 4728 - loss = 1.612, (2.566 sec/step)\n",
      "step 4729 - loss = 2.204, (2.399 sec/step)\n",
      "step 4730 - loss = 1.845, (2.691 sec/step)\n",
      "step 4731 - loss = 2.219, (1.920 sec/step)\n",
      "step 4732 - loss = 1.335, (1.769 sec/step)\n",
      "step 4733 - loss = 1.829, (2.126 sec/step)\n",
      "step 4734 - loss = 1.963, (1.684 sec/step)\n",
      "step 4735 - loss = 2.298, (1.866 sec/step)\n",
      "step 4736 - loss = 1.464, (1.345 sec/step)\n",
      "step 4737 - loss = 1.736, (1.648 sec/step)\n",
      "step 4738 - loss = 1.245, (1.348 sec/step)\n",
      "step 4739 - loss = 2.164, (2.048 sec/step)\n",
      "step 4740 - loss = 2.565, (1.226 sec/step)\n",
      "step 4741 - loss = 1.515, (2.768 sec/step)\n",
      "step 4742 - loss = 1.612, (1.165 sec/step)\n",
      "step 4743 - loss = 1.381, (1.647 sec/step)\n",
      "step 4744 - loss = 2.018, (1.782 sec/step)\n",
      "step 4745 - loss = 1.985, (2.485 sec/step)\n",
      "step 4746 - loss = 2.065, (0.883 sec/step)\n",
      "step 4747 - loss = 1.741, (1.457 sec/step)\n",
      "step 4748 - loss = 1.470, (2.179 sec/step)\n",
      "step 4749 - loss = 1.611, (2.080 sec/step)\n",
      "step 4750 - loss = 2.277, (1.296 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4751 - loss = 2.008, (1.827 sec/step)\n",
      "step 4752 - loss = 1.756, (2.056 sec/step)\n",
      "step 4753 - loss = 2.010, (1.333 sec/step)\n",
      "step 4754 - loss = 2.291, (1.409 sec/step)\n",
      "step 4755 - loss = 1.877, (1.536 sec/step)\n",
      "step 4756 - loss = 1.892, (1.870 sec/step)\n",
      "step 4757 - loss = 1.658, (2.134 sec/step)\n",
      "step 4758 - loss = 2.001, (2.399 sec/step)\n",
      "step 4759 - loss = 1.856, (1.092 sec/step)\n",
      "step 4760 - loss = 1.707, (2.482 sec/step)\n",
      "step 4761 - loss = 0.528, (0.521 sec/step)\n",
      "step 4762 - loss = 1.964, (1.042 sec/step)\n",
      "step 4763 - loss = 1.930, (1.097 sec/step)\n",
      "step 4764 - loss = 2.064, (3.117 sec/step)\n",
      "step 4765 - loss = 2.200, (1.144 sec/step)\n",
      "step 4766 - loss = 2.158, (1.358 sec/step)\n",
      "step 4767 - loss = 2.272, (2.101 sec/step)\n",
      "step 4768 - loss = 1.858, (1.905 sec/step)\n",
      "step 4769 - loss = 2.062, (1.461 sec/step)\n",
      "step 4770 - loss = 2.137, (2.223 sec/step)\n",
      "step 4771 - loss = 1.667, (1.457 sec/step)\n",
      "step 4772 - loss = 1.400, (0.961 sec/step)\n",
      "step 4773 - loss = 1.830, (0.843 sec/step)\n",
      "step 4774 - loss = 1.001, (1.201 sec/step)\n",
      "step 4775 - loss = 2.188, (1.303 sec/step)\n",
      "step 4776 - loss = 1.781, (1.409 sec/step)\n",
      "step 4777 - loss = 1.888, (2.932 sec/step)\n",
      "step 4778 - loss = 1.990, (1.426 sec/step)\n",
      "step 4779 - loss = 1.594, (0.940 sec/step)\n",
      "step 4780 - loss = 1.899, (2.665 sec/step)\n",
      "step 4781 - loss = 2.491, (2.485 sec/step)\n",
      "step 4782 - loss = 2.752, (2.381 sec/step)\n",
      "step 4783 - loss = 1.889, (1.698 sec/step)\n",
      "step 4784 - loss = 2.104, (1.578 sec/step)\n",
      "step 4785 - loss = 1.823, (2.045 sec/step)\n",
      "step 4786 - loss = 1.971, (1.196 sec/step)\n",
      "step 4787 - loss = 1.727, (1.680 sec/step)\n",
      "step 4788 - loss = 2.129, (1.704 sec/step)\n",
      "step 4789 - loss = 1.829, (0.996 sec/step)\n",
      "step 4790 - loss = 1.331, (1.275 sec/step)\n",
      "step 4791 - loss = 1.964, (1.198 sec/step)\n",
      "step 4792 - loss = 1.528, (1.473 sec/step)\n",
      "step 4793 - loss = 1.292, (1.176 sec/step)\n",
      "step 4794 - loss = 1.359, (0.857 sec/step)\n",
      "step 4795 - loss = 1.698, (1.153 sec/step)\n",
      "step 4796 - loss = 1.788, (1.458 sec/step)\n",
      "step 4797 - loss = 1.995, (2.007 sec/step)\n",
      "step 4798 - loss = 2.063, (3.362 sec/step)\n",
      "step 4799 - loss = 2.071, (2.089 sec/step)\n",
      "step 4800 - loss = 1.513, (2.429 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4801 - loss = 1.973, (1.387 sec/step)\n",
      "step 4802 - loss = 2.135, (2.213 sec/step)\n",
      "step 4803 - loss = 1.464, (1.049 sec/step)\n",
      "step 4804 - loss = 1.809, (2.636 sec/step)\n",
      "step 4805 - loss = 1.468, (1.494 sec/step)\n",
      "step 4806 - loss = 1.711, (1.642 sec/step)\n",
      "step 4807 - loss = 1.925, (2.126 sec/step)\n",
      "step 4808 - loss = 2.225, (2.075 sec/step)\n",
      "step 4809 - loss = 1.361, (1.299 sec/step)\n",
      "step 4810 - loss = 2.349, (2.010 sec/step)\n",
      "step 4811 - loss = 1.894, (1.881 sec/step)\n",
      "step 4812 - loss = 1.377, (1.089 sec/step)\n",
      "step 4813 - loss = 2.188, (0.971 sec/step)\n",
      "step 4814 - loss = 1.214, (1.315 sec/step)\n",
      "step 4815 - loss = 1.830, (1.129 sec/step)\n",
      "step 4816 - loss = 2.326, (1.271 sec/step)\n",
      "step 4817 - loss = 2.086, (1.325 sec/step)\n",
      "step 4818 - loss = 2.353, (1.624 sec/step)\n",
      "step 4819 - loss = 0.514, (2.422 sec/step)\n",
      "step 4820 - loss = 2.215, (2.003 sec/step)\n",
      "step 4821 - loss = 1.955, (2.472 sec/step)\n",
      "step 4822 - loss = 1.860, (1.282 sec/step)\n",
      "step 4823 - loss = 1.432, (1.020 sec/step)\n",
      "step 4824 - loss = 1.928, (1.359 sec/step)\n",
      "step 4825 - loss = 1.409, (1.118 sec/step)\n",
      "step 4826 - loss = 2.191, (1.296 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4827 - loss = 1.301, (1.560 sec/step)\n",
      "step 4828 - loss = 1.731, (0.843 sec/step)\n",
      "step 4829 - loss = 1.780, (1.389 sec/step)\n",
      "step 4830 - loss = 1.858, (1.146 sec/step)\n",
      "step 4831 - loss = 1.951, (2.428 sec/step)\n",
      "step 4832 - loss = 2.277, (1.353 sec/step)\n",
      "step 4833 - loss = 1.183, (1.597 sec/step)\n",
      "step 4834 - loss = 1.928, (1.253 sec/step)\n",
      "step 4835 - loss = 1.731, (1.029 sec/step)\n",
      "step 4836 - loss = 1.743, (1.649 sec/step)\n",
      "step 4837 - loss = 2.654, (1.784 sec/step)\n",
      "step 4838 - loss = 1.323, (1.179 sec/step)\n",
      "step 4839 - loss = 1.650, (0.997 sec/step)\n",
      "step 4840 - loss = 1.952, (2.541 sec/step)\n",
      "step 4841 - loss = 2.007, (3.181 sec/step)\n",
      "step 4842 - loss = 1.927, (1.113 sec/step)\n",
      "step 4843 - loss = 2.240, (3.005 sec/step)\n",
      "step 4844 - loss = 2.172, (1.098 sec/step)\n",
      "step 4845 - loss = 1.969, (1.182 sec/step)\n",
      "step 4846 - loss = 2.261, (1.898 sec/step)\n",
      "step 4847 - loss = 1.555, (1.562 sec/step)\n",
      "step 4848 - loss = 1.270, (1.457 sec/step)\n",
      "step 4849 - loss = 1.368, (2.074 sec/step)\n",
      "step 4850 - loss = 1.539, (1.962 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4851 - loss = 1.640, (1.049 sec/step)\n",
      "step 4852 - loss = 1.466, (1.377 sec/step)\n",
      "step 4853 - loss = 2.175, (1.731 sec/step)\n",
      "step 4854 - loss = 1.843, (0.998 sec/step)\n",
      "step 4855 - loss = 2.360, (1.325 sec/step)\n",
      "step 4856 - loss = 2.545, (1.557 sec/step)\n",
      "step 4857 - loss = 1.817, (1.524 sec/step)\n",
      "step 4858 - loss = 2.028, (3.277 sec/step)\n",
      "step 4859 - loss = 1.183, (2.486 sec/step)\n",
      "step 4860 - loss = 2.064, (2.728 sec/step)\n",
      "step 4861 - loss = 1.530, (1.101 sec/step)\n",
      "step 4862 - loss = 1.954, (1.051 sec/step)\n",
      "step 4863 - loss = 1.549, (2.487 sec/step)\n",
      "step 4864 - loss = 0.742, (0.999 sec/step)\n",
      "step 4865 - loss = 2.150, (2.035 sec/step)\n",
      "step 4866 - loss = 2.218, (2.695 sec/step)\n",
      "step 4867 - loss = 2.325, (2.616 sec/step)\n",
      "step 4868 - loss = 2.355, (1.258 sec/step)\n",
      "step 4869 - loss = 1.655, (1.033 sec/step)\n",
      "step 4870 - loss = 1.889, (1.971 sec/step)\n",
      "step 4871 - loss = 1.177, (3.387 sec/step)\n",
      "step 4872 - loss = 1.836, (1.228 sec/step)\n",
      "step 4873 - loss = 1.448, (0.952 sec/step)\n",
      "step 4874 - loss = 2.110, (2.054 sec/step)\n",
      "step 4875 - loss = 1.991, (1.625 sec/step)\n",
      "step 4876 - loss = 1.624, (1.429 sec/step)\n",
      "step 4877 - loss = 2.079, (1.400 sec/step)\n",
      "step 4878 - loss = 1.861, (0.927 sec/step)\n",
      "step 4879 - loss = 2.181, (2.552 sec/step)\n",
      "step 4880 - loss = 1.872, (1.257 sec/step)\n",
      "step 4881 - loss = 2.161, (2.001 sec/step)\n",
      "step 4882 - loss = 2.224, (1.718 sec/step)\n",
      "step 4883 - loss = 0.901, (1.756 sec/step)\n",
      "step 4884 - loss = 1.634, (1.385 sec/step)\n",
      "step 4885 - loss = 1.986, (1.807 sec/step)\n",
      "step 4886 - loss = 1.811, (2.792 sec/step)\n",
      "step 4887 - loss = 1.442, (1.762 sec/step)\n",
      "step 4888 - loss = 1.764, (1.303 sec/step)\n",
      "step 4889 - loss = 2.829, (2.486 sec/step)\n",
      "step 4890 - loss = 1.859, (1.987 sec/step)\n",
      "step 4891 - loss = 2.037, (1.864 sec/step)\n",
      "step 4892 - loss = 2.196, (2.004 sec/step)\n",
      "step 4893 - loss = 1.973, (1.523 sec/step)\n",
      "step 4894 - loss = 1.668, (1.033 sec/step)\n",
      "step 4895 - loss = 2.328, (2.313 sec/step)\n",
      "step 4896 - loss = 1.470, (1.457 sec/step)\n",
      "step 4897 - loss = 1.569, (2.483 sec/step)\n",
      "step 4898 - loss = 0.605, (0.694 sec/step)\n",
      "step 4899 - loss = 1.766, (1.323 sec/step)\n",
      "step 4900 - loss = 2.161, (1.851 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4901 - loss = 1.539, (1.114 sec/step)\n",
      "step 4902 - loss = 1.627, (1.013 sec/step)\n",
      "step 4903 - loss = 2.368, (2.377 sec/step)\n",
      "step 4904 - loss = 1.780, (1.939 sec/step)\n",
      "step 4905 - loss = 1.623, (1.160 sec/step)\n",
      "step 4906 - loss = 2.336, (2.846 sec/step)\n",
      "step 4907 - loss = 1.872, (1.230 sec/step)\n",
      "step 4908 - loss = 1.761, (1.128 sec/step)\n",
      "step 4909 - loss = 2.272, (1.943 sec/step)\n",
      "step 4910 - loss = 2.077, (1.067 sec/step)\n",
      "step 4911 - loss = 1.410, (2.412 sec/step)\n",
      "step 4912 - loss = 1.896, (1.762 sec/step)\n",
      "step 4913 - loss = 1.653, (1.561 sec/step)\n",
      "step 4914 - loss = 2.214, (1.729 sec/step)\n",
      "step 4915 - loss = 2.082, (1.276 sec/step)\n",
      "step 4916 - loss = 1.971, (1.424 sec/step)\n",
      "step 4917 - loss = 1.831, (1.192 sec/step)\n",
      "step 4918 - loss = 2.028, (1.346 sec/step)\n",
      "step 4919 - loss = 1.712, (0.952 sec/step)\n",
      "step 4920 - loss = 1.723, (1.343 sec/step)\n",
      "step 4921 - loss = 1.647, (1.708 sec/step)\n",
      "step 4922 - loss = 1.861, (1.124 sec/step)\n",
      "step 4923 - loss = 1.945, (1.182 sec/step)\n",
      "step 4924 - loss = 1.878, (2.171 sec/step)\n",
      "step 4925 - loss = 1.740, (1.849 sec/step)\n",
      "step 4926 - loss = 2.027, (1.864 sec/step)\n",
      "step 4927 - loss = 1.730, (1.410 sec/step)\n",
      "step 4928 - loss = 1.871, (1.256 sec/step)\n",
      "step 4929 - loss = 2.308, (2.499 sec/step)\n",
      "step 4930 - loss = 1.991, (0.831 sec/step)\n",
      "step 4931 - loss = 1.824, (1.131 sec/step)\n",
      "step 4932 - loss = 2.284, (0.856 sec/step)\n",
      "step 4933 - loss = 1.368, (1.273 sec/step)\n",
      "step 4934 - loss = 1.808, (1.358 sec/step)\n",
      "step 4935 - loss = 1.897, (1.000 sec/step)\n",
      "step 4936 - loss = 2.073, (2.409 sec/step)\n",
      "step 4937 - loss = 1.941, (1.273 sec/step)\n",
      "step 4938 - loss = 1.237, (1.281 sec/step)\n",
      "step 4939 - loss = 1.811, (1.430 sec/step)\n",
      "step 4940 - loss = 2.295, (1.462 sec/step)\n",
      "step 4941 - loss = 1.470, (1.347 sec/step)\n",
      "step 4942 - loss = 2.148, (1.423 sec/step)\n",
      "step 4943 - loss = 1.807, (1.310 sec/step)\n",
      "step 4944 - loss = 1.416, (2.839 sec/step)\n",
      "step 4945 - loss = 1.708, (1.872 sec/step)\n",
      "step 4946 - loss = 1.732, (2.638 sec/step)\n",
      "step 4947 - loss = 1.625, (2.267 sec/step)\n",
      "step 4948 - loss = 2.057, (3.080 sec/step)\n",
      "step 4949 - loss = 1.993, (1.382 sec/step)\n",
      "step 4950 - loss = 1.954, (1.931 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 4951 - loss = 1.633, (1.759 sec/step)\n",
      "step 4952 - loss = 1.779, (0.861 sec/step)\n",
      "step 4953 - loss = 1.395, (1.680 sec/step)\n",
      "step 4954 - loss = 1.542, (1.015 sec/step)\n",
      "step 4955 - loss = 1.343, (1.211 sec/step)\n",
      "step 4956 - loss = 1.934, (1.512 sec/step)\n",
      "step 4957 - loss = 1.696, (2.193 sec/step)\n",
      "step 4958 - loss = 1.585, (1.660 sec/step)\n",
      "step 4959 - loss = 1.554, (2.876 sec/step)\n",
      "step 4960 - loss = 2.133, (1.099 sec/step)\n",
      "step 4961 - loss = 1.259, (1.442 sec/step)\n",
      "step 4962 - loss = 1.866, (1.355 sec/step)\n",
      "step 4963 - loss = 1.717, (1.887 sec/step)\n",
      "step 4964 - loss = 1.303, (1.849 sec/step)\n",
      "step 4965 - loss = 1.049, (2.484 sec/step)\n",
      "step 4966 - loss = 0.640, (2.484 sec/step)\n",
      "step 4967 - loss = 0.538, (1.871 sec/step)\n",
      "step 4968 - loss = 1.654, (1.474 sec/step)\n",
      "step 4969 - loss = 1.507, (1.147 sec/step)\n",
      "step 4970 - loss = 1.808, (1.322 sec/step)\n",
      "step 4971 - loss = 1.880, (1.289 sec/step)\n",
      "step 4972 - loss = 2.314, (2.156 sec/step)\n",
      "step 4973 - loss = 2.303, (0.940 sec/step)\n",
      "step 4974 - loss = 1.696, (2.482 sec/step)\n",
      "step 4975 - loss = 0.501, (0.567 sec/step)\n",
      "step 4976 - loss = 1.470, (1.515 sec/step)\n",
      "step 4977 - loss = 2.232, (1.525 sec/step)\n",
      "step 4978 - loss = 2.133, (1.373 sec/step)\n",
      "step 4979 - loss = 1.753, (3.580 sec/step)\n",
      "step 4980 - loss = 1.674, (1.629 sec/step)\n",
      "step 4981 - loss = 1.724, (1.992 sec/step)\n",
      "step 4982 - loss = 1.872, (1.355 sec/step)\n",
      "step 4983 - loss = 2.009, (2.024 sec/step)\n",
      "step 4984 - loss = 2.262, (2.187 sec/step)\n",
      "step 4985 - loss = 2.095, (1.895 sec/step)\n",
      "step 4986 - loss = 1.654, (1.276 sec/step)\n",
      "step 4987 - loss = 1.971, (1.494 sec/step)\n",
      "step 4988 - loss = 2.360, (2.006 sec/step)\n",
      "step 4989 - loss = 1.716, (2.066 sec/step)\n",
      "step 4990 - loss = 1.534, (1.867 sec/step)\n",
      "step 4991 - loss = 1.695, (2.241 sec/step)\n",
      "step 4992 - loss = 1.532, (2.980 sec/step)\n",
      "step 4993 - loss = 1.568, (1.589 sec/step)\n",
      "step 4994 - loss = 2.147, (2.482 sec/step)\n",
      "step 4995 - loss = 1.936, (0.983 sec/step)\n",
      "step 4996 - loss = 1.498, (0.709 sec/step)\n",
      "step 4997 - loss = 2.033, (2.379 sec/step)\n",
      "step 4998 - loss = 1.841, (1.223 sec/step)\n",
      "step 4999 - loss = 1.674, (1.274 sec/step)\n",
      "step 5000 - loss = 2.068, (1.419 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5001 - loss = 2.040, (1.722 sec/step)\n",
      "step 5002 - loss = 1.369, (1.326 sec/step)\n",
      "step 5003 - loss = 2.042, (1.424 sec/step)\n",
      "step 5004 - loss = 2.038, (2.492 sec/step)\n",
      "step 5005 - loss = 2.279, (2.487 sec/step)\n",
      "step 5006 - loss = 1.680, (0.961 sec/step)\n",
      "step 5007 - loss = 2.061, (1.083 sec/step)\n",
      "step 5008 - loss = 1.654, (1.369 sec/step)\n",
      "step 5009 - loss = 1.936, (1.989 sec/step)\n",
      "step 5010 - loss = 1.955, (1.744 sec/step)\n",
      "step 5011 - loss = 2.269, (3.546 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5012 - loss = 1.706, (1.550 sec/step)\n",
      "step 5013 - loss = 1.652, (1.273 sec/step)\n",
      "step 5014 - loss = 2.491, (2.076 sec/step)\n",
      "step 5015 - loss = 1.822, (2.490 sec/step)\n",
      "step 5016 - loss = 0.867, (0.742 sec/step)\n",
      "step 5017 - loss = 2.075, (1.330 sec/step)\n",
      "step 5018 - loss = 1.730, (1.655 sec/step)\n",
      "step 5019 - loss = 2.371, (2.727 sec/step)\n",
      "step 5020 - loss = 2.312, (2.488 sec/step)\n",
      "step 5021 - loss = 2.317, (3.814 sec/step)\n",
      "step 5022 - loss = 1.931, (1.145 sec/step)\n",
      "step 5023 - loss = 1.513, (1.712 sec/step)\n",
      "step 5024 - loss = 1.355, (1.606 sec/step)\n",
      "step 5025 - loss = 1.753, (1.559 sec/step)\n",
      "step 5026 - loss = 1.815, (1.003 sec/step)\n",
      "step 5027 - loss = 1.746, (1.115 sec/step)\n",
      "step 5028 - loss = 1.744, (1.264 sec/step)\n",
      "step 5029 - loss = 1.741, (1.132 sec/step)\n",
      "step 5030 - loss = 2.437, (2.486 sec/step)\n",
      "step 5031 - loss = 0.884, (2.132 sec/step)\n",
      "step 5032 - loss = 2.255, (1.942 sec/step)\n",
      "step 5033 - loss = 2.022, (1.408 sec/step)\n",
      "step 5034 - loss = 1.926, (1.789 sec/step)\n",
      "step 5035 - loss = 1.917, (1.994 sec/step)\n",
      "step 5036 - loss = 1.673, (1.117 sec/step)\n",
      "step 5037 - loss = 1.948, (1.666 sec/step)\n",
      "step 5038 - loss = 1.684, (1.296 sec/step)\n",
      "step 5039 - loss = 1.381, (1.396 sec/step)\n",
      "step 5040 - loss = 2.113, (2.265 sec/step)\n",
      "step 5041 - loss = 2.321, (2.796 sec/step)\n",
      "step 5042 - loss = 1.829, (1.107 sec/step)\n",
      "step 5043 - loss = 1.057, (1.873 sec/step)\n",
      "step 5044 - loss = 1.760, (2.090 sec/step)\n",
      "step 5045 - loss = 2.162, (1.962 sec/step)\n",
      "step 5046 - loss = 2.215, (2.963 sec/step)\n",
      "step 5047 - loss = 1.708, (1.909 sec/step)\n",
      "step 5048 - loss = 2.131, (1.188 sec/step)\n",
      "step 5049 - loss = 2.039, (1.639 sec/step)\n",
      "step 5050 - loss = 1.358, (2.273 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5051 - loss = 1.905, (1.780 sec/step)\n",
      "step 5052 - loss = 1.713, (1.721 sec/step)\n",
      "step 5053 - loss = 1.897, (1.650 sec/step)\n",
      "step 5054 - loss = 2.086, (1.089 sec/step)\n",
      "step 5055 - loss = 1.739, (0.987 sec/step)\n",
      "step 5056 - loss = 2.094, (1.151 sec/step)\n",
      "step 5057 - loss = 1.978, (2.483 sec/step)\n",
      "step 5058 - loss = 0.993, (0.952 sec/step)\n",
      "step 5059 - loss = 2.147, (1.100 sec/step)\n",
      "step 5060 - loss = 2.231, (1.490 sec/step)\n",
      "step 5061 - loss = 1.738, (1.169 sec/step)\n",
      "step 5062 - loss = 2.013, (1.886 sec/step)\n",
      "step 5063 - loss = 1.612, (1.244 sec/step)\n",
      "step 5064 - loss = 1.320, (1.876 sec/step)\n",
      "step 5065 - loss = 1.634, (1.579 sec/step)\n",
      "step 5066 - loss = 1.966, (1.506 sec/step)\n",
      "step 5067 - loss = 1.686, (1.143 sec/step)\n",
      "step 5068 - loss = 1.990, (2.483 sec/step)\n",
      "step 5069 - loss = 1.501, (1.869 sec/step)\n",
      "step 5070 - loss = 1.795, (1.256 sec/step)\n",
      "step 5071 - loss = 1.772, (1.281 sec/step)\n",
      "step 5072 - loss = 2.105, (1.541 sec/step)\n",
      "step 5073 - loss = 2.375, (2.027 sec/step)\n",
      "step 5074 - loss = 2.302, (1.262 sec/step)\n",
      "step 5075 - loss = 1.867, (1.085 sec/step)\n",
      "step 5076 - loss = 2.015, (2.097 sec/step)\n",
      "step 5077 - loss = 2.190, (1.160 sec/step)\n",
      "step 5078 - loss = 1.874, (1.194 sec/step)\n",
      "step 5079 - loss = 1.319, (1.800 sec/step)\n",
      "step 5080 - loss = 2.378, (1.455 sec/step)\n",
      "step 5081 - loss = 1.938, (1.337 sec/step)\n",
      "step 5082 - loss = 1.456, (1.779 sec/step)\n",
      "step 5083 - loss = 1.939, (1.554 sec/step)\n",
      "step 5084 - loss = 1.776, (2.754 sec/step)\n",
      "step 5085 - loss = 1.152, (1.380 sec/step)\n",
      "step 5086 - loss = 1.972, (1.346 sec/step)\n",
      "step 5087 - loss = 1.598, (2.004 sec/step)\n",
      "step 5088 - loss = 1.790, (1.329 sec/step)\n",
      "step 5089 - loss = 1.721, (2.699 sec/step)\n",
      "step 5090 - loss = 2.182, (1.157 sec/step)\n",
      "step 5091 - loss = 1.771, (1.356 sec/step)\n",
      "step 5092 - loss = 2.744, (2.485 sec/step)\n",
      "step 5093 - loss = 1.887, (2.286 sec/step)\n",
      "step 5094 - loss = 1.654, (1.839 sec/step)\n",
      "step 5095 - loss = 2.381, (1.093 sec/step)\n",
      "step 5096 - loss = 2.044, (1.145 sec/step)\n",
      "step 5097 - loss = 1.997, (1.199 sec/step)\n",
      "step 5098 - loss = 1.972, (1.244 sec/step)\n",
      "step 5099 - loss = 1.701, (1.099 sec/step)\n",
      "step 5100 - loss = 2.007, (2.219 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5101 - loss = 1.689, (1.570 sec/step)\n",
      "step 5102 - loss = 1.310, (1.303 sec/step)\n",
      "step 5103 - loss = 2.230, (1.465 sec/step)\n",
      "step 5104 - loss = 1.500, (1.953 sec/step)\n",
      "step 5105 - loss = 1.904, (1.492 sec/step)\n",
      "step 5106 - loss = 2.135, (2.488 sec/step)\n",
      "step 5107 - loss = 1.875, (0.231 sec/step)\n",
      "step 5108 - loss = 1.616, (2.085 sec/step)\n",
      "step 5109 - loss = 2.244, (1.925 sec/step)\n",
      "step 5110 - loss = 1.880, (1.804 sec/step)\n",
      "step 5111 - loss = 2.004, (1.519 sec/step)\n",
      "step 5112 - loss = 1.862, (2.728 sec/step)\n",
      "step 5113 - loss = 1.800, (1.447 sec/step)\n",
      "step 5114 - loss = 1.456, (1.873 sec/step)\n",
      "step 5115 - loss = 1.681, (1.086 sec/step)\n",
      "step 5116 - loss = 1.629, (2.342 sec/step)\n",
      "step 5117 - loss = 2.235, (2.808 sec/step)\n",
      "step 5118 - loss = 1.606, (1.480 sec/step)\n",
      "step 5119 - loss = 1.570, (1.104 sec/step)\n",
      "step 5120 - loss = 1.607, (0.868 sec/step)\n",
      "step 5121 - loss = 2.383, (1.297 sec/step)\n",
      "step 5122 - loss = 2.153, (1.896 sec/step)\n",
      "step 5123 - loss = 1.451, (1.361 sec/step)\n",
      "step 5124 - loss = 2.139, (1.544 sec/step)\n",
      "step 5125 - loss = 1.981, (1.588 sec/step)\n",
      "step 5126 - loss = 1.573, (1.147 sec/step)\n",
      "step 5127 - loss = 1.765, (0.989 sec/step)\n",
      "step 5128 - loss = 2.338, (1.293 sec/step)\n",
      "step 5129 - loss = 1.871, (2.486 sec/step)\n",
      "step 5130 - loss = 1.898, (1.351 sec/step)\n",
      "step 5131 - loss = 2.068, (1.830 sec/step)\n",
      "step 5132 - loss = 2.024, (2.033 sec/step)\n",
      "step 5133 - loss = 2.342, (2.486 sec/step)\n",
      "step 5134 - loss = 1.021, (0.430 sec/step)\n",
      "step 5135 - loss = 2.000, (0.867 sec/step)\n",
      "step 5136 - loss = 2.251, (1.873 sec/step)\n",
      "step 5137 - loss = 2.173, (1.684 sec/step)\n",
      "step 5138 - loss = 2.377, (0.991 sec/step)\n",
      "step 5139 - loss = 2.336, (1.112 sec/step)\n",
      "step 5140 - loss = 1.496, (2.485 sec/step)\n",
      "step 5141 - loss = 1.700, (2.542 sec/step)\n",
      "step 5142 - loss = 1.656, (2.797 sec/step)\n",
      "step 5143 - loss = 2.051, (1.705 sec/step)\n",
      "step 5144 - loss = 2.232, (1.922 sec/step)\n",
      "step 5145 - loss = 1.580, (1.849 sec/step)\n",
      "step 5146 - loss = 2.113, (1.094 sec/step)\n",
      "step 5147 - loss = 1.975, (1.257 sec/step)\n",
      "step 5148 - loss = 1.787, (1.674 sec/step)\n",
      "step 5149 - loss = 1.983, (1.343 sec/step)\n",
      "step 5150 - loss = 1.915, (1.677 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5151 - loss = 1.811, (1.824 sec/step)\n",
      "step 5152 - loss = 1.559, (1.226 sec/step)\n",
      "step 5153 - loss = 2.216, (1.233 sec/step)\n",
      "step 5154 - loss = 1.413, (1.844 sec/step)\n",
      "step 5155 - loss = 1.657, (1.377 sec/step)\n",
      "step 5156 - loss = 2.104, (1.442 sec/step)\n",
      "step 5157 - loss = 1.895, (1.572 sec/step)\n",
      "step 5158 - loss = 2.003, (2.635 sec/step)\n",
      "step 5159 - loss = 2.174, (2.688 sec/step)\n",
      "step 5160 - loss = 2.140, (1.291 sec/step)\n",
      "step 5161 - loss = 1.626, (1.031 sec/step)\n",
      "step 5162 - loss = 2.410, (1.824 sec/step)\n",
      "step 5163 - loss = 1.597, (1.211 sec/step)\n",
      "step 5164 - loss = 2.135, (1.101 sec/step)\n",
      "step 5165 - loss = 2.053, (1.596 sec/step)\n",
      "step 5166 - loss = 1.948, (1.560 sec/step)\n",
      "step 5167 - loss = 1.612, (2.263 sec/step)\n",
      "step 5168 - loss = 1.860, (1.916 sec/step)\n",
      "step 5169 - loss = 1.784, (1.185 sec/step)\n",
      "step 5170 - loss = 1.761, (1.329 sec/step)\n",
      "step 5171 - loss = 2.261, (1.246 sec/step)\n",
      "step 5172 - loss = 1.690, (1.455 sec/step)\n",
      "step 5173 - loss = 2.221, (1.674 sec/step)\n",
      "step 5174 - loss = 1.661, (1.279 sec/step)\n",
      "step 5175 - loss = 2.286, (2.041 sec/step)\n",
      "step 5176 - loss = 1.620, (2.076 sec/step)\n",
      "step 5177 - loss = 1.817, (0.912 sec/step)\n",
      "step 5178 - loss = 1.432, (1.750 sec/step)\n",
      "step 5179 - loss = 1.895, (1.456 sec/step)\n",
      "step 5180 - loss = 1.957, (1.798 sec/step)\n",
      "step 5181 - loss = 2.040, (1.284 sec/step)\n",
      "step 5182 - loss = 1.648, (1.096 sec/step)\n",
      "step 5183 - loss = 1.551, (1.491 sec/step)\n",
      "step 5184 - loss = 1.852, (2.169 sec/step)\n",
      "step 5185 - loss = 2.275, (1.747 sec/step)\n",
      "step 5186 - loss = 2.554, (0.868 sec/step)\n",
      "step 5187 - loss = 1.874, (0.762 sec/step)\n",
      "step 5188 - loss = 2.236, (1.116 sec/step)\n",
      "step 5189 - loss = 1.994, (1.659 sec/step)\n",
      "step 5190 - loss = 1.504, (2.480 sec/step)\n",
      "step 5191 - loss = 1.713, (1.099 sec/step)\n",
      "step 5192 - loss = 2.396, (2.488 sec/step)\n",
      "step 5193 - loss = 1.955, (0.511 sec/step)\n",
      "step 5194 - loss = 1.399, (1.283 sec/step)\n",
      "step 5195 - loss = 2.115, (2.516 sec/step)\n",
      "step 5196 - loss = 1.705, (1.460 sec/step)\n",
      "step 5197 - loss = 2.082, (1.747 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5198 - loss = 2.514, (1.052 sec/step)\n",
      "step 5199 - loss = 1.831, (1.630 sec/step)\n",
      "step 5200 - loss = 2.458, (1.113 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5201 - loss = 1.649, (1.115 sec/step)\n",
      "step 5202 - loss = 2.120, (1.893 sec/step)\n",
      "step 5203 - loss = 1.721, (1.683 sec/step)\n",
      "step 5204 - loss = 1.489, (1.676 sec/step)\n",
      "step 5205 - loss = 1.917, (1.178 sec/step)\n",
      "step 5206 - loss = 1.169, (3.148 sec/step)\n",
      "step 5207 - loss = 2.283, (1.360 sec/step)\n",
      "step 5208 - loss = 2.387, (2.316 sec/step)\n",
      "step 5209 - loss = 1.256, (2.609 sec/step)\n",
      "step 5210 - loss = 2.228, (0.793 sec/step)\n",
      "step 5211 - loss = 2.007, (1.246 sec/step)\n",
      "step 5212 - loss = 2.488, (3.646 sec/step)\n",
      "step 5213 - loss = 1.185, (2.255 sec/step)\n",
      "step 5214 - loss = 1.755, (1.015 sec/step)\n",
      "step 5215 - loss = 1.534, (1.651 sec/step)\n",
      "step 5216 - loss = 2.280, (2.650 sec/step)\n",
      "step 5217 - loss = 1.615, (1.809 sec/step)\n",
      "step 5218 - loss = 1.600, (2.635 sec/step)\n",
      "step 5219 - loss = 1.880, (1.779 sec/step)\n",
      "step 5220 - loss = 1.944, (1.952 sec/step)\n",
      "step 5221 - loss = 2.033, (2.296 sec/step)\n",
      "step 5222 - loss = 1.765, (2.244 sec/step)\n",
      "step 5223 - loss = 1.797, (1.488 sec/step)\n",
      "step 5224 - loss = 1.570, (1.162 sec/step)\n",
      "step 5225 - loss = 2.317, (2.568 sec/step)\n",
      "step 5226 - loss = 2.196, (2.446 sec/step)\n",
      "step 5227 - loss = 1.730, (2.484 sec/step)\n",
      "step 5228 - loss = 0.557, (0.382 sec/step)\n",
      "step 5229 - loss = 1.898, (2.620 sec/step)\n",
      "step 5230 - loss = 1.747, (1.577 sec/step)\n",
      "step 5231 - loss = 1.677, (1.445 sec/step)\n",
      "step 5232 - loss = 1.458, (2.702 sec/step)\n",
      "step 5233 - loss = 1.935, (1.683 sec/step)\n",
      "step 5234 - loss = 2.410, (2.393 sec/step)\n",
      "step 5235 - loss = 1.209, (1.179 sec/step)\n",
      "step 5236 - loss = 2.296, (2.319 sec/step)\n",
      "step 5237 - loss = 1.773, (1.673 sec/step)\n",
      "step 5238 - loss = 1.948, (1.256 sec/step)\n",
      "step 5239 - loss = 2.041, (0.987 sec/step)\n",
      "step 5240 - loss = 1.584, (2.378 sec/step)\n",
      "step 5241 - loss = 1.672, (1.835 sec/step)\n",
      "step 5242 - loss = 1.530, (1.660 sec/step)\n",
      "step 5243 - loss = 2.373, (1.890 sec/step)\n",
      "step 5244 - loss = 1.565, (2.067 sec/step)\n",
      "step 5245 - loss = 1.644, (1.361 sec/step)\n",
      "step 5246 - loss = 1.511, (0.987 sec/step)\n",
      "step 5247 - loss = 1.442, (1.097 sec/step)\n",
      "step 5248 - loss = 1.794, (2.484 sec/step)\n",
      "step 5249 - loss = 0.649, (0.953 sec/step)\n",
      "step 5250 - loss = 1.956, (1.411 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5251 - loss = 1.888, (1.554 sec/step)\n",
      "step 5252 - loss = 1.731, (2.585 sec/step)\n",
      "step 5253 - loss = 1.612, (1.976 sec/step)\n",
      "step 5254 - loss = 1.625, (2.036 sec/step)\n",
      "step 5255 - loss = 1.705, (2.486 sec/step)\n",
      "step 5256 - loss = 2.090, (0.513 sec/step)\n",
      "step 5257 - loss = 2.303, (2.711 sec/step)\n",
      "step 5258 - loss = 1.492, (2.582 sec/step)\n",
      "step 5259 - loss = 1.925, (1.467 sec/step)\n",
      "step 5260 - loss = 2.207, (1.159 sec/step)\n",
      "step 5261 - loss = 1.951, (1.543 sec/step)\n",
      "step 5262 - loss = 1.641, (1.266 sec/step)\n",
      "step 5263 - loss = 1.763, (1.638 sec/step)\n",
      "step 5264 - loss = 1.836, (1.160 sec/step)\n",
      "step 5265 - loss = 2.306, (2.365 sec/step)\n",
      "step 5266 - loss = 1.742, (1.701 sec/step)\n",
      "step 5267 - loss = 1.779, (1.194 sec/step)\n",
      "step 5268 - loss = 2.268, (2.105 sec/step)\n",
      "step 5269 - loss = 1.831, (2.917 sec/step)\n",
      "step 5270 - loss = 2.388, (2.001 sec/step)\n",
      "step 5271 - loss = 1.976, (1.257 sec/step)\n",
      "step 5272 - loss = 1.859, (2.026 sec/step)\n",
      "step 5273 - loss = 1.942, (0.998 sec/step)\n",
      "step 5274 - loss = 1.985, (1.458 sec/step)\n",
      "step 5275 - loss = 2.237, (1.494 sec/step)\n",
      "step 5276 - loss = 1.591, (1.088 sec/step)\n",
      "step 5277 - loss = 1.772, (1.099 sec/step)\n",
      "step 5278 - loss = 1.815, (1.639 sec/step)\n",
      "step 5279 - loss = 1.865, (1.388 sec/step)\n",
      "step 5280 - loss = 1.573, (1.633 sec/step)\n",
      "step 5281 - loss = 2.411, (0.940 sec/step)\n",
      "step 5282 - loss = 1.948, (1.933 sec/step)\n",
      "step 5283 - loss = 1.918, (2.675 sec/step)\n",
      "step 5284 - loss = 2.157, (1.558 sec/step)\n",
      "step 5285 - loss = 1.505, (0.932 sec/step)\n",
      "step 5286 - loss = 1.818, (3.267 sec/step)\n",
      "step 5287 - loss = 2.281, (1.492 sec/step)\n",
      "step 5288 - loss = 1.846, (0.998 sec/step)\n",
      "step 5289 - loss = 2.118, (2.446 sec/step)\n",
      "step 5290 - loss = 1.872, (1.309 sec/step)\n",
      "step 5291 - loss = 1.646, (1.306 sec/step)\n",
      "step 5292 - loss = 1.439, (1.389 sec/step)\n",
      "step 5293 - loss = 2.118, (1.440 sec/step)\n",
      "step 5294 - loss = 1.530, (1.589 sec/step)\n",
      "step 5295 - loss = 1.585, (1.784 sec/step)\n",
      "step 5296 - loss = 1.615, (2.483 sec/step)\n",
      "step 5297 - loss = 1.277, (1.225 sec/step)\n",
      "step 5298 - loss = 1.586, (1.123 sec/step)\n",
      "step 5299 - loss = 1.731, (1.319 sec/step)\n",
      "step 5300 - loss = 1.399, (1.278 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5301 - loss = 2.011, (1.560 sec/step)\n",
      "step 5302 - loss = 2.416, (2.488 sec/step)\n",
      "step 5303 - loss = 2.482, (1.593 sec/step)\n",
      "step 5304 - loss = 2.103, (1.202 sec/step)\n",
      "step 5305 - loss = 1.679, (1.669 sec/step)\n",
      "step 5306 - loss = 1.897, (1.546 sec/step)\n",
      "step 5307 - loss = 2.494, (1.229 sec/step)\n",
      "step 5308 - loss = 1.888, (0.830 sec/step)\n",
      "step 5309 - loss = 1.976, (1.546 sec/step)\n",
      "step 5310 - loss = 1.922, (1.972 sec/step)\n",
      "step 5311 - loss = 1.691, (2.487 sec/step)\n",
      "step 5312 - loss = 0.413, (0.379 sec/step)\n",
      "step 5313 - loss = 2.520, (2.187 sec/step)\n",
      "step 5314 - loss = 1.526, (0.988 sec/step)\n",
      "step 5315 - loss = 1.808, (0.990 sec/step)\n",
      "step 5316 - loss = 1.591, (3.019 sec/step)\n",
      "step 5317 - loss = 1.331, (2.749 sec/step)\n",
      "step 5318 - loss = 1.841, (2.489 sec/step)\n",
      "step 5319 - loss = 1.264, (0.672 sec/step)\n",
      "step 5320 - loss = 2.093, (1.648 sec/step)\n",
      "step 5321 - loss = 1.902, (1.171 sec/step)\n",
      "step 5322 - loss = 1.774, (1.834 sec/step)\n",
      "step 5323 - loss = 2.003, (1.346 sec/step)\n",
      "step 5324 - loss = 1.923, (1.999 sec/step)\n",
      "step 5325 - loss = 2.464, (1.348 sec/step)\n",
      "step 5326 - loss = 2.091, (1.922 sec/step)\n",
      "step 5327 - loss = 1.452, (3.262 sec/step)\n",
      "step 5328 - loss = 1.731, (2.485 sec/step)\n",
      "step 5329 - loss = 2.214, (1.262 sec/step)\n",
      "step 5330 - loss = 1.683, (1.488 sec/step)\n",
      "step 5331 - loss = 2.106, (1.930 sec/step)\n",
      "step 5332 - loss = 1.531, (3.011 sec/step)\n",
      "step 5333 - loss = 1.358, (1.309 sec/step)\n",
      "step 5334 - loss = 1.593, (1.095 sec/step)\n",
      "step 5335 - loss = 1.732, (1.442 sec/step)\n",
      "step 5336 - loss = 1.594, (1.424 sec/step)\n",
      "step 5337 - loss = 2.628, (1.601 sec/step)\n",
      "step 5338 - loss = 1.978, (2.656 sec/step)\n",
      "step 5339 - loss = 2.198, (1.048 sec/step)\n",
      "step 5340 - loss = 2.268, (1.181 sec/step)\n",
      "step 5341 - loss = 1.864, (2.636 sec/step)\n",
      "step 5342 - loss = 1.561, (1.197 sec/step)\n",
      "step 5343 - loss = 2.432, (2.489 sec/step)\n",
      "step 5344 - loss = 2.025, (2.655 sec/step)\n",
      "step 5345 - loss = 1.429, (2.467 sec/step)\n",
      "step 5346 - loss = 2.477, (1.558 sec/step)\n",
      "step 5347 - loss = 2.071, (1.310 sec/step)\n",
      "step 5348 - loss = 1.423, (1.148 sec/step)\n",
      "step 5349 - loss = 2.030, (1.607 sec/step)\n",
      "step 5350 - loss = 1.520, (1.179 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5351 - loss = 1.692, (0.905 sec/step)\n",
      "step 5352 - loss = 1.108, (3.306 sec/step)\n",
      "step 5353 - loss = 2.567, (1.992 sec/step)\n",
      "step 5354 - loss = 1.425, (1.178 sec/step)\n",
      "step 5355 - loss = 1.208, (1.366 sec/step)\n",
      "step 5356 - loss = 1.846, (1.134 sec/step)\n",
      "step 5357 - loss = 1.545, (2.882 sec/step)\n",
      "step 5358 - loss = 1.609, (1.714 sec/step)\n",
      "step 5359 - loss = 1.538, (1.392 sec/step)\n",
      "step 5360 - loss = 2.674, (1.418 sec/step)\n",
      "step 5361 - loss = 1.357, (2.613 sec/step)\n",
      "step 5362 - loss = 1.223, (2.498 sec/step)\n",
      "step 5363 - loss = 1.631, (1.707 sec/step)\n",
      "step 5364 - loss = 1.641, (1.109 sec/step)\n",
      "step 5365 - loss = 2.696, (1.685 sec/step)\n",
      "step 5366 - loss = 1.718, (3.355 sec/step)\n",
      "step 5367 - loss = 1.402, (1.385 sec/step)\n",
      "step 5368 - loss = 2.155, (1.475 sec/step)\n",
      "step 5369 - loss = 2.139, (1.577 sec/step)\n",
      "step 5370 - loss = 1.702, (1.409 sec/step)\n",
      "step 5371 - loss = 1.882, (2.265 sec/step)\n",
      "step 5372 - loss = 1.561, (1.218 sec/step)\n",
      "step 5373 - loss = 1.617, (1.591 sec/step)\n",
      "step 5374 - loss = 1.726, (2.662 sec/step)\n",
      "step 5375 - loss = 2.048, (1.722 sec/step)\n",
      "step 5376 - loss = 1.767, (2.800 sec/step)\n",
      "step 5377 - loss = 1.703, (1.290 sec/step)\n",
      "step 5378 - loss = 2.216, (2.194 sec/step)\n",
      "step 5379 - loss = 1.993, (1.823 sec/step)\n",
      "step 5380 - loss = 2.086, (1.391 sec/step)\n",
      "step 5381 - loss = 1.887, (1.325 sec/step)\n",
      "step 5382 - loss = 1.772, (1.941 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5383 - loss = 2.303, (2.488 sec/step)\n",
      "step 5384 - loss = 2.319, (2.487 sec/step)\n",
      "step 5385 - loss = 1.479, (1.601 sec/step)\n",
      "step 5386 - loss = 2.415, (2.707 sec/step)\n",
      "step 5387 - loss = 1.692, (1.288 sec/step)\n",
      "step 5388 - loss = 1.291, (1.017 sec/step)\n",
      "step 5389 - loss = 2.189, (1.514 sec/step)\n",
      "step 5390 - loss = 1.742, (1.278 sec/step)\n",
      "step 5391 - loss = 2.013, (1.496 sec/step)\n",
      "step 5392 - loss = 1.591, (1.446 sec/step)\n",
      "step 5393 - loss = 2.218, (1.322 sec/step)\n",
      "step 5394 - loss = 1.810, (1.423 sec/step)\n",
      "step 5395 - loss = 1.591, (1.557 sec/step)\n",
      "step 5396 - loss = 2.116, (1.408 sec/step)\n",
      "step 5397 - loss = 1.239, (1.131 sec/step)\n",
      "step 5398 - loss = 2.337, (1.147 sec/step)\n",
      "step 5399 - loss = 2.084, (2.463 sec/step)\n",
      "step 5400 - loss = 1.601, (1.246 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5401 - loss = 1.856, (2.903 sec/step)\n",
      "step 5402 - loss = 2.237, (2.212 sec/step)\n",
      "step 5403 - loss = 2.261, (0.958 sec/step)\n",
      "step 5404 - loss = 1.847, (1.470 sec/step)\n",
      "step 5405 - loss = 1.633, (1.142 sec/step)\n",
      "step 5406 - loss = 1.692, (1.127 sec/step)\n",
      "step 5407 - loss = 1.647, (1.051 sec/step)\n",
      "step 5408 - loss = 2.009, (1.059 sec/step)\n",
      "step 5409 - loss = 1.822, (0.896 sec/step)\n",
      "step 5410 - loss = 2.367, (2.482 sec/step)\n",
      "step 5411 - loss = 2.694, (3.516 sec/step)\n",
      "step 5412 - loss = 1.870, (1.034 sec/step)\n",
      "step 5413 - loss = 2.333, (1.828 sec/step)\n",
      "step 5414 - loss = 1.941, (2.116 sec/step)\n",
      "step 5415 - loss = 2.216, (1.253 sec/step)\n",
      "step 5416 - loss = 1.889, (1.663 sec/step)\n",
      "step 5417 - loss = 1.934, (0.957 sec/step)\n",
      "step 5418 - loss = 1.977, (1.710 sec/step)\n",
      "step 5419 - loss = 1.580, (1.523 sec/step)\n",
      "step 5420 - loss = 2.011, (1.124 sec/step)\n",
      "step 5421 - loss = 2.058, (1.083 sec/step)\n",
      "step 5422 - loss = 1.951, (3.111 sec/step)\n",
      "step 5423 - loss = 2.310, (1.909 sec/step)\n",
      "step 5424 - loss = 2.078, (1.067 sec/step)\n",
      "step 5425 - loss = 1.882, (1.382 sec/step)\n",
      "step 5426 - loss = 2.019, (2.376 sec/step)\n",
      "step 5427 - loss = 1.819, (1.520 sec/step)\n",
      "step 5428 - loss = 2.049, (1.606 sec/step)\n",
      "step 5429 - loss = 1.631, (3.194 sec/step)\n",
      "step 5430 - loss = 2.000, (2.001 sec/step)\n",
      "step 5431 - loss = 1.364, (1.736 sec/step)\n",
      "step 5432 - loss = 1.671, (1.637 sec/step)\n",
      "step 5433 - loss = 1.943, (2.340 sec/step)\n",
      "step 5434 - loss = 1.381, (1.307 sec/step)\n",
      "step 5435 - loss = 2.070, (1.637 sec/step)\n",
      "step 5436 - loss = 1.791, (1.894 sec/step)\n",
      "step 5437 - loss = 1.660, (1.221 sec/step)\n",
      "step 5438 - loss = 2.537, (1.481 sec/step)\n",
      "step 5439 - loss = 1.741, (1.801 sec/step)\n",
      "step 5440 - loss = 2.110, (1.680 sec/step)\n",
      "step 5441 - loss = 1.917, (1.445 sec/step)\n",
      "step 5442 - loss = 2.119, (1.650 sec/step)\n",
      "step 5443 - loss = 2.026, (1.744 sec/step)\n",
      "step 5444 - loss = 1.628, (1.242 sec/step)\n",
      "step 5445 - loss = 1.975, (1.866 sec/step)\n",
      "step 5446 - loss = 1.922, (1.931 sec/step)\n",
      "step 5447 - loss = 2.196, (1.965 sec/step)\n",
      "step 5448 - loss = 1.944, (1.051 sec/step)\n",
      "step 5449 - loss = 1.467, (1.929 sec/step)\n",
      "step 5450 - loss = 2.296, (1.493 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5451 - loss = 2.112, (3.151 sec/step)\n",
      "step 5452 - loss = 1.652, (0.911 sec/step)\n",
      "step 5453 - loss = 1.740, (2.709 sec/step)\n",
      "step 5454 - loss = 2.331, (1.491 sec/step)\n",
      "step 5455 - loss = 1.943, (1.333 sec/step)\n",
      "step 5456 - loss = 2.419, (1.458 sec/step)\n",
      "step 5457 - loss = 1.681, (1.363 sec/step)\n",
      "step 5458 - loss = 1.504, (1.282 sec/step)\n",
      "step 5459 - loss = 1.979, (1.443 sec/step)\n",
      "step 5460 - loss = 1.398, (2.543 sec/step)\n",
      "step 5461 - loss = 1.344, (1.419 sec/step)\n",
      "step 5462 - loss = 1.658, (2.094 sec/step)\n",
      "step 5463 - loss = 2.324, (1.801 sec/step)\n",
      "step 5464 - loss = 2.028, (0.926 sec/step)\n",
      "step 5465 - loss = 1.764, (1.115 sec/step)\n",
      "step 5466 - loss = 1.913, (1.143 sec/step)\n",
      "step 5467 - loss = 2.687, (1.535 sec/step)\n",
      "step 5468 - loss = 2.090, (1.744 sec/step)\n",
      "step 5469 - loss = 1.810, (1.312 sec/step)\n",
      "step 5470 - loss = 1.683, (1.102 sec/step)\n",
      "step 5471 - loss = 1.578, (1.097 sec/step)\n",
      "step 5472 - loss = 2.599, (1.749 sec/step)\n",
      "step 5473 - loss = 1.836, (1.791 sec/step)\n",
      "step 5474 - loss = 1.404, (1.279 sec/step)\n",
      "step 5475 - loss = 2.029, (0.839 sec/step)\n",
      "step 5476 - loss = 2.395, (2.783 sec/step)\n",
      "step 5477 - loss = 1.904, (1.229 sec/step)\n",
      "step 5478 - loss = 1.781, (2.763 sec/step)\n",
      "step 5479 - loss = 2.579, (2.486 sec/step)\n",
      "step 5480 - loss = 2.144, (1.232 sec/step)\n",
      "step 5481 - loss = 1.888, (1.412 sec/step)\n",
      "step 5482 - loss = 1.669, (1.541 sec/step)\n",
      "step 5483 - loss = 1.812, (1.775 sec/step)\n",
      "step 5484 - loss = 2.052, (0.907 sec/step)\n",
      "step 5485 - loss = 1.687, (2.918 sec/step)\n",
      "step 5486 - loss = 1.675, (2.023 sec/step)\n",
      "step 5487 - loss = 1.838, (1.962 sec/step)\n",
      "step 5488 - loss = 1.953, (1.559 sec/step)\n",
      "step 5489 - loss = 1.764, (1.639 sec/step)\n",
      "step 5490 - loss = 1.878, (1.608 sec/step)\n",
      "step 5491 - loss = 2.644, (1.262 sec/step)\n",
      "step 5492 - loss = 2.010, (2.064 sec/step)\n",
      "step 5493 - loss = 2.003, (1.095 sec/step)\n",
      "step 5494 - loss = 1.897, (1.557 sec/step)\n",
      "step 5495 - loss = 2.099, (1.530 sec/step)\n",
      "step 5496 - loss = 1.747, (1.643 sec/step)\n",
      "step 5497 - loss = 1.813, (1.967 sec/step)\n",
      "step 5498 - loss = 1.884, (1.917 sec/step)\n",
      "step 5499 - loss = 1.462, (0.971 sec/step)\n",
      "step 5500 - loss = 2.046, (2.057 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5501 - loss = 1.505, (1.300 sec/step)\n",
      "step 5502 - loss = 1.874, (1.366 sec/step)\n",
      "step 5503 - loss = 2.240, (1.246 sec/step)\n",
      "step 5504 - loss = 2.042, (1.986 sec/step)\n",
      "step 5505 - loss = 2.059, (1.071 sec/step)\n",
      "step 5506 - loss = 1.427, (1.093 sec/step)\n",
      "step 5507 - loss = 1.820, (1.113 sec/step)\n",
      "step 5508 - loss = 2.013, (1.575 sec/step)\n",
      "step 5509 - loss = 1.668, (2.054 sec/step)\n",
      "step 5510 - loss = 2.051, (1.224 sec/step)\n",
      "step 5511 - loss = 1.835, (1.127 sec/step)\n",
      "step 5512 - loss = 1.810, (1.813 sec/step)\n",
      "step 5513 - loss = 1.637, (1.506 sec/step)\n",
      "step 5514 - loss = 1.501, (2.994 sec/step)\n",
      "step 5515 - loss = 2.223, (1.156 sec/step)\n",
      "step 5516 - loss = 1.896, (1.278 sec/step)\n",
      "step 5517 - loss = 1.424, (1.149 sec/step)\n",
      "step 5518 - loss = 2.057, (2.006 sec/step)\n",
      "step 5519 - loss = 1.568, (1.087 sec/step)\n",
      "step 5520 - loss = 2.191, (1.209 sec/step)\n",
      "step 5521 - loss = 2.024, (2.766 sec/step)\n",
      "step 5522 - loss = 1.951, (1.087 sec/step)\n",
      "step 5523 - loss = 1.861, (1.392 sec/step)\n",
      "step 5524 - loss = 2.376, (1.409 sec/step)\n",
      "step 5525 - loss = 1.884, (1.125 sec/step)\n",
      "step 5526 - loss = 1.670, (2.518 sec/step)\n",
      "step 5527 - loss = 2.017, (1.555 sec/step)\n",
      "step 5528 - loss = 2.047, (2.486 sec/step)\n",
      "step 5529 - loss = 1.931, (2.485 sec/step)\n",
      "step 5530 - loss = 1.022, (1.558 sec/step)\n",
      "step 5531 - loss = 2.552, (2.482 sec/step)\n",
      "step 5532 - loss = 1.599, (1.990 sec/step)\n",
      "step 5533 - loss = 2.229, (1.505 sec/step)\n",
      "step 5534 - loss = 1.398, (0.867 sec/step)\n",
      "step 5535 - loss = 1.814, (1.348 sec/step)\n",
      "step 5536 - loss = 1.952, (1.757 sec/step)\n",
      "step 5537 - loss = 2.548, (3.403 sec/step)\n",
      "step 5538 - loss = 1.772, (2.749 sec/step)\n",
      "step 5539 - loss = 2.723, (1.260 sec/step)\n",
      "step 5540 - loss = 1.997, (1.527 sec/step)\n",
      "step 5541 - loss = 1.516, (2.672 sec/step)\n",
      "step 5542 - loss = 1.881, (1.257 sec/step)\n",
      "step 5543 - loss = 1.630, (1.029 sec/step)\n",
      "step 5544 - loss = 2.344, (1.327 sec/step)\n",
      "step 5545 - loss = 1.712, (1.420 sec/step)\n",
      "step 5546 - loss = 1.857, (1.407 sec/step)\n",
      "step 5547 - loss = 2.072, (1.314 sec/step)\n",
      "step 5548 - loss = 1.732, (1.688 sec/step)\n",
      "step 5549 - loss = 1.836, (1.101 sec/step)\n",
      "step 5550 - loss = 1.795, (1.201 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5551 - loss = 1.685, (0.801 sec/step)\n",
      "step 5552 - loss = 1.574, (1.525 sec/step)\n",
      "step 5553 - loss = 1.433, (1.362 sec/step)\n",
      "step 5554 - loss = 2.076, (1.176 sec/step)\n",
      "step 5555 - loss = 2.211, (1.424 sec/step)\n",
      "step 5556 - loss = 1.979, (1.560 sec/step)\n",
      "step 5557 - loss = 1.991, (2.035 sec/step)\n",
      "step 5558 - loss = 2.066, (2.684 sec/step)\n",
      "step 5559 - loss = 1.820, (1.340 sec/step)\n",
      "step 5560 - loss = 1.755, (2.485 sec/step)\n",
      "step 5561 - loss = 0.802, (1.781 sec/step)\n",
      "step 5562 - loss = 2.074, (1.475 sec/step)\n",
      "step 5563 - loss = 1.986, (3.303 sec/step)\n",
      "step 5564 - loss = 1.780, (0.957 sec/step)\n",
      "step 5565 - loss = 1.300, (2.400 sec/step)\n",
      "step 5566 - loss = 2.087, (0.868 sec/step)\n",
      "step 5567 - loss = 1.707, (1.392 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5568 - loss = 2.275, (0.984 sec/step)\n",
      "step 5569 - loss = 1.861, (1.170 sec/step)\n",
      "step 5570 - loss = 1.436, (1.793 sec/step)\n",
      "step 5571 - loss = 2.164, (1.097 sec/step)\n",
      "step 5572 - loss = 2.013, (1.197 sec/step)\n",
      "step 5573 - loss = 1.777, (1.310 sec/step)\n",
      "step 5574 - loss = 1.514, (1.126 sec/step)\n",
      "step 5575 - loss = 2.043, (1.974 sec/step)\n",
      "step 5576 - loss = 2.248, (1.407 sec/step)\n",
      "step 5577 - loss = 2.487, (1.653 sec/step)\n",
      "step 5578 - loss = 2.299, (1.381 sec/step)\n",
      "step 5579 - loss = 1.740, (0.726 sec/step)\n",
      "step 5580 - loss = 2.005, (1.516 sec/step)\n",
      "step 5581 - loss = 2.792, (0.988 sec/step)\n",
      "step 5582 - loss = 1.807, (1.505 sec/step)\n",
      "step 5583 - loss = 1.742, (2.104 sec/step)\n",
      "step 5584 - loss = 2.055, (2.001 sec/step)\n",
      "step 5585 - loss = 1.652, (1.210 sec/step)\n",
      "step 5586 - loss = 1.666, (1.606 sec/step)\n",
      "step 5587 - loss = 2.114, (1.195 sec/step)\n",
      "step 5588 - loss = 2.002, (1.444 sec/step)\n",
      "step 5589 - loss = 1.824, (1.175 sec/step)\n",
      "step 5590 - loss = 1.546, (1.359 sec/step)\n",
      "step 5591 - loss = 1.502, (2.260 sec/step)\n",
      "step 5592 - loss = 1.052, (1.206 sec/step)\n",
      "step 5593 - loss = 1.769, (2.080 sec/step)\n",
      "step 5594 - loss = 1.546, (1.271 sec/step)\n",
      "step 5595 - loss = 1.767, (1.428 sec/step)\n",
      "step 5596 - loss = 2.003, (0.984 sec/step)\n",
      "step 5597 - loss = 1.958, (2.070 sec/step)\n",
      "step 5598 - loss = 2.584, (1.122 sec/step)\n",
      "step 5599 - loss = 1.923, (1.365 sec/step)\n",
      "step 5600 - loss = 1.880, (2.118 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5601 - loss = 1.732, (1.290 sec/step)\n",
      "step 5602 - loss = 1.767, (1.127 sec/step)\n",
      "step 5603 - loss = 1.738, (1.001 sec/step)\n",
      "step 5604 - loss = 1.855, (1.026 sec/step)\n",
      "step 5605 - loss = 2.189, (1.356 sec/step)\n",
      "step 5606 - loss = 1.912, (2.483 sec/step)\n",
      "step 5607 - loss = 0.701, (2.987 sec/step)\n",
      "step 5608 - loss = 2.014, (1.596 sec/step)\n",
      "step 5609 - loss = 1.630, (1.556 sec/step)\n",
      "step 5610 - loss = 1.747, (1.892 sec/step)\n",
      "step 5611 - loss = 1.803, (1.325 sec/step)\n",
      "step 5612 - loss = 1.609, (1.983 sec/step)\n",
      "step 5613 - loss = 1.602, (1.049 sec/step)\n",
      "step 5614 - loss = 1.985, (2.903 sec/step)\n",
      "step 5615 - loss = 1.911, (1.426 sec/step)\n",
      "step 5616 - loss = 2.312, (1.685 sec/step)\n",
      "step 5617 - loss = 2.150, (1.457 sec/step)\n",
      "step 5618 - loss = 2.243, (1.916 sec/step)\n",
      "step 5619 - loss = 1.817, (0.791 sec/step)\n",
      "step 5620 - loss = 1.325, (1.321 sec/step)\n",
      "step 5621 - loss = 1.309, (1.803 sec/step)\n",
      "step 5622 - loss = 1.997, (1.879 sec/step)\n",
      "step 5623 - loss = 2.451, (2.487 sec/step)\n",
      "step 5624 - loss = 0.998, (0.635 sec/step)\n",
      "step 5625 - loss = 1.656, (2.396 sec/step)\n",
      "step 5626 - loss = 2.272, (1.333 sec/step)\n",
      "step 5627 - loss = 2.033, (0.925 sec/step)\n",
      "step 5628 - loss = 2.102, (1.239 sec/step)\n",
      "step 5629 - loss = 1.878, (1.224 sec/step)\n",
      "step 5630 - loss = 1.443, (2.311 sec/step)\n",
      "step 5631 - loss = 2.130, (1.235 sec/step)\n",
      "step 5632 - loss = 1.769, (1.909 sec/step)\n",
      "step 5633 - loss = 1.803, (1.888 sec/step)\n",
      "step 5634 - loss = 1.816, (2.297 sec/step)\n",
      "step 5635 - loss = 1.792, (1.160 sec/step)\n",
      "step 5636 - loss = 1.601, (1.636 sec/step)\n",
      "step 5637 - loss = 1.966, (1.934 sec/step)\n",
      "step 5638 - loss = 2.005, (1.816 sec/step)\n",
      "step 5639 - loss = 1.675, (2.093 sec/step)\n",
      "step 5640 - loss = 1.915, (1.365 sec/step)\n",
      "step 5641 - loss = 1.555, (1.396 sec/step)\n",
      "step 5642 - loss = 1.859, (1.487 sec/step)\n",
      "step 5643 - loss = 2.297, (1.705 sec/step)\n",
      "step 5644 - loss = 1.515, (1.069 sec/step)\n",
      "step 5645 - loss = 2.073, (1.950 sec/step)\n",
      "step 5646 - loss = 1.891, (1.471 sec/step)\n",
      "step 5647 - loss = 2.133, (0.988 sec/step)\n",
      "step 5648 - loss = 2.437, (2.484 sec/step)\n",
      "step 5649 - loss = 0.612, (0.721 sec/step)\n",
      "step 5650 - loss = 2.005, (1.781 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5651 - loss = 2.038, (0.940 sec/step)\n",
      "step 5652 - loss = 1.752, (0.966 sec/step)\n",
      "step 5653 - loss = 2.078, (1.238 sec/step)\n",
      "step 5654 - loss = 1.412, (3.049 sec/step)\n",
      "step 5655 - loss = 1.419, (1.263 sec/step)\n",
      "step 5656 - loss = 1.404, (2.301 sec/step)\n",
      "step 5657 - loss = 2.273, (2.488 sec/step)\n",
      "step 5658 - loss = 0.517, (0.664 sec/step)\n",
      "step 5659 - loss = 2.034, (2.370 sec/step)\n",
      "step 5660 - loss = 1.420, (2.400 sec/step)\n",
      "step 5661 - loss = 2.099, (1.101 sec/step)\n",
      "step 5662 - loss = 2.308, (1.149 sec/step)\n",
      "step 5663 - loss = 2.776, (1.745 sec/step)\n",
      "step 5664 - loss = 2.237, (0.969 sec/step)\n",
      "step 5665 - loss = 2.067, (1.293 sec/step)\n",
      "step 5666 - loss = 2.436, (1.294 sec/step)\n",
      "step 5667 - loss = 1.962, (1.829 sec/step)\n",
      "step 5668 - loss = 2.019, (1.869 sec/step)\n",
      "step 5669 - loss = 2.191, (1.523 sec/step)\n",
      "step 5670 - loss = 1.751, (1.836 sec/step)\n",
      "step 5671 - loss = 2.156, (1.245 sec/step)\n",
      "step 5672 - loss = 1.684, (1.774 sec/step)\n",
      "step 5673 - loss = 2.080, (1.429 sec/step)\n",
      "step 5674 - loss = 2.105, (1.711 sec/step)\n",
      "step 5675 - loss = 2.102, (1.313 sec/step)\n",
      "step 5676 - loss = 2.748, (2.169 sec/step)\n",
      "step 5677 - loss = 1.994, (1.458 sec/step)\n",
      "step 5678 - loss = 1.450, (1.476 sec/step)\n",
      "step 5679 - loss = 1.561, (1.823 sec/step)\n",
      "step 5680 - loss = 1.699, (0.823 sec/step)\n",
      "step 5681 - loss = 1.853, (1.047 sec/step)\n",
      "step 5682 - loss = 2.264, (1.679 sec/step)\n",
      "step 5683 - loss = 1.923, (1.146 sec/step)\n",
      "step 5684 - loss = 1.905, (1.115 sec/step)\n",
      "step 5685 - loss = 2.212, (1.817 sec/step)\n",
      "step 5686 - loss = 1.640, (2.283 sec/step)\n",
      "step 5687 - loss = 1.530, (1.528 sec/step)\n",
      "step 5688 - loss = 1.869, (1.490 sec/step)\n",
      "step 5689 - loss = 1.821, (1.296 sec/step)\n",
      "step 5690 - loss = 2.112, (1.257 sec/step)\n",
      "step 5691 - loss = 2.203, (1.245 sec/step)\n",
      "step 5692 - loss = 1.501, (0.959 sec/step)\n",
      "step 5693 - loss = 1.997, (1.633 sec/step)\n",
      "step 5694 - loss = 1.614, (1.312 sec/step)\n",
      "step 5695 - loss = 1.779, (1.146 sec/step)\n",
      "step 5696 - loss = 1.640, (2.108 sec/step)\n",
      "step 5697 - loss = 1.932, (1.313 sec/step)\n",
      "step 5698 - loss = 1.763, (1.282 sec/step)\n",
      "step 5699 - loss = 1.772, (2.344 sec/step)\n",
      "step 5700 - loss = 1.728, (1.479 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5701 - loss = 2.132, (1.100 sec/step)\n",
      "step 5702 - loss = 1.890, (1.539 sec/step)\n",
      "step 5703 - loss = 1.927, (1.760 sec/step)\n",
      "step 5704 - loss = 1.810, (1.341 sec/step)\n",
      "step 5705 - loss = 1.675, (1.217 sec/step)\n",
      "step 5706 - loss = 1.504, (1.391 sec/step)\n",
      "step 5707 - loss = 1.765, (1.244 sec/step)\n",
      "step 5708 - loss = 1.546, (1.194 sec/step)\n",
      "step 5709 - loss = 2.155, (1.560 sec/step)\n",
      "step 5710 - loss = 1.856, (1.091 sec/step)\n",
      "step 5711 - loss = 2.111, (2.487 sec/step)\n",
      "step 5712 - loss = 0.570, (0.516 sec/step)\n",
      "step 5713 - loss = 1.796, (1.381 sec/step)\n",
      "step 5714 - loss = 1.586, (1.584 sec/step)\n",
      "step 5715 - loss = 1.960, (1.991 sec/step)\n",
      "step 5716 - loss = 2.077, (0.982 sec/step)\n",
      "step 5717 - loss = 1.620, (1.820 sec/step)\n",
      "step 5718 - loss = 1.544, (1.220 sec/step)\n",
      "step 5719 - loss = 2.030, (2.361 sec/step)\n",
      "step 5720 - loss = 1.655, (1.477 sec/step)\n",
      "step 5721 - loss = 2.009, (1.215 sec/step)\n",
      "step 5722 - loss = 2.188, (3.215 sec/step)\n",
      "step 5723 - loss = 1.788, (2.593 sec/step)\n",
      "step 5724 - loss = 1.743, (1.477 sec/step)\n",
      "step 5725 - loss = 1.839, (1.231 sec/step)\n",
      "step 5726 - loss = 1.439, (2.166 sec/step)\n",
      "step 5727 - loss = 1.998, (0.953 sec/step)\n",
      "step 5728 - loss = 1.729, (1.392 sec/step)\n",
      "step 5729 - loss = 2.206, (1.825 sec/step)\n",
      "step 5730 - loss = 1.825, (2.672 sec/step)\n",
      "step 5731 - loss = 1.759, (1.142 sec/step)\n",
      "step 5732 - loss = 1.952, (1.394 sec/step)\n",
      "step 5733 - loss = 2.051, (1.400 sec/step)\n",
      "step 5734 - loss = 2.049, (1.117 sec/step)\n",
      "step 5735 - loss = 1.300, (1.093 sec/step)\n",
      "step 5736 - loss = 2.280, (1.327 sec/step)\n",
      "step 5737 - loss = 1.913, (1.424 sec/step)\n",
      "step 5738 - loss = 1.872, (1.825 sec/step)\n",
      "step 5739 - loss = 2.078, (2.482 sec/step)\n",
      "step 5740 - loss = 1.232, (1.836 sec/step)\n",
      "step 5741 - loss = 2.151, (1.275 sec/step)\n",
      "step 5742 - loss = 1.788, (1.333 sec/step)\n",
      "step 5743 - loss = 1.848, (1.412 sec/step)\n",
      "step 5744 - loss = 1.875, (1.414 sec/step)\n",
      "step 5745 - loss = 1.561, (1.113 sec/step)\n",
      "step 5746 - loss = 1.503, (1.607 sec/step)\n",
      "step 5747 - loss = 2.236, (1.387 sec/step)\n",
      "step 5748 - loss = 1.237, (1.727 sec/step)\n",
      "step 5749 - loss = 1.610, (0.954 sec/step)\n",
      "step 5750 - loss = 1.756, (1.198 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5751 - loss = 2.036, (1.390 sec/step)\n",
      "step 5752 - loss = 1.852, (2.111 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5753 - loss = 1.858, (1.348 sec/step)\n",
      "step 5754 - loss = 2.341, (2.483 sec/step)\n",
      "step 5755 - loss = 1.526, (0.593 sec/step)\n",
      "step 5756 - loss = 2.185, (1.407 sec/step)\n",
      "step 5757 - loss = 1.825, (1.155 sec/step)\n",
      "step 5758 - loss = 1.436, (1.262 sec/step)\n",
      "step 5759 - loss = 1.911, (1.050 sec/step)\n",
      "step 5760 - loss = 2.538, (1.844 sec/step)\n",
      "step 5761 - loss = 2.256, (2.487 sec/step)\n",
      "step 5762 - loss = 2.707, (1.929 sec/step)\n",
      "step 5763 - loss = 2.050, (1.201 sec/step)\n",
      "step 5764 - loss = 2.001, (2.813 sec/step)\n",
      "step 5765 - loss = 1.568, (2.928 sec/step)\n",
      "step 5766 - loss = 1.681, (1.160 sec/step)\n",
      "step 5767 - loss = 1.658, (1.160 sec/step)\n",
      "step 5768 - loss = 1.644, (1.885 sec/step)\n",
      "step 5769 - loss = 1.160, (2.003 sec/step)\n",
      "step 5770 - loss = 2.054, (1.842 sec/step)\n",
      "step 5771 - loss = 2.116, (1.069 sec/step)\n",
      "step 5772 - loss = 2.071, (0.910 sec/step)\n",
      "step 5773 - loss = 2.547, (1.160 sec/step)\n",
      "step 5774 - loss = 1.810, (3.249 sec/step)\n",
      "step 5775 - loss = 1.780, (1.498 sec/step)\n",
      "step 5776 - loss = 1.834, (1.476 sec/step)\n",
      "step 5777 - loss = 1.701, (0.971 sec/step)\n",
      "step 5778 - loss = 1.726, (1.127 sec/step)\n",
      "step 5779 - loss = 1.857, (1.255 sec/step)\n",
      "step 5780 - loss = 1.204, (1.178 sec/step)\n",
      "step 5781 - loss = 2.001, (1.380 sec/step)\n",
      "step 5782 - loss = 1.961, (1.686 sec/step)\n",
      "step 5783 - loss = 1.907, (1.255 sec/step)\n",
      "step 5784 - loss = 1.915, (2.456 sec/step)\n",
      "step 5785 - loss = 1.320, (2.487 sec/step)\n",
      "step 5786 - loss = 0.551, (1.342 sec/step)\n",
      "step 5787 - loss = 1.230, (1.184 sec/step)\n",
      "step 5788 - loss = 2.176, (2.485 sec/step)\n",
      "step 5789 - loss = 2.221, (2.370 sec/step)\n",
      "step 5790 - loss = 1.975, (1.584 sec/step)\n",
      "step 5791 - loss = 1.767, (1.359 sec/step)\n",
      "step 5792 - loss = 1.961, (1.749 sec/step)\n",
      "step 5793 - loss = 1.852, (0.956 sec/step)\n",
      "step 5794 - loss = 2.435, (1.013 sec/step)\n",
      "step 5795 - loss = 1.695, (1.877 sec/step)\n",
      "step 5796 - loss = 1.823, (2.103 sec/step)\n",
      "step 5797 - loss = 2.027, (1.714 sec/step)\n",
      "step 5798 - loss = 1.767, (1.359 sec/step)\n",
      "step 5799 - loss = 1.813, (1.558 sec/step)\n",
      "step 5800 - loss = 1.798, (1.387 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5801 - loss = 1.685, (1.826 sec/step)\n",
      "step 5802 - loss = 1.635, (1.139 sec/step)\n",
      "step 5803 - loss = 1.839, (1.100 sec/step)\n",
      "step 5804 - loss = 1.672, (1.011 sec/step)\n",
      "step 5805 - loss = 1.934, (1.291 sec/step)\n",
      "step 5806 - loss = 2.050, (2.345 sec/step)\n",
      "step 5807 - loss = 1.753, (1.650 sec/step)\n",
      "step 5808 - loss = 2.196, (2.593 sec/step)\n",
      "step 5809 - loss = 2.433, (2.484 sec/step)\n",
      "step 5810 - loss = 1.846, (1.157 sec/step)\n",
      "step 5811 - loss = 2.642, (1.471 sec/step)\n",
      "step 5812 - loss = 1.347, (1.445 sec/step)\n",
      "step 5813 - loss = 2.075, (1.149 sec/step)\n",
      "step 5814 - loss = 1.944, (1.610 sec/step)\n",
      "step 5815 - loss = 2.072, (1.212 sec/step)\n",
      "step 5816 - loss = 1.684, (1.356 sec/step)\n",
      "step 5817 - loss = 1.564, (1.979 sec/step)\n",
      "step 5818 - loss = 2.019, (1.721 sec/step)\n",
      "step 5819 - loss = 1.530, (1.069 sec/step)\n",
      "step 5820 - loss = 1.741, (1.544 sec/step)\n",
      "step 5821 - loss = 1.810, (1.193 sec/step)\n",
      "step 5822 - loss = 1.830, (1.323 sec/step)\n",
      "step 5823 - loss = 1.723, (1.516 sec/step)\n",
      "step 5824 - loss = 2.181, (1.419 sec/step)\n",
      "step 5825 - loss = 1.712, (1.758 sec/step)\n",
      "step 5826 - loss = 1.572, (1.127 sec/step)\n",
      "step 5827 - loss = 1.754, (1.139 sec/step)\n",
      "step 5828 - loss = 1.769, (1.465 sec/step)\n",
      "step 5829 - loss = 2.445, (1.416 sec/step)\n",
      "step 5830 - loss = 1.735, (1.208 sec/step)\n",
      "step 5831 - loss = 1.742, (1.386 sec/step)\n",
      "step 5832 - loss = 1.297, (2.452 sec/step)\n",
      "step 5833 - loss = 1.274, (1.143 sec/step)\n",
      "step 5834 - loss = 1.698, (2.300 sec/step)\n",
      "step 5835 - loss = 1.728, (1.714 sec/step)\n",
      "step 5836 - loss = 1.776, (1.714 sec/step)\n",
      "step 5837 - loss = 1.683, (2.573 sec/step)\n",
      "step 5838 - loss = 2.354, (2.468 sec/step)\n",
      "step 5839 - loss = 1.754, (1.642 sec/step)\n",
      "step 5840 - loss = 1.558, (1.198 sec/step)\n",
      "step 5841 - loss = 1.573, (1.665 sec/step)\n",
      "step 5842 - loss = 1.778, (1.205 sec/step)\n",
      "step 5843 - loss = 1.842, (1.067 sec/step)\n",
      "step 5844 - loss = 1.777, (1.854 sec/step)\n",
      "step 5845 - loss = 2.183, (1.525 sec/step)\n",
      "step 5846 - loss = 1.891, (1.469 sec/step)\n",
      "step 5847 - loss = 1.722, (1.293 sec/step)\n",
      "step 5848 - loss = 2.247, (1.523 sec/step)\n",
      "step 5849 - loss = 2.144, (1.699 sec/step)\n",
      "step 5850 - loss = 1.914, (2.482 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5851 - loss = 1.799, (0.512 sec/step)\n",
      "step 5852 - loss = 2.242, (1.652 sec/step)\n",
      "step 5853 - loss = 1.830, (1.162 sec/step)\n",
      "step 5854 - loss = 2.288, (1.861 sec/step)\n",
      "step 5855 - loss = 1.439, (1.319 sec/step)\n",
      "step 5856 - loss = 2.143, (1.144 sec/step)\n",
      "step 5857 - loss = 2.237, (1.289 sec/step)\n",
      "step 5858 - loss = 1.615, (0.853 sec/step)\n",
      "step 5859 - loss = 1.907, (2.703 sec/step)\n",
      "step 5860 - loss = 1.910, (1.146 sec/step)\n",
      "step 5861 - loss = 1.729, (2.003 sec/step)\n",
      "step 5862 - loss = 1.345, (1.195 sec/step)\n",
      "step 5863 - loss = 1.758, (2.222 sec/step)\n",
      "step 5864 - loss = 1.897, (1.350 sec/step)\n",
      "step 5865 - loss = 1.899, (1.604 sec/step)\n",
      "step 5866 - loss = 1.744, (1.424 sec/step)\n",
      "step 5867 - loss = 1.360, (1.398 sec/step)\n",
      "step 5868 - loss = 1.014, (2.485 sec/step)\n",
      "step 5869 - loss = 0.612, (1.120 sec/step)\n",
      "step 5870 - loss = 1.674, (1.442 sec/step)\n",
      "step 5871 - loss = 1.846, (1.862 sec/step)\n",
      "step 5872 - loss = 2.217, (2.633 sec/step)\n",
      "step 5873 - loss = 2.328, (1.247 sec/step)\n",
      "step 5874 - loss = 2.029, (1.661 sec/step)\n",
      "step 5875 - loss = 1.859, (2.486 sec/step)\n",
      "step 5876 - loss = 1.201, (0.750 sec/step)\n",
      "step 5877 - loss = 2.216, (2.214 sec/step)\n",
      "step 5878 - loss = 2.143, (0.956 sec/step)\n",
      "step 5879 - loss = 1.580, (1.015 sec/step)\n",
      "step 5880 - loss = 2.186, (1.211 sec/step)\n",
      "step 5881 - loss = 1.646, (1.544 sec/step)\n",
      "step 5882 - loss = 1.364, (1.314 sec/step)\n",
      "step 5883 - loss = 2.060, (1.635 sec/step)\n",
      "step 5884 - loss = 1.787, (2.936 sec/step)\n",
      "step 5885 - loss = 1.487, (1.093 sec/step)\n",
      "step 5886 - loss = 1.755, (2.576 sec/step)\n",
      "step 5887 - loss = 2.142, (1.028 sec/step)\n",
      "step 5888 - loss = 1.583, (1.343 sec/step)\n",
      "step 5889 - loss = 1.400, (1.493 sec/step)\n",
      "step 5890 - loss = 2.367, (1.124 sec/step)\n",
      "step 5891 - loss = 1.382, (2.057 sec/step)\n",
      "step 5892 - loss = 2.378, (2.826 sec/step)\n",
      "step 5893 - loss = 1.256, (1.284 sec/step)\n",
      "step 5894 - loss = 1.759, (1.229 sec/step)\n",
      "step 5895 - loss = 2.130, (0.960 sec/step)\n",
      "step 5896 - loss = 1.760, (1.514 sec/step)\n",
      "step 5897 - loss = 1.918, (1.476 sec/step)\n",
      "step 5898 - loss = 2.149, (1.150 sec/step)\n",
      "step 5899 - loss = 1.745, (1.241 sec/step)\n",
      "step 5900 - loss = 2.267, (1.477 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5901 - loss = 1.796, (2.389 sec/step)\n",
      "step 5902 - loss = 1.487, (0.939 sec/step)\n",
      "step 5903 - loss = 2.213, (1.490 sec/step)\n",
      "step 5904 - loss = 1.790, (1.331 sec/step)\n",
      "step 5905 - loss = 1.981, (1.567 sec/step)\n",
      "step 5906 - loss = 1.704, (1.206 sec/step)\n",
      "step 5907 - loss = 1.823, (0.902 sec/step)\n",
      "step 5908 - loss = 1.360, (1.449 sec/step)\n",
      "step 5909 - loss = 2.017, (1.337 sec/step)\n",
      "step 5910 - loss = 1.846, (0.909 sec/step)\n",
      "step 5911 - loss = 2.309, (1.515 sec/step)\n",
      "step 5912 - loss = 2.210, (2.145 sec/step)\n",
      "step 5913 - loss = 2.161, (1.777 sec/step)\n",
      "step 5914 - loss = 2.072, (1.815 sec/step)\n",
      "step 5915 - loss = 2.385, (1.112 sec/step)\n",
      "step 5916 - loss = 2.116, (1.934 sec/step)\n",
      "step 5917 - loss = 2.040, (0.969 sec/step)\n",
      "step 5918 - loss = 2.158, (0.694 sec/step)\n",
      "step 5919 - loss = 1.556, (1.439 sec/step)\n",
      "step 5920 - loss = 1.734, (1.072 sec/step)\n",
      "step 5921 - loss = 2.028, (1.229 sec/step)\n",
      "step 5922 - loss = 1.682, (1.541 sec/step)\n",
      "step 5923 - loss = 1.941, (2.207 sec/step)\n",
      "step 5924 - loss = 2.613, (2.483 sec/step)\n",
      "step 5925 - loss = 2.918, (1.495 sec/step)\n",
      "step 5926 - loss = 1.827, (1.567 sec/step)\n",
      "step 5927 - loss = 1.811, (1.289 sec/step)\n",
      "step 5928 - loss = 1.918, (1.060 sec/step)\n",
      "step 5929 - loss = 1.305, (3.336 sec/step)\n",
      "step 5930 - loss = 1.549, (2.479 sec/step)\n",
      "step 5931 - loss = 1.494, (0.953 sec/step)\n",
      "step 5932 - loss = 2.157, (1.125 sec/step)\n",
      "step 5933 - loss = 1.880, (1.379 sec/step)\n",
      "step 5934 - loss = 1.626, (1.049 sec/step)\n",
      "step 5935 - loss = 1.930, (1.107 sec/step)\n",
      "step 5936 - loss = 1.376, (1.380 sec/step)\n",
      "step 5937 - loss = 2.118, (1.255 sec/step)\n",
      "step 5938 - loss = 1.815, (1.787 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5939 - loss = 2.245, (1.130 sec/step)\n",
      "step 5940 - loss = 1.855, (1.330 sec/step)\n",
      "step 5941 - loss = 1.550, (1.357 sec/step)\n",
      "step 5942 - loss = 2.190, (1.422 sec/step)\n",
      "step 5943 - loss = 2.208, (2.285 sec/step)\n",
      "step 5944 - loss = 1.892, (0.840 sec/step)\n",
      "step 5945 - loss = 1.532, (1.115 sec/step)\n",
      "step 5946 - loss = 1.944, (1.164 sec/step)\n",
      "step 5947 - loss = 1.663, (1.050 sec/step)\n",
      "step 5948 - loss = 1.539, (1.862 sec/step)\n",
      "step 5949 - loss = 2.075, (1.994 sec/step)\n",
      "step 5950 - loss = 2.264, (1.970 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 5951 - loss = 2.094, (1.374 sec/step)\n",
      "step 5952 - loss = 2.034, (1.374 sec/step)\n",
      "step 5953 - loss = 1.953, (1.623 sec/step)\n",
      "step 5954 - loss = 2.196, (1.800 sec/step)\n",
      "step 5955 - loss = 1.804, (1.150 sec/step)\n",
      "step 5956 - loss = 1.851, (3.011 sec/step)\n",
      "step 5957 - loss = 2.292, (1.181 sec/step)\n",
      "step 5958 - loss = 1.303, (1.731 sec/step)\n",
      "step 5959 - loss = 1.013, (2.484 sec/step)\n",
      "step 5960 - loss = 0.603, (0.272 sec/step)\n",
      "step 5961 - loss = 1.606, (0.989 sec/step)\n",
      "step 5962 - loss = 2.554, (0.956 sec/step)\n",
      "step 5963 - loss = 2.045, (1.712 sec/step)\n",
      "step 5964 - loss = 1.301, (2.485 sec/step)\n",
      "step 5965 - loss = 0.507, (2.474 sec/step)\n",
      "step 5966 - loss = 2.269, (1.102 sec/step)\n",
      "step 5967 - loss = 2.296, (1.425 sec/step)\n",
      "step 5968 - loss = 2.119, (1.050 sec/step)\n",
      "step 5969 - loss = 1.530, (1.349 sec/step)\n",
      "step 5970 - loss = 2.488, (2.484 sec/step)\n",
      "step 5971 - loss = 1.716, (0.926 sec/step)\n",
      "step 5972 - loss = 1.590, (1.246 sec/step)\n",
      "step 5973 - loss = 1.831, (1.086 sec/step)\n",
      "step 5974 - loss = 1.962, (1.442 sec/step)\n",
      "step 5975 - loss = 1.993, (1.362 sec/step)\n",
      "step 5976 - loss = 2.009, (1.865 sec/step)\n",
      "step 5977 - loss = 1.518, (1.293 sec/step)\n",
      "step 5978 - loss = 2.553, (2.486 sec/step)\n",
      "step 5979 - loss = 2.290, (1.554 sec/step)\n",
      "step 5980 - loss = 2.210, (1.612 sec/step)\n",
      "step 5981 - loss = 1.888, (2.358 sec/step)\n",
      "step 5982 - loss = 1.856, (1.662 sec/step)\n",
      "step 5983 - loss = 2.110, (1.394 sec/step)\n",
      "step 5984 - loss = 1.235, (1.407 sec/step)\n",
      "step 5985 - loss = 1.708, (1.331 sec/step)\n",
      "step 5986 - loss = 1.906, (1.312 sec/step)\n",
      "step 5987 - loss = 1.570, (1.258 sec/step)\n",
      "step 5988 - loss = 1.730, (0.841 sec/step)\n",
      "step 5989 - loss = 2.399, (1.316 sec/step)\n",
      "step 5990 - loss = 2.010, (1.833 sec/step)\n",
      "step 5991 - loss = 1.713, (1.159 sec/step)\n",
      "step 5992 - loss = 2.604, (2.483 sec/step)\n",
      "step 5993 - loss = 2.821, (0.517 sec/step)\n",
      "step 5994 - loss = 2.133, (1.449 sec/step)\n",
      "step 5995 - loss = 2.156, (1.684 sec/step)\n",
      "step 5996 - loss = 1.923, (2.378 sec/step)\n",
      "step 5997 - loss = 1.417, (1.203 sec/step)\n",
      "step 5998 - loss = 1.602, (1.409 sec/step)\n",
      "step 5999 - loss = 2.161, (2.337 sec/step)\n",
      "step 6000 - loss = 1.571, (2.644 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6001 - loss = 1.307, (1.971 sec/step)\n",
      "step 6002 - loss = 2.096, (1.818 sec/step)\n",
      "step 6003 - loss = 2.388, (1.977 sec/step)\n",
      "step 6004 - loss = 1.892, (1.174 sec/step)\n",
      "step 6005 - loss = 1.692, (2.746 sec/step)\n",
      "step 6006 - loss = 1.563, (1.309 sec/step)\n",
      "step 6007 - loss = 1.413, (2.997 sec/step)\n",
      "step 6008 - loss = 2.137, (1.427 sec/step)\n",
      "step 6009 - loss = 1.661, (1.803 sec/step)\n",
      "step 6010 - loss = 1.702, (1.682 sec/step)\n",
      "step 6011 - loss = 2.423, (1.523 sec/step)\n",
      "step 6012 - loss = 1.981, (3.569 sec/step)\n",
      "step 6013 - loss = 2.054, (1.514 sec/step)\n",
      "step 6014 - loss = 1.984, (2.094 sec/step)\n",
      "step 6015 - loss = 1.614, (1.738 sec/step)\n",
      "step 6016 - loss = 1.589, (1.102 sec/step)\n",
      "step 6017 - loss = 1.831, (1.683 sec/step)\n",
      "step 6018 - loss = 2.066, (1.179 sec/step)\n",
      "step 6019 - loss = 1.787, (1.240 sec/step)\n",
      "step 6020 - loss = 0.539, (0.622 sec/step)\n",
      "step 6021 - loss = 1.880, (1.462 sec/step)\n",
      "step 6022 - loss = 2.000, (1.212 sec/step)\n",
      "step 6023 - loss = 2.156, (1.592 sec/step)\n",
      "step 6024 - loss = 1.843, (1.542 sec/step)\n",
      "step 6025 - loss = 1.754, (1.570 sec/step)\n",
      "step 6026 - loss = 2.074, (1.390 sec/step)\n",
      "step 6027 - loss = 2.012, (1.257 sec/step)\n",
      "step 6028 - loss = 1.498, (1.230 sec/step)\n",
      "step 6029 - loss = 1.401, (1.421 sec/step)\n",
      "step 6030 - loss = 1.575, (0.858 sec/step)\n",
      "step 6031 - loss = 1.997, (1.459 sec/step)\n",
      "step 6032 - loss = 2.375, (1.641 sec/step)\n",
      "step 6033 - loss = 2.006, (1.639 sec/step)\n",
      "step 6034 - loss = 1.970, (1.578 sec/step)\n",
      "step 6035 - loss = 1.816, (1.635 sec/step)\n",
      "step 6036 - loss = 2.019, (0.893 sec/step)\n",
      "step 6037 - loss = 1.803, (2.412 sec/step)\n",
      "step 6038 - loss = 1.680, (1.551 sec/step)\n",
      "step 6039 - loss = 1.946, (1.938 sec/step)\n",
      "step 6040 - loss = 2.145, (1.256 sec/step)\n",
      "step 6041 - loss = 1.899, (0.940 sec/step)\n",
      "step 6042 - loss = 1.762, (1.114 sec/step)\n",
      "step 6043 - loss = 1.903, (1.614 sec/step)\n",
      "step 6044 - loss = 2.147, (1.291 sec/step)\n",
      "step 6045 - loss = 1.989, (1.661 sec/step)\n",
      "step 6046 - loss = 2.101, (2.333 sec/step)\n",
      "step 6047 - loss = 2.034, (1.689 sec/step)\n",
      "step 6048 - loss = 2.043, (1.098 sec/step)\n",
      "step 6049 - loss = 1.929, (1.959 sec/step)\n",
      "step 6050 - loss = 1.623, (1.412 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6051 - loss = 2.035, (1.244 sec/step)\n",
      "step 6052 - loss = 1.337, (1.252 sec/step)\n",
      "step 6053 - loss = 2.282, (2.832 sec/step)\n",
      "step 6054 - loss = 1.915, (1.800 sec/step)\n",
      "step 6055 - loss = 2.001, (3.008 sec/step)\n",
      "step 6056 - loss = 1.655, (1.396 sec/step)\n",
      "step 6057 - loss = 1.934, (1.159 sec/step)\n",
      "step 6058 - loss = 1.881, (2.626 sec/step)\n",
      "step 6059 - loss = 1.683, (2.780 sec/step)\n",
      "step 6060 - loss = 2.276, (2.565 sec/step)\n",
      "step 6061 - loss = 2.071, (1.424 sec/step)\n",
      "step 6062 - loss = 1.240, (1.197 sec/step)\n",
      "step 6063 - loss = 1.713, (1.187 sec/step)\n",
      "step 6064 - loss = 2.207, (1.070 sec/step)\n",
      "step 6065 - loss = 1.895, (1.509 sec/step)\n",
      "step 6066 - loss = 2.086, (1.458 sec/step)\n",
      "step 6067 - loss = 1.883, (1.189 sec/step)\n",
      "step 6068 - loss = 2.273, (1.458 sec/step)\n",
      "step 6069 - loss = 2.056, (1.523 sec/step)\n",
      "step 6070 - loss = 1.540, (2.725 sec/step)\n",
      "step 6071 - loss = 1.613, (1.113 sec/step)\n",
      "step 6072 - loss = 2.457, (1.246 sec/step)\n",
      "step 6073 - loss = 1.872, (1.457 sec/step)\n",
      "step 6074 - loss = 2.053, (1.310 sec/step)\n",
      "step 6075 - loss = 2.027, (1.495 sec/step)\n",
      "step 6076 - loss = 1.997, (1.602 sec/step)\n",
      "step 6077 - loss = 1.878, (1.752 sec/step)\n",
      "step 6078 - loss = 1.525, (2.772 sec/step)\n",
      "step 6079 - loss = 2.074, (1.654 sec/step)\n",
      "step 6080 - loss = 1.839, (1.892 sec/step)\n",
      "step 6081 - loss = 1.885, (2.855 sec/step)\n",
      "step 6082 - loss = 2.253, (1.007 sec/step)\n",
      "step 6083 - loss = 1.595, (1.248 sec/step)\n",
      "step 6084 - loss = 2.276, (2.408 sec/step)\n",
      "step 6085 - loss = 2.234, (1.277 sec/step)\n",
      "step 6086 - loss = 2.272, (2.485 sec/step)\n",
      "step 6087 - loss = 2.210, (2.347 sec/step)\n",
      "step 6088 - loss = 2.416, (2.486 sec/step)\n",
      "step 6089 - loss = 1.618, (1.181 sec/step)\n",
      "step 6090 - loss = 1.663, (1.293 sec/step)\n",
      "step 6091 - loss = 1.240, (1.410 sec/step)\n",
      "step 6092 - loss = 2.038, (1.716 sec/step)\n",
      "step 6093 - loss = 1.833, (1.160 sec/step)\n",
      "step 6094 - loss = 2.347, (1.459 sec/step)\n",
      "step 6095 - loss = 1.967, (1.198 sec/step)\n",
      "step 6096 - loss = 1.580, (1.126 sec/step)\n",
      "step 6097 - loss = 1.549, (1.001 sec/step)\n",
      "step 6098 - loss = 2.598, (1.444 sec/step)\n",
      "step 6099 - loss = 2.007, (1.310 sec/step)\n",
      "step 6100 - loss = 2.405, (1.595 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6101 - loss = 1.692, (1.202 sec/step)\n",
      "step 6102 - loss = 2.191, (2.532 sec/step)\n",
      "step 6103 - loss = 1.631, (1.312 sec/step)\n",
      "step 6104 - loss = 2.288, (1.098 sec/step)\n",
      "step 6105 - loss = 1.628, (1.671 sec/step)\n",
      "step 6106 - loss = 1.444, (1.090 sec/step)\n",
      "step 6107 - loss = 1.544, (1.197 sec/step)\n",
      "step 6108 - loss = 2.133, (1.658 sec/step)\n",
      "step 6109 - loss = 1.768, (0.808 sec/step)\n",
      "step 6110 - loss = 1.928, (1.371 sec/step)\n",
      "step 6111 - loss = 2.029, (1.443 sec/step)\n",
      "step 6112 - loss = 1.829, (0.954 sec/step)\n",
      "step 6113 - loss = 1.737, (2.693 sec/step)\n",
      "step 6114 - loss = 1.977, (1.584 sec/step)\n",
      "step 6115 - loss = 1.902, (1.239 sec/step)\n",
      "step 6116 - loss = 2.339, (2.150 sec/step)\n",
      "step 6117 - loss = 1.896, (1.622 sec/step)\n",
      "step 6118 - loss = 1.677, (1.212 sec/step)\n",
      "step 6119 - loss = 1.893, (1.193 sec/step)\n",
      "step 6120 - loss = 1.944, (2.185 sec/step)\n",
      "step 6121 - loss = 1.934, (1.578 sec/step)\n",
      "step 6122 - loss = 1.947, (1.322 sec/step)\n",
      "step 6123 - loss = 1.246, (1.125 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6124 - loss = 2.109, (1.255 sec/step)\n",
      "step 6125 - loss = 2.299, (2.347 sec/step)\n",
      "step 6126 - loss = 1.919, (1.405 sec/step)\n",
      "step 6127 - loss = 2.088, (1.528 sec/step)\n",
      "step 6128 - loss = 1.806, (0.924 sec/step)\n",
      "step 6129 - loss = 2.352, (2.484 sec/step)\n",
      "step 6130 - loss = 1.794, (1.330 sec/step)\n",
      "step 6131 - loss = 2.020, (1.483 sec/step)\n",
      "step 6132 - loss = 1.815, (1.093 sec/step)\n",
      "step 6133 - loss = 1.962, (1.088 sec/step)\n",
      "step 6134 - loss = 1.779, (1.210 sec/step)\n",
      "step 6135 - loss = 2.301, (1.357 sec/step)\n",
      "step 6136 - loss = 1.432, (1.395 sec/step)\n",
      "step 6137 - loss = 1.687, (2.066 sec/step)\n",
      "step 6138 - loss = 1.745, (2.145 sec/step)\n",
      "step 6139 - loss = 1.381, (3.420 sec/step)\n",
      "step 6140 - loss = 1.755, (1.130 sec/step)\n",
      "step 6141 - loss = 1.841, (1.421 sec/step)\n",
      "step 6142 - loss = 1.590, (2.390 sec/step)\n",
      "step 6143 - loss = 2.199, (1.456 sec/step)\n",
      "step 6144 - loss = 1.535, (1.108 sec/step)\n",
      "step 6145 - loss = 1.836, (1.162 sec/step)\n",
      "step 6146 - loss = 1.900, (1.054 sec/step)\n",
      "step 6147 - loss = 1.600, (1.516 sec/step)\n",
      "step 6148 - loss = 2.158, (2.017 sec/step)\n",
      "step 6149 - loss = 1.908, (2.964 sec/step)\n",
      "step 6150 - loss = 1.865, (1.518 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6151 - loss = 2.050, (1.088 sec/step)\n",
      "step 6152 - loss = 1.949, (2.102 sec/step)\n",
      "step 6153 - loss = 1.565, (2.207 sec/step)\n",
      "step 6154 - loss = 2.017, (1.114 sec/step)\n",
      "step 6155 - loss = 1.469, (1.848 sec/step)\n",
      "step 6156 - loss = 2.005, (2.484 sec/step)\n",
      "step 6157 - loss = 0.589, (1.052 sec/step)\n",
      "step 6158 - loss = 1.679, (3.051 sec/step)\n",
      "step 6159 - loss = 1.655, (3.018 sec/step)\n",
      "step 6160 - loss = 1.746, (1.114 sec/step)\n",
      "step 6161 - loss = 2.319, (1.875 sec/step)\n",
      "step 6162 - loss = 2.090, (2.417 sec/step)\n",
      "step 6163 - loss = 1.525, (0.841 sec/step)\n",
      "step 6164 - loss = 1.740, (2.156 sec/step)\n",
      "step 6165 - loss = 1.749, (1.517 sec/step)\n",
      "step 6166 - loss = 1.990, (1.409 sec/step)\n",
      "step 6167 - loss = 1.656, (2.675 sec/step)\n",
      "step 6168 - loss = 1.847, (1.245 sec/step)\n",
      "step 6169 - loss = 1.211, (1.811 sec/step)\n",
      "step 6170 - loss = 1.892, (1.088 sec/step)\n",
      "step 6171 - loss = 1.354, (1.898 sec/step)\n",
      "step 6172 - loss = 1.492, (1.390 sec/step)\n",
      "step 6173 - loss = 2.054, (1.014 sec/step)\n",
      "step 6174 - loss = 1.515, (1.197 sec/step)\n",
      "step 6175 - loss = 1.942, (1.034 sec/step)\n",
      "step 6176 - loss = 1.552, (1.784 sec/step)\n",
      "step 6177 - loss = 1.736, (1.646 sec/step)\n",
      "step 6178 - loss = 2.313, (1.638 sec/step)\n",
      "step 6179 - loss = 1.273, (1.018 sec/step)\n",
      "step 6180 - loss = 1.480, (1.344 sec/step)\n",
      "step 6181 - loss = 1.975, (1.662 sec/step)\n",
      "step 6182 - loss = 2.110, (1.094 sec/step)\n",
      "step 6183 - loss = 2.342, (1.563 sec/step)\n",
      "step 6184 - loss = 2.211, (2.488 sec/step)\n",
      "step 6185 - loss = 2.300, (2.125 sec/step)\n",
      "step 6186 - loss = 1.590, (1.780 sec/step)\n",
      "step 6187 - loss = 1.832, (1.051 sec/step)\n",
      "step 6188 - loss = 1.780, (1.219 sec/step)\n",
      "step 6189 - loss = 2.270, (2.315 sec/step)\n",
      "step 6190 - loss = 1.004, (2.488 sec/step)\n",
      "step 6191 - loss = 1.755, (2.188 sec/step)\n",
      "step 6192 - loss = 2.164, (1.399 sec/step)\n",
      "step 6193 - loss = 2.062, (2.489 sec/step)\n",
      "step 6194 - loss = 0.660, (0.149 sec/step)\n",
      "step 6195 - loss = 2.025, (1.147 sec/step)\n",
      "step 6196 - loss = 2.429, (1.246 sec/step)\n",
      "step 6197 - loss = 1.544, (0.973 sec/step)\n",
      "step 6198 - loss = 1.935, (1.106 sec/step)\n",
      "step 6199 - loss = 1.524, (1.524 sec/step)\n",
      "step 6200 - loss = 1.744, (2.047 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6201 - loss = 1.843, (2.760 sec/step)\n",
      "step 6202 - loss = 2.258, (1.997 sec/step)\n",
      "step 6203 - loss = 2.233, (1.258 sec/step)\n",
      "step 6204 - loss = 1.260, (3.246 sec/step)\n",
      "step 6205 - loss = 1.463, (1.515 sec/step)\n",
      "step 6206 - loss = 2.198, (2.019 sec/step)\n",
      "step 6207 - loss = 1.997, (1.142 sec/step)\n",
      "step 6208 - loss = 1.821, (1.861 sec/step)\n",
      "step 6209 - loss = 2.135, (3.176 sec/step)\n",
      "step 6210 - loss = 1.358, (0.998 sec/step)\n",
      "step 6211 - loss = 1.885, (1.847 sec/step)\n",
      "step 6212 - loss = 1.203, (2.484 sec/step)\n",
      "step 6213 - loss = 2.481, (2.485 sec/step)\n",
      "step 6214 - loss = 1.836, (2.484 sec/step)\n",
      "step 6215 - loss = 0.518, (1.333 sec/step)\n",
      "step 6216 - loss = 2.148, (1.681 sec/step)\n",
      "step 6217 - loss = 1.902, (1.331 sec/step)\n",
      "step 6218 - loss = 1.801, (0.963 sec/step)\n",
      "step 6219 - loss = 2.442, (2.485 sec/step)\n",
      "step 6220 - loss = 1.979, (2.469 sec/step)\n",
      "step 6221 - loss = 1.925, (1.473 sec/step)\n",
      "step 6222 - loss = 1.598, (2.178 sec/step)\n",
      "step 6223 - loss = 2.364, (1.491 sec/step)\n",
      "step 6224 - loss = 2.607, (1.680 sec/step)\n",
      "step 6225 - loss = 1.415, (0.986 sec/step)\n",
      "step 6226 - loss = 1.820, (2.485 sec/step)\n",
      "step 6227 - loss = 1.713, (2.608 sec/step)\n",
      "step 6228 - loss = 1.930, (1.648 sec/step)\n",
      "step 6229 - loss = 1.378, (1.085 sec/step)\n",
      "step 6230 - loss = 1.468, (0.950 sec/step)\n",
      "step 6231 - loss = 2.205, (2.080 sec/step)\n",
      "step 6232 - loss = 1.692, (2.036 sec/step)\n",
      "step 6233 - loss = 1.919, (1.293 sec/step)\n",
      "step 6234 - loss = 1.791, (1.383 sec/step)\n",
      "step 6235 - loss = 2.067, (1.355 sec/step)\n",
      "step 6236 - loss = 1.777, (1.942 sec/step)\n",
      "step 6237 - loss = 1.547, (1.599 sec/step)\n",
      "step 6238 - loss = 1.779, (1.396 sec/step)\n",
      "step 6239 - loss = 1.771, (1.325 sec/step)\n",
      "step 6240 - loss = 2.009, (3.102 sec/step)\n",
      "step 6241 - loss = 1.823, (1.735 sec/step)\n",
      "step 6242 - loss = 1.971, (2.621 sec/step)\n",
      "step 6243 - loss = 2.174, (1.567 sec/step)\n",
      "step 6244 - loss = 1.809, (1.791 sec/step)\n",
      "step 6245 - loss = 2.115, (1.240 sec/step)\n",
      "step 6246 - loss = 1.704, (1.277 sec/step)\n",
      "step 6247 - loss = 1.917, (1.258 sec/step)\n",
      "step 6248 - loss = 1.955, (1.383 sec/step)\n",
      "step 6249 - loss = 2.057, (1.283 sec/step)\n",
      "step 6250 - loss = 1.402, (1.636 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6251 - loss = 1.629, (1.104 sec/step)\n",
      "step 6252 - loss = 1.835, (1.519 sec/step)\n",
      "step 6253 - loss = 2.008, (1.527 sec/step)\n",
      "step 6254 - loss = 1.583, (0.996 sec/step)\n",
      "step 6255 - loss = 2.297, (2.323 sec/step)\n",
      "step 6256 - loss = 1.343, (1.920 sec/step)\n",
      "step 6257 - loss = 1.374, (1.377 sec/step)\n",
      "step 6258 - loss = 2.258, (2.158 sec/step)\n",
      "step 6259 - loss = 1.709, (1.991 sec/step)\n",
      "step 6260 - loss = 2.099, (1.409 sec/step)\n",
      "step 6261 - loss = 1.963, (1.106 sec/step)\n",
      "step 6262 - loss = 1.668, (1.005 sec/step)\n",
      "step 6263 - loss = 1.958, (2.602 sec/step)\n",
      "step 6264 - loss = 2.162, (2.988 sec/step)\n",
      "step 6265 - loss = 2.173, (1.520 sec/step)\n",
      "step 6266 - loss = 1.899, (1.298 sec/step)\n",
      "step 6267 - loss = 1.722, (1.359 sec/step)\n",
      "step 6268 - loss = 1.884, (1.494 sec/step)\n",
      "step 6269 - loss = 1.353, (2.752 sec/step)\n",
      "step 6270 - loss = 1.582, (1.626 sec/step)\n",
      "step 6271 - loss = 1.717, (2.474 sec/step)\n",
      "step 6272 - loss = 1.602, (0.941 sec/step)\n",
      "step 6273 - loss = 1.756, (2.533 sec/step)\n",
      "step 6274 - loss = 1.960, (1.202 sec/step)\n",
      "step 6275 - loss = 1.476, (2.039 sec/step)\n",
      "step 6276 - loss = 1.616, (2.291 sec/step)\n",
      "step 6277 - loss = 1.087, (1.656 sec/step)\n",
      "step 6278 - loss = 2.060, (1.820 sec/step)\n",
      "step 6279 - loss = 2.008, (1.244 sec/step)\n",
      "step 6280 - loss = 2.078, (1.007 sec/step)\n",
      "step 6281 - loss = 2.064, (1.441 sec/step)\n",
      "step 6282 - loss = 2.010, (1.649 sec/step)\n",
      "step 6283 - loss = 1.999, (2.127 sec/step)\n",
      "step 6284 - loss = 1.530, (0.960 sec/step)\n",
      "step 6285 - loss = 2.183, (1.817 sec/step)\n",
      "step 6286 - loss = 1.831, (3.337 sec/step)\n",
      "step 6287 - loss = 1.280, (1.555 sec/step)\n",
      "step 6288 - loss = 1.364, (1.953 sec/step)\n",
      "step 6289 - loss = 1.739, (1.256 sec/step)\n",
      "step 6290 - loss = 1.232, (2.484 sec/step)\n",
      "step 6291 - loss = 2.786, (2.483 sec/step)\n",
      "step 6292 - loss = 2.644, (0.780 sec/step)\n",
      "step 6293 - loss = 2.061, (2.486 sec/step)\n",
      "step 6294 - loss = 0.898, (1.236 sec/step)\n",
      "step 6295 - loss = 1.643, (0.913 sec/step)\n",
      "step 6296 - loss = 1.786, (2.010 sec/step)\n",
      "step 6297 - loss = 1.704, (1.127 sec/step)\n",
      "step 6298 - loss = 1.855, (1.123 sec/step)\n",
      "step 6299 - loss = 1.906, (0.989 sec/step)\n",
      "step 6300 - loss = 1.802, (1.550 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6301 - loss = 2.314, (1.183 sec/step)\n",
      "step 6302 - loss = 1.931, (1.425 sec/step)\n",
      "step 6303 - loss = 1.694, (1.460 sec/step)\n",
      "step 6304 - loss = 1.463, (1.676 sec/step)\n",
      "step 6305 - loss = 2.039, (1.177 sec/step)\n",
      "step 6306 - loss = 1.662, (1.380 sec/step)\n",
      "step 6307 - loss = 1.651, (1.581 sec/step)\n",
      "step 6308 - loss = 1.472, (1.729 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6309 - loss = 1.517, (1.287 sec/step)\n",
      "step 6310 - loss = 2.138, (2.484 sec/step)\n",
      "step 6311 - loss = 1.131, (1.575 sec/step)\n",
      "step 6312 - loss = 1.507, (1.639 sec/step)\n",
      "step 6313 - loss = 2.049, (1.395 sec/step)\n",
      "step 6314 - loss = 2.146, (1.645 sec/step)\n",
      "step 6315 - loss = 1.895, (1.420 sec/step)\n",
      "step 6316 - loss = 1.507, (1.866 sec/step)\n",
      "step 6317 - loss = 1.949, (1.259 sec/step)\n",
      "step 6318 - loss = 1.960, (1.572 sec/step)\n",
      "step 6319 - loss = 1.841, (1.347 sec/step)\n",
      "step 6320 - loss = 2.112, (1.688 sec/step)\n",
      "step 6321 - loss = 1.336, (3.085 sec/step)\n",
      "step 6322 - loss = 2.013, (2.276 sec/step)\n",
      "step 6323 - loss = 2.030, (1.705 sec/step)\n",
      "step 6324 - loss = 2.111, (2.445 sec/step)\n",
      "step 6325 - loss = 1.496, (1.559 sec/step)\n",
      "step 6326 - loss = 1.758, (1.288 sec/step)\n",
      "step 6327 - loss = 2.058, (1.443 sec/step)\n",
      "step 6328 - loss = 1.909, (2.018 sec/step)\n",
      "step 6329 - loss = 1.876, (1.432 sec/step)\n",
      "step 6330 - loss = 2.213, (1.099 sec/step)\n",
      "step 6331 - loss = 1.754, (1.129 sec/step)\n",
      "step 6332 - loss = 1.811, (1.526 sec/step)\n",
      "step 6333 - loss = 1.634, (0.791 sec/step)\n",
      "step 6334 - loss = 2.001, (2.853 sec/step)\n",
      "step 6335 - loss = 1.677, (2.512 sec/step)\n",
      "step 6336 - loss = 1.779, (1.084 sec/step)\n",
      "step 6337 - loss = 1.115, (2.485 sec/step)\n",
      "step 6338 - loss = 0.560, (0.663 sec/step)\n",
      "step 6339 - loss = 1.344, (1.352 sec/step)\n",
      "step 6340 - loss = 1.486, (1.991 sec/step)\n",
      "step 6341 - loss = 1.691, (2.485 sec/step)\n",
      "step 6342 - loss = 0.553, (1.853 sec/step)\n",
      "step 6343 - loss = 2.378, (1.122 sec/step)\n",
      "step 6344 - loss = 1.619, (1.624 sec/step)\n",
      "step 6345 - loss = 1.941, (2.693 sec/step)\n",
      "step 6346 - loss = 2.127, (2.058 sec/step)\n",
      "step 6347 - loss = 1.773, (1.523 sec/step)\n",
      "step 6348 - loss = 1.861, (2.655 sec/step)\n",
      "step 6349 - loss = 1.846, (1.866 sec/step)\n",
      "step 6350 - loss = 1.353, (1.315 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6351 - loss = 1.806, (1.356 sec/step)\n",
      "step 6352 - loss = 1.706, (1.331 sec/step)\n",
      "step 6353 - loss = 1.884, (1.359 sec/step)\n",
      "step 6354 - loss = 1.694, (2.639 sec/step)\n",
      "step 6355 - loss = 1.163, (1.921 sec/step)\n",
      "step 6356 - loss = 1.904, (1.089 sec/step)\n",
      "step 6357 - loss = 2.238, (1.822 sec/step)\n",
      "step 6358 - loss = 1.765, (2.339 sec/step)\n",
      "step 6359 - loss = 1.778, (1.230 sec/step)\n",
      "step 6360 - loss = 2.417, (2.411 sec/step)\n",
      "step 6361 - loss = 1.429, (0.957 sec/step)\n",
      "step 6362 - loss = 1.775, (1.599 sec/step)\n",
      "step 6363 - loss = 1.625, (3.490 sec/step)\n",
      "step 6364 - loss = 2.145, (1.951 sec/step)\n",
      "step 6365 - loss = 1.374, (1.479 sec/step)\n",
      "step 6366 - loss = 1.570, (1.440 sec/step)\n",
      "step 6367 - loss = 1.710, (1.477 sec/step)\n",
      "step 6368 - loss = 2.875, (2.597 sec/step)\n",
      "step 6369 - loss = 1.906, (1.192 sec/step)\n",
      "step 6370 - loss = 1.901, (1.100 sec/step)\n",
      "step 6371 - loss = 1.849, (1.122 sec/step)\n",
      "step 6372 - loss = 1.250, (1.358 sec/step)\n",
      "step 6373 - loss = 1.822, (2.568 sec/step)\n",
      "step 6374 - loss = 1.892, (2.119 sec/step)\n",
      "step 6375 - loss = 2.184, (1.342 sec/step)\n",
      "step 6376 - loss = 1.742, (1.069 sec/step)\n",
      "step 6377 - loss = 1.371, (0.820 sec/step)\n",
      "step 6378 - loss = 1.805, (1.541 sec/step)\n",
      "step 6379 - loss = 1.867, (1.459 sec/step)\n",
      "step 6380 - loss = 1.948, (1.297 sec/step)\n",
      "step 6381 - loss = 1.578, (2.260 sec/step)\n",
      "step 6382 - loss = 2.179, (1.244 sec/step)\n",
      "step 6383 - loss = 1.987, (1.127 sec/step)\n",
      "step 6384 - loss = 1.959, (1.145 sec/step)\n",
      "step 6385 - loss = 1.566, (1.162 sec/step)\n",
      "step 6386 - loss = 2.247, (2.165 sec/step)\n",
      "step 6387 - loss = 1.414, (1.230 sec/step)\n",
      "step 6388 - loss = 1.640, (1.583 sec/step)\n",
      "step 6389 - loss = 1.835, (1.151 sec/step)\n",
      "step 6390 - loss = 1.834, (1.180 sec/step)\n",
      "step 6391 - loss = 1.725, (1.596 sec/step)\n",
      "step 6392 - loss = 2.064, (1.229 sec/step)\n",
      "step 6393 - loss = 1.085, (2.484 sec/step)\n",
      "step 6394 - loss = 0.538, (2.451 sec/step)\n",
      "step 6395 - loss = 2.098, (1.258 sec/step)\n",
      "step 6396 - loss = 1.731, (2.361 sec/step)\n",
      "step 6397 - loss = 1.791, (1.213 sec/step)\n",
      "step 6398 - loss = 2.223, (1.962 sec/step)\n",
      "step 6399 - loss = 1.190, (1.275 sec/step)\n",
      "step 6400 - loss = 1.495, (1.948 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6401 - loss = 1.716, (2.010 sec/step)\n",
      "step 6402 - loss = 1.898, (0.918 sec/step)\n",
      "step 6403 - loss = 2.232, (3.425 sec/step)\n",
      "step 6404 - loss = 2.012, (1.277 sec/step)\n",
      "step 6405 - loss = 1.688, (0.989 sec/step)\n",
      "step 6406 - loss = 1.386, (0.958 sec/step)\n",
      "step 6407 - loss = 1.320, (1.679 sec/step)\n",
      "step 6408 - loss = 2.322, (1.149 sec/step)\n",
      "step 6409 - loss = 1.255, (1.218 sec/step)\n",
      "step 6410 - loss = 1.934, (1.836 sec/step)\n",
      "step 6411 - loss = 1.560, (1.230 sec/step)\n",
      "step 6412 - loss = 1.392, (1.242 sec/step)\n",
      "step 6413 - loss = 1.171, (3.148 sec/step)\n",
      "step 6414 - loss = 2.422, (1.003 sec/step)\n",
      "step 6415 - loss = 1.684, (2.573 sec/step)\n",
      "step 6416 - loss = 1.946, (1.178 sec/step)\n",
      "step 6417 - loss = 2.318, (1.331 sec/step)\n",
      "step 6418 - loss = 1.671, (2.696 sec/step)\n",
      "step 6419 - loss = 1.375, (1.328 sec/step)\n",
      "step 6420 - loss = 1.861, (2.724 sec/step)\n",
      "step 6421 - loss = 1.771, (1.494 sec/step)\n",
      "step 6422 - loss = 1.651, (1.108 sec/step)\n",
      "step 6423 - loss = 1.707, (2.188 sec/step)\n",
      "step 6424 - loss = 1.584, (1.924 sec/step)\n",
      "step 6425 - loss = 1.979, (1.562 sec/step)\n",
      "step 6426 - loss = 1.627, (3.111 sec/step)\n",
      "step 6427 - loss = 2.127, (1.848 sec/step)\n",
      "step 6428 - loss = 1.823, (1.823 sec/step)\n",
      "step 6429 - loss = 1.357, (2.196 sec/step)\n",
      "step 6430 - loss = 1.808, (0.891 sec/step)\n",
      "step 6431 - loss = 1.879, (1.679 sec/step)\n",
      "step 6432 - loss = 1.420, (1.994 sec/step)\n",
      "step 6433 - loss = 1.962, (2.249 sec/step)\n",
      "step 6434 - loss = 1.656, (1.128 sec/step)\n",
      "step 6435 - loss = 2.706, (1.558 sec/step)\n",
      "step 6436 - loss = 1.737, (1.555 sec/step)\n",
      "step 6437 - loss = 1.881, (1.658 sec/step)\n",
      "step 6438 - loss = 1.670, (1.518 sec/step)\n",
      "step 6439 - loss = 1.769, (1.647 sec/step)\n",
      "step 6440 - loss = 2.143, (0.925 sec/step)\n",
      "step 6441 - loss = 2.284, (1.495 sec/step)\n",
      "step 6442 - loss = 2.266, (1.365 sec/step)\n",
      "step 6443 - loss = 1.831, (0.960 sec/step)\n",
      "step 6444 - loss = 1.615, (1.508 sec/step)\n",
      "step 6445 - loss = 2.048, (2.485 sec/step)\n",
      "step 6446 - loss = 1.423, (2.537 sec/step)\n",
      "step 6447 - loss = 2.200, (1.427 sec/step)\n",
      "step 6448 - loss = 2.662, (3.209 sec/step)\n",
      "step 6449 - loss = 2.094, (1.410 sec/step)\n",
      "step 6450 - loss = 2.151, (1.882 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6451 - loss = 2.118, (2.305 sec/step)\n",
      "step 6452 - loss = 1.660, (1.182 sec/step)\n",
      "step 6453 - loss = 2.340, (1.952 sec/step)\n",
      "step 6454 - loss = 1.793, (1.196 sec/step)\n",
      "step 6455 - loss = 1.843, (2.531 sec/step)\n",
      "step 6456 - loss = 1.710, (2.504 sec/step)\n",
      "step 6457 - loss = 1.631, (1.177 sec/step)\n",
      "step 6458 - loss = 2.348, (2.485 sec/step)\n",
      "step 6459 - loss = 2.300, (1.187 sec/step)\n",
      "step 6460 - loss = 1.921, (1.170 sec/step)\n",
      "step 6461 - loss = 1.903, (1.392 sec/step)\n",
      "step 6462 - loss = 1.816, (1.586 sec/step)\n",
      "step 6463 - loss = 1.820, (1.111 sec/step)\n",
      "step 6464 - loss = 1.440, (1.603 sec/step)\n",
      "step 6465 - loss = 2.199, (1.530 sec/step)\n",
      "step 6466 - loss = 1.730, (0.963 sec/step)\n",
      "step 6467 - loss = 1.981, (2.693 sec/step)\n",
      "step 6468 - loss = 1.852, (1.608 sec/step)\n",
      "step 6469 - loss = 2.360, (1.949 sec/step)\n",
      "step 6470 - loss = 1.884, (2.052 sec/step)\n",
      "step 6471 - loss = 1.713, (1.893 sec/step)\n",
      "step 6472 - loss = 2.006, (1.127 sec/step)\n",
      "step 6473 - loss = 1.919, (1.087 sec/step)\n",
      "step 6474 - loss = 1.712, (2.183 sec/step)\n",
      "step 6475 - loss = 1.668, (1.783 sec/step)\n",
      "step 6476 - loss = 2.167, (1.411 sec/step)\n",
      "step 6477 - loss = 2.386, (2.487 sec/step)\n",
      "step 6478 - loss = 0.979, (0.151 sec/step)\n",
      "step 6479 - loss = 1.839, (1.387 sec/step)\n",
      "step 6480 - loss = 1.369, (1.715 sec/step)\n",
      "step 6481 - loss = 2.082, (1.258 sec/step)\n",
      "step 6482 - loss = 2.052, (1.261 sec/step)\n",
      "step 6483 - loss = 1.674, (2.215 sec/step)\n",
      "step 6484 - loss = 2.191, (1.402 sec/step)\n",
      "step 6485 - loss = 1.596, (1.293 sec/step)\n",
      "step 6486 - loss = 1.560, (0.763 sec/step)\n",
      "step 6487 - loss = 2.164, (1.401 sec/step)\n",
      "step 6488 - loss = 2.053, (1.494 sec/step)\n",
      "step 6489 - loss = 2.288, (1.392 sec/step)\n",
      "step 6490 - loss = 1.914, (1.522 sec/step)\n",
      "step 6491 - loss = 2.383, (1.376 sec/step)\n",
      "step 6492 - loss = 2.283, (2.487 sec/step)\n",
      "step 6493 - loss = 2.772, (2.608 sec/step)\n",
      "step 6494 - loss = 1.768, (2.864 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6495 - loss = 1.545, (1.412 sec/step)\n",
      "step 6496 - loss = 1.557, (1.196 sec/step)\n",
      "step 6497 - loss = 1.698, (1.187 sec/step)\n",
      "step 6498 - loss = 1.627, (2.101 sec/step)\n",
      "step 6499 - loss = 1.588, (2.421 sec/step)\n",
      "step 6500 - loss = 1.904, (1.609 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6501 - loss = 1.420, (0.699 sec/step)\n",
      "step 6502 - loss = 2.215, (1.515 sec/step)\n",
      "step 6503 - loss = 2.102, (1.274 sec/step)\n",
      "step 6504 - loss = 2.444, (1.198 sec/step)\n",
      "step 6505 - loss = 1.736, (1.236 sec/step)\n",
      "step 6506 - loss = 2.251, (1.445 sec/step)\n",
      "step 6507 - loss = 2.104, (1.269 sec/step)\n",
      "step 6508 - loss = 1.731, (2.258 sec/step)\n",
      "step 6509 - loss = 2.095, (1.892 sec/step)\n",
      "step 6510 - loss = 1.811, (1.589 sec/step)\n",
      "step 6511 - loss = 2.652, (1.909 sec/step)\n",
      "step 6512 - loss = 1.492, (2.431 sec/step)\n",
      "step 6513 - loss = 1.968, (1.128 sec/step)\n",
      "step 6514 - loss = 1.520, (0.952 sec/step)\n",
      "step 6515 - loss = 1.675, (1.517 sec/step)\n",
      "step 6516 - loss = 1.314, (1.597 sec/step)\n",
      "step 6517 - loss = 1.751, (2.561 sec/step)\n",
      "step 6518 - loss = 1.912, (1.520 sec/step)\n",
      "step 6519 - loss = 1.411, (1.971 sec/step)\n",
      "step 6520 - loss = 1.726, (1.355 sec/step)\n",
      "step 6521 - loss = 2.011, (1.005 sec/step)\n",
      "step 6522 - loss = 2.350, (2.652 sec/step)\n",
      "step 6523 - loss = 1.757, (1.036 sec/step)\n",
      "step 6524 - loss = 2.380, (2.293 sec/step)\n",
      "step 6525 - loss = 1.691, (1.288 sec/step)\n",
      "step 6526 - loss = 2.170, (1.292 sec/step)\n",
      "step 6527 - loss = 1.824, (1.116 sec/step)\n",
      "step 6528 - loss = 1.772, (1.648 sec/step)\n",
      "step 6529 - loss = 1.684, (2.032 sec/step)\n",
      "step 6530 - loss = 1.501, (1.782 sec/step)\n",
      "step 6531 - loss = 1.684, (0.961 sec/step)\n",
      "step 6532 - loss = 1.366, (0.847 sec/step)\n",
      "step 6533 - loss = 1.378, (0.968 sec/step)\n",
      "step 6534 - loss = 2.060, (2.486 sec/step)\n",
      "step 6535 - loss = 0.546, (0.612 sec/step)\n",
      "step 6536 - loss = 1.735, (1.321 sec/step)\n",
      "step 6537 - loss = 2.334, (2.485 sec/step)\n",
      "step 6538 - loss = 2.774, (2.646 sec/step)\n",
      "step 6539 - loss = 2.009, (0.958 sec/step)\n",
      "step 6540 - loss = 2.162, (2.787 sec/step)\n",
      "step 6541 - loss = 1.982, (1.759 sec/step)\n",
      "step 6542 - loss = 2.016, (1.573 sec/step)\n",
      "step 6543 - loss = 1.560, (1.719 sec/step)\n",
      "step 6544 - loss = 2.080, (2.045 sec/step)\n",
      "step 6545 - loss = 1.756, (1.158 sec/step)\n",
      "step 6546 - loss = 1.995, (1.612 sec/step)\n",
      "step 6547 - loss = 1.795, (1.255 sec/step)\n",
      "step 6548 - loss = 2.333, (1.874 sec/step)\n",
      "step 6549 - loss = 1.544, (1.423 sec/step)\n",
      "step 6550 - loss = 1.794, (1.221 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6551 - loss = 1.600, (1.013 sec/step)\n",
      "step 6552 - loss = 1.927, (1.137 sec/step)\n",
      "step 6553 - loss = 1.827, (3.604 sec/step)\n",
      "step 6554 - loss = 1.456, (1.783 sec/step)\n",
      "step 6555 - loss = 1.229, (1.947 sec/step)\n",
      "step 6556 - loss = 1.473, (0.940 sec/step)\n",
      "step 6557 - loss = 1.587, (1.067 sec/step)\n",
      "step 6558 - loss = 1.858, (2.172 sec/step)\n",
      "step 6559 - loss = 1.845, (0.957 sec/step)\n",
      "step 6560 - loss = 1.906, (3.075 sec/step)\n",
      "step 6561 - loss = 1.263, (2.223 sec/step)\n",
      "step 6562 - loss = 1.990, (3.322 sec/step)\n",
      "step 6563 - loss = 2.113, (1.141 sec/step)\n",
      "step 6564 - loss = 2.144, (1.256 sec/step)\n",
      "step 6565 - loss = 1.505, (1.446 sec/step)\n",
      "step 6566 - loss = 1.816, (1.201 sec/step)\n",
      "step 6567 - loss = 1.977, (1.380 sec/step)\n",
      "step 6568 - loss = 1.860, (0.953 sec/step)\n",
      "step 6569 - loss = 1.735, (1.113 sec/step)\n",
      "step 6570 - loss = 2.077, (2.538 sec/step)\n",
      "step 6571 - loss = 1.848, (0.958 sec/step)\n",
      "step 6572 - loss = 1.362, (1.685 sec/step)\n",
      "step 6573 - loss = 1.688, (1.860 sec/step)\n",
      "step 6574 - loss = 2.155, (1.335 sec/step)\n",
      "step 6575 - loss = 1.709, (1.114 sec/step)\n",
      "step 6576 - loss = 1.904, (1.265 sec/step)\n",
      "step 6577 - loss = 1.906, (1.116 sec/step)\n",
      "step 6578 - loss = 2.556, (2.429 sec/step)\n",
      "step 6579 - loss = 1.921, (1.119 sec/step)\n",
      "step 6580 - loss = 2.048, (1.113 sec/step)\n",
      "step 6581 - loss = 2.165, (1.278 sec/step)\n",
      "step 6582 - loss = 1.806, (0.970 sec/step)\n",
      "step 6583 - loss = 1.728, (1.128 sec/step)\n",
      "step 6584 - loss = 2.349, (1.765 sec/step)\n",
      "step 6585 - loss = 2.354, (2.638 sec/step)\n",
      "step 6586 - loss = 1.653, (1.621 sec/step)\n",
      "step 6587 - loss = 1.741, (1.233 sec/step)\n",
      "step 6588 - loss = 1.657, (2.051 sec/step)\n",
      "step 6589 - loss = 2.344, (1.219 sec/step)\n",
      "step 6590 - loss = 2.338, (2.708 sec/step)\n",
      "step 6591 - loss = 1.463, (2.015 sec/step)\n",
      "step 6592 - loss = 2.400, (1.054 sec/step)\n",
      "step 6593 - loss = 1.878, (1.129 sec/step)\n",
      "step 6594 - loss = 2.257, (1.494 sec/step)\n",
      "step 6595 - loss = 1.667, (1.275 sec/step)\n",
      "step 6596 - loss = 1.860, (1.374 sec/step)\n",
      "step 6597 - loss = 2.309, (1.866 sec/step)\n",
      "step 6598 - loss = 2.270, (3.379 sec/step)\n",
      "step 6599 - loss = 1.576, (2.731 sec/step)\n",
      "step 6600 - loss = 1.424, (1.423 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6601 - loss = 1.729, (2.303 sec/step)\n",
      "step 6602 - loss = 2.360, (3.052 sec/step)\n",
      "step 6603 - loss = 2.014, (2.810 sec/step)\n",
      "step 6604 - loss = 1.229, (1.168 sec/step)\n",
      "step 6605 - loss = 2.224, (1.852 sec/step)\n",
      "step 6606 - loss = 1.231, (1.067 sec/step)\n",
      "step 6607 - loss = 1.550, (1.995 sec/step)\n",
      "step 6608 - loss = 2.213, (2.150 sec/step)\n",
      "step 6609 - loss = 1.906, (1.511 sec/step)\n",
      "step 6610 - loss = 1.616, (1.107 sec/step)\n",
      "step 6611 - loss = 1.879, (1.934 sec/step)\n",
      "step 6612 - loss = 1.402, (1.327 sec/step)\n",
      "step 6613 - loss = 2.142, (1.230 sec/step)\n",
      "step 6614 - loss = 1.447, (1.780 sec/step)\n",
      "step 6615 - loss = 1.803, (2.274 sec/step)\n",
      "step 6616 - loss = 1.607, (2.623 sec/step)\n",
      "step 6617 - loss = 2.070, (1.158 sec/step)\n",
      "step 6618 - loss = 2.027, (1.391 sec/step)\n",
      "step 6619 - loss = 2.037, (1.912 sec/step)\n",
      "step 6620 - loss = 2.110, (2.256 sec/step)\n",
      "step 6621 - loss = 2.163, (1.536 sec/step)\n",
      "step 6622 - loss = 1.680, (0.921 sec/step)\n",
      "step 6623 - loss = 1.843, (1.567 sec/step)\n",
      "step 6624 - loss = 1.979, (2.044 sec/step)\n",
      "step 6625 - loss = 2.021, (1.375 sec/step)\n",
      "step 6626 - loss = 1.090, (2.163 sec/step)\n",
      "step 6627 - loss = 1.752, (1.091 sec/step)\n",
      "step 6628 - loss = 1.548, (1.959 sec/step)\n",
      "step 6629 - loss = 1.975, (1.227 sec/step)\n",
      "step 6630 - loss = 1.692, (1.690 sec/step)\n",
      "step 6631 - loss = 2.464, (2.432 sec/step)\n",
      "step 6632 - loss = 2.153, (1.248 sec/step)\n",
      "step 6633 - loss = 1.991, (2.483 sec/step)\n",
      "step 6634 - loss = 3.193, (0.639 sec/step)\n",
      "step 6635 - loss = 1.960, (1.719 sec/step)\n",
      "step 6636 - loss = 2.400, (1.378 sec/step)\n",
      "step 6637 - loss = 1.637, (0.810 sec/step)\n",
      "step 6638 - loss = 2.378, (2.486 sec/step)\n",
      "step 6639 - loss = 2.170, (1.178 sec/step)\n",
      "step 6640 - loss = 1.660, (1.119 sec/step)\n",
      "step 6641 - loss = 1.488, (1.053 sec/step)\n",
      "step 6642 - loss = 2.061, (1.541 sec/step)\n",
      "step 6643 - loss = 2.309, (1.556 sec/step)\n",
      "step 6644 - loss = 1.974, (1.246 sec/step)\n",
      "step 6645 - loss = 1.551, (2.488 sec/step)\n",
      "step 6646 - loss = 0.780, (0.980 sec/step)\n",
      "step 6647 - loss = 2.012, (1.700 sec/step)\n",
      "step 6648 - loss = 1.968, (1.448 sec/step)\n",
      "step 6649 - loss = 1.943, (1.836 sec/step)\n",
      "step 6650 - loss = 1.650, (1.428 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6651 - loss = 1.972, (1.449 sec/step)\n",
      "step 6652 - loss = 1.494, (1.081 sec/step)\n",
      "step 6653 - loss = 1.383, (1.822 sec/step)\n",
      "step 6654 - loss = 1.835, (1.121 sec/step)\n",
      "step 6655 - loss = 1.903, (2.407 sec/step)\n",
      "step 6656 - loss = 1.832, (2.485 sec/step)\n",
      "step 6657 - loss = 0.661, (1.151 sec/step)\n",
      "step 6658 - loss = 1.828, (3.095 sec/step)\n",
      "step 6659 - loss = 1.945, (1.068 sec/step)\n",
      "step 6660 - loss = 1.169, (1.766 sec/step)\n",
      "step 6661 - loss = 2.539, (1.214 sec/step)\n",
      "step 6662 - loss = 2.135, (1.405 sec/step)\n",
      "step 6663 - loss = 2.022, (1.281 sec/step)\n",
      "step 6664 - loss = 2.127, (1.458 sec/step)\n",
      "step 6665 - loss = 2.112, (2.483 sec/step)\n",
      "step 6666 - loss = 2.486, (2.484 sec/step)\n",
      "step 6667 - loss = 0.605, (1.289 sec/step)\n",
      "step 6668 - loss = 1.291, (0.969 sec/step)\n",
      "step 6669 - loss = 1.888, (1.342 sec/step)\n",
      "step 6670 - loss = 2.312, (1.517 sec/step)\n",
      "step 6671 - loss = 1.897, (1.303 sec/step)\n",
      "step 6672 - loss = 1.767, (2.483 sec/step)\n",
      "step 6673 - loss = 2.637, (1.649 sec/step)\n",
      "step 6674 - loss = 1.443, (0.889 sec/step)\n",
      "step 6675 - loss = 2.212, (2.663 sec/step)\n",
      "step 6676 - loss = 2.387, (2.483 sec/step)\n",
      "step 6677 - loss = 2.280, (2.146 sec/step)\n",
      "step 6678 - loss = 2.278, (2.483 sec/step)\n",
      "step 6679 - loss = 2.645, (2.063 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6680 - loss = 2.197, (1.719 sec/step)\n",
      "step 6681 - loss = 2.349, (1.258 sec/step)\n",
      "step 6682 - loss = 1.561, (1.503 sec/step)\n",
      "step 6683 - loss = 1.522, (1.709 sec/step)\n",
      "step 6684 - loss = 2.215, (2.483 sec/step)\n",
      "step 6685 - loss = 2.889, (1.707 sec/step)\n",
      "step 6686 - loss = 1.719, (1.172 sec/step)\n",
      "step 6687 - loss = 1.980, (2.540 sec/step)\n",
      "step 6688 - loss = 1.937, (1.493 sec/step)\n",
      "step 6689 - loss = 2.067, (0.999 sec/step)\n",
      "step 6690 - loss = 1.946, (3.119 sec/step)\n",
      "step 6691 - loss = 1.531, (1.244 sec/step)\n",
      "step 6692 - loss = 2.372, (2.486 sec/step)\n",
      "step 6693 - loss = 1.780, (0.895 sec/step)\n",
      "step 6694 - loss = 1.763, (1.342 sec/step)\n",
      "step 6695 - loss = 2.392, (1.743 sec/step)\n",
      "step 6696 - loss = 2.303, (2.070 sec/step)\n",
      "step 6697 - loss = 1.398, (0.882 sec/step)\n",
      "step 6698 - loss = 2.238, (2.006 sec/step)\n",
      "step 6699 - loss = 2.306, (2.303 sec/step)\n",
      "step 6700 - loss = 1.725, (1.287 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6701 - loss = 2.141, (1.074 sec/step)\n",
      "step 6702 - loss = 1.607, (1.685 sec/step)\n",
      "step 6703 - loss = 1.631, (2.344 sec/step)\n",
      "step 6704 - loss = 1.883, (1.205 sec/step)\n",
      "step 6705 - loss = 2.372, (1.380 sec/step)\n",
      "step 6706 - loss = 1.397, (0.881 sec/step)\n",
      "step 6707 - loss = 2.019, (2.229 sec/step)\n",
      "step 6708 - loss = 1.808, (1.058 sec/step)\n",
      "step 6709 - loss = 2.324, (1.350 sec/step)\n",
      "step 6710 - loss = 2.215, (2.485 sec/step)\n",
      "step 6711 - loss = 2.728, (1.209 sec/step)\n",
      "step 6712 - loss = 1.072, (2.466 sec/step)\n",
      "step 6713 - loss = 1.797, (1.516 sec/step)\n",
      "step 6714 - loss = 2.250, (1.520 sec/step)\n",
      "step 6715 - loss = 2.076, (1.702 sec/step)\n",
      "step 6716 - loss = 2.238, (1.781 sec/step)\n",
      "step 6717 - loss = 2.323, (1.540 sec/step)\n",
      "step 6718 - loss = 2.146, (1.705 sec/step)\n",
      "step 6719 - loss = 1.629, (1.247 sec/step)\n",
      "step 6720 - loss = 1.503, (1.016 sec/step)\n",
      "step 6721 - loss = 1.881, (2.141 sec/step)\n",
      "step 6722 - loss = 1.925, (2.488 sec/step)\n",
      "step 6723 - loss = 0.864, (0.401 sec/step)\n",
      "step 6724 - loss = 1.905, (1.291 sec/step)\n",
      "step 6725 - loss = 1.760, (2.592 sec/step)\n",
      "step 6726 - loss = 1.964, (2.175 sec/step)\n",
      "step 6727 - loss = 1.544, (2.665 sec/step)\n",
      "step 6728 - loss = 1.432, (1.053 sec/step)\n",
      "step 6729 - loss = 2.024, (1.211 sec/step)\n",
      "step 6730 - loss = 1.116, (2.487 sec/step)\n",
      "step 6731 - loss = 0.622, (0.166 sec/step)\n",
      "step 6732 - loss = 1.308, (1.150 sec/step)\n",
      "step 6733 - loss = 1.953, (1.052 sec/step)\n",
      "step 6734 - loss = 1.780, (1.496 sec/step)\n",
      "step 6735 - loss = 1.878, (1.149 sec/step)\n",
      "step 6736 - loss = 2.059, (1.799 sec/step)\n",
      "step 6737 - loss = 1.753, (1.286 sec/step)\n",
      "step 6738 - loss = 2.123, (0.927 sec/step)\n",
      "step 6739 - loss = 2.153, (1.341 sec/step)\n",
      "step 6740 - loss = 1.896, (1.492 sec/step)\n",
      "step 6741 - loss = 1.975, (1.124 sec/step)\n",
      "step 6742 - loss = 1.139, (1.112 sec/step)\n",
      "step 6743 - loss = 1.958, (1.681 sec/step)\n",
      "step 6744 - loss = 2.318, (1.602 sec/step)\n",
      "step 6745 - loss = 1.886, (1.344 sec/step)\n",
      "step 6746 - loss = 2.294, (1.261 sec/step)\n",
      "step 6747 - loss = 1.278, (1.405 sec/step)\n",
      "step 6748 - loss = 1.957, (1.230 sec/step)\n",
      "step 6749 - loss = 1.801, (2.484 sec/step)\n",
      "step 6750 - loss = 1.412, (1.597 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6751 - loss = 1.690, (1.290 sec/step)\n",
      "step 6752 - loss = 1.929, (1.115 sec/step)\n",
      "step 6753 - loss = 1.288, (1.151 sec/step)\n",
      "step 6754 - loss = 1.789, (1.297 sec/step)\n",
      "step 6755 - loss = 2.462, (1.382 sec/step)\n",
      "step 6756 - loss = 2.460, (2.488 sec/step)\n",
      "step 6757 - loss = 2.436, (2.597 sec/step)\n",
      "step 6758 - loss = 2.378, (1.897 sec/step)\n",
      "step 6759 - loss = 1.935, (1.392 sec/step)\n",
      "step 6760 - loss = 1.973, (1.258 sec/step)\n",
      "step 6761 - loss = 1.843, (1.556 sec/step)\n",
      "step 6762 - loss = 2.292, (1.222 sec/step)\n",
      "step 6763 - loss = 2.213, (2.223 sec/step)\n",
      "step 6764 - loss = 1.483, (1.321 sec/step)\n",
      "step 6765 - loss = 1.997, (1.983 sec/step)\n",
      "step 6766 - loss = 1.740, (1.066 sec/step)\n",
      "step 6767 - loss = 1.805, (2.886 sec/step)\n",
      "step 6768 - loss = 2.602, (2.410 sec/step)\n",
      "step 6769 - loss = 1.410, (1.745 sec/step)\n",
      "step 6770 - loss = 1.916, (1.257 sec/step)\n",
      "step 6771 - loss = 1.748, (1.210 sec/step)\n",
      "step 6772 - loss = 1.052, (2.485 sec/step)\n",
      "step 6773 - loss = 1.561, (1.218 sec/step)\n",
      "step 6774 - loss = 2.284, (1.493 sec/step)\n",
      "step 6775 - loss = 1.781, (1.147 sec/step)\n",
      "step 6776 - loss = 2.076, (2.485 sec/step)\n",
      "step 6777 - loss = 1.926, (2.364 sec/step)\n",
      "step 6778 - loss = 2.115, (1.313 sec/step)\n",
      "step 6779 - loss = 1.496, (1.068 sec/step)\n",
      "step 6780 - loss = 1.887, (1.486 sec/step)\n",
      "step 6781 - loss = 1.619, (1.312 sec/step)\n",
      "step 6782 - loss = 1.824, (1.901 sec/step)\n",
      "step 6783 - loss = 2.254, (1.146 sec/step)\n",
      "step 6784 - loss = 1.849, (1.535 sec/step)\n",
      "step 6785 - loss = 1.434, (2.485 sec/step)\n",
      "step 6786 - loss = 0.802, (2.433 sec/step)\n",
      "step 6787 - loss = 2.174, (1.292 sec/step)\n",
      "step 6788 - loss = 1.943, (1.718 sec/step)\n",
      "step 6789 - loss = 1.839, (2.111 sec/step)\n",
      "step 6790 - loss = 2.131, (1.409 sec/step)\n",
      "step 6791 - loss = 1.240, (1.256 sec/step)\n",
      "step 6792 - loss = 1.838, (1.502 sec/step)\n",
      "step 6793 - loss = 2.117, (1.513 sec/step)\n",
      "step 6794 - loss = 1.437, (1.610 sec/step)\n",
      "step 6795 - loss = 1.964, (1.255 sec/step)\n",
      "step 6796 - loss = 1.875, (1.512 sec/step)\n",
      "step 6797 - loss = 2.221, (1.346 sec/step)\n",
      "step 6798 - loss = 1.438, (2.179 sec/step)\n",
      "step 6799 - loss = 1.763, (1.458 sec/step)\n",
      "step 6800 - loss = 1.977, (1.342 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6801 - loss = 2.152, (1.686 sec/step)\n",
      "step 6802 - loss = 1.944, (0.896 sec/step)\n",
      "step 6803 - loss = 1.290, (1.285 sec/step)\n",
      "step 6804 - loss = 1.544, (1.487 sec/step)\n",
      "step 6805 - loss = 2.641, (1.343 sec/step)\n",
      "step 6806 - loss = 2.087, (1.272 sec/step)\n",
      "step 6807 - loss = 2.204, (2.742 sec/step)\n",
      "step 6808 - loss = 2.145, (1.593 sec/step)\n",
      "step 6809 - loss = 1.660, (3.086 sec/step)\n",
      "step 6810 - loss = 2.200, (1.312 sec/step)\n",
      "step 6811 - loss = 1.872, (1.266 sec/step)\n",
      "step 6812 - loss = 1.705, (1.573 sec/step)\n",
      "step 6813 - loss = 1.819, (1.495 sec/step)\n",
      "step 6814 - loss = 1.278, (2.143 sec/step)\n",
      "step 6815 - loss = 1.836, (1.427 sec/step)\n",
      "step 6816 - loss = 2.028, (3.004 sec/step)\n",
      "step 6817 - loss = 1.260, (1.231 sec/step)\n",
      "step 6818 - loss = 2.137, (1.053 sec/step)\n",
      "step 6819 - loss = 1.498, (1.680 sec/step)\n",
      "step 6820 - loss = 0.748, (1.155 sec/step)\n",
      "step 6821 - loss = 1.796, (1.848 sec/step)\n",
      "step 6822 - loss = 1.702, (1.540 sec/step)\n",
      "step 6823 - loss = 1.714, (1.310 sec/step)\n",
      "step 6824 - loss = 2.063, (1.261 sec/step)\n",
      "step 6825 - loss = 2.623, (1.144 sec/step)\n",
      "step 6826 - loss = 2.120, (0.911 sec/step)\n",
      "step 6827 - loss = 2.316, (1.621 sec/step)\n",
      "step 6828 - loss = 2.051, (1.199 sec/step)\n",
      "step 6829 - loss = 2.388, (2.485 sec/step)\n",
      "step 6830 - loss = 2.348, (2.562 sec/step)\n",
      "step 6831 - loss = 2.026, (2.039 sec/step)\n",
      "step 6832 - loss = 1.656, (1.254 sec/step)\n",
      "step 6833 - loss = 1.923, (1.612 sec/step)\n",
      "step 6834 - loss = 1.867, (1.246 sec/step)\n",
      "step 6835 - loss = 2.288, (1.978 sec/step)\n",
      "step 6836 - loss = 1.950, (1.482 sec/step)\n",
      "step 6837 - loss = 2.284, (1.896 sec/step)\n",
      "step 6838 - loss = 1.720, (1.613 sec/step)\n",
      "step 6839 - loss = 1.574, (2.125 sec/step)\n",
      "step 6840 - loss = 1.904, (2.695 sec/step)\n",
      "step 6841 - loss = 2.006, (1.093 sec/step)\n",
      "step 6842 - loss = 2.319, (1.090 sec/step)\n",
      "step 6843 - loss = 1.687, (1.954 sec/step)\n",
      "step 6844 - loss = 1.523, (1.557 sec/step)\n",
      "step 6845 - loss = 1.257, (1.734 sec/step)\n",
      "step 6846 - loss = 1.638, (1.429 sec/step)\n",
      "step 6847 - loss = 2.045, (3.212 sec/step)\n",
      "step 6848 - loss = 1.669, (1.282 sec/step)\n",
      "step 6849 - loss = 1.810, (1.174 sec/step)\n",
      "step 6850 - loss = 1.287, (1.709 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6851 - loss = 1.790, (1.058 sec/step)\n",
      "step 6852 - loss = 2.276, (1.637 sec/step)\n",
      "step 6853 - loss = 1.671, (1.586 sec/step)\n",
      "step 6854 - loss = 1.656, (1.226 sec/step)\n",
      "step 6855 - loss = 1.780, (2.812 sec/step)\n",
      "step 6856 - loss = 1.382, (1.478 sec/step)\n",
      "step 6857 - loss = 2.031, (1.229 sec/step)\n",
      "step 6858 - loss = 1.775, (0.856 sec/step)\n",
      "step 6859 - loss = 1.580, (1.175 sec/step)\n",
      "step 6860 - loss = 1.731, (2.004 sec/step)\n",
      "step 6861 - loss = 1.761, (1.445 sec/step)\n",
      "step 6862 - loss = 1.825, (1.313 sec/step)\n",
      "step 6863 - loss = 1.533, (1.576 sec/step)\n",
      "step 6864 - loss = 1.657, (0.939 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6865 - loss = 2.086, (1.519 sec/step)\n",
      "step 6866 - loss = 2.020, (1.593 sec/step)\n",
      "step 6867 - loss = 2.386, (1.376 sec/step)\n",
      "step 6868 - loss = 1.656, (2.137 sec/step)\n",
      "step 6869 - loss = 2.159, (2.261 sec/step)\n",
      "step 6870 - loss = 2.034, (1.757 sec/step)\n",
      "step 6871 - loss = 1.790, (1.411 sec/step)\n",
      "step 6872 - loss = 2.004, (0.926 sec/step)\n",
      "step 6873 - loss = 2.258, (2.661 sec/step)\n",
      "step 6874 - loss = 1.781, (1.868 sec/step)\n",
      "step 6875 - loss = 1.839, (2.657 sec/step)\n",
      "step 6876 - loss = 1.897, (1.004 sec/step)\n",
      "step 6877 - loss = 2.274, (1.511 sec/step)\n",
      "step 6878 - loss = 2.007, (1.598 sec/step)\n",
      "step 6879 - loss = 2.188, (1.578 sec/step)\n",
      "step 6880 - loss = 1.819, (2.337 sec/step)\n",
      "step 6881 - loss = 1.840, (1.638 sec/step)\n",
      "step 6882 - loss = 1.324, (1.741 sec/step)\n",
      "step 6883 - loss = 1.733, (2.451 sec/step)\n",
      "step 6884 - loss = 1.658, (1.625 sec/step)\n",
      "step 6885 - loss = 1.898, (1.391 sec/step)\n",
      "step 6886 - loss = 1.386, (1.867 sec/step)\n",
      "step 6887 - loss = 1.458, (0.998 sec/step)\n",
      "step 6888 - loss = 2.024, (3.049 sec/step)\n",
      "step 6889 - loss = 1.797, (1.838 sec/step)\n",
      "step 6890 - loss = 2.058, (1.655 sec/step)\n",
      "step 6891 - loss = 1.962, (1.225 sec/step)\n",
      "step 6892 - loss = 1.761, (1.693 sec/step)\n",
      "step 6893 - loss = 1.196, (2.484 sec/step)\n",
      "step 6894 - loss = 2.470, (2.483 sec/step)\n",
      "step 6895 - loss = 1.821, (2.483 sec/step)\n",
      "step 6896 - loss = 0.514, (0.306 sec/step)\n",
      "step 6897 - loss = 1.759, (1.121 sec/step)\n",
      "step 6898 - loss = 2.342, (1.180 sec/step)\n",
      "step 6899 - loss = 1.548, (1.004 sec/step)\n",
      "step 6900 - loss = 1.757, (1.180 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6901 - loss = 2.142, (1.518 sec/step)\n",
      "step 6902 - loss = 2.016, (1.358 sec/step)\n",
      "step 6903 - loss = 1.481, (2.391 sec/step)\n",
      "step 6904 - loss = 2.048, (1.273 sec/step)\n",
      "step 6905 - loss = 1.815, (1.083 sec/step)\n",
      "step 6906 - loss = 2.020, (2.121 sec/step)\n",
      "step 6907 - loss = 1.848, (1.392 sec/step)\n",
      "step 6908 - loss = 1.259, (1.047 sec/step)\n",
      "step 6909 - loss = 2.062, (1.706 sec/step)\n",
      "step 6910 - loss = 2.006, (1.382 sec/step)\n",
      "step 6911 - loss = 1.753, (1.608 sec/step)\n",
      "step 6912 - loss = 2.035, (0.925 sec/step)\n",
      "step 6913 - loss = 1.811, (1.069 sec/step)\n",
      "step 6914 - loss = 2.169, (1.513 sec/step)\n",
      "step 6915 - loss = 1.360, (1.682 sec/step)\n",
      "step 6916 - loss = 1.616, (2.392 sec/step)\n",
      "step 6917 - loss = 1.281, (1.916 sec/step)\n",
      "step 6918 - loss = 2.117, (1.116 sec/step)\n",
      "step 6919 - loss = 1.863, (1.318 sec/step)\n",
      "step 6920 - loss = 2.014, (1.908 sec/step)\n",
      "step 6921 - loss = 2.033, (0.895 sec/step)\n",
      "step 6922 - loss = 2.054, (1.512 sec/step)\n",
      "step 6923 - loss = 1.191, (1.412 sec/step)\n",
      "step 6924 - loss = 1.324, (1.614 sec/step)\n",
      "step 6925 - loss = 1.675, (1.154 sec/step)\n",
      "step 6926 - loss = 1.967, (1.290 sec/step)\n",
      "step 6927 - loss = 2.055, (1.257 sec/step)\n",
      "step 6928 - loss = 1.869, (1.246 sec/step)\n",
      "step 6929 - loss = 1.835, (1.520 sec/step)\n",
      "step 6930 - loss = 2.113, (1.705 sec/step)\n",
      "step 6931 - loss = 1.244, (1.460 sec/step)\n",
      "step 6932 - loss = 2.117, (1.240 sec/step)\n",
      "step 6933 - loss = 1.939, (1.190 sec/step)\n",
      "step 6934 - loss = 1.649, (1.130 sec/step)\n",
      "step 6935 - loss = 1.356, (1.382 sec/step)\n",
      "step 6936 - loss = 1.410, (1.034 sec/step)\n",
      "step 6937 - loss = 1.839, (1.755 sec/step)\n",
      "step 6938 - loss = 2.552, (1.198 sec/step)\n",
      "step 6939 - loss = 1.550, (1.890 sec/step)\n",
      "step 6940 - loss = 2.354, (2.482 sec/step)\n",
      "step 6941 - loss = 2.330, (2.371 sec/step)\n",
      "step 6942 - loss = 1.572, (1.230 sec/step)\n",
      "step 6943 - loss = 1.705, (1.868 sec/step)\n",
      "step 6944 - loss = 1.761, (1.591 sec/step)\n",
      "step 6945 - loss = 2.060, (1.825 sec/step)\n",
      "step 6946 - loss = 1.649, (1.115 sec/step)\n",
      "step 6947 - loss = 1.992, (1.596 sec/step)\n",
      "step 6948 - loss = 1.949, (2.389 sec/step)\n",
      "step 6949 - loss = 1.870, (1.198 sec/step)\n",
      "step 6950 - loss = 1.786, (2.778 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 6951 - loss = 1.883, (1.178 sec/step)\n",
      "step 6952 - loss = 1.507, (2.665 sec/step)\n",
      "step 6953 - loss = 1.722, (1.032 sec/step)\n",
      "step 6954 - loss = 2.156, (1.390 sec/step)\n",
      "step 6955 - loss = 1.369, (2.212 sec/step)\n",
      "step 6956 - loss = 1.739, (1.845 sec/step)\n",
      "step 6957 - loss = 2.020, (1.399 sec/step)\n",
      "step 6958 - loss = 1.880, (1.177 sec/step)\n",
      "step 6959 - loss = 1.859, (1.943 sec/step)\n",
      "step 6960 - loss = 1.897, (1.243 sec/step)\n",
      "step 6961 - loss = 1.916, (0.759 sec/step)\n",
      "step 6962 - loss = 1.505, (1.945 sec/step)\n",
      "step 6963 - loss = 1.990, (1.100 sec/step)\n",
      "step 6964 - loss = 1.618, (1.591 sec/step)\n",
      "step 6965 - loss = 1.514, (1.652 sec/step)\n",
      "step 6966 - loss = 1.759, (1.441 sec/step)\n",
      "step 6967 - loss = 1.556, (1.423 sec/step)\n",
      "step 6968 - loss = 1.338, (1.294 sec/step)\n",
      "step 6969 - loss = 2.246, (1.850 sec/step)\n",
      "step 6970 - loss = 1.968, (1.030 sec/step)\n",
      "step 6971 - loss = 1.599, (1.531 sec/step)\n",
      "step 6972 - loss = 1.560, (0.745 sec/step)\n",
      "step 6973 - loss = 2.398, (2.482 sec/step)\n",
      "step 6974 - loss = 1.806, (0.950 sec/step)\n",
      "step 6975 - loss = 1.979, (0.923 sec/step)\n",
      "step 6976 - loss = 2.089, (1.781 sec/step)\n",
      "step 6977 - loss = 1.409, (1.340 sec/step)\n",
      "step 6978 - loss = 2.000, (1.660 sec/step)\n",
      "step 6979 - loss = 2.139, (1.252 sec/step)\n",
      "step 6980 - loss = 1.915, (1.427 sec/step)\n",
      "step 6981 - loss = 1.588, (1.574 sec/step)\n",
      "step 6982 - loss = 1.213, (2.413 sec/step)\n",
      "step 6983 - loss = 1.332, (2.644 sec/step)\n",
      "step 6984 - loss = 2.107, (2.673 sec/step)\n",
      "step 6985 - loss = 1.731, (1.342 sec/step)\n",
      "step 6986 - loss = 2.030, (1.706 sec/step)\n",
      "step 6987 - loss = 1.490, (2.585 sec/step)\n",
      "step 6988 - loss = 1.875, (1.131 sec/step)\n",
      "step 6989 - loss = 2.098, (0.986 sec/step)\n",
      "step 6990 - loss = 2.131, (2.375 sec/step)\n",
      "step 6991 - loss = 1.791, (2.572 sec/step)\n",
      "step 6992 - loss = 1.664, (1.521 sec/step)\n",
      "step 6993 - loss = 1.430, (1.913 sec/step)\n",
      "step 6994 - loss = 1.915, (1.192 sec/step)\n",
      "step 6995 - loss = 1.987, (1.887 sec/step)\n",
      "step 6996 - loss = 2.731, (1.987 sec/step)\n",
      "step 6997 - loss = 1.871, (1.227 sec/step)\n",
      "step 6998 - loss = 1.944, (1.130 sec/step)\n",
      "step 6999 - loss = 2.049, (1.920 sec/step)\n",
      "step 7000 - loss = 1.174, (2.471 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7001 - loss = 2.405, (1.419 sec/step)\n",
      "step 7002 - loss = 1.737, (1.069 sec/step)\n",
      "step 7003 - loss = 1.325, (2.798 sec/step)\n",
      "step 7004 - loss = 1.908, (1.607 sec/step)\n",
      "step 7005 - loss = 1.487, (1.282 sec/step)\n",
      "step 7006 - loss = 1.882, (0.958 sec/step)\n",
      "step 7007 - loss = 2.039, (1.053 sec/step)\n",
      "step 7008 - loss = 1.832, (0.984 sec/step)\n",
      "step 7009 - loss = 1.283, (1.217 sec/step)\n",
      "step 7010 - loss = 1.832, (1.174 sec/step)\n",
      "step 7011 - loss = 2.113, (1.051 sec/step)\n",
      "step 7012 - loss = 1.977, (1.179 sec/step)\n",
      "step 7013 - loss = 1.607, (2.331 sec/step)\n",
      "step 7014 - loss = 1.384, (1.642 sec/step)\n",
      "step 7015 - loss = 1.847, (2.811 sec/step)\n",
      "step 7016 - loss = 1.809, (0.956 sec/step)\n",
      "step 7017 - loss = 1.804, (1.017 sec/step)\n",
      "step 7018 - loss = 1.812, (2.486 sec/step)\n",
      "step 7019 - loss = 1.429, (1.318 sec/step)\n",
      "step 7020 - loss = 1.925, (2.204 sec/step)\n",
      "step 7021 - loss = 1.066, (1.684 sec/step)\n",
      "step 7022 - loss = 2.160, (1.048 sec/step)\n",
      "step 7023 - loss = 1.602, (0.955 sec/step)\n",
      "step 7024 - loss = 1.946, (2.485 sec/step)\n",
      "step 7025 - loss = 2.641, (2.060 sec/step)\n",
      "step 7026 - loss = 1.313, (1.281 sec/step)\n",
      "step 7027 - loss = 1.553, (2.462 sec/step)\n",
      "step 7028 - loss = 1.648, (1.114 sec/step)\n",
      "step 7029 - loss = 1.811, (3.040 sec/step)\n",
      "step 7030 - loss = 2.124, (1.557 sec/step)\n",
      "step 7031 - loss = 1.885, (1.459 sec/step)\n",
      "step 7032 - loss = 2.013, (1.256 sec/step)\n",
      "step 7033 - loss = 1.716, (1.288 sec/step)\n",
      "step 7034 - loss = 2.337, (2.156 sec/step)\n",
      "step 7035 - loss = 1.695, (3.807 sec/step)\n",
      "step 7036 - loss = 1.902, (1.104 sec/step)\n",
      "step 7037 - loss = 2.004, (0.985 sec/step)\n",
      "step 7038 - loss = 1.830, (2.450 sec/step)\n",
      "step 7039 - loss = 1.486, (3.184 sec/step)\n",
      "step 7040 - loss = 1.840, (1.448 sec/step)\n",
      "step 7041 - loss = 2.052, (0.894 sec/step)\n",
      "step 7042 - loss = 2.039, (1.646 sec/step)\n",
      "step 7043 - loss = 1.840, (1.201 sec/step)\n",
      "step 7044 - loss = 1.758, (2.735 sec/step)\n",
      "step 7045 - loss = 1.849, (1.427 sec/step)\n",
      "step 7046 - loss = 1.490, (1.982 sec/step)\n",
      "step 7047 - loss = 1.322, (1.349 sec/step)\n",
      "step 7048 - loss = 2.077, (1.381 sec/step)\n",
      "step 7049 - loss = 1.689, (3.362 sec/step)\n",
      "step 7050 - loss = 1.495, (1.232 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7051 - loss = 2.082, (1.189 sec/step)\n",
      "step 7052 - loss = 1.689, (1.157 sec/step)\n",
      "step 7053 - loss = 2.024, (1.539 sec/step)\n",
      "step 7054 - loss = 1.724, (2.459 sec/step)\n",
      "step 7055 - loss = 1.849, (1.131 sec/step)\n",
      "step 7056 - loss = 1.317, (1.704 sec/step)\n",
      "step 7057 - loss = 2.162, (1.069 sec/step)\n",
      "step 7058 - loss = 2.412, (1.692 sec/step)\n",
      "step 7059 - loss = 1.737, (1.098 sec/step)\n",
      "step 7060 - loss = 1.568, (1.188 sec/step)\n",
      "step 7061 - loss = 1.712, (0.857 sec/step)\n",
      "step 7062 - loss = 2.052, (2.047 sec/step)\n",
      "step 7063 - loss = 2.088, (1.557 sec/step)\n",
      "step 7064 - loss = 2.613, (1.464 sec/step)\n",
      "step 7065 - loss = 2.150, (1.329 sec/step)\n",
      "step 7066 - loss = 2.132, (3.215 sec/step)\n",
      "step 7067 - loss = 1.815, (1.860 sec/step)\n",
      "step 7068 - loss = 1.716, (1.388 sec/step)\n",
      "step 7069 - loss = 1.845, (1.573 sec/step)\n",
      "step 7070 - loss = 1.673, (3.247 sec/step)\n",
      "step 7071 - loss = 2.054, (1.161 sec/step)\n",
      "step 7072 - loss = 1.233, (3.060 sec/step)\n",
      "step 7073 - loss = 1.100, (1.742 sec/step)\n",
      "step 7074 - loss = 1.836, (1.168 sec/step)\n",
      "step 7075 - loss = 1.772, (1.581 sec/step)\n",
      "step 7076 - loss = 1.510, (1.158 sec/step)\n",
      "step 7077 - loss = 1.936, (1.093 sec/step)\n",
      "step 7078 - loss = 1.424, (1.867 sec/step)\n",
      "step 7079 - loss = 2.321, (2.482 sec/step)\n",
      "step 7080 - loss = 2.094, (2.038 sec/step)\n",
      "step 7081 - loss = 2.341, (1.314 sec/step)\n",
      "step 7082 - loss = 2.062, (1.259 sec/step)\n",
      "step 7083 - loss = 1.837, (1.178 sec/step)\n",
      "step 7084 - loss = 2.141, (1.395 sec/step)\n",
      "step 7085 - loss = 2.069, (2.310 sec/step)\n",
      "step 7086 - loss = 1.928, (1.399 sec/step)\n",
      "step 7087 - loss = 1.924, (2.494 sec/step)\n",
      "step 7088 - loss = 1.974, (1.732 sec/step)\n",
      "step 7089 - loss = 2.258, (1.345 sec/step)\n",
      "step 7090 - loss = 1.470, (1.151 sec/step)\n",
      "step 7091 - loss = 2.251, (1.608 sec/step)\n",
      "step 7092 - loss = 1.703, (1.084 sec/step)\n",
      "step 7093 - loss = 1.862, (1.045 sec/step)\n",
      "step 7094 - loss = 1.984, (2.121 sec/step)\n",
      "step 7095 - loss = 1.668, (2.709 sec/step)\n",
      "step 7096 - loss = 2.070, (1.590 sec/step)\n",
      "step 7097 - loss = 2.252, (1.081 sec/step)\n",
      "step 7098 - loss = 1.943, (1.195 sec/step)\n",
      "step 7099 - loss = 2.157, (1.924 sec/step)\n",
      "step 7100 - loss = 1.351, (2.122 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7101 - loss = 2.048, (2.486 sec/step)\n",
      "step 7102 - loss = 1.344, (2.155 sec/step)\n",
      "step 7103 - loss = 1.631, (1.178 sec/step)\n",
      "step 7104 - loss = 2.009, (2.575 sec/step)\n",
      "step 7105 - loss = 2.252, (1.777 sec/step)\n",
      "step 7106 - loss = 2.755, (2.484 sec/step)\n",
      "step 7107 - loss = 2.814, (2.044 sec/step)\n",
      "step 7108 - loss = 1.405, (1.315 sec/step)\n",
      "step 7109 - loss = 1.681, (2.414 sec/step)\n",
      "step 7110 - loss = 1.486, (0.857 sec/step)\n",
      "step 7111 - loss = 1.734, (1.086 sec/step)\n",
      "step 7112 - loss = 1.458, (1.258 sec/step)\n",
      "step 7113 - loss = 2.255, (1.188 sec/step)\n",
      "step 7114 - loss = 1.573, (1.382 sec/step)\n",
      "step 7115 - loss = 2.316, (2.346 sec/step)\n",
      "step 7116 - loss = 1.767, (1.112 sec/step)\n",
      "step 7117 - loss = 1.832, (1.760 sec/step)\n",
      "step 7118 - loss = 1.918, (1.295 sec/step)\n",
      "step 7119 - loss = 1.518, (1.117 sec/step)\n",
      "step 7120 - loss = 1.768, (0.744 sec/step)\n",
      "step 7121 - loss = 2.286, (2.486 sec/step)\n",
      "step 7122 - loss = 2.028, (1.412 sec/step)\n",
      "step 7123 - loss = 1.212, (1.212 sec/step)\n",
      "step 7124 - loss = 1.362, (1.584 sec/step)\n",
      "step 7125 - loss = 2.205, (1.391 sec/step)\n",
      "step 7126 - loss = 1.903, (1.370 sec/step)\n",
      "step 7127 - loss = 2.223, (1.183 sec/step)\n",
      "step 7128 - loss = 1.245, (1.453 sec/step)\n",
      "step 7129 - loss = 1.562, (1.677 sec/step)\n",
      "step 7130 - loss = 1.322, (1.177 sec/step)\n",
      "step 7131 - loss = 1.718, (2.074 sec/step)\n",
      "step 7132 - loss = 2.037, (1.252 sec/step)\n",
      "step 7133 - loss = 1.554, (1.594 sec/step)\n",
      "step 7134 - loss = 1.756, (0.987 sec/step)\n",
      "step 7135 - loss = 1.847, (1.661 sec/step)\n",
      "step 7136 - loss = 2.329, (1.427 sec/step)\n",
      "step 7137 - loss = 1.734, (1.703 sec/step)\n",
      "step 7138 - loss = 1.858, (1.477 sec/step)\n",
      "step 7139 - loss = 1.701, (1.655 sec/step)\n",
      "step 7140 - loss = 2.138, (2.361 sec/step)\n",
      "step 7141 - loss = 1.418, (1.661 sec/step)\n",
      "step 7142 - loss = 1.742, (1.015 sec/step)\n",
      "step 7143 - loss = 1.911, (1.300 sec/step)\n",
      "step 7144 - loss = 1.424, (0.923 sec/step)\n",
      "step 7145 - loss = 2.396, (1.248 sec/step)\n",
      "step 7146 - loss = 2.137, (2.893 sec/step)\n",
      "step 7147 - loss = 1.520, (1.763 sec/step)\n",
      "step 7148 - loss = 2.098, (1.099 sec/step)\n",
      "step 7149 - loss = 2.267, (1.446 sec/step)\n",
      "step 7150 - loss = 1.998, (1.159 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7151 - loss = 1.763, (1.093 sec/step)\n",
      "step 7152 - loss = 1.381, (0.857 sec/step)\n",
      "step 7153 - loss = 1.806, (1.033 sec/step)\n",
      "step 7154 - loss = 1.853, (2.486 sec/step)\n",
      "step 7155 - loss = 2.188, (2.697 sec/step)\n",
      "step 7156 - loss = 1.989, (1.479 sec/step)\n",
      "step 7157 - loss = 2.018, (1.164 sec/step)\n",
      "step 7158 - loss = 1.633, (1.296 sec/step)\n",
      "step 7159 - loss = 1.428, (1.459 sec/step)\n",
      "step 7160 - loss = 1.477, (1.219 sec/step)\n",
      "step 7161 - loss = 1.297, (1.502 sec/step)\n",
      "step 7162 - loss = 2.009, (1.159 sec/step)\n",
      "step 7163 - loss = 1.855, (1.560 sec/step)\n",
      "step 7164 - loss = 2.043, (1.461 sec/step)\n",
      "step 7165 - loss = 2.218, (2.320 sec/step)\n",
      "step 7166 - loss = 1.702, (1.801 sec/step)\n",
      "step 7167 - loss = 1.878, (1.544 sec/step)\n",
      "step 7168 - loss = 1.742, (1.556 sec/step)\n",
      "step 7169 - loss = 2.214, (1.147 sec/step)\n",
      "step 7170 - loss = 1.901, (2.670 sec/step)\n",
      "step 7171 - loss = 1.487, (1.160 sec/step)\n",
      "step 7172 - loss = 1.583, (1.001 sec/step)\n",
      "step 7173 - loss = 1.455, (0.986 sec/step)\n",
      "step 7174 - loss = 1.712, (1.479 sec/step)\n",
      "step 7175 - loss = 1.593, (1.912 sec/step)\n",
      "step 7176 - loss = 2.060, (1.034 sec/step)\n",
      "step 7177 - loss = 1.645, (1.306 sec/step)\n",
      "step 7178 - loss = 2.247, (1.699 sec/step)\n",
      "step 7179 - loss = 1.790, (2.157 sec/step)\n",
      "step 7180 - loss = 1.606, (0.906 sec/step)\n",
      "step 7181 - loss = 1.441, (1.712 sec/step)\n",
      "step 7182 - loss = 1.805, (1.357 sec/step)\n",
      "step 7183 - loss = 1.990, (0.774 sec/step)\n",
      "step 7184 - loss = 1.839, (1.746 sec/step)\n",
      "step 7185 - loss = 1.793, (1.344 sec/step)\n",
      "step 7186 - loss = 2.298, (2.485 sec/step)\n",
      "step 7187 - loss = 1.584, (2.067 sec/step)\n",
      "step 7188 - loss = 0.987, (1.685 sec/step)\n",
      "step 7189 - loss = 1.837, (1.344 sec/step)\n",
      "step 7190 - loss = 1.996, (1.908 sec/step)\n",
      "step 7191 - loss = 1.672, (1.976 sec/step)\n",
      "step 7192 - loss = 2.058, (1.574 sec/step)\n",
      "step 7193 - loss = 2.272, (1.403 sec/step)\n",
      "step 7194 - loss = 2.295, (2.029 sec/step)\n",
      "step 7195 - loss = 1.692, (1.494 sec/step)\n",
      "step 7196 - loss = 1.613, (1.150 sec/step)\n",
      "step 7197 - loss = 1.763, (1.463 sec/step)\n",
      "step 7198 - loss = 1.255, (1.132 sec/step)\n",
      "step 7199 - loss = 1.782, (0.975 sec/step)\n",
      "step 7200 - loss = 1.685, (0.826 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7201 - loss = 1.550, (1.495 sec/step)\n",
      "step 7202 - loss = 1.371, (1.151 sec/step)\n",
      "step 7203 - loss = 1.520, (1.540 sec/step)\n",
      "step 7204 - loss = 1.213, (2.439 sec/step)\n",
      "step 7205 - loss = 1.610, (1.425 sec/step)\n",
      "step 7206 - loss = 1.736, (2.984 sec/step)\n",
      "step 7207 - loss = 1.729, (1.322 sec/step)\n",
      "step 7208 - loss = 1.983, (1.749 sec/step)\n",
      "step 7209 - loss = 1.708, (0.896 sec/step)\n",
      "step 7210 - loss = 1.895, (2.089 sec/step)\n",
      "step 7211 - loss = 2.073, (1.409 sec/step)\n",
      "step 7212 - loss = 1.319, (2.256 sec/step)\n",
      "step 7213 - loss = 1.421, (1.243 sec/step)\n",
      "step 7214 - loss = 1.611, (0.632 sec/step)\n",
      "step 7215 - loss = 1.595, (2.281 sec/step)\n",
      "step 7216 - loss = 2.366, (2.487 sec/step)\n",
      "step 7217 - loss = 2.098, (2.598 sec/step)\n",
      "step 7218 - loss = 1.377, (1.626 sec/step)\n",
      "step 7219 - loss = 2.178, (1.681 sec/step)\n",
      "step 7220 - loss = 1.831, (1.606 sec/step)\n",
      "step 7221 - loss = 0.961, (2.851 sec/step)\n",
      "step 7222 - loss = 2.146, (1.376 sec/step)\n",
      "step 7223 - loss = 2.073, (1.181 sec/step)\n",
      "step 7224 - loss = 1.632, (1.363 sec/step)\n",
      "step 7225 - loss = 1.776, (1.365 sec/step)\n",
      "step 7226 - loss = 1.360, (1.398 sec/step)\n",
      "step 7227 - loss = 1.537, (1.179 sec/step)\n",
      "step 7228 - loss = 1.472, (1.273 sec/step)\n",
      "step 7229 - loss = 2.279, (2.651 sec/step)\n",
      "step 7230 - loss = 2.023, (1.459 sec/step)\n",
      "step 7231 - loss = 1.837, (1.209 sec/step)\n",
      "step 7232 - loss = 1.328, (0.938 sec/step)\n",
      "step 7233 - loss = 1.853, (2.950 sec/step)\n",
      "step 7234 - loss = 2.092, (1.869 sec/step)\n",
      "step 7235 - loss = 0.956, (1.712 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7236 - loss = 2.015, (1.125 sec/step)\n",
      "step 7237 - loss = 2.057, (2.483 sec/step)\n",
      "step 7238 - loss = 1.021, (1.229 sec/step)\n",
      "step 7239 - loss = 1.843, (1.455 sec/step)\n",
      "step 7240 - loss = 2.377, (2.030 sec/step)\n",
      "step 7241 - loss = 1.757, (1.637 sec/step)\n",
      "step 7242 - loss = 1.813, (1.921 sec/step)\n",
      "step 7243 - loss = 1.993, (1.230 sec/step)\n",
      "step 7244 - loss = 2.215, (1.087 sec/step)\n",
      "step 7245 - loss = 1.566, (1.475 sec/step)\n",
      "step 7246 - loss = 1.540, (1.066 sec/step)\n",
      "step 7247 - loss = 1.869, (1.568 sec/step)\n",
      "step 7248 - loss = 1.873, (1.337 sec/step)\n",
      "step 7249 - loss = 1.691, (0.868 sec/step)\n",
      "step 7250 - loss = 1.662, (0.823 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7251 - loss = 1.332, (0.725 sec/step)\n",
      "step 7252 - loss = 2.109, (1.032 sec/step)\n",
      "step 7253 - loss = 1.830, (1.345 sec/step)\n",
      "step 7254 - loss = 1.999, (2.276 sec/step)\n",
      "step 7255 - loss = 1.625, (1.025 sec/step)\n",
      "step 7256 - loss = 1.841, (2.416 sec/step)\n",
      "step 7257 - loss = 2.370, (1.541 sec/step)\n",
      "step 7258 - loss = 1.783, (0.988 sec/step)\n",
      "step 7259 - loss = 2.207, (1.258 sec/step)\n",
      "step 7260 - loss = 1.430, (1.227 sec/step)\n",
      "step 7261 - loss = 1.775, (1.102 sec/step)\n",
      "step 7262 - loss = 1.228, (1.311 sec/step)\n",
      "step 7263 - loss = 1.851, (1.277 sec/step)\n",
      "step 7264 - loss = 1.351, (2.486 sec/step)\n",
      "step 7265 - loss = 0.576, (1.901 sec/step)\n",
      "step 7266 - loss = 1.698, (1.327 sec/step)\n",
      "step 7267 - loss = 1.553, (1.644 sec/step)\n",
      "step 7268 - loss = 1.778, (1.953 sec/step)\n",
      "step 7269 - loss = 1.409, (1.232 sec/step)\n",
      "step 7270 - loss = 2.183, (1.149 sec/step)\n",
      "step 7271 - loss = 1.484, (1.276 sec/step)\n",
      "step 7272 - loss = 1.913, (3.248 sec/step)\n",
      "step 7273 - loss = 1.854, (1.955 sec/step)\n",
      "step 7274 - loss = 1.786, (1.101 sec/step)\n",
      "step 7275 - loss = 1.992, (1.126 sec/step)\n",
      "step 7276 - loss = 2.038, (0.910 sec/step)\n",
      "step 7277 - loss = 2.051, (1.174 sec/step)\n",
      "step 7278 - loss = 1.667, (2.322 sec/step)\n",
      "step 7279 - loss = 2.261, (2.199 sec/step)\n",
      "step 7280 - loss = 2.235, (2.343 sec/step)\n",
      "step 7281 - loss = 2.313, (3.304 sec/step)\n",
      "step 7282 - loss = 1.307, (3.177 sec/step)\n",
      "step 7283 - loss = 1.640, (0.953 sec/step)\n",
      "step 7284 - loss = 2.331, (1.704 sec/step)\n",
      "step 7285 - loss = 2.073, (2.653 sec/step)\n",
      "step 7286 - loss = 1.835, (1.494 sec/step)\n",
      "step 7287 - loss = 1.612, (1.314 sec/step)\n",
      "step 7288 - loss = 1.865, (1.407 sec/step)\n",
      "step 7289 - loss = 1.714, (2.487 sec/step)\n",
      "step 7290 - loss = 1.835, (1.051 sec/step)\n",
      "step 7291 - loss = 1.325, (2.104 sec/step)\n",
      "step 7292 - loss = 2.306, (1.086 sec/step)\n",
      "step 7293 - loss = 2.251, (1.223 sec/step)\n",
      "step 7294 - loss = 1.591, (2.051 sec/step)\n",
      "step 7295 - loss = 2.845, (2.484 sec/step)\n",
      "step 7296 - loss = 2.378, (1.677 sec/step)\n",
      "step 7297 - loss = 1.676, (0.987 sec/step)\n",
      "step 7298 - loss = 2.321, (1.648 sec/step)\n",
      "step 7299 - loss = 1.810, (1.158 sec/step)\n",
      "step 7300 - loss = 1.631, (1.888 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7301 - loss = 1.872, (1.211 sec/step)\n",
      "step 7302 - loss = 1.735, (0.912 sec/step)\n",
      "step 7303 - loss = 1.711, (1.821 sec/step)\n",
      "step 7304 - loss = 1.679, (1.562 sec/step)\n",
      "step 7305 - loss = 1.608, (0.841 sec/step)\n",
      "step 7306 - loss = 1.772, (3.003 sec/step)\n",
      "step 7307 - loss = 1.775, (1.380 sec/step)\n",
      "step 7308 - loss = 1.878, (1.112 sec/step)\n",
      "step 7309 - loss = 1.571, (1.538 sec/step)\n",
      "step 7310 - loss = 1.547, (1.374 sec/step)\n",
      "step 7311 - loss = 1.511, (1.130 sec/step)\n",
      "step 7312 - loss = 1.411, (1.736 sec/step)\n",
      "step 7313 - loss = 1.638, (0.924 sec/step)\n",
      "step 7314 - loss = 1.670, (1.132 sec/step)\n",
      "step 7315 - loss = 1.807, (1.445 sec/step)\n",
      "step 7316 - loss = 2.044, (1.285 sec/step)\n",
      "step 7317 - loss = 1.815, (1.128 sec/step)\n",
      "step 7318 - loss = 1.866, (1.537 sec/step)\n",
      "step 7319 - loss = 1.875, (1.635 sec/step)\n",
      "step 7320 - loss = 2.185, (1.346 sec/step)\n",
      "step 7321 - loss = 1.662, (1.976 sec/step)\n",
      "step 7322 - loss = 1.668, (1.561 sec/step)\n",
      "step 7323 - loss = 1.343, (2.743 sec/step)\n",
      "step 7324 - loss = 2.566, (1.590 sec/step)\n",
      "step 7325 - loss = 1.942, (1.892 sec/step)\n",
      "step 7326 - loss = 2.334, (2.006 sec/step)\n",
      "step 7327 - loss = 1.818, (0.981 sec/step)\n",
      "step 7328 - loss = 1.688, (1.102 sec/step)\n",
      "step 7329 - loss = 1.897, (0.989 sec/step)\n",
      "step 7330 - loss = 1.874, (1.147 sec/step)\n",
      "step 7331 - loss = 2.348, (1.154 sec/step)\n",
      "step 7332 - loss = 1.943, (1.146 sec/step)\n",
      "step 7333 - loss = 1.571, (1.623 sec/step)\n",
      "step 7334 - loss = 1.738, (2.486 sec/step)\n",
      "step 7335 - loss = 0.834, (1.330 sec/step)\n",
      "step 7336 - loss = 1.660, (1.467 sec/step)\n",
      "step 7337 - loss = 1.831, (1.404 sec/step)\n",
      "step 7338 - loss = 1.923, (1.905 sec/step)\n",
      "step 7339 - loss = 1.540, (1.022 sec/step)\n",
      "step 7340 - loss = 2.142, (1.590 sec/step)\n",
      "step 7341 - loss = 2.057, (1.175 sec/step)\n",
      "step 7342 - loss = 2.073, (2.260 sec/step)\n",
      "step 7343 - loss = 2.553, (1.260 sec/step)\n",
      "step 7344 - loss = 1.193, (2.484 sec/step)\n",
      "step 7345 - loss = 0.645, (1.285 sec/step)\n",
      "step 7346 - loss = 1.781, (1.249 sec/step)\n",
      "step 7347 - loss = 2.228, (2.486 sec/step)\n",
      "step 7348 - loss = 1.860, (2.665 sec/step)\n",
      "step 7349 - loss = 2.154, (1.899 sec/step)\n",
      "step 7350 - loss = 1.741, (1.331 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7351 - loss = 1.251, (1.628 sec/step)\n",
      "step 7352 - loss = 2.342, (2.486 sec/step)\n",
      "step 7353 - loss = 1.517, (3.686 sec/step)\n",
      "step 7354 - loss = 1.895, (1.528 sec/step)\n",
      "step 7355 - loss = 1.812, (1.331 sec/step)\n",
      "step 7356 - loss = 1.837, (1.383 sec/step)\n",
      "step 7357 - loss = 1.852, (1.158 sec/step)\n",
      "step 7358 - loss = 2.135, (1.846 sec/step)\n",
      "step 7359 - loss = 1.929, (3.227 sec/step)\n",
      "step 7360 - loss = 2.322, (1.122 sec/step)\n",
      "step 7361 - loss = 1.792, (1.123 sec/step)\n",
      "step 7362 - loss = 1.758, (1.242 sec/step)\n",
      "step 7363 - loss = 1.552, (1.150 sec/step)\n",
      "step 7364 - loss = 2.668, (1.281 sec/step)\n",
      "step 7365 - loss = 2.356, (1.343 sec/step)\n",
      "step 7366 - loss = 1.831, (2.014 sec/step)\n",
      "step 7367 - loss = 2.015, (1.704 sec/step)\n",
      "step 7368 - loss = 1.894, (2.422 sec/step)\n",
      "step 7369 - loss = 2.067, (1.047 sec/step)\n",
      "step 7370 - loss = 2.291, (2.487 sec/step)\n",
      "step 7371 - loss = 2.680, (1.971 sec/step)\n",
      "step 7372 - loss = 1.332, (2.512 sec/step)\n",
      "step 7373 - loss = 1.336, (1.439 sec/step)\n",
      "step 7374 - loss = 2.025, (1.551 sec/step)\n",
      "step 7375 - loss = 1.725, (1.052 sec/step)\n",
      "step 7376 - loss = 1.560, (1.380 sec/step)\n",
      "step 7377 - loss = 2.233, (2.051 sec/step)\n",
      "step 7378 - loss = 1.764, (1.683 sec/step)\n",
      "step 7379 - loss = 1.874, (2.738 sec/step)\n",
      "step 7380 - loss = 2.220, (1.798 sec/step)\n",
      "step 7381 - loss = 1.771, (1.149 sec/step)\n",
      "step 7382 - loss = 1.523, (1.211 sec/step)\n",
      "step 7383 - loss = 1.586, (1.891 sec/step)\n",
      "step 7384 - loss = 1.939, (1.158 sec/step)\n",
      "step 7385 - loss = 1.905, (1.556 sec/step)\n",
      "step 7386 - loss = 1.648, (2.667 sec/step)\n",
      "step 7387 - loss = 1.745, (1.245 sec/step)\n",
      "step 7388 - loss = 1.709, (1.160 sec/step)\n",
      "step 7389 - loss = 1.996, (1.410 sec/step)\n",
      "step 7390 - loss = 2.203, (1.555 sec/step)\n",
      "step 7391 - loss = 1.719, (1.149 sec/step)\n",
      "step 7392 - loss = 1.909, (1.258 sec/step)\n",
      "step 7393 - loss = 2.397, (1.561 sec/step)\n",
      "step 7394 - loss = 1.468, (2.135 sec/step)\n",
      "step 7395 - loss = 2.287, (1.388 sec/step)\n",
      "step 7396 - loss = 1.610, (1.410 sec/step)\n",
      "step 7397 - loss = 1.865, (1.117 sec/step)\n",
      "step 7398 - loss = 1.579, (1.527 sec/step)\n",
      "step 7399 - loss = 1.718, (1.728 sec/step)\n",
      "step 7400 - loss = 1.474, (0.938 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7401 - loss = 1.550, (1.656 sec/step)\n",
      "step 7402 - loss = 1.724, (1.727 sec/step)\n",
      "step 7403 - loss = 1.570, (1.098 sec/step)\n",
      "step 7404 - loss = 2.294, (1.387 sec/step)\n",
      "step 7405 - loss = 1.495, (2.415 sec/step)\n",
      "step 7406 - loss = 2.043, (2.461 sec/step)\n",
      "step 7407 - loss = 1.333, (0.986 sec/step)\n",
      "step 7408 - loss = 1.521, (0.857 sec/step)\n",
      "step 7409 - loss = 1.371, (2.682 sec/step)\n",
      "step 7410 - loss = 2.164, (1.245 sec/step)\n",
      "step 7411 - loss = 1.835, (1.345 sec/step)\n",
      "step 7412 - loss = 1.774, (1.862 sec/step)\n",
      "step 7413 - loss = 1.494, (2.209 sec/step)\n",
      "step 7414 - loss = 2.258, (1.803 sec/step)\n",
      "step 7415 - loss = 1.827, (1.278 sec/step)\n",
      "step 7416 - loss = 2.112, (1.473 sec/step)\n",
      "step 7417 - loss = 1.912, (1.822 sec/step)\n",
      "step 7418 - loss = 1.676, (1.310 sec/step)\n",
      "step 7419 - loss = 1.454, (0.991 sec/step)\n",
      "step 7420 - loss = 2.002, (0.984 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7421 - loss = 2.117, (1.781 sec/step)\n",
      "step 7422 - loss = 2.281, (2.487 sec/step)\n",
      "step 7423 - loss = 2.086, (1.740 sec/step)\n",
      "step 7424 - loss = 1.483, (1.645 sec/step)\n",
      "step 7425 - loss = 1.515, (1.031 sec/step)\n",
      "step 7426 - loss = 2.168, (0.991 sec/step)\n",
      "step 7427 - loss = 1.735, (1.756 sec/step)\n",
      "step 7428 - loss = 1.634, (1.151 sec/step)\n",
      "step 7429 - loss = 1.887, (1.113 sec/step)\n",
      "step 7430 - loss = 1.531, (1.552 sec/step)\n",
      "step 7431 - loss = 1.578, (2.649 sec/step)\n",
      "step 7432 - loss = 2.101, (1.245 sec/step)\n",
      "step 7433 - loss = 1.740, (1.157 sec/step)\n",
      "step 7434 - loss = 1.545, (2.485 sec/step)\n",
      "step 7435 - loss = 0.510, (2.093 sec/step)\n",
      "step 7436 - loss = 1.727, (2.318 sec/step)\n",
      "step 7437 - loss = 2.121, (0.939 sec/step)\n",
      "step 7438 - loss = 1.642, (1.213 sec/step)\n",
      "step 7439 - loss = 1.548, (2.485 sec/step)\n",
      "step 7440 - loss = 0.505, (0.564 sec/step)\n",
      "step 7441 - loss = 1.920, (0.857 sec/step)\n",
      "step 7442 - loss = 1.347, (1.657 sec/step)\n",
      "step 7443 - loss = 1.618, (1.070 sec/step)\n",
      "step 7444 - loss = 1.917, (2.032 sec/step)\n",
      "step 7445 - loss = 2.010, (1.684 sec/step)\n",
      "step 7446 - loss = 1.897, (1.684 sec/step)\n",
      "step 7447 - loss = 1.639, (2.360 sec/step)\n",
      "step 7448 - loss = 1.875, (2.379 sec/step)\n",
      "step 7449 - loss = 2.233, (1.874 sec/step)\n",
      "step 7450 - loss = 1.957, (1.270 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7451 - loss = 1.546, (1.378 sec/step)\n",
      "step 7452 - loss = 1.632, (1.920 sec/step)\n",
      "step 7453 - loss = 2.193, (1.511 sec/step)\n",
      "step 7454 - loss = 1.432, (0.927 sec/step)\n",
      "step 7455 - loss = 1.295, (2.757 sec/step)\n",
      "step 7456 - loss = 1.968, (0.954 sec/step)\n",
      "step 7457 - loss = 1.621, (1.275 sec/step)\n",
      "step 7458 - loss = 1.521, (1.608 sec/step)\n",
      "step 7459 - loss = 1.948, (1.964 sec/step)\n",
      "step 7460 - loss = 1.821, (1.174 sec/step)\n",
      "step 7461 - loss = 1.436, (1.884 sec/step)\n",
      "step 7462 - loss = 2.017, (1.621 sec/step)\n",
      "step 7463 - loss = 1.807, (1.292 sec/step)\n",
      "step 7464 - loss = 1.709, (1.074 sec/step)\n",
      "step 7465 - loss = 2.220, (1.786 sec/step)\n",
      "step 7466 - loss = 1.873, (2.567 sec/step)\n",
      "step 7467 - loss = 1.559, (1.230 sec/step)\n",
      "step 7468 - loss = 1.600, (1.580 sec/step)\n",
      "step 7469 - loss = 1.515, (1.093 sec/step)\n",
      "step 7470 - loss = 1.721, (1.331 sec/step)\n",
      "step 7471 - loss = 1.714, (1.098 sec/step)\n",
      "step 7472 - loss = 1.730, (1.906 sec/step)\n",
      "step 7473 - loss = 1.705, (1.371 sec/step)\n",
      "step 7474 - loss = 1.676, (1.279 sec/step)\n",
      "step 7475 - loss = 1.487, (0.787 sec/step)\n",
      "step 7476 - loss = 2.118, (0.956 sec/step)\n",
      "step 7477 - loss = 1.391, (2.037 sec/step)\n",
      "step 7478 - loss = 2.142, (1.160 sec/step)\n",
      "step 7479 - loss = 1.988, (1.759 sec/step)\n",
      "step 7480 - loss = 1.691, (1.662 sec/step)\n",
      "step 7481 - loss = 1.589, (1.015 sec/step)\n",
      "step 7482 - loss = 2.113, (2.397 sec/step)\n",
      "step 7483 - loss = 2.011, (1.337 sec/step)\n",
      "step 7484 - loss = 1.972, (1.216 sec/step)\n",
      "step 7485 - loss = 1.947, (0.988 sec/step)\n",
      "step 7486 - loss = 1.689, (1.349 sec/step)\n",
      "step 7487 - loss = 2.367, (2.485 sec/step)\n",
      "step 7488 - loss = 1.738, (2.333 sec/step)\n",
      "step 7489 - loss = 1.966, (0.794 sec/step)\n",
      "step 7490 - loss = 1.246, (1.462 sec/step)\n",
      "step 7491 - loss = 1.705, (1.125 sec/step)\n",
      "step 7492 - loss = 1.871, (1.480 sec/step)\n",
      "step 7493 - loss = 1.491, (1.253 sec/step)\n",
      "step 7494 - loss = 1.780, (2.597 sec/step)\n",
      "step 7495 - loss = 1.826, (1.528 sec/step)\n",
      "step 7496 - loss = 2.278, (1.732 sec/step)\n",
      "step 7497 - loss = 1.698, (1.850 sec/step)\n",
      "step 7498 - loss = 2.524, (0.956 sec/step)\n",
      "step 7499 - loss = 1.463, (1.165 sec/step)\n",
      "step 7500 - loss = 1.638, (1.514 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7501 - loss = 2.267, (0.958 sec/step)\n",
      "step 7502 - loss = 1.976, (1.744 sec/step)\n",
      "step 7503 - loss = 2.072, (1.068 sec/step)\n",
      "step 7504 - loss = 1.930, (2.669 sec/step)\n",
      "step 7505 - loss = 1.771, (2.061 sec/step)\n",
      "step 7506 - loss = 1.565, (1.839 sec/step)\n",
      "step 7507 - loss = 2.150, (2.737 sec/step)\n",
      "step 7508 - loss = 2.064, (1.497 sec/step)\n",
      "step 7509 - loss = 1.764, (1.963 sec/step)\n",
      "step 7510 - loss = 1.455, (1.246 sec/step)\n",
      "step 7511 - loss = 2.029, (1.163 sec/step)\n",
      "step 7512 - loss = 1.792, (2.634 sec/step)\n",
      "step 7513 - loss = 1.454, (1.738 sec/step)\n",
      "step 7514 - loss = 1.855, (1.431 sec/step)\n",
      "step 7515 - loss = 1.769, (1.953 sec/step)\n",
      "step 7516 - loss = 2.122, (1.424 sec/step)\n",
      "step 7517 - loss = 1.753, (2.751 sec/step)\n",
      "step 7518 - loss = 1.869, (1.494 sec/step)\n",
      "step 7519 - loss = 1.572, (1.000 sec/step)\n",
      "step 7520 - loss = 1.530, (1.083 sec/step)\n",
      "step 7521 - loss = 1.765, (1.311 sec/step)\n",
      "step 7522 - loss = 1.756, (1.163 sec/step)\n",
      "step 7523 - loss = 2.210, (1.497 sec/step)\n",
      "step 7524 - loss = 1.505, (1.147 sec/step)\n",
      "step 7525 - loss = 1.769, (1.817 sec/step)\n",
      "step 7526 - loss = 1.621, (1.553 sec/step)\n",
      "step 7527 - loss = 2.061, (1.199 sec/step)\n",
      "step 7528 - loss = 1.972, (0.985 sec/step)\n",
      "step 7529 - loss = 2.027, (1.445 sec/step)\n",
      "step 7530 - loss = 1.909, (1.426 sec/step)\n",
      "step 7531 - loss = 1.618, (1.424 sec/step)\n",
      "step 7532 - loss = 1.305, (2.040 sec/step)\n",
      "step 7533 - loss = 1.604, (2.377 sec/step)\n",
      "step 7534 - loss = 2.744, (1.897 sec/step)\n",
      "step 7535 - loss = 2.197, (1.154 sec/step)\n",
      "step 7536 - loss = 1.908, (2.278 sec/step)\n",
      "step 7537 - loss = 2.014, (2.333 sec/step)\n",
      "step 7538 - loss = 1.413, (1.872 sec/step)\n",
      "step 7539 - loss = 1.798, (2.159 sec/step)\n",
      "step 7540 - loss = 1.771, (1.158 sec/step)\n",
      "step 7541 - loss = 2.026, (1.291 sec/step)\n",
      "step 7542 - loss = 1.607, (0.889 sec/step)\n",
      "step 7543 - loss = 1.425, (1.491 sec/step)\n",
      "step 7544 - loss = 1.821, (1.728 sec/step)\n",
      "step 7545 - loss = 2.326, (1.099 sec/step)\n",
      "step 7546 - loss = 1.761, (1.082 sec/step)\n",
      "step 7547 - loss = 2.148, (1.635 sec/step)\n",
      "step 7548 - loss = 1.998, (1.106 sec/step)\n",
      "step 7549 - loss = 2.001, (1.310 sec/step)\n",
      "step 7550 - loss = 1.531, (1.147 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7551 - loss = 1.853, (1.806 sec/step)\n",
      "step 7552 - loss = 1.802, (1.375 sec/step)\n",
      "step 7553 - loss = 1.669, (1.560 sec/step)\n",
      "step 7554 - loss = 2.131, (1.897 sec/step)\n",
      "step 7555 - loss = 1.900, (2.514 sec/step)\n",
      "step 7556 - loss = 1.885, (2.402 sec/step)\n",
      "step 7557 - loss = 2.238, (2.087 sec/step)\n",
      "step 7558 - loss = 2.312, (1.380 sec/step)\n",
      "step 7559 - loss = 2.313, (0.999 sec/step)\n",
      "step 7560 - loss = 2.458, (1.089 sec/step)\n",
      "step 7561 - loss = 1.488, (1.113 sec/step)\n",
      "step 7562 - loss = 1.379, (1.129 sec/step)\n",
      "step 7563 - loss = 2.198, (2.486 sec/step)\n",
      "step 7564 - loss = 0.583, (1.415 sec/step)\n",
      "step 7565 - loss = 2.039, (1.559 sec/step)\n",
      "step 7566 - loss = 1.508, (1.333 sec/step)\n",
      "step 7567 - loss = 1.255, (1.227 sec/step)\n",
      "step 7568 - loss = 1.391, (1.276 sec/step)\n",
      "step 7569 - loss = 1.501, (2.378 sec/step)\n",
      "step 7570 - loss = 2.105, (1.699 sec/step)\n",
      "step 7571 - loss = 1.416, (0.873 sec/step)\n",
      "step 7572 - loss = 1.963, (1.602 sec/step)\n",
      "step 7573 - loss = 2.356, (1.004 sec/step)\n",
      "step 7574 - loss = 1.813, (1.064 sec/step)\n",
      "step 7575 - loss = 2.315, (1.478 sec/step)\n",
      "step 7576 - loss = 1.485, (1.495 sec/step)\n",
      "step 7577 - loss = 2.011, (2.165 sec/step)\n",
      "step 7578 - loss = 2.230, (1.440 sec/step)\n",
      "step 7579 - loss = 1.556, (1.314 sec/step)\n",
      "step 7580 - loss = 2.186, (1.650 sec/step)\n",
      "step 7581 - loss = 1.602, (1.095 sec/step)\n",
      "step 7582 - loss = 2.383, (2.486 sec/step)\n",
      "step 7583 - loss = 1.701, (0.651 sec/step)\n",
      "step 7584 - loss = 1.435, (1.336 sec/step)\n",
      "step 7585 - loss = 2.422, (2.485 sec/step)\n",
      "step 7586 - loss = 2.253, (2.486 sec/step)\n",
      "step 7587 - loss = 1.106, (1.172 sec/step)\n",
      "step 7588 - loss = 2.170, (1.659 sec/step)\n",
      "step 7589 - loss = 1.400, (1.731 sec/step)\n",
      "step 7590 - loss = 1.522, (1.209 sec/step)\n",
      "step 7591 - loss = 1.881, (2.182 sec/step)\n",
      "step 7592 - loss = 1.586, (1.311 sec/step)\n",
      "step 7593 - loss = 1.487, (2.465 sec/step)\n",
      "step 7594 - loss = 1.691, (1.110 sec/step)\n",
      "step 7595 - loss = 2.256, (2.486 sec/step)\n",
      "step 7596 - loss = 0.494, (0.455 sec/step)\n",
      "step 7597 - loss = 2.045, (1.280 sec/step)\n",
      "step 7598 - loss = 1.519, (1.011 sec/step)\n",
      "step 7599 - loss = 1.198, (1.256 sec/step)\n",
      "step 7600 - loss = 2.072, (1.032 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7601 - loss = 1.268, (1.180 sec/step)\n",
      "step 7602 - loss = 2.439, (1.709 sec/step)\n",
      "step 7603 - loss = 2.304, (2.483 sec/step)\n",
      "step 7604 - loss = 2.140, (1.714 sec/step)\n",
      "step 7605 - loss = 1.882, (1.228 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7606 - loss = 1.542, (1.229 sec/step)\n",
      "step 7607 - loss = 1.419, (0.984 sec/step)\n",
      "step 7608 - loss = 2.574, (1.644 sec/step)\n",
      "step 7609 - loss = 1.139, (1.713 sec/step)\n",
      "step 7610 - loss = 1.244, (1.256 sec/step)\n",
      "step 7611 - loss = 1.752, (1.605 sec/step)\n",
      "step 7612 - loss = 1.801, (1.411 sec/step)\n",
      "step 7613 - loss = 1.843, (2.386 sec/step)\n",
      "step 7614 - loss = 1.813, (1.543 sec/step)\n",
      "step 7615 - loss = 1.423, (1.012 sec/step)\n",
      "step 7616 - loss = 1.651, (0.661 sec/step)\n",
      "step 7617 - loss = 1.858, (2.623 sec/step)\n",
      "step 7618 - loss = 1.559, (2.486 sec/step)\n",
      "step 7619 - loss = 1.711, (1.265 sec/step)\n",
      "step 7620 - loss = 1.317, (1.992 sec/step)\n",
      "step 7621 - loss = 1.840, (1.446 sec/step)\n",
      "step 7622 - loss = 2.009, (1.092 sec/step)\n",
      "step 7623 - loss = 1.844, (1.398 sec/step)\n",
      "step 7624 - loss = 1.551, (1.211 sec/step)\n",
      "step 7625 - loss = 1.677, (1.442 sec/step)\n",
      "step 7626 - loss = 1.201, (1.463 sec/step)\n",
      "step 7627 - loss = 1.448, (1.525 sec/step)\n",
      "step 7628 - loss = 1.719, (1.096 sec/step)\n",
      "step 7629 - loss = 2.142, (1.363 sec/step)\n",
      "step 7630 - loss = 1.631, (1.395 sec/step)\n",
      "step 7631 - loss = 1.923, (1.237 sec/step)\n",
      "step 7632 - loss = 1.371, (1.862 sec/step)\n",
      "step 7633 - loss = 1.498, (1.922 sec/step)\n",
      "step 7634 - loss = 2.201, (1.587 sec/step)\n",
      "step 7635 - loss = 1.603, (1.229 sec/step)\n",
      "step 7636 - loss = 1.866, (0.970 sec/step)\n",
      "step 7637 - loss = 0.985, (1.733 sec/step)\n",
      "step 7638 - loss = 1.514, (0.958 sec/step)\n",
      "step 7639 - loss = 1.716, (1.816 sec/step)\n",
      "step 7640 - loss = 1.637, (1.313 sec/step)\n",
      "step 7641 - loss = 1.887, (1.304 sec/step)\n",
      "step 7642 - loss = 1.764, (1.279 sec/step)\n",
      "step 7643 - loss = 2.200, (1.786 sec/step)\n",
      "step 7644 - loss = 1.777, (1.068 sec/step)\n",
      "step 7645 - loss = 2.254, (1.591 sec/step)\n",
      "step 7646 - loss = 2.056, (3.533 sec/step)\n",
      "step 7647 - loss = 1.500, (1.147 sec/step)\n",
      "step 7648 - loss = 1.763, (1.696 sec/step)\n",
      "step 7649 - loss = 1.298, (1.179 sec/step)\n",
      "step 7650 - loss = 2.212, (2.325 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7651 - loss = 2.101, (1.117 sec/step)\n",
      "step 7652 - loss = 1.589, (1.741 sec/step)\n",
      "step 7653 - loss = 2.206, (1.254 sec/step)\n",
      "step 7654 - loss = 2.060, (1.139 sec/step)\n",
      "step 7655 - loss = 2.348, (1.477 sec/step)\n",
      "step 7656 - loss = 1.932, (2.624 sec/step)\n",
      "step 7657 - loss = 1.615, (1.033 sec/step)\n",
      "step 7658 - loss = 1.885, (0.972 sec/step)\n",
      "step 7659 - loss = 2.164, (1.180 sec/step)\n",
      "step 7660 - loss = 2.162, (1.340 sec/step)\n",
      "step 7661 - loss = 1.992, (1.698 sec/step)\n",
      "step 7662 - loss = 1.651, (2.027 sec/step)\n",
      "step 7663 - loss = 1.834, (0.986 sec/step)\n",
      "step 7664 - loss = 1.971, (1.458 sec/step)\n",
      "step 7665 - loss = 2.069, (2.235 sec/step)\n",
      "step 7666 - loss = 1.717, (2.658 sec/step)\n",
      "step 7667 - loss = 1.482, (1.479 sec/step)\n",
      "step 7668 - loss = 2.214, (2.084 sec/step)\n",
      "step 7669 - loss = 1.731, (0.989 sec/step)\n",
      "step 7670 - loss = 1.825, (1.343 sec/step)\n",
      "step 7671 - loss = 1.677, (2.321 sec/step)\n",
      "step 7672 - loss = 1.841, (1.314 sec/step)\n",
      "step 7673 - loss = 1.906, (1.658 sec/step)\n",
      "step 7674 - loss = 2.061, (2.699 sec/step)\n",
      "step 7675 - loss = 2.021, (2.484 sec/step)\n",
      "step 7676 - loss = 2.508, (1.719 sec/step)\n",
      "step 7677 - loss = 2.212, (1.715 sec/step)\n",
      "step 7678 - loss = 1.849, (1.763 sec/step)\n",
      "step 7679 - loss = 1.473, (1.196 sec/step)\n",
      "step 7680 - loss = 1.521, (0.934 sec/step)\n",
      "step 7681 - loss = 1.655, (0.937 sec/step)\n",
      "step 7682 - loss = 1.682, (1.787 sec/step)\n",
      "step 7683 - loss = 2.007, (1.091 sec/step)\n",
      "step 7684 - loss = 2.048, (2.278 sec/step)\n",
      "step 7685 - loss = 1.509, (1.427 sec/step)\n",
      "step 7686 - loss = 1.335, (0.913 sec/step)\n",
      "step 7687 - loss = 1.656, (1.279 sec/step)\n",
      "step 7688 - loss = 1.808, (1.861 sec/step)\n",
      "step 7689 - loss = 1.677, (1.102 sec/step)\n",
      "step 7690 - loss = 1.934, (1.553 sec/step)\n",
      "step 7691 - loss = 1.446, (1.151 sec/step)\n",
      "step 7692 - loss = 1.778, (0.996 sec/step)\n",
      "step 7693 - loss = 1.243, (1.237 sec/step)\n",
      "step 7694 - loss = 1.733, (1.115 sec/step)\n",
      "step 7695 - loss = 2.005, (1.271 sec/step)\n",
      "step 7696 - loss = 1.867, (0.842 sec/step)\n",
      "step 7697 - loss = 1.864, (1.332 sec/step)\n",
      "step 7698 - loss = 1.479, (1.890 sec/step)\n",
      "step 7699 - loss = 1.980, (1.845 sec/step)\n",
      "step 7700 - loss = 1.497, (1.201 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7701 - loss = 1.887, (2.141 sec/step)\n",
      "step 7702 - loss = 1.848, (1.096 sec/step)\n",
      "step 7703 - loss = 1.578, (1.579 sec/step)\n",
      "step 7704 - loss = 1.569, (1.448 sec/step)\n",
      "step 7705 - loss = 1.884, (1.245 sec/step)\n",
      "step 7706 - loss = 1.654, (1.707 sec/step)\n",
      "step 7707 - loss = 2.273, (1.716 sec/step)\n",
      "step 7708 - loss = 2.345, (1.456 sec/step)\n",
      "step 7709 - loss = 1.511, (1.131 sec/step)\n",
      "step 7710 - loss = 1.492, (1.326 sec/step)\n",
      "step 7711 - loss = 1.979, (1.479 sec/step)\n",
      "step 7712 - loss = 1.695, (2.254 sec/step)\n",
      "step 7713 - loss = 2.199, (1.241 sec/step)\n",
      "step 7714 - loss = 1.395, (1.014 sec/step)\n",
      "step 7715 - loss = 2.116, (1.889 sec/step)\n",
      "step 7716 - loss = 1.851, (1.728 sec/step)\n",
      "step 7717 - loss = 1.784, (2.976 sec/step)\n",
      "step 7718 - loss = 1.902, (1.044 sec/step)\n",
      "step 7719 - loss = 1.967, (1.342 sec/step)\n",
      "step 7720 - loss = 1.732, (1.686 sec/step)\n",
      "step 7721 - loss = 2.152, (0.906 sec/step)\n",
      "step 7722 - loss = 2.048, (1.115 sec/step)\n",
      "step 7723 - loss = 1.592, (1.440 sec/step)\n",
      "step 7724 - loss = 1.733, (2.404 sec/step)\n",
      "step 7725 - loss = 1.795, (1.735 sec/step)\n",
      "step 7726 - loss = 2.441, (1.289 sec/step)\n",
      "step 7727 - loss = 1.822, (1.308 sec/step)\n",
      "step 7728 - loss = 1.885, (1.112 sec/step)\n",
      "step 7729 - loss = 1.926, (1.016 sec/step)\n",
      "step 7730 - loss = 2.191, (1.918 sec/step)\n",
      "step 7731 - loss = 2.151, (1.424 sec/step)\n",
      "step 7732 - loss = 1.900, (2.485 sec/step)\n",
      "step 7733 - loss = 0.614, (0.766 sec/step)\n",
      "step 7734 - loss = 2.050, (1.672 sec/step)\n",
      "step 7735 - loss = 1.826, (1.594 sec/step)\n",
      "step 7736 - loss = 2.022, (1.819 sec/step)\n",
      "step 7737 - loss = 1.574, (1.251 sec/step)\n",
      "step 7738 - loss = 1.773, (2.110 sec/step)\n",
      "step 7739 - loss = 2.126, (2.643 sec/step)\n",
      "step 7740 - loss = 2.228, (1.091 sec/step)\n",
      "step 7741 - loss = 1.574, (1.128 sec/step)\n",
      "step 7742 - loss = 1.947, (1.346 sec/step)\n",
      "step 7743 - loss = 1.428, (0.942 sec/step)\n",
      "step 7744 - loss = 1.647, (2.741 sec/step)\n",
      "step 7745 - loss = 2.124, (0.926 sec/step)\n",
      "step 7746 - loss = 1.639, (1.125 sec/step)\n",
      "step 7747 - loss = 1.284, (2.510 sec/step)\n",
      "step 7748 - loss = 1.482, (1.454 sec/step)\n",
      "step 7749 - loss = 1.736, (1.740 sec/step)\n",
      "step 7750 - loss = 1.829, (1.286 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7751 - loss = 2.007, (1.389 sec/step)\n",
      "step 7752 - loss = 2.082, (1.539 sec/step)\n",
      "step 7753 - loss = 1.716, (1.297 sec/step)\n",
      "step 7754 - loss = 1.026, (2.566 sec/step)\n",
      "step 7755 - loss = 1.863, (1.030 sec/step)\n",
      "step 7756 - loss = 1.710, (1.242 sec/step)\n",
      "step 7757 - loss = 1.669, (1.522 sec/step)\n",
      "step 7758 - loss = 2.393, (2.483 sec/step)\n",
      "step 7759 - loss = 2.503, (1.385 sec/step)\n",
      "step 7760 - loss = 2.386, (1.003 sec/step)\n",
      "step 7761 - loss = 2.026, (1.623 sec/step)\n",
      "step 7762 - loss = 2.110, (2.033 sec/step)\n",
      "step 7763 - loss = 2.202, (2.486 sec/step)\n",
      "step 7764 - loss = 2.083, (1.843 sec/step)\n",
      "step 7765 - loss = 1.934, (1.522 sec/step)\n",
      "step 7766 - loss = 1.898, (1.991 sec/step)\n",
      "step 7767 - loss = 2.327, (1.182 sec/step)\n",
      "step 7768 - loss = 1.661, (1.765 sec/step)\n",
      "step 7769 - loss = 2.012, (0.867 sec/step)\n",
      "step 7770 - loss = 1.717, (0.869 sec/step)\n",
      "step 7771 - loss = 2.304, (2.724 sec/step)\n",
      "step 7772 - loss = 1.623, (1.165 sec/step)\n",
      "step 7773 - loss = 1.659, (0.964 sec/step)\n",
      "step 7774 - loss = 1.552, (2.217 sec/step)\n",
      "step 7775 - loss = 1.254, (1.369 sec/step)\n",
      "step 7776 - loss = 1.439, (1.948 sec/step)\n",
      "step 7777 - loss = 1.914, (1.094 sec/step)\n",
      "step 7778 - loss = 1.811, (1.654 sec/step)\n",
      "step 7779 - loss = 1.316, (1.541 sec/step)\n",
      "step 7780 - loss = 1.690, (1.124 sec/step)\n",
      "step 7781 - loss = 1.644, (2.816 sec/step)\n",
      "step 7782 - loss = 2.441, (1.230 sec/step)\n",
      "step 7783 - loss = 1.871, (2.280 sec/step)\n",
      "step 7784 - loss = 2.189, (0.977 sec/step)\n",
      "step 7785 - loss = 1.913, (2.476 sec/step)\n",
      "step 7786 - loss = 1.877, (1.247 sec/step)\n",
      "step 7787 - loss = 2.206, (2.487 sec/step)\n",
      "step 7788 - loss = 0.659, (0.246 sec/step)\n",
      "step 7789 - loss = 1.858, (1.227 sec/step)\n",
      "step 7790 - loss = 1.780, (1.361 sec/step)\n",
      "step 7791 - loss = 1.403, (1.152 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7792 - loss = 1.583, (1.070 sec/step)\n",
      "step 7793 - loss = 2.001, (1.411 sec/step)\n",
      "step 7794 - loss = 1.259, (1.325 sec/step)\n",
      "step 7795 - loss = 1.859, (1.479 sec/step)\n",
      "step 7796 - loss = 2.505, (1.521 sec/step)\n",
      "step 7797 - loss = 1.340, (1.204 sec/step)\n",
      "step 7798 - loss = 1.660, (2.488 sec/step)\n",
      "step 7799 - loss = 2.405, (2.487 sec/step)\n",
      "step 7800 - loss = 2.043, (0.932 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7801 - loss = 1.510, (2.221 sec/step)\n",
      "step 7802 - loss = 1.709, (2.501 sec/step)\n",
      "step 7803 - loss = 2.346, (2.485 sec/step)\n",
      "step 7804 - loss = 0.833, (0.398 sec/step)\n",
      "step 7805 - loss = 1.522, (1.704 sec/step)\n",
      "step 7806 - loss = 1.851, (1.664 sec/step)\n",
      "step 7807 - loss = 2.006, (1.368 sec/step)\n",
      "step 7808 - loss = 1.130, (0.971 sec/step)\n",
      "step 7809 - loss = 2.020, (2.400 sec/step)\n",
      "step 7810 - loss = 2.159, (1.149 sec/step)\n",
      "step 7811 - loss = 2.096, (2.641 sec/step)\n",
      "step 7812 - loss = 1.455, (1.798 sec/step)\n",
      "step 7813 - loss = 2.290, (2.010 sec/step)\n",
      "step 7814 - loss = 2.309, (3.031 sec/step)\n",
      "step 7815 - loss = 2.190, (1.256 sec/step)\n",
      "step 7816 - loss = 1.607, (1.409 sec/step)\n",
      "step 7817 - loss = 1.983, (1.281 sec/step)\n",
      "step 7818 - loss = 1.896, (1.593 sec/step)\n",
      "step 7819 - loss = 2.279, (1.708 sec/step)\n",
      "step 7820 - loss = 2.054, (2.193 sec/step)\n",
      "step 7821 - loss = 2.351, (1.869 sec/step)\n",
      "step 7822 - loss = 1.631, (1.650 sec/step)\n",
      "step 7823 - loss = 2.358, (2.463 sec/step)\n",
      "step 7824 - loss = 1.891, (1.067 sec/step)\n",
      "step 7825 - loss = 2.429, (2.393 sec/step)\n",
      "step 7826 - loss = 1.992, (1.292 sec/step)\n",
      "step 7827 - loss = 1.823, (1.476 sec/step)\n",
      "step 7828 - loss = 1.462, (1.789 sec/step)\n",
      "step 7829 - loss = 1.897, (1.033 sec/step)\n",
      "step 7830 - loss = 1.242, (2.087 sec/step)\n",
      "step 7831 - loss = 1.287, (2.441 sec/step)\n",
      "step 7832 - loss = 1.722, (1.355 sec/step)\n",
      "step 7833 - loss = 1.562, (1.178 sec/step)\n",
      "step 7834 - loss = 1.453, (1.358 sec/step)\n",
      "step 7835 - loss = 1.623, (0.867 sec/step)\n",
      "step 7836 - loss = 1.712, (1.609 sec/step)\n",
      "step 7837 - loss = 2.270, (2.482 sec/step)\n",
      "step 7838 - loss = 1.443, (2.523 sec/step)\n",
      "step 7839 - loss = 2.218, (1.461 sec/step)\n",
      "step 7840 - loss = 1.988, (0.838 sec/step)\n",
      "step 7841 - loss = 2.490, (2.482 sec/step)\n",
      "step 7842 - loss = 2.576, (2.483 sec/step)\n",
      "step 7843 - loss = 0.543, (1.942 sec/step)\n",
      "step 7844 - loss = 2.440, (1.000 sec/step)\n",
      "step 7845 - loss = 2.061, (2.483 sec/step)\n",
      "step 7846 - loss = 0.649, (0.396 sec/step)\n",
      "step 7847 - loss = 1.960, (1.417 sec/step)\n",
      "step 7848 - loss = 1.986, (1.711 sec/step)\n",
      "step 7849 - loss = 2.180, (1.390 sec/step)\n",
      "step 7850 - loss = 1.550, (1.989 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7851 - loss = 1.777, (1.210 sec/step)\n",
      "step 7852 - loss = 1.214, (2.484 sec/step)\n",
      "step 7853 - loss = 0.681, (0.563 sec/step)\n",
      "step 7854 - loss = 1.840, (1.706 sec/step)\n",
      "step 7855 - loss = 1.991, (1.446 sec/step)\n",
      "step 7856 - loss = 1.777, (1.978 sec/step)\n",
      "step 7857 - loss = 1.531, (1.196 sec/step)\n",
      "step 7858 - loss = 2.391, (1.478 sec/step)\n",
      "step 7859 - loss = 1.598, (1.741 sec/step)\n",
      "step 7860 - loss = 1.554, (1.276 sec/step)\n",
      "step 7861 - loss = 1.401, (2.484 sec/step)\n",
      "step 7862 - loss = 0.598, (1.264 sec/step)\n",
      "step 7863 - loss = 1.636, (1.017 sec/step)\n",
      "step 7864 - loss = 2.031, (2.471 sec/step)\n",
      "step 7865 - loss = 1.806, (1.404 sec/step)\n",
      "step 7866 - loss = 1.744, (0.791 sec/step)\n",
      "step 7867 - loss = 1.977, (1.312 sec/step)\n",
      "step 7868 - loss = 1.393, (1.165 sec/step)\n",
      "step 7869 - loss = 1.918, (1.274 sec/step)\n",
      "step 7870 - loss = 2.371, (2.950 sec/step)\n",
      "step 7871 - loss = 2.534, (1.209 sec/step)\n",
      "step 7872 - loss = 2.005, (1.279 sec/step)\n",
      "step 7873 - loss = 1.756, (0.728 sec/step)\n",
      "step 7874 - loss = 2.019, (1.256 sec/step)\n",
      "step 7875 - loss = 2.186, (1.270 sec/step)\n",
      "step 7876 - loss = 2.432, (1.421 sec/step)\n",
      "step 7877 - loss = 1.507, (2.789 sec/step)\n",
      "step 7878 - loss = 1.888, (1.347 sec/step)\n",
      "step 7879 - loss = 1.987, (0.897 sec/step)\n",
      "step 7880 - loss = 2.678, (1.639 sec/step)\n",
      "step 7881 - loss = 2.247, (1.224 sec/step)\n",
      "step 7882 - loss = 2.157, (1.408 sec/step)\n",
      "step 7883 - loss = 1.808, (1.468 sec/step)\n",
      "step 7884 - loss = 1.682, (1.212 sec/step)\n",
      "step 7885 - loss = 1.638, (1.514 sec/step)\n",
      "step 7886 - loss = 2.164, (2.646 sec/step)\n",
      "step 7887 - loss = 2.304, (2.485 sec/step)\n",
      "step 7888 - loss = 0.750, (0.708 sec/step)\n",
      "step 7889 - loss = 1.092, (2.625 sec/step)\n",
      "step 7890 - loss = 1.388, (2.487 sec/step)\n",
      "step 7891 - loss = 0.564, (2.525 sec/step)\n",
      "step 7892 - loss = 2.429, (1.908 sec/step)\n",
      "step 7893 - loss = 1.494, (0.925 sec/step)\n",
      "step 7894 - loss = 2.191, (2.577 sec/step)\n",
      "step 7895 - loss = 1.710, (1.193 sec/step)\n",
      "step 7896 - loss = 1.765, (1.293 sec/step)\n",
      "step 7897 - loss = 2.518, (2.076 sec/step)\n",
      "step 7898 - loss = 1.751, (1.117 sec/step)\n",
      "step 7899 - loss = 1.642, (2.236 sec/step)\n",
      "step 7900 - loss = 1.601, (1.681 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7901 - loss = 1.551, (1.669 sec/step)\n",
      "step 7902 - loss = 1.316, (2.208 sec/step)\n",
      "step 7903 - loss = 2.134, (0.959 sec/step)\n",
      "step 7904 - loss = 1.439, (1.500 sec/step)\n",
      "step 7905 - loss = 2.253, (1.862 sec/step)\n",
      "step 7906 - loss = 1.421, (1.539 sec/step)\n",
      "step 7907 - loss = 1.848, (1.242 sec/step)\n",
      "step 7908 - loss = 1.873, (1.668 sec/step)\n",
      "step 7909 - loss = 2.015, (1.140 sec/step)\n",
      "step 7910 - loss = 2.158, (1.901 sec/step)\n",
      "step 7911 - loss = 1.675, (1.146 sec/step)\n",
      "step 7912 - loss = 1.592, (2.461 sec/step)\n",
      "step 7913 - loss = 2.197, (2.669 sec/step)\n",
      "step 7914 - loss = 1.443, (1.356 sec/step)\n",
      "step 7915 - loss = 1.977, (1.584 sec/step)\n",
      "step 7916 - loss = 1.575, (1.602 sec/step)\n",
      "step 7917 - loss = 2.093, (1.573 sec/step)\n",
      "step 7918 - loss = 1.566, (1.157 sec/step)\n",
      "step 7919 - loss = 2.125, (1.103 sec/step)\n",
      "step 7920 - loss = 2.161, (1.728 sec/step)\n",
      "step 7921 - loss = 1.432, (1.310 sec/step)\n",
      "step 7922 - loss = 1.631, (1.746 sec/step)\n",
      "step 7923 - loss = 1.824, (1.515 sec/step)\n",
      "step 7924 - loss = 1.993, (0.986 sec/step)\n",
      "step 7925 - loss = 1.840, (1.339 sec/step)\n",
      "step 7926 - loss = 1.878, (1.488 sec/step)\n",
      "step 7927 - loss = 1.868, (1.052 sec/step)\n",
      "step 7928 - loss = 1.626, (2.364 sec/step)\n",
      "step 7929 - loss = 1.803, (2.052 sec/step)\n",
      "step 7930 - loss = 1.888, (1.258 sec/step)\n",
      "step 7931 - loss = 1.313, (1.557 sec/step)\n",
      "step 7932 - loss = 1.490, (2.485 sec/step)\n",
      "step 7933 - loss = 0.740, (0.129 sec/step)\n",
      "step 7934 - loss = 1.912, (2.353 sec/step)\n",
      "step 7935 - loss = 1.797, (1.245 sec/step)\n",
      "step 7936 - loss = 1.890, (1.310 sec/step)\n",
      "step 7937 - loss = 1.739, (1.968 sec/step)\n",
      "step 7938 - loss = 1.509, (0.986 sec/step)\n",
      "step 7939 - loss = 1.691, (2.485 sec/step)\n",
      "step 7940 - loss = 0.425, (0.377 sec/step)\n",
      "step 7941 - loss = 2.296, (2.039 sec/step)\n",
      "step 7942 - loss = 2.466, (2.486 sec/step)\n",
      "step 7943 - loss = 2.231, (1.286 sec/step)\n",
      "step 7944 - loss = 1.656, (0.970 sec/step)\n",
      "step 7945 - loss = 2.141, (1.490 sec/step)\n",
      "step 7946 - loss = 2.102, (1.427 sec/step)\n",
      "step 7947 - loss = 1.125, (1.303 sec/step)\n",
      "step 7948 - loss = 2.042, (1.161 sec/step)\n",
      "step 7949 - loss = 1.999, (2.487 sec/step)\n",
      "step 7950 - loss = 0.609, (0.273 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 7951 - loss = 1.687, (2.766 sec/step)\n",
      "step 7952 - loss = 2.414, (1.408 sec/step)\n",
      "step 7953 - loss = 1.834, (1.463 sec/step)\n",
      "step 7954 - loss = 2.319, (1.642 sec/step)\n",
      "step 7955 - loss = 2.097, (1.556 sec/step)\n",
      "step 7956 - loss = 1.779, (1.520 sec/step)\n",
      "step 7957 - loss = 2.019, (1.230 sec/step)\n",
      "step 7958 - loss = 1.276, (1.033 sec/step)\n",
      "step 7959 - loss = 1.608, (2.321 sec/step)\n",
      "step 7960 - loss = 1.564, (1.128 sec/step)\n",
      "step 7961 - loss = 2.052, (1.804 sec/step)\n",
      "step 7962 - loss = 1.656, (1.276 sec/step)\n",
      "step 7963 - loss = 1.624, (1.344 sec/step)\n",
      "step 7964 - loss = 1.440, (1.228 sec/step)\n",
      "step 7965 - loss = 1.630, (2.642 sec/step)\n",
      "step 7966 - loss = 2.005, (2.689 sec/step)\n",
      "step 7967 - loss = 2.097, (1.238 sec/step)\n",
      "step 7968 - loss = 1.960, (1.452 sec/step)\n",
      "step 7969 - loss = 2.342, (1.799 sec/step)\n",
      "step 7970 - loss = 1.638, (1.389 sec/step)\n",
      "step 7971 - loss = 2.256, (2.196 sec/step)\n",
      "step 7972 - loss = 1.489, (1.081 sec/step)\n",
      "step 7973 - loss = 1.783, (1.477 sec/step)\n",
      "step 7974 - loss = 1.107, (1.726 sec/step)\n",
      "step 7975 - loss = 1.839, (1.477 sec/step)\n",
      "step 7976 - loss = 1.806, (1.274 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7977 - loss = 1.439, (1.096 sec/step)\n",
      "step 7978 - loss = 1.819, (1.094 sec/step)\n",
      "step 7979 - loss = 1.767, (1.122 sec/step)\n",
      "step 7980 - loss = 1.484, (1.616 sec/step)\n",
      "step 7981 - loss = 1.901, (1.305 sec/step)\n",
      "step 7982 - loss = 2.366, (1.260 sec/step)\n",
      "step 7983 - loss = 1.769, (1.325 sec/step)\n",
      "step 7984 - loss = 1.958, (1.321 sec/step)\n",
      "step 7985 - loss = 1.430, (1.091 sec/step)\n",
      "step 7986 - loss = 1.626, (1.285 sec/step)\n",
      "step 7987 - loss = 2.302, (1.160 sec/step)\n",
      "step 7988 - loss = 1.757, (0.939 sec/step)\n",
      "step 7989 - loss = 1.441, (1.501 sec/step)\n",
      "step 7990 - loss = 1.820, (1.939 sec/step)\n",
      "step 7991 - loss = 1.537, (2.000 sec/step)\n",
      "step 7992 - loss = 1.619, (1.253 sec/step)\n",
      "step 7993 - loss = 1.974, (1.480 sec/step)\n",
      "step 7994 - loss = 1.837, (1.521 sec/step)\n",
      "step 7995 - loss = 1.799, (1.200 sec/step)\n",
      "step 7996 - loss = 1.882, (1.785 sec/step)\n",
      "step 7997 - loss = 1.428, (1.068 sec/step)\n",
      "step 7998 - loss = 1.954, (1.442 sec/step)\n",
      "step 7999 - loss = 1.933, (1.189 sec/step)\n",
      "step 8000 - loss = 1.834, (1.376 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8001 - loss = 1.747, (1.357 sec/step)\n",
      "step 8002 - loss = 2.215, (1.950 sec/step)\n",
      "step 8003 - loss = 2.044, (2.209 sec/step)\n",
      "step 8004 - loss = 1.700, (1.768 sec/step)\n",
      "step 8005 - loss = 1.770, (1.034 sec/step)\n",
      "step 8006 - loss = 2.067, (0.997 sec/step)\n",
      "step 8007 - loss = 1.361, (1.285 sec/step)\n",
      "step 8008 - loss = 1.519, (1.541 sec/step)\n",
      "step 8009 - loss = 1.921, (2.142 sec/step)\n",
      "step 8010 - loss = 1.972, (1.587 sec/step)\n",
      "step 8011 - loss = 1.721, (1.354 sec/step)\n",
      "step 8012 - loss = 2.019, (2.484 sec/step)\n",
      "step 8013 - loss = 1.665, (0.306 sec/step)\n",
      "step 8014 - loss = 2.068, (1.286 sec/step)\n",
      "step 8015 - loss = 1.821, (1.542 sec/step)\n",
      "step 8016 - loss = 2.542, (1.380 sec/step)\n",
      "step 8017 - loss = 1.379, (1.127 sec/step)\n",
      "step 8018 - loss = 1.864, (0.926 sec/step)\n",
      "step 8019 - loss = 1.704, (2.083 sec/step)\n",
      "step 8020 - loss = 1.709, (1.327 sec/step)\n",
      "step 8021 - loss = 1.363, (1.394 sec/step)\n",
      "step 8022 - loss = 2.091, (1.310 sec/step)\n",
      "step 8023 - loss = 2.025, (1.359 sec/step)\n",
      "step 8024 - loss = 1.873, (1.012 sec/step)\n",
      "step 8025 - loss = 2.054, (1.553 sec/step)\n",
      "step 8026 - loss = 1.865, (1.249 sec/step)\n",
      "step 8027 - loss = 1.983, (2.486 sec/step)\n",
      "step 8028 - loss = 0.605, (1.435 sec/step)\n",
      "step 8029 - loss = 2.150, (0.995 sec/step)\n",
      "step 8030 - loss = 1.711, (0.999 sec/step)\n",
      "step 8031 - loss = 1.822, (2.646 sec/step)\n",
      "step 8032 - loss = 1.751, (1.224 sec/step)\n",
      "step 8033 - loss = 1.536, (2.004 sec/step)\n",
      "step 8034 - loss = 2.587, (1.766 sec/step)\n",
      "step 8035 - loss = 1.890, (0.893 sec/step)\n",
      "step 8036 - loss = 2.094, (1.918 sec/step)\n",
      "step 8037 - loss = 1.978, (0.925 sec/step)\n",
      "step 8038 - loss = 1.502, (2.120 sec/step)\n",
      "step 8039 - loss = 2.086, (2.045 sec/step)\n",
      "step 8040 - loss = 1.673, (0.840 sec/step)\n",
      "step 8041 - loss = 1.738, (1.033 sec/step)\n",
      "step 8042 - loss = 2.029, (1.573 sec/step)\n",
      "step 8043 - loss = 1.710, (1.478 sec/step)\n",
      "step 8044 - loss = 1.913, (1.031 sec/step)\n",
      "step 8045 - loss = 1.829, (0.986 sec/step)\n",
      "step 8046 - loss = 2.071, (2.801 sec/step)\n",
      "step 8047 - loss = 1.823, (1.322 sec/step)\n",
      "step 8048 - loss = 2.104, (2.631 sec/step)\n",
      "step 8049 - loss = 2.131, (1.359 sec/step)\n",
      "step 8050 - loss = 1.600, (1.380 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8051 - loss = 1.839, (0.983 sec/step)\n",
      "step 8052 - loss = 1.732, (1.236 sec/step)\n",
      "step 8053 - loss = 2.031, (1.247 sec/step)\n",
      "step 8054 - loss = 2.003, (1.228 sec/step)\n",
      "step 8055 - loss = 1.826, (1.054 sec/step)\n",
      "step 8056 - loss = 1.361, (0.960 sec/step)\n",
      "step 8057 - loss = 2.036, (0.924 sec/step)\n",
      "step 8058 - loss = 2.056, (1.941 sec/step)\n",
      "step 8059 - loss = 2.394, (1.017 sec/step)\n",
      "step 8060 - loss = 1.622, (1.499 sec/step)\n",
      "step 8061 - loss = 0.905, (2.483 sec/step)\n",
      "step 8062 - loss = 0.537, (0.639 sec/step)\n",
      "step 8063 - loss = 2.025, (1.152 sec/step)\n",
      "step 8064 - loss = 1.989, (1.968 sec/step)\n",
      "step 8065 - loss = 1.531, (0.821 sec/step)\n",
      "step 8066 - loss = 2.355, (0.941 sec/step)\n",
      "step 8067 - loss = 1.793, (1.293 sec/step)\n",
      "step 8068 - loss = 2.121, (2.413 sec/step)\n",
      "step 8069 - loss = 2.432, (1.657 sec/step)\n",
      "step 8070 - loss = 1.905, (1.252 sec/step)\n",
      "step 8071 - loss = 2.462, (1.570 sec/step)\n",
      "step 8072 - loss = 2.665, (1.559 sec/step)\n",
      "step 8073 - loss = 1.810, (1.820 sec/step)\n",
      "step 8074 - loss = 1.795, (1.724 sec/step)\n",
      "step 8075 - loss = 1.937, (2.568 sec/step)\n",
      "step 8076 - loss = 2.418, (1.326 sec/step)\n",
      "step 8077 - loss = 2.232, (1.445 sec/step)\n",
      "step 8078 - loss = 1.922, (1.032 sec/step)\n",
      "step 8079 - loss = 2.043, (1.598 sec/step)\n",
      "step 8080 - loss = 2.017, (1.409 sec/step)\n",
      "step 8081 - loss = 1.999, (1.343 sec/step)\n",
      "step 8082 - loss = 2.275, (2.486 sec/step)\n",
      "step 8083 - loss = 1.027, (2.204 sec/step)\n",
      "step 8084 - loss = 1.869, (0.985 sec/step)\n",
      "step 8085 - loss = 1.905, (1.227 sec/step)\n",
      "step 8086 - loss = 1.799, (2.360 sec/step)\n",
      "step 8087 - loss = 2.301, (1.732 sec/step)\n",
      "step 8088 - loss = 1.505, (2.487 sec/step)\n",
      "step 8089 - loss = 1.480, (1.520 sec/step)\n",
      "step 8090 - loss = 1.666, (1.196 sec/step)\n",
      "step 8091 - loss = 1.802, (1.711 sec/step)\n",
      "step 8092 - loss = 2.124, (2.486 sec/step)\n",
      "step 8093 - loss = 1.605, (2.572 sec/step)\n",
      "step 8094 - loss = 1.700, (1.280 sec/step)\n",
      "step 8095 - loss = 1.677, (1.257 sec/step)\n",
      "step 8096 - loss = 2.170, (1.910 sec/step)\n",
      "step 8097 - loss = 2.112, (1.423 sec/step)\n",
      "step 8098 - loss = 1.951, (1.475 sec/step)\n",
      "step 8099 - loss = 1.862, (1.443 sec/step)\n",
      "step 8100 - loss = 2.113, (1.031 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8101 - loss = 1.556, (1.128 sec/step)\n",
      "step 8102 - loss = 1.962, (1.177 sec/step)\n",
      "step 8103 - loss = 1.688, (1.524 sec/step)\n",
      "step 8104 - loss = 1.776, (1.322 sec/step)\n",
      "step 8105 - loss = 2.184, (1.217 sec/step)\n",
      "step 8106 - loss = 1.291, (2.484 sec/step)\n",
      "step 8107 - loss = 0.610, (1.777 sec/step)\n",
      "step 8108 - loss = 2.249, (1.384 sec/step)\n",
      "step 8109 - loss = 1.671, (0.952 sec/step)\n",
      "step 8110 - loss = 1.918, (0.996 sec/step)\n",
      "step 8111 - loss = 1.782, (2.653 sec/step)\n",
      "step 8112 - loss = 2.118, (0.958 sec/step)\n",
      "step 8113 - loss = 2.294, (1.763 sec/step)\n",
      "step 8114 - loss = 2.243, (2.485 sec/step)\n",
      "step 8115 - loss = 0.824, (0.374 sec/step)\n",
      "step 8116 - loss = 2.056, (1.606 sec/step)\n",
      "step 8117 - loss = 2.261, (2.485 sec/step)\n",
      "step 8118 - loss = 1.236, (1.236 sec/step)\n",
      "step 8119 - loss = 1.235, (1.317 sec/step)\n",
      "step 8120 - loss = 1.837, (0.892 sec/step)\n",
      "step 8121 - loss = 2.063, (1.292 sec/step)\n",
      "step 8122 - loss = 1.619, (1.229 sec/step)\n",
      "step 8123 - loss = 2.147, (2.652 sec/step)\n",
      "step 8124 - loss = 2.050, (1.222 sec/step)\n",
      "step 8125 - loss = 2.070, (2.228 sec/step)\n",
      "step 8126 - loss = 1.917, (1.230 sec/step)\n",
      "step 8127 - loss = 1.393, (1.675 sec/step)\n",
      "step 8128 - loss = 1.466, (1.355 sec/step)\n",
      "step 8129 - loss = 2.106, (1.712 sec/step)\n",
      "step 8130 - loss = 2.043, (1.147 sec/step)\n",
      "step 8131 - loss = 1.632, (0.851 sec/step)\n",
      "step 8132 - loss = 1.803, (1.458 sec/step)\n",
      "step 8133 - loss = 1.910, (1.172 sec/step)\n",
      "step 8134 - loss = 1.686, (1.458 sec/step)\n",
      "step 8135 - loss = 2.014, (2.426 sec/step)\n",
      "step 8136 - loss = 1.768, (1.166 sec/step)\n",
      "step 8137 - loss = 1.424, (1.609 sec/step)\n",
      "step 8138 - loss = 1.751, (1.312 sec/step)\n",
      "step 8139 - loss = 1.858, (1.098 sec/step)\n",
      "step 8140 - loss = 1.727, (0.725 sec/step)\n",
      "step 8141 - loss = 1.368, (1.142 sec/step)\n",
      "step 8142 - loss = 1.157, (2.481 sec/step)\n",
      "step 8143 - loss = 0.650, (1.805 sec/step)\n",
      "step 8144 - loss = 2.299, (1.031 sec/step)\n",
      "step 8145 - loss = 2.291, (1.173 sec/step)\n",
      "step 8146 - loss = 1.680, (1.319 sec/step)\n",
      "step 8147 - loss = 2.355, (1.050 sec/step)\n",
      "step 8148 - loss = 1.974, (2.227 sec/step)\n",
      "step 8149 - loss = 2.237, (1.892 sec/step)\n",
      "step 8150 - loss = 1.642, (1.293 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8151 - loss = 1.848, (1.708 sec/step)\n",
      "step 8152 - loss = 1.605, (1.192 sec/step)\n",
      "step 8153 - loss = 2.057, (1.686 sec/step)\n",
      "step 8154 - loss = 1.258, (1.354 sec/step)\n",
      "step 8155 - loss = 1.651, (1.130 sec/step)\n",
      "step 8156 - loss = 1.798, (1.245 sec/step)\n",
      "step 8157 - loss = 2.267, (1.435 sec/step)\n",
      "step 8158 - loss = 2.148, (1.234 sec/step)\n",
      "step 8159 - loss = 1.634, (1.254 sec/step)\n",
      "step 8160 - loss = 1.692, (1.482 sec/step)\n",
      "step 8161 - loss = 2.706, (2.612 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8162 - loss = 2.037, (2.013 sec/step)\n",
      "step 8163 - loss = 2.100, (1.519 sec/step)\n",
      "step 8164 - loss = 2.055, (1.637 sec/step)\n",
      "step 8165 - loss = 2.054, (1.000 sec/step)\n",
      "step 8166 - loss = 1.378, (0.852 sec/step)\n",
      "step 8167 - loss = 1.396, (1.964 sec/step)\n",
      "step 8168 - loss = 2.121, (2.174 sec/step)\n",
      "step 8169 - loss = 1.932, (1.833 sec/step)\n",
      "step 8170 - loss = 2.089, (1.780 sec/step)\n",
      "step 8171 - loss = 1.689, (0.911 sec/step)\n",
      "step 8172 - loss = 1.774, (1.741 sec/step)\n",
      "step 8173 - loss = 2.465, (1.536 sec/step)\n",
      "step 8174 - loss = 1.809, (1.292 sec/step)\n",
      "step 8175 - loss = 1.952, (1.731 sec/step)\n",
      "step 8176 - loss = 2.065, (1.560 sec/step)\n",
      "step 8177 - loss = 2.240, (1.510 sec/step)\n",
      "step 8178 - loss = 1.914, (1.362 sec/step)\n",
      "step 8179 - loss = 1.476, (2.213 sec/step)\n",
      "step 8180 - loss = 1.922, (1.265 sec/step)\n",
      "step 8181 - loss = 2.240, (1.513 sec/step)\n",
      "step 8182 - loss = 1.725, (1.258 sec/step)\n",
      "step 8183 - loss = 1.852, (1.117 sec/step)\n",
      "step 8184 - loss = 1.984, (1.069 sec/step)\n",
      "step 8185 - loss = 1.348, (2.321 sec/step)\n",
      "step 8186 - loss = 1.678, (1.256 sec/step)\n",
      "step 8187 - loss = 1.868, (1.257 sec/step)\n",
      "step 8188 - loss = 2.237, (1.529 sec/step)\n",
      "step 8189 - loss = 1.937, (1.345 sec/step)\n",
      "step 8190 - loss = 2.002, (2.255 sec/step)\n",
      "step 8191 - loss = 1.973, (1.811 sec/step)\n",
      "step 8192 - loss = 1.540, (2.485 sec/step)\n",
      "step 8193 - loss = 0.731, (1.203 sec/step)\n",
      "step 8194 - loss = 1.992, (1.418 sec/step)\n",
      "step 8195 - loss = 2.261, (1.385 sec/step)\n",
      "step 8196 - loss = 2.095, (1.762 sec/step)\n",
      "step 8197 - loss = 1.508, (1.541 sec/step)\n",
      "step 8198 - loss = 1.961, (1.240 sec/step)\n",
      "step 8199 - loss = 2.071, (1.408 sec/step)\n",
      "step 8200 - loss = 1.809, (2.381 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8201 - loss = 1.531, (2.651 sec/step)\n",
      "step 8202 - loss = 2.111, (3.104 sec/step)\n",
      "step 8203 - loss = 1.507, (1.309 sec/step)\n",
      "step 8204 - loss = 2.655, (2.483 sec/step)\n",
      "step 8205 - loss = 0.890, (1.089 sec/step)\n",
      "step 8206 - loss = 1.956, (1.125 sec/step)\n",
      "step 8207 - loss = 1.479, (1.818 sec/step)\n",
      "step 8208 - loss = 1.610, (1.542 sec/step)\n",
      "step 8209 - loss = 1.158, (1.282 sec/step)\n",
      "step 8210 - loss = 1.613, (2.200 sec/step)\n",
      "step 8211 - loss = 1.536, (2.025 sec/step)\n",
      "step 8212 - loss = 2.113, (2.149 sec/step)\n",
      "step 8213 - loss = 2.141, (1.763 sec/step)\n",
      "step 8214 - loss = 2.428, (1.941 sec/step)\n",
      "step 8215 - loss = 1.696, (2.499 sec/step)\n",
      "step 8216 - loss = 1.626, (1.724 sec/step)\n",
      "step 8217 - loss = 2.163, (1.726 sec/step)\n",
      "step 8218 - loss = 1.719, (1.047 sec/step)\n",
      "step 8219 - loss = 1.610, (2.148 sec/step)\n",
      "step 8220 - loss = 2.256, (0.868 sec/step)\n",
      "step 8221 - loss = 2.050, (1.699 sec/step)\n",
      "step 8222 - loss = 2.229, (1.051 sec/step)\n",
      "step 8223 - loss = 2.395, (1.590 sec/step)\n",
      "step 8224 - loss = 1.794, (0.989 sec/step)\n",
      "step 8225 - loss = 1.867, (1.361 sec/step)\n",
      "step 8226 - loss = 2.305, (1.627 sec/step)\n",
      "step 8227 - loss = 1.404, (1.109 sec/step)\n",
      "step 8228 - loss = 1.178, (1.480 sec/step)\n",
      "step 8229 - loss = 2.172, (1.429 sec/step)\n",
      "step 8230 - loss = 1.893, (1.214 sec/step)\n",
      "step 8231 - loss = 1.385, (2.003 sec/step)\n",
      "step 8232 - loss = 2.162, (1.873 sec/step)\n",
      "step 8233 - loss = 1.525, (1.708 sec/step)\n",
      "step 8234 - loss = 2.074, (2.281 sec/step)\n",
      "step 8235 - loss = 2.565, (2.104 sec/step)\n",
      "step 8236 - loss = 2.053, (1.245 sec/step)\n",
      "step 8237 - loss = 1.260, (2.119 sec/step)\n",
      "step 8238 - loss = 2.474, (1.818 sec/step)\n",
      "step 8239 - loss = 2.523, (2.487 sec/step)\n",
      "step 8240 - loss = 2.468, (1.662 sec/step)\n",
      "step 8241 - loss = 1.366, (1.312 sec/step)\n",
      "step 8242 - loss = 1.676, (1.325 sec/step)\n",
      "step 8243 - loss = 1.767, (1.535 sec/step)\n",
      "step 8244 - loss = 2.179, (1.819 sec/step)\n",
      "step 8245 - loss = 2.298, (1.741 sec/step)\n",
      "step 8246 - loss = 1.751, (1.230 sec/step)\n",
      "step 8247 - loss = 2.421, (1.031 sec/step)\n",
      "step 8248 - loss = 1.571, (1.410 sec/step)\n",
      "step 8249 - loss = 2.125, (1.360 sec/step)\n",
      "step 8250 - loss = 1.617, (2.389 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8251 - loss = 2.152, (2.254 sec/step)\n",
      "step 8252 - loss = 1.863, (1.650 sec/step)\n",
      "step 8253 - loss = 2.126, (0.921 sec/step)\n",
      "step 8254 - loss = 2.044, (3.034 sec/step)\n",
      "step 8255 - loss = 2.341, (2.486 sec/step)\n",
      "step 8256 - loss = 0.769, (0.325 sec/step)\n",
      "step 8257 - loss = 1.602, (1.535 sec/step)\n",
      "step 8258 - loss = 1.662, (1.781 sec/step)\n",
      "step 8259 - loss = 1.874, (1.130 sec/step)\n",
      "step 8260 - loss = 2.032, (2.058 sec/step)\n",
      "step 8261 - loss = 2.122, (0.951 sec/step)\n",
      "step 8262 - loss = 2.028, (1.247 sec/step)\n",
      "step 8263 - loss = 2.221, (1.209 sec/step)\n",
      "step 8264 - loss = 1.983, (1.572 sec/step)\n",
      "step 8265 - loss = 1.891, (0.940 sec/step)\n",
      "step 8266 - loss = 1.306, (1.112 sec/step)\n",
      "step 8267 - loss = 1.885, (2.114 sec/step)\n",
      "step 8268 - loss = 1.979, (1.619 sec/step)\n",
      "step 8269 - loss = 1.435, (2.483 sec/step)\n",
      "step 8270 - loss = 0.678, (0.333 sec/step)\n",
      "step 8271 - loss = 1.920, (2.483 sec/step)\n",
      "step 8272 - loss = 0.685, (1.208 sec/step)\n",
      "step 8273 - loss = 1.791, (1.087 sec/step)\n",
      "step 8274 - loss = 1.684, (0.775 sec/step)\n",
      "step 8275 - loss = 2.211, (1.558 sec/step)\n",
      "step 8276 - loss = 1.788, (1.161 sec/step)\n",
      "step 8277 - loss = 2.402, (1.170 sec/step)\n",
      "step 8278 - loss = 1.843, (1.160 sec/step)\n",
      "step 8279 - loss = 1.512, (1.039 sec/step)\n",
      "step 8280 - loss = 1.781, (0.937 sec/step)\n",
      "step 8281 - loss = 1.765, (2.426 sec/step)\n",
      "step 8282 - loss = 1.565, (0.912 sec/step)\n",
      "step 8283 - loss = 1.758, (0.912 sec/step)\n",
      "step 8284 - loss = 2.096, (1.313 sec/step)\n",
      "step 8285 - loss = 1.703, (1.269 sec/step)\n",
      "step 8286 - loss = 1.771, (1.149 sec/step)\n",
      "step 8287 - loss = 1.524, (1.697 sec/step)\n",
      "step 8288 - loss = 2.277, (1.360 sec/step)\n",
      "step 8289 - loss = 1.554, (1.163 sec/step)\n",
      "step 8290 - loss = 2.019, (1.189 sec/step)\n",
      "step 8291 - loss = 1.429, (1.229 sec/step)\n",
      "step 8292 - loss = 1.694, (0.926 sec/step)\n",
      "step 8293 - loss = 2.511, (1.201 sec/step)\n",
      "step 8294 - loss = 2.239, (1.690 sec/step)\n",
      "step 8295 - loss = 1.937, (1.448 sec/step)\n",
      "step 8296 - loss = 1.413, (1.254 sec/step)\n",
      "step 8297 - loss = 1.718, (1.016 sec/step)\n",
      "step 8298 - loss = 2.539, (1.446 sec/step)\n",
      "step 8299 - loss = 1.815, (2.240 sec/step)\n",
      "step 8300 - loss = 1.666, (1.253 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8301 - loss = 2.181, (1.180 sec/step)\n",
      "step 8302 - loss = 1.374, (2.613 sec/step)\n",
      "step 8303 - loss = 1.825, (2.152 sec/step)\n",
      "step 8304 - loss = 2.062, (2.015 sec/step)\n",
      "step 8305 - loss = 1.958, (1.323 sec/step)\n",
      "step 8306 - loss = 2.018, (1.518 sec/step)\n",
      "step 8307 - loss = 1.965, (1.176 sec/step)\n",
      "step 8308 - loss = 1.851, (1.086 sec/step)\n",
      "step 8309 - loss = 1.478, (2.037 sec/step)\n",
      "step 8310 - loss = 1.809, (1.195 sec/step)\n",
      "step 8311 - loss = 1.767, (1.046 sec/step)\n",
      "step 8312 - loss = 2.256, (1.258 sec/step)\n",
      "step 8313 - loss = 2.223, (1.504 sec/step)\n",
      "step 8314 - loss = 1.323, (2.114 sec/step)\n",
      "step 8315 - loss = 2.176, (1.149 sec/step)\n",
      "step 8316 - loss = 2.042, (1.876 sec/step)\n",
      "step 8317 - loss = 1.472, (1.112 sec/step)\n",
      "step 8318 - loss = 1.478, (1.612 sec/step)\n",
      "step 8319 - loss = 2.260, (2.487 sec/step)\n",
      "step 8320 - loss = 2.796, (1.512 sec/step)\n",
      "step 8321 - loss = 1.269, (2.643 sec/step)\n",
      "step 8322 - loss = 2.199, (2.770 sec/step)\n",
      "step 8323 - loss = 1.937, (2.981 sec/step)\n",
      "step 8324 - loss = 1.199, (1.813 sec/step)\n",
      "step 8325 - loss = 1.481, (1.158 sec/step)\n",
      "step 8326 - loss = 1.919, (1.190 sec/step)\n",
      "step 8327 - loss = 1.710, (1.908 sec/step)\n",
      "step 8328 - loss = 1.812, (1.426 sec/step)\n",
      "step 8329 - loss = 2.584, (1.523 sec/step)\n",
      "step 8330 - loss = 2.585, (1.126 sec/step)\n",
      "step 8331 - loss = 1.871, (2.409 sec/step)\n",
      "step 8332 - loss = 1.731, (1.309 sec/step)\n",
      "step 8333 - loss = 1.802, (1.382 sec/step)\n",
      "step 8334 - loss = 1.482, (1.154 sec/step)\n",
      "step 8335 - loss = 1.542, (1.626 sec/step)\n",
      "step 8336 - loss = 2.067, (2.229 sec/step)\n",
      "step 8337 - loss = 1.632, (2.264 sec/step)\n",
      "step 8338 - loss = 2.045, (1.469 sec/step)\n",
      "step 8339 - loss = 1.503, (1.062 sec/step)\n",
      "step 8340 - loss = 1.511, (1.478 sec/step)\n",
      "step 8341 - loss = 1.762, (1.328 sec/step)\n",
      "step 8342 - loss = 2.139, (1.515 sec/step)\n",
      "step 8343 - loss = 1.544, (3.068 sec/step)\n",
      "step 8344 - loss = 2.052, (0.957 sec/step)\n",
      "step 8345 - loss = 2.027, (2.291 sec/step)\n",
      "step 8346 - loss = 2.066, (1.452 sec/step)\n",
      "step 8347 - loss = 1.562, (1.046 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8348 - loss = 2.433, (1.226 sec/step)\n",
      "step 8349 - loss = 1.609, (1.540 sec/step)\n",
      "step 8350 - loss = 2.270, (1.539 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8351 - loss = 1.898, (1.646 sec/step)\n",
      "step 8352 - loss = 1.340, (0.910 sec/step)\n",
      "step 8353 - loss = 2.405, (2.483 sec/step)\n",
      "step 8354 - loss = 2.482, (1.847 sec/step)\n",
      "step 8355 - loss = 1.573, (2.314 sec/step)\n",
      "step 8356 - loss = 2.055, (1.151 sec/step)\n",
      "step 8357 - loss = 2.067, (1.132 sec/step)\n",
      "step 8358 - loss = 1.804, (2.086 sec/step)\n",
      "step 8359 - loss = 1.126, (2.513 sec/step)\n",
      "step 8360 - loss = 1.810, (3.217 sec/step)\n",
      "step 8361 - loss = 2.123, (1.285 sec/step)\n",
      "step 8362 - loss = 1.598, (2.645 sec/step)\n",
      "step 8363 - loss = 1.634, (1.389 sec/step)\n",
      "step 8364 - loss = 1.412, (1.144 sec/step)\n",
      "step 8365 - loss = 2.245, (1.806 sec/step)\n",
      "step 8366 - loss = 1.691, (1.888 sec/step)\n",
      "step 8367 - loss = 2.425, (1.310 sec/step)\n",
      "step 8368 - loss = 2.196, (1.244 sec/step)\n",
      "step 8369 - loss = 2.391, (2.485 sec/step)\n",
      "step 8370 - loss = 2.477, (1.318 sec/step)\n",
      "step 8371 - loss = 2.091, (2.084 sec/step)\n",
      "step 8372 - loss = 2.160, (1.572 sec/step)\n",
      "step 8373 - loss = 2.745, (0.987 sec/step)\n",
      "step 8374 - loss = 1.794, (2.138 sec/step)\n",
      "step 8375 - loss = 1.746, (1.809 sec/step)\n",
      "step 8376 - loss = 1.879, (1.214 sec/step)\n",
      "step 8377 - loss = 1.871, (1.294 sec/step)\n",
      "step 8378 - loss = 2.161, (1.714 sec/step)\n",
      "step 8379 - loss = 1.858, (1.742 sec/step)\n",
      "step 8380 - loss = 1.642, (1.683 sec/step)\n",
      "step 8381 - loss = 1.645, (1.656 sec/step)\n",
      "step 8382 - loss = 1.603, (1.643 sec/step)\n",
      "step 8383 - loss = 2.526, (1.250 sec/step)\n",
      "step 8384 - loss = 2.148, (1.410 sec/step)\n",
      "step 8385 - loss = 1.605, (2.385 sec/step)\n",
      "step 8386 - loss = 2.170, (2.485 sec/step)\n",
      "step 8387 - loss = 1.958, (1.349 sec/step)\n",
      "step 8388 - loss = 2.094, (1.918 sec/step)\n",
      "step 8389 - loss = 1.662, (1.524 sec/step)\n",
      "step 8390 - loss = 2.044, (1.515 sec/step)\n",
      "step 8391 - loss = 2.117, (2.149 sec/step)\n",
      "step 8392 - loss = 1.740, (1.672 sec/step)\n",
      "step 8393 - loss = 1.812, (1.774 sec/step)\n",
      "step 8394 - loss = 1.505, (1.070 sec/step)\n",
      "step 8395 - loss = 1.750, (1.823 sec/step)\n",
      "step 8396 - loss = 2.294, (1.637 sec/step)\n",
      "step 8397 - loss = 1.510, (0.969 sec/step)\n",
      "step 8398 - loss = 1.561, (0.867 sec/step)\n",
      "step 8399 - loss = 2.330, (1.841 sec/step)\n",
      "step 8400 - loss = 1.647, (1.170 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8401 - loss = 1.262, (1.182 sec/step)\n",
      "step 8402 - loss = 2.490, (2.574 sec/step)\n",
      "step 8403 - loss = 1.499, (1.333 sec/step)\n",
      "step 8404 - loss = 1.603, (1.263 sec/step)\n",
      "step 8405 - loss = 1.445, (1.386 sec/step)\n",
      "step 8406 - loss = 1.817, (1.209 sec/step)\n",
      "step 8407 - loss = 2.093, (1.724 sec/step)\n",
      "step 8408 - loss = 2.045, (2.022 sec/step)\n",
      "step 8409 - loss = 2.019, (1.396 sec/step)\n",
      "step 8410 - loss = 2.055, (1.128 sec/step)\n",
      "step 8411 - loss = 2.012, (1.562 sec/step)\n",
      "step 8412 - loss = 2.040, (1.068 sec/step)\n",
      "step 8413 - loss = 2.147, (1.556 sec/step)\n",
      "step 8414 - loss = 1.781, (1.145 sec/step)\n",
      "step 8415 - loss = 2.262, (1.495 sec/step)\n",
      "step 8416 - loss = 2.151, (1.490 sec/step)\n",
      "step 8417 - loss = 1.816, (1.940 sec/step)\n",
      "step 8418 - loss = 1.746, (1.294 sec/step)\n",
      "step 8419 - loss = 1.958, (1.448 sec/step)\n",
      "step 8420 - loss = 1.514, (1.275 sec/step)\n",
      "step 8421 - loss = 1.635, (1.033 sec/step)\n",
      "step 8422 - loss = 1.653, (1.318 sec/step)\n",
      "step 8423 - loss = 2.176, (1.333 sec/step)\n",
      "step 8424 - loss = 1.995, (0.922 sec/step)\n",
      "step 8425 - loss = 1.705, (1.121 sec/step)\n",
      "step 8426 - loss = 1.475, (2.178 sec/step)\n",
      "step 8427 - loss = 2.066, (1.091 sec/step)\n",
      "step 8428 - loss = 2.141, (1.390 sec/step)\n",
      "step 8429 - loss = 2.391, (2.136 sec/step)\n",
      "step 8430 - loss = 1.467, (1.591 sec/step)\n",
      "step 8431 - loss = 1.694, (1.360 sec/step)\n",
      "step 8432 - loss = 1.493, (1.542 sec/step)\n",
      "step 8433 - loss = 1.952, (1.251 sec/step)\n",
      "step 8434 - loss = 1.867, (1.086 sec/step)\n",
      "step 8435 - loss = 1.722, (1.440 sec/step)\n",
      "step 8436 - loss = 1.761, (1.093 sec/step)\n",
      "step 8437 - loss = 1.924, (1.402 sec/step)\n",
      "step 8438 - loss = 2.357, (2.319 sec/step)\n",
      "step 8439 - loss = 1.576, (1.440 sec/step)\n",
      "step 8440 - loss = 2.166, (1.385 sec/step)\n",
      "step 8441 - loss = 1.951, (1.601 sec/step)\n",
      "step 8442 - loss = 1.727, (0.908 sec/step)\n",
      "step 8443 - loss = 1.702, (1.386 sec/step)\n",
      "step 8444 - loss = 2.080, (0.928 sec/step)\n",
      "step 8445 - loss = 2.022, (1.255 sec/step)\n",
      "step 8446 - loss = 1.620, (1.984 sec/step)\n",
      "step 8447 - loss = 1.774, (1.637 sec/step)\n",
      "step 8448 - loss = 2.258, (2.150 sec/step)\n",
      "step 8449 - loss = 2.127, (1.663 sec/step)\n",
      "step 8450 - loss = 1.744, (1.872 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8451 - loss = 2.010, (1.198 sec/step)\n",
      "step 8452 - loss = 2.172, (2.487 sec/step)\n",
      "step 8453 - loss = 1.160, (2.489 sec/step)\n",
      "step 8454 - loss = 1.049, (1.104 sec/step)\n",
      "step 8455 - loss = 1.788, (1.967 sec/step)\n",
      "step 8456 - loss = 1.827, (1.392 sec/step)\n",
      "step 8457 - loss = 2.335, (2.319 sec/step)\n",
      "step 8458 - loss = 2.547, (2.486 sec/step)\n",
      "step 8459 - loss = 2.419, (1.939 sec/step)\n",
      "step 8460 - loss = 1.609, (1.354 sec/step)\n",
      "step 8461 - loss = 1.631, (1.339 sec/step)\n",
      "step 8462 - loss = 1.773, (2.334 sec/step)\n",
      "step 8463 - loss = 1.746, (1.491 sec/step)\n",
      "step 8464 - loss = 1.692, (1.096 sec/step)\n",
      "step 8465 - loss = 1.369, (1.630 sec/step)\n",
      "step 8466 - loss = 2.336, (2.483 sec/step)\n",
      "step 8467 - loss = 0.563, (1.205 sec/step)\n",
      "step 8468 - loss = 1.735, (1.158 sec/step)\n",
      "step 8469 - loss = 1.465, (0.957 sec/step)\n",
      "step 8470 - loss = 1.743, (1.672 sec/step)\n",
      "step 8471 - loss = 2.113, (1.176 sec/step)\n",
      "step 8472 - loss = 1.753, (1.557 sec/step)\n",
      "step 8473 - loss = 2.091, (0.927 sec/step)\n",
      "step 8474 - loss = 1.641, (1.644 sec/step)\n",
      "step 8475 - loss = 1.879, (1.679 sec/step)\n",
      "step 8476 - loss = 1.828, (0.987 sec/step)\n",
      "step 8477 - loss = 1.845, (1.426 sec/step)\n",
      "step 8478 - loss = 1.741, (1.175 sec/step)\n",
      "step 8479 - loss = 1.793, (2.427 sec/step)\n",
      "step 8480 - loss = 2.326, (1.717 sec/step)\n",
      "step 8481 - loss = 2.021, (0.961 sec/step)\n",
      "step 8482 - loss = 1.507, (1.224 sec/step)\n",
      "step 8483 - loss = 1.748, (1.199 sec/step)\n",
      "step 8484 - loss = 1.874, (1.852 sec/step)\n",
      "step 8485 - loss = 1.459, (1.435 sec/step)\n",
      "step 8486 - loss = 1.908, (2.485 sec/step)\n",
      "step 8487 - loss = 2.279, (0.922 sec/step)\n",
      "step 8488 - loss = 2.134, (2.483 sec/step)\n",
      "step 8489 - loss = 1.192, (1.376 sec/step)\n",
      "step 8490 - loss = 1.571, (1.134 sec/step)\n",
      "step 8491 - loss = 1.882, (1.008 sec/step)\n",
      "step 8492 - loss = 2.112, (1.470 sec/step)\n",
      "step 8493 - loss = 2.063, (1.269 sec/step)\n",
      "step 8494 - loss = 1.927, (1.558 sec/step)\n",
      "step 8495 - loss = 1.879, (2.182 sec/step)\n",
      "step 8496 - loss = 1.919, (1.593 sec/step)\n",
      "step 8497 - loss = 1.315, (2.485 sec/step)\n",
      "step 8498 - loss = 0.522, (0.406 sec/step)\n",
      "step 8499 - loss = 2.203, (1.390 sec/step)\n",
      "step 8500 - loss = 2.391, (2.471 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8501 - loss = 2.104, (2.329 sec/step)\n",
      "step 8502 - loss = 1.508, (2.619 sec/step)\n",
      "step 8503 - loss = 2.398, (1.074 sec/step)\n",
      "step 8504 - loss = 2.033, (1.462 sec/step)\n",
      "step 8505 - loss = 1.622, (1.164 sec/step)\n",
      "step 8506 - loss = 1.942, (1.609 sec/step)\n",
      "step 8507 - loss = 1.947, (1.457 sec/step)\n",
      "step 8508 - loss = 1.357, (1.684 sec/step)\n",
      "step 8509 - loss = 1.906, (1.412 sec/step)\n",
      "step 8510 - loss = 1.747, (1.076 sec/step)\n",
      "step 8511 - loss = 1.805, (2.485 sec/step)\n",
      "step 8512 - loss = 0.579, (0.282 sec/step)\n",
      "step 8513 - loss = 1.682, (1.003 sec/step)\n",
      "step 8514 - loss = 2.033, (1.180 sec/step)\n",
      "step 8515 - loss = 1.691, (2.449 sec/step)\n",
      "step 8516 - loss = 2.174, (2.067 sec/step)\n",
      "step 8517 - loss = 1.906, (1.000 sec/step)\n",
      "step 8518 - loss = 1.567, (1.247 sec/step)\n",
      "step 8519 - loss = 1.328, (0.987 sec/step)\n",
      "step 8520 - loss = 1.698, (1.406 sec/step)\n",
      "step 8521 - loss = 1.562, (3.175 sec/step)\n",
      "step 8522 - loss = 2.055, (1.786 sec/step)\n",
      "step 8523 - loss = 1.799, (1.409 sec/step)\n",
      "step 8524 - loss = 2.206, (1.601 sec/step)\n",
      "step 8525 - loss = 2.275, (2.482 sec/step)\n",
      "step 8526 - loss = 2.338, (1.809 sec/step)\n",
      "step 8527 - loss = 1.708, (0.969 sec/step)\n",
      "step 8528 - loss = 2.123, (2.021 sec/step)\n",
      "step 8529 - loss = 2.267, (2.756 sec/step)\n",
      "step 8530 - loss = 2.188, (2.930 sec/step)\n",
      "step 8531 - loss = 1.292, (1.310 sec/step)\n",
      "step 8532 - loss = 1.078, (1.197 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8533 - loss = 1.222, (0.926 sec/step)\n",
      "step 8534 - loss = 2.225, (0.954 sec/step)\n",
      "step 8535 - loss = 2.411, (1.412 sec/step)\n",
      "step 8536 - loss = 1.449, (1.049 sec/step)\n",
      "step 8537 - loss = 1.413, (1.996 sec/step)\n",
      "step 8538 - loss = 2.322, (1.778 sec/step)\n",
      "step 8539 - loss = 2.166, (2.354 sec/step)\n",
      "step 8540 - loss = 2.093, (1.806 sec/step)\n",
      "step 8541 - loss = 1.507, (1.341 sec/step)\n",
      "step 8542 - loss = 1.743, (1.015 sec/step)\n",
      "step 8543 - loss = 2.071, (2.640 sec/step)\n",
      "step 8544 - loss = 1.904, (0.869 sec/step)\n",
      "step 8545 - loss = 1.828, (1.034 sec/step)\n",
      "step 8546 - loss = 2.283, (1.114 sec/step)\n",
      "step 8547 - loss = 2.008, (1.594 sec/step)\n",
      "step 8548 - loss = 2.484, (2.096 sec/step)\n",
      "step 8549 - loss = 1.572, (1.033 sec/step)\n",
      "step 8550 - loss = 1.846, (1.147 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8551 - loss = 2.080, (1.624 sec/step)\n",
      "step 8552 - loss = 2.539, (3.320 sec/step)\n",
      "step 8553 - loss = 1.472, (1.372 sec/step)\n",
      "step 8554 - loss = 1.780, (1.427 sec/step)\n",
      "step 8555 - loss = 1.755, (1.324 sec/step)\n",
      "step 8556 - loss = 1.950, (1.201 sec/step)\n",
      "step 8557 - loss = 1.887, (1.112 sec/step)\n",
      "step 8558 - loss = 2.023, (1.345 sec/step)\n",
      "step 8559 - loss = 2.310, (1.599 sec/step)\n",
      "step 8560 - loss = 2.109, (1.160 sec/step)\n",
      "step 8561 - loss = 1.743, (1.816 sec/step)\n",
      "step 8562 - loss = 1.545, (1.418 sec/step)\n",
      "step 8563 - loss = 1.474, (1.158 sec/step)\n",
      "step 8564 - loss = 1.840, (1.250 sec/step)\n",
      "step 8565 - loss = 2.052, (1.054 sec/step)\n",
      "step 8566 - loss = 2.042, (2.476 sec/step)\n",
      "step 8567 - loss = 1.729, (1.710 sec/step)\n",
      "step 8568 - loss = 1.456, (1.333 sec/step)\n",
      "step 8569 - loss = 1.678, (1.228 sec/step)\n",
      "step 8570 - loss = 1.571, (1.286 sec/step)\n",
      "step 8571 - loss = 1.489, (0.894 sec/step)\n",
      "step 8572 - loss = 1.884, (1.164 sec/step)\n",
      "step 8573 - loss = 2.058, (1.201 sec/step)\n",
      "step 8574 - loss = 1.615, (1.990 sec/step)\n",
      "step 8575 - loss = 1.947, (1.650 sec/step)\n",
      "step 8576 - loss = 2.139, (1.126 sec/step)\n",
      "step 8577 - loss = 1.339, (1.440 sec/step)\n",
      "step 8578 - loss = 1.909, (2.360 sec/step)\n",
      "step 8579 - loss = 1.587, (0.863 sec/step)\n",
      "step 8580 - loss = 2.001, (1.148 sec/step)\n",
      "step 8581 - loss = 2.433, (1.512 sec/step)\n",
      "step 8582 - loss = 1.974, (1.543 sec/step)\n",
      "step 8583 - loss = 1.795, (0.866 sec/step)\n",
      "step 8584 - loss = 1.885, (0.833 sec/step)\n",
      "step 8585 - loss = 2.422, (2.136 sec/step)\n",
      "step 8586 - loss = 2.000, (2.120 sec/step)\n",
      "step 8587 - loss = 1.289, (1.461 sec/step)\n",
      "step 8588 - loss = 1.447, (1.379 sec/step)\n",
      "step 8589 - loss = 1.957, (2.483 sec/step)\n",
      "step 8590 - loss = 0.580, (1.415 sec/step)\n",
      "step 8591 - loss = 1.488, (1.556 sec/step)\n",
      "step 8592 - loss = 1.739, (1.040 sec/step)\n",
      "step 8593 - loss = 1.337, (1.066 sec/step)\n",
      "step 8594 - loss = 1.384, (1.559 sec/step)\n",
      "step 8595 - loss = 2.083, (2.484 sec/step)\n",
      "step 8596 - loss = 1.760, (2.244 sec/step)\n",
      "step 8597 - loss = 1.823, (1.406 sec/step)\n",
      "step 8598 - loss = 2.003, (2.530 sec/step)\n",
      "step 8599 - loss = 2.063, (1.365 sec/step)\n",
      "step 8600 - loss = 1.980, (1.734 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8601 - loss = 2.434, (1.619 sec/step)\n",
      "step 8602 - loss = 1.722, (0.958 sec/step)\n",
      "step 8603 - loss = 1.539, (2.480 sec/step)\n",
      "step 8604 - loss = 1.504, (1.509 sec/step)\n",
      "step 8605 - loss = 1.586, (1.593 sec/step)\n",
      "step 8606 - loss = 1.856, (1.024 sec/step)\n",
      "step 8607 - loss = 2.117, (1.624 sec/step)\n",
      "step 8608 - loss = 2.193, (1.323 sec/step)\n",
      "step 8609 - loss = 1.714, (1.130 sec/step)\n",
      "step 8610 - loss = 1.932, (1.686 sec/step)\n",
      "step 8611 - loss = 2.050, (1.538 sec/step)\n",
      "step 8612 - loss = 2.158, (2.486 sec/step)\n",
      "step 8613 - loss = 0.614, (2.371 sec/step)\n",
      "step 8614 - loss = 1.649, (1.796 sec/step)\n",
      "step 8615 - loss = 1.661, (2.974 sec/step)\n",
      "step 8616 - loss = 1.447, (2.419 sec/step)\n",
      "step 8617 - loss = 2.181, (2.806 sec/step)\n",
      "step 8618 - loss = 1.969, (2.769 sec/step)\n",
      "step 8619 - loss = 2.076, (2.267 sec/step)\n",
      "step 8620 - loss = 1.659, (2.357 sec/step)\n",
      "step 8621 - loss = 1.441, (2.168 sec/step)\n",
      "step 8622 - loss = 2.156, (2.088 sec/step)\n",
      "step 8623 - loss = 1.579, (2.212 sec/step)\n",
      "step 8624 - loss = 1.414, (0.970 sec/step)\n",
      "step 8625 - loss = 1.875, (2.482 sec/step)\n",
      "step 8626 - loss = 2.219, (1.132 sec/step)\n",
      "step 8627 - loss = 2.012, (2.306 sec/step)\n",
      "step 8628 - loss = 1.973, (1.181 sec/step)\n",
      "step 8629 - loss = 1.812, (1.847 sec/step)\n",
      "step 8630 - loss = 2.279, (2.506 sec/step)\n",
      "step 8631 - loss = 1.336, (0.892 sec/step)\n",
      "step 8632 - loss = 2.031, (1.338 sec/step)\n",
      "step 8633 - loss = 1.947, (1.361 sec/step)\n",
      "step 8634 - loss = 1.717, (1.133 sec/step)\n",
      "step 8635 - loss = 1.806, (1.102 sec/step)\n",
      "step 8636 - loss = 1.802, (1.607 sec/step)\n",
      "step 8637 - loss = 2.100, (1.031 sec/step)\n",
      "step 8638 - loss = 2.118, (1.216 sec/step)\n",
      "step 8639 - loss = 1.370, (0.928 sec/step)\n",
      "step 8640 - loss = 2.063, (1.741 sec/step)\n",
      "step 8641 - loss = 1.185, (1.652 sec/step)\n",
      "step 8642 - loss = 2.458, (1.039 sec/step)\n",
      "step 8643 - loss = 2.140, (1.198 sec/step)\n",
      "step 8644 - loss = 1.260, (1.407 sec/step)\n",
      "step 8645 - loss = 1.939, (1.327 sec/step)\n",
      "step 8646 - loss = 1.667, (2.484 sec/step)\n",
      "step 8647 - loss = 0.834, (2.389 sec/step)\n",
      "step 8648 - loss = 1.562, (1.715 sec/step)\n",
      "step 8649 - loss = 1.920, (1.158 sec/step)\n",
      "step 8650 - loss = 1.296, (1.620 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8651 - loss = 1.251, (1.324 sec/step)\n",
      "step 8652 - loss = 1.848, (1.052 sec/step)\n",
      "step 8653 - loss = 1.236, (0.948 sec/step)\n",
      "step 8654 - loss = 1.621, (1.493 sec/step)\n",
      "step 8655 - loss = 1.659, (1.148 sec/step)\n",
      "step 8656 - loss = 2.022, (3.043 sec/step)\n",
      "step 8657 - loss = 1.424, (1.794 sec/step)\n",
      "step 8658 - loss = 1.639, (1.120 sec/step)\n",
      "step 8659 - loss = 1.664, (0.981 sec/step)\n",
      "step 8660 - loss = 1.777, (2.396 sec/step)\n",
      "step 8661 - loss = 1.856, (0.954 sec/step)\n",
      "step 8662 - loss = 1.979, (2.597 sec/step)\n",
      "step 8663 - loss = 1.802, (2.367 sec/step)\n",
      "step 8664 - loss = 1.403, (1.293 sec/step)\n",
      "step 8665 - loss = 1.446, (1.604 sec/step)\n",
      "step 8666 - loss = 2.094, (1.944 sec/step)\n",
      "step 8667 - loss = 1.952, (0.838 sec/step)\n",
      "step 8668 - loss = 2.463, (1.216 sec/step)\n",
      "step 8669 - loss = 1.577, (1.228 sec/step)\n",
      "step 8670 - loss = 2.007, (2.482 sec/step)\n",
      "step 8671 - loss = 2.004, (1.970 sec/step)\n",
      "step 8672 - loss = 1.372, (1.474 sec/step)\n",
      "step 8673 - loss = 2.171, (1.067 sec/step)\n",
      "step 8674 - loss = 1.962, (1.490 sec/step)\n",
      "step 8675 - loss = 1.792, (0.964 sec/step)\n",
      "step 8676 - loss = 1.739, (1.920 sec/step)\n",
      "step 8677 - loss = 1.197, (1.287 sec/step)\n",
      "step 8678 - loss = 2.511, (0.966 sec/step)\n",
      "step 8679 - loss = 2.575, (1.342 sec/step)\n",
      "step 8680 - loss = 2.341, (2.485 sec/step)\n",
      "step 8681 - loss = 1.664, (0.677 sec/step)\n",
      "step 8682 - loss = 1.993, (1.558 sec/step)\n",
      "step 8683 - loss = 2.241, (2.773 sec/step)\n",
      "step 8684 - loss = 2.041, (1.087 sec/step)\n",
      "step 8685 - loss = 2.172, (1.510 sec/step)\n",
      "step 8686 - loss = 2.150, (1.720 sec/step)\n",
      "step 8687 - loss = 1.436, (2.458 sec/step)\n",
      "step 8688 - loss = 2.330, (1.128 sec/step)\n",
      "step 8689 - loss = 1.354, (2.631 sec/step)\n",
      "step 8690 - loss = 1.660, (0.761 sec/step)\n",
      "step 8691 - loss = 1.471, (2.486 sec/step)\n",
      "step 8692 - loss = 1.411, (1.137 sec/step)\n",
      "step 8693 - loss = 1.549, (3.086 sec/step)\n",
      "step 8694 - loss = 1.981, (2.284 sec/step)\n",
      "step 8695 - loss = 1.727, (1.256 sec/step)\n",
      "step 8696 - loss = 2.174, (1.357 sec/step)\n",
      "step 8697 - loss = 2.046, (1.162 sec/step)\n",
      "step 8698 - loss = 1.956, (1.227 sec/step)\n",
      "step 8699 - loss = 2.264, (1.444 sec/step)\n",
      "step 8700 - loss = 1.999, (1.066 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8701 - loss = 1.332, (1.920 sec/step)\n",
      "step 8702 - loss = 1.925, (1.571 sec/step)\n",
      "step 8703 - loss = 1.955, (1.270 sec/step)\n",
      "step 8704 - loss = 1.747, (2.677 sec/step)\n",
      "step 8705 - loss = 1.731, (1.066 sec/step)\n",
      "step 8706 - loss = 1.955, (2.172 sec/step)\n",
      "step 8707 - loss = 1.771, (1.393 sec/step)\n",
      "step 8708 - loss = 2.259, (1.141 sec/step)\n",
      "step 8709 - loss = 1.956, (1.416 sec/step)\n",
      "step 8710 - loss = 1.622, (2.466 sec/step)\n",
      "step 8711 - loss = 1.316, (1.195 sec/step)\n",
      "step 8712 - loss = 1.818, (1.430 sec/step)\n",
      "step 8713 - loss = 1.608, (0.940 sec/step)\n",
      "step 8714 - loss = 2.012, (1.032 sec/step)\n",
      "step 8715 - loss = 1.590, (1.543 sec/step)\n",
      "step 8716 - loss = 1.478, (1.670 sec/step)\n",
      "step 8717 - loss = 1.795, (1.461 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8718 - loss = 1.972, (2.066 sec/step)\n",
      "step 8719 - loss = 1.601, (1.197 sec/step)\n",
      "step 8720 - loss = 1.642, (0.917 sec/step)\n",
      "step 8721 - loss = 1.565, (1.096 sec/step)\n",
      "step 8722 - loss = 1.808, (1.486 sec/step)\n",
      "step 8723 - loss = 1.848, (1.941 sec/step)\n",
      "step 8724 - loss = 2.517, (1.297 sec/step)\n",
      "step 8725 - loss = 1.880, (1.578 sec/step)\n",
      "step 8726 - loss = 1.933, (1.409 sec/step)\n",
      "step 8727 - loss = 1.791, (1.213 sec/step)\n",
      "step 8728 - loss = 1.868, (0.926 sec/step)\n",
      "step 8729 - loss = 1.697, (3.382 sec/step)\n",
      "step 8730 - loss = 2.255, (1.410 sec/step)\n",
      "step 8731 - loss = 1.942, (2.291 sec/step)\n",
      "step 8732 - loss = 2.220, (1.817 sec/step)\n",
      "step 8733 - loss = 1.698, (1.447 sec/step)\n",
      "step 8734 - loss = 1.772, (1.571 sec/step)\n",
      "step 8735 - loss = 2.205, (2.485 sec/step)\n",
      "step 8736 - loss = 2.005, (2.717 sec/step)\n",
      "step 8737 - loss = 1.842, (3.254 sec/step)\n",
      "step 8738 - loss = 1.703, (1.668 sec/step)\n",
      "step 8739 - loss = 1.761, (1.125 sec/step)\n",
      "step 8740 - loss = 1.714, (1.191 sec/step)\n",
      "step 8741 - loss = 1.720, (2.686 sec/step)\n",
      "step 8742 - loss = 1.669, (1.240 sec/step)\n",
      "step 8743 - loss = 1.750, (1.903 sec/step)\n",
      "step 8744 - loss = 2.217, (1.380 sec/step)\n",
      "step 8745 - loss = 1.218, (1.612 sec/step)\n",
      "step 8746 - loss = 1.536, (1.526 sec/step)\n",
      "step 8747 - loss = 1.664, (1.068 sec/step)\n",
      "step 8748 - loss = 2.085, (1.892 sec/step)\n",
      "step 8749 - loss = 1.512, (3.378 sec/step)\n",
      "step 8750 - loss = 1.843, (1.461 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8751 - loss = 1.760, (1.002 sec/step)\n",
      "step 8752 - loss = 1.589, (1.479 sec/step)\n",
      "step 8753 - loss = 1.475, (1.101 sec/step)\n",
      "step 8754 - loss = 1.943, (2.483 sec/step)\n",
      "step 8755 - loss = 0.545, (1.697 sec/step)\n",
      "step 8756 - loss = 1.901, (2.486 sec/step)\n",
      "step 8757 - loss = 1.439, (0.450 sec/step)\n",
      "step 8758 - loss = 1.470, (1.099 sec/step)\n",
      "step 8759 - loss = 2.229, (2.483 sec/step)\n",
      "step 8760 - loss = 1.948, (2.401 sec/step)\n",
      "step 8761 - loss = 2.258, (1.068 sec/step)\n",
      "step 8762 - loss = 1.696, (1.249 sec/step)\n",
      "step 8763 - loss = 1.986, (2.229 sec/step)\n",
      "step 8764 - loss = 2.271, (2.018 sec/step)\n",
      "step 8765 - loss = 1.349, (1.087 sec/step)\n",
      "step 8766 - loss = 1.978, (2.483 sec/step)\n",
      "step 8767 - loss = 0.585, (0.272 sec/step)\n",
      "step 8768 - loss = 1.761, (1.112 sec/step)\n",
      "step 8769 - loss = 1.534, (1.196 sec/step)\n",
      "step 8770 - loss = 1.449, (1.316 sec/step)\n",
      "step 8771 - loss = 1.517, (2.651 sec/step)\n",
      "step 8772 - loss = 1.932, (1.803 sec/step)\n",
      "step 8773 - loss = 1.962, (1.279 sec/step)\n",
      "step 8774 - loss = 1.885, (1.113 sec/step)\n",
      "step 8775 - loss = 1.804, (1.031 sec/step)\n",
      "step 8776 - loss = 2.408, (2.063 sec/step)\n",
      "step 8777 - loss = 1.796, (1.449 sec/step)\n",
      "step 8778 - loss = 1.768, (0.839 sec/step)\n",
      "step 8779 - loss = 1.686, (1.108 sec/step)\n",
      "step 8780 - loss = 1.790, (1.331 sec/step)\n",
      "step 8781 - loss = 1.913, (1.355 sec/step)\n",
      "step 8782 - loss = 2.022, (2.139 sec/step)\n",
      "step 8783 - loss = 1.578, (1.179 sec/step)\n",
      "step 8784 - loss = 2.213, (1.537 sec/step)\n",
      "step 8785 - loss = 1.930, (1.022 sec/step)\n",
      "step 8786 - loss = 1.765, (1.441 sec/step)\n",
      "step 8787 - loss = 1.777, (1.865 sec/step)\n",
      "step 8788 - loss = 1.854, (1.295 sec/step)\n",
      "step 8789 - loss = 1.477, (1.391 sec/step)\n",
      "step 8790 - loss = 1.949, (1.097 sec/step)\n",
      "step 8791 - loss = 1.348, (1.722 sec/step)\n",
      "step 8792 - loss = 2.215, (1.390 sec/step)\n",
      "step 8793 - loss = 1.433, (1.159 sec/step)\n",
      "step 8794 - loss = 1.705, (1.064 sec/step)\n",
      "step 8795 - loss = 2.192, (1.679 sec/step)\n",
      "step 8796 - loss = 1.861, (1.018 sec/step)\n",
      "step 8797 - loss = 1.587, (1.055 sec/step)\n",
      "step 8798 - loss = 1.461, (1.062 sec/step)\n",
      "step 8799 - loss = 1.905, (1.129 sec/step)\n",
      "step 8800 - loss = 1.611, (1.191 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8801 - loss = 1.807, (1.086 sec/step)\n",
      "step 8802 - loss = 2.184, (1.438 sec/step)\n",
      "step 8803 - loss = 1.428, (1.274 sec/step)\n",
      "step 8804 - loss = 1.967, (1.651 sec/step)\n",
      "step 8805 - loss = 1.710, (1.073 sec/step)\n",
      "step 8806 - loss = 1.989, (1.154 sec/step)\n",
      "step 8807 - loss = 2.487, (1.681 sec/step)\n",
      "step 8808 - loss = 1.620, (1.016 sec/step)\n",
      "step 8809 - loss = 1.701, (1.319 sec/step)\n",
      "step 8810 - loss = 1.772, (2.155 sec/step)\n",
      "step 8811 - loss = 1.818, (1.197 sec/step)\n",
      "step 8812 - loss = 2.020, (1.575 sec/step)\n",
      "step 8813 - loss = 1.876, (2.389 sec/step)\n",
      "step 8814 - loss = 1.794, (1.810 sec/step)\n",
      "step 8815 - loss = 1.618, (1.267 sec/step)\n",
      "step 8816 - loss = 1.541, (1.374 sec/step)\n",
      "step 8817 - loss = 2.117, (1.115 sec/step)\n",
      "step 8818 - loss = 1.916, (1.089 sec/step)\n",
      "step 8819 - loss = 2.176, (1.475 sec/step)\n",
      "step 8820 - loss = 1.991, (2.579 sec/step)\n",
      "step 8821 - loss = 2.094, (1.002 sec/step)\n",
      "step 8822 - loss = 1.564, (1.540 sec/step)\n",
      "step 8823 - loss = 2.332, (1.817 sec/step)\n",
      "step 8824 - loss = 2.184, (2.157 sec/step)\n",
      "step 8825 - loss = 1.621, (1.337 sec/step)\n",
      "step 8826 - loss = 1.498, (1.635 sec/step)\n",
      "step 8827 - loss = 1.827, (1.114 sec/step)\n",
      "step 8828 - loss = 1.508, (2.314 sec/step)\n",
      "step 8829 - loss = 2.061, (2.290 sec/step)\n",
      "step 8830 - loss = 1.447, (1.899 sec/step)\n",
      "step 8831 - loss = 1.890, (2.135 sec/step)\n",
      "step 8832 - loss = 1.770, (1.837 sec/step)\n",
      "step 8833 - loss = 2.093, (2.377 sec/step)\n",
      "step 8834 - loss = 1.761, (1.702 sec/step)\n",
      "step 8835 - loss = 2.399, (1.636 sec/step)\n",
      "step 8836 - loss = 1.438, (1.745 sec/step)\n",
      "step 8837 - loss = 2.061, (2.483 sec/step)\n",
      "step 8838 - loss = 2.384, (2.214 sec/step)\n",
      "step 8839 - loss = 2.120, (2.069 sec/step)\n",
      "step 8840 - loss = 1.797, (3.317 sec/step)\n",
      "step 8841 - loss = 1.406, (1.559 sec/step)\n",
      "step 8842 - loss = 1.615, (1.405 sec/step)\n",
      "step 8843 - loss = 1.783, (1.037 sec/step)\n",
      "step 8844 - loss = 1.455, (1.821 sec/step)\n",
      "step 8845 - loss = 1.694, (1.682 sec/step)\n",
      "step 8846 - loss = 1.598, (1.151 sec/step)\n",
      "step 8847 - loss = 1.446, (2.487 sec/step)\n",
      "step 8848 - loss = 0.494, (1.255 sec/step)\n",
      "step 8849 - loss = 1.886, (1.213 sec/step)\n",
      "step 8850 - loss = 1.646, (1.560 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8851 - loss = 1.907, (0.930 sec/step)\n",
      "step 8852 - loss = 2.185, (2.471 sec/step)\n",
      "step 8853 - loss = 1.340, (1.684 sec/step)\n",
      "step 8854 - loss = 2.370, (2.766 sec/step)\n",
      "step 8855 - loss = 2.357, (1.496 sec/step)\n",
      "step 8856 - loss = 1.356, (1.383 sec/step)\n",
      "step 8857 - loss = 1.988, (0.958 sec/step)\n",
      "step 8858 - loss = 2.363, (2.073 sec/step)\n",
      "step 8859 - loss = 1.735, (1.054 sec/step)\n",
      "step 8860 - loss = 2.153, (1.063 sec/step)\n",
      "step 8861 - loss = 2.079, (1.377 sec/step)\n",
      "step 8862 - loss = 2.059, (1.070 sec/step)\n",
      "step 8863 - loss = 1.778, (1.129 sec/step)\n",
      "step 8864 - loss = 2.054, (2.414 sec/step)\n",
      "step 8865 - loss = 2.019, (1.711 sec/step)\n",
      "step 8866 - loss = 0.965, (1.346 sec/step)\n",
      "step 8867 - loss = 1.288, (1.159 sec/step)\n",
      "step 8868 - loss = 1.845, (0.941 sec/step)\n",
      "step 8869 - loss = 2.117, (1.296 sec/step)\n",
      "step 8870 - loss = 1.930, (2.889 sec/step)\n",
      "step 8871 - loss = 1.915, (2.968 sec/step)\n",
      "step 8872 - loss = 1.287, (1.052 sec/step)\n",
      "step 8873 - loss = 1.930, (1.779 sec/step)\n",
      "step 8874 - loss = 1.757, (1.393 sec/step)\n",
      "step 8875 - loss = 1.740, (1.328 sec/step)\n",
      "step 8876 - loss = 2.150, (1.259 sec/step)\n",
      "step 8877 - loss = 2.097, (3.446 sec/step)\n",
      "step 8878 - loss = 1.436, (2.289 sec/step)\n",
      "step 8879 - loss = 1.885, (1.683 sec/step)\n",
      "step 8880 - loss = 1.841, (1.633 sec/step)\n",
      "step 8881 - loss = 1.586, (1.492 sec/step)\n",
      "step 8882 - loss = 1.616, (2.573 sec/step)\n",
      "step 8883 - loss = 2.260, (1.573 sec/step)\n",
      "step 8884 - loss = 1.755, (1.488 sec/step)\n",
      "step 8885 - loss = 1.430, (2.089 sec/step)\n",
      "step 8886 - loss = 1.722, (1.385 sec/step)\n",
      "step 8887 - loss = 1.731, (2.288 sec/step)\n",
      "step 8888 - loss = 1.619, (1.252 sec/step)\n",
      "step 8889 - loss = 1.827, (1.936 sec/step)\n",
      "step 8890 - loss = 1.594, (1.213 sec/step)\n",
      "step 8891 - loss = 1.845, (2.414 sec/step)\n",
      "step 8892 - loss = 2.099, (1.150 sec/step)\n",
      "step 8893 - loss = 1.523, (1.167 sec/step)\n",
      "step 8894 - loss = 1.798, (2.581 sec/step)\n",
      "step 8895 - loss = 1.496, (1.607 sec/step)\n",
      "step 8896 - loss = 2.385, (1.161 sec/step)\n",
      "step 8897 - loss = 1.452, (2.578 sec/step)\n",
      "step 8898 - loss = 1.700, (1.334 sec/step)\n",
      "step 8899 - loss = 1.086, (1.226 sec/step)\n",
      "step 8900 - loss = 1.591, (1.084 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8901 - loss = 1.910, (1.000 sec/step)\n",
      "step 8902 - loss = 1.841, (0.934 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8903 - loss = 1.622, (1.390 sec/step)\n",
      "step 8904 - loss = 1.653, (1.180 sec/step)\n",
      "step 8905 - loss = 1.603, (2.827 sec/step)\n",
      "step 8906 - loss = 2.485, (1.590 sec/step)\n",
      "step 8907 - loss = 2.363, (1.497 sec/step)\n",
      "step 8908 - loss = 1.544, (1.818 sec/step)\n",
      "step 8909 - loss = 1.505, (1.548 sec/step)\n",
      "step 8910 - loss = 2.081, (1.993 sec/step)\n",
      "step 8911 - loss = 2.082, (1.971 sec/step)\n",
      "step 8912 - loss = 2.052, (1.068 sec/step)\n",
      "step 8913 - loss = 1.748, (1.631 sec/step)\n",
      "step 8914 - loss = 1.941, (1.559 sec/step)\n",
      "step 8915 - loss = 1.485, (1.497 sec/step)\n",
      "step 8916 - loss = 1.790, (1.482 sec/step)\n",
      "step 8917 - loss = 2.229, (1.542 sec/step)\n",
      "step 8918 - loss = 2.093, (1.606 sec/step)\n",
      "step 8919 - loss = 2.389, (1.001 sec/step)\n",
      "step 8920 - loss = 2.046, (1.888 sec/step)\n",
      "step 8921 - loss = 1.516, (1.736 sec/step)\n",
      "step 8922 - loss = 1.929, (1.647 sec/step)\n",
      "step 8923 - loss = 1.907, (1.158 sec/step)\n",
      "step 8924 - loss = 1.793, (0.987 sec/step)\n",
      "step 8925 - loss = 2.280, (0.868 sec/step)\n",
      "step 8926 - loss = 2.387, (2.902 sec/step)\n",
      "step 8927 - loss = 1.729, (2.005 sec/step)\n",
      "step 8928 - loss = 1.826, (1.143 sec/step)\n",
      "step 8929 - loss = 1.616, (2.325 sec/step)\n",
      "step 8930 - loss = 1.333, (1.652 sec/step)\n",
      "step 8931 - loss = 1.512, (1.373 sec/step)\n",
      "step 8932 - loss = 2.069, (1.503 sec/step)\n",
      "step 8933 - loss = 1.564, (2.431 sec/step)\n",
      "step 8934 - loss = 1.353, (0.760 sec/step)\n",
      "step 8935 - loss = 1.698, (1.426 sec/step)\n",
      "step 8936 - loss = 2.066, (1.247 sec/step)\n",
      "step 8937 - loss = 2.065, (1.542 sec/step)\n",
      "step 8938 - loss = 2.076, (1.099 sec/step)\n",
      "step 8939 - loss = 1.955, (1.620 sec/step)\n",
      "step 8940 - loss = 1.873, (1.250 sec/step)\n",
      "step 8941 - loss = 1.599, (1.677 sec/step)\n",
      "step 8942 - loss = 2.107, (1.527 sec/step)\n",
      "step 8943 - loss = 1.644, (1.408 sec/step)\n",
      "step 8944 - loss = 1.927, (1.932 sec/step)\n",
      "step 8945 - loss = 1.848, (2.983 sec/step)\n",
      "step 8946 - loss = 2.410, (1.332 sec/step)\n",
      "step 8947 - loss = 1.594, (1.016 sec/step)\n",
      "step 8948 - loss = 1.677, (0.954 sec/step)\n",
      "step 8949 - loss = 2.274, (1.446 sec/step)\n",
      "step 8950 - loss = 1.681, (2.244 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 8951 - loss = 2.251, (1.261 sec/step)\n",
      "step 8952 - loss = 1.639, (2.240 sec/step)\n",
      "step 8953 - loss = 1.753, (1.274 sec/step)\n",
      "step 8954 - loss = 1.682, (1.311 sec/step)\n",
      "step 8955 - loss = 2.221, (1.049 sec/step)\n",
      "step 8956 - loss = 1.780, (0.871 sec/step)\n",
      "step 8957 - loss = 1.989, (1.165 sec/step)\n",
      "step 8958 - loss = 1.540, (1.246 sec/step)\n",
      "step 8959 - loss = 2.205, (1.116 sec/step)\n",
      "step 8960 - loss = 2.149, (2.267 sec/step)\n",
      "step 8961 - loss = 1.858, (1.332 sec/step)\n",
      "step 8962 - loss = 1.709, (0.774 sec/step)\n",
      "step 8963 - loss = 1.701, (1.152 sec/step)\n",
      "step 8964 - loss = 1.444, (0.869 sec/step)\n",
      "step 8965 - loss = 2.461, (1.802 sec/step)\n",
      "step 8966 - loss = 1.729, (0.958 sec/step)\n",
      "step 8967 - loss = 1.863, (0.999 sec/step)\n",
      "step 8968 - loss = 1.650, (1.259 sec/step)\n",
      "step 8969 - loss = 1.516, (1.525 sec/step)\n",
      "step 8970 - loss = 1.442, (1.100 sec/step)\n",
      "step 8971 - loss = 1.683, (1.655 sec/step)\n",
      "step 8972 - loss = 2.180, (2.051 sec/step)\n",
      "step 8973 - loss = 1.884, (1.343 sec/step)\n",
      "step 8974 - loss = 1.661, (2.485 sec/step)\n",
      "step 8975 - loss = 1.667, (1.186 sec/step)\n",
      "step 8976 - loss = 1.272, (1.476 sec/step)\n",
      "step 8977 - loss = 1.808, (1.851 sec/step)\n",
      "step 8978 - loss = 1.735, (0.987 sec/step)\n",
      "step 8979 - loss = 1.550, (1.695 sec/step)\n",
      "step 8980 - loss = 1.752, (1.646 sec/step)\n",
      "step 8981 - loss = 1.252, (1.292 sec/step)\n",
      "step 8982 - loss = 2.098, (1.198 sec/step)\n",
      "step 8983 - loss = 1.919, (1.071 sec/step)\n",
      "step 8984 - loss = 1.737, (1.083 sec/step)\n",
      "step 8985 - loss = 1.914, (1.338 sec/step)\n",
      "step 8986 - loss = 1.537, (2.747 sec/step)\n",
      "step 8987 - loss = 2.121, (1.426 sec/step)\n",
      "step 8988 - loss = 1.740, (2.095 sec/step)\n",
      "step 8989 - loss = 1.550, (1.054 sec/step)\n",
      "step 8990 - loss = 1.578, (1.165 sec/step)\n",
      "step 8991 - loss = 1.698, (2.152 sec/step)\n",
      "step 8992 - loss = 1.799, (1.713 sec/step)\n",
      "step 8993 - loss = 1.380, (1.292 sec/step)\n",
      "step 8994 - loss = 1.563, (1.341 sec/step)\n",
      "step 8995 - loss = 1.713, (1.266 sec/step)\n",
      "step 8996 - loss = 2.079, (1.682 sec/step)\n",
      "step 8997 - loss = 1.925, (1.526 sec/step)\n",
      "step 8998 - loss = 2.128, (3.244 sec/step)\n",
      "step 8999 - loss = 1.545, (3.364 sec/step)\n",
      "step 9000 - loss = 1.191, (3.282 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9001 - loss = 1.647, (1.863 sec/step)\n",
      "step 9002 - loss = 1.652, (1.162 sec/step)\n",
      "step 9003 - loss = 1.674, (3.114 sec/step)\n",
      "step 9004 - loss = 1.521, (2.489 sec/step)\n",
      "step 9005 - loss = 2.304, (1.955 sec/step)\n",
      "step 9006 - loss = 1.564, (1.051 sec/step)\n",
      "step 9007 - loss = 1.597, (1.112 sec/step)\n",
      "step 9008 - loss = 1.812, (2.856 sec/step)\n",
      "step 9009 - loss = 1.893, (1.778 sec/step)\n",
      "step 9010 - loss = 1.908, (0.869 sec/step)\n",
      "step 9011 - loss = 1.774, (1.075 sec/step)\n",
      "step 9012 - loss = 1.333, (0.910 sec/step)\n",
      "step 9013 - loss = 2.070, (1.686 sec/step)\n",
      "step 9014 - loss = 2.353, (1.068 sec/step)\n",
      "step 9015 - loss = 1.920, (1.681 sec/step)\n",
      "step 9016 - loss = 1.885, (1.412 sec/step)\n",
      "step 9017 - loss = 2.198, (2.274 sec/step)\n",
      "step 9018 - loss = 1.445, (1.373 sec/step)\n",
      "step 9019 - loss = 1.664, (1.515 sec/step)\n",
      "step 9020 - loss = 1.920, (1.088 sec/step)\n",
      "step 9021 - loss = 1.954, (1.190 sec/step)\n",
      "step 9022 - loss = 2.673, (1.606 sec/step)\n",
      "step 9023 - loss = 1.769, (0.896 sec/step)\n",
      "step 9024 - loss = 1.682, (1.230 sec/step)\n",
      "step 9025 - loss = 1.939, (1.394 sec/step)\n",
      "step 9026 - loss = 1.986, (1.312 sec/step)\n",
      "step 9027 - loss = 2.233, (1.533 sec/step)\n",
      "step 9028 - loss = 1.701, (1.495 sec/step)\n",
      "step 9029 - loss = 1.505, (1.002 sec/step)\n",
      "step 9030 - loss = 1.559, (1.520 sec/step)\n",
      "step 9031 - loss = 1.984, (1.229 sec/step)\n",
      "step 9032 - loss = 1.657, (1.725 sec/step)\n",
      "step 9033 - loss = 1.358, (1.287 sec/step)\n",
      "step 9034 - loss = 1.706, (2.066 sec/step)\n",
      "step 9035 - loss = 1.833, (1.213 sec/step)\n",
      "step 9036 - loss = 2.088, (1.512 sec/step)\n",
      "step 9037 - loss = 1.872, (1.538 sec/step)\n",
      "step 9038 - loss = 1.705, (1.356 sec/step)\n",
      "step 9039 - loss = 1.752, (1.383 sec/step)\n",
      "step 9040 - loss = 1.371, (2.548 sec/step)\n",
      "step 9041 - loss = 2.611, (1.047 sec/step)\n",
      "step 9042 - loss = 1.463, (2.699 sec/step)\n",
      "step 9043 - loss = 2.228, (2.693 sec/step)\n",
      "step 9044 - loss = 1.433, (0.773 sec/step)\n",
      "step 9045 - loss = 2.341, (1.705 sec/step)\n",
      "step 9046 - loss = 1.874, (2.355 sec/step)\n",
      "step 9047 - loss = 1.745, (0.833 sec/step)\n",
      "step 9048 - loss = 1.884, (1.711 sec/step)\n",
      "step 9049 - loss = 1.699, (2.482 sec/step)\n",
      "step 9050 - loss = 1.678, (0.894 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9051 - loss = 1.691, (1.834 sec/step)\n",
      "step 9052 - loss = 2.337, (1.095 sec/step)\n",
      "step 9053 - loss = 1.669, (1.395 sec/step)\n",
      "step 9054 - loss = 1.930, (1.130 sec/step)\n",
      "step 9055 - loss = 2.246, (1.004 sec/step)\n",
      "step 9056 - loss = 2.041, (1.334 sec/step)\n",
      "step 9057 - loss = 1.695, (0.969 sec/step)\n",
      "step 9058 - loss = 1.959, (1.769 sec/step)\n",
      "step 9059 - loss = 1.821, (0.959 sec/step)\n",
      "step 9060 - loss = 1.793, (1.240 sec/step)\n",
      "step 9061 - loss = 2.183, (0.990 sec/step)\n",
      "step 9062 - loss = 1.588, (2.720 sec/step)\n",
      "step 9063 - loss = 1.603, (0.940 sec/step)\n",
      "step 9064 - loss = 2.221, (2.028 sec/step)\n",
      "step 9065 - loss = 1.308, (1.052 sec/step)\n",
      "step 9066 - loss = 1.846, (1.740 sec/step)\n",
      "step 9067 - loss = 1.423, (1.371 sec/step)\n",
      "step 9068 - loss = 1.417, (1.153 sec/step)\n",
      "step 9069 - loss = 1.594, (1.007 sec/step)\n",
      "step 9070 - loss = 1.772, (1.054 sec/step)\n",
      "step 9071 - loss = 1.365, (1.573 sec/step)\n",
      "step 9072 - loss = 2.226, (2.040 sec/step)\n",
      "step 9073 - loss = 2.227, (1.278 sec/step)\n",
      "step 9074 - loss = 2.525, (1.603 sec/step)\n",
      "step 9075 - loss = 2.098, (1.259 sec/step)\n",
      "step 9076 - loss = 1.622, (1.663 sec/step)\n",
      "step 9077 - loss = 1.476, (1.128 sec/step)\n",
      "step 9078 - loss = 1.753, (1.336 sec/step)\n",
      "step 9079 - loss = 1.731, (1.556 sec/step)\n",
      "step 9080 - loss = 1.928, (1.804 sec/step)\n",
      "step 9081 - loss = 2.136, (1.934 sec/step)\n",
      "step 9082 - loss = 1.723, (1.415 sec/step)\n",
      "step 9083 - loss = 2.217, (1.094 sec/step)\n",
      "step 9084 - loss = 1.817, (1.254 sec/step)\n",
      "step 9085 - loss = 2.406, (1.518 sec/step)\n",
      "step 9086 - loss = 1.960, (2.582 sec/step)\n",
      "step 9087 - loss = 1.912, (1.173 sec/step)\n",
      "step 9088 - loss = 1.209, (1.602 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9089 - loss = 1.800, (2.632 sec/step)\n",
      "step 9090 - loss = 2.077, (1.306 sec/step)\n",
      "step 9091 - loss = 1.713, (1.226 sec/step)\n",
      "step 9092 - loss = 1.825, (0.969 sec/step)\n",
      "step 9093 - loss = 2.452, (1.427 sec/step)\n",
      "step 9094 - loss = 1.747, (2.446 sec/step)\n",
      "step 9095 - loss = 2.182, (1.216 sec/step)\n",
      "step 9096 - loss = 1.265, (2.784 sec/step)\n",
      "step 9097 - loss = 1.688, (1.774 sec/step)\n",
      "step 9098 - loss = 1.236, (1.346 sec/step)\n",
      "step 9099 - loss = 1.697, (1.293 sec/step)\n",
      "step 9100 - loss = 1.781, (1.652 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9101 - loss = 1.886, (2.487 sec/step)\n",
      "step 9102 - loss = 1.964, (0.885 sec/step)\n",
      "step 9103 - loss = 1.531, (1.313 sec/step)\n",
      "step 9104 - loss = 1.932, (1.286 sec/step)\n",
      "step 9105 - loss = 1.469, (3.137 sec/step)\n",
      "step 9106 - loss = 2.079, (2.007 sec/step)\n",
      "step 9107 - loss = 2.045, (2.789 sec/step)\n",
      "step 9108 - loss = 1.968, (1.803 sec/step)\n",
      "step 9109 - loss = 1.643, (1.210 sec/step)\n",
      "step 9110 - loss = 2.069, (1.377 sec/step)\n",
      "step 9111 - loss = 2.275, (1.893 sec/step)\n",
      "step 9112 - loss = 1.766, (2.395 sec/step)\n",
      "step 9113 - loss = 1.771, (2.609 sec/step)\n",
      "step 9114 - loss = 2.034, (1.150 sec/step)\n",
      "step 9115 - loss = 1.860, (1.336 sec/step)\n",
      "step 9116 - loss = 1.763, (1.447 sec/step)\n",
      "step 9117 - loss = 1.593, (1.967 sec/step)\n",
      "step 9118 - loss = 1.816, (1.731 sec/step)\n",
      "step 9119 - loss = 1.822, (1.273 sec/step)\n",
      "step 9120 - loss = 2.412, (2.484 sec/step)\n",
      "step 9121 - loss = 2.245, (2.685 sec/step)\n",
      "step 9122 - loss = 1.424, (1.705 sec/step)\n",
      "step 9123 - loss = 1.759, (1.973 sec/step)\n",
      "step 9124 - loss = 2.175, (1.653 sec/step)\n",
      "step 9125 - loss = 2.317, (0.858 sec/step)\n",
      "step 9126 - loss = 1.566, (1.268 sec/step)\n",
      "step 9127 - loss = 1.928, (1.538 sec/step)\n",
      "step 9128 - loss = 1.736, (1.164 sec/step)\n",
      "step 9129 - loss = 1.804, (1.227 sec/step)\n",
      "step 9130 - loss = 1.997, (1.128 sec/step)\n",
      "step 9131 - loss = 2.236, (1.752 sec/step)\n",
      "step 9132 - loss = 1.942, (1.126 sec/step)\n",
      "step 9133 - loss = 2.114, (1.529 sec/step)\n",
      "step 9134 - loss = 1.976, (1.415 sec/step)\n",
      "step 9135 - loss = 1.929, (2.155 sec/step)\n",
      "step 9136 - loss = 2.245, (2.485 sec/step)\n",
      "step 9137 - loss = 0.730, (0.199 sec/step)\n",
      "step 9138 - loss = 1.703, (1.713 sec/step)\n",
      "step 9139 - loss = 1.922, (1.049 sec/step)\n",
      "step 9140 - loss = 1.368, (1.513 sec/step)\n",
      "step 9141 - loss = 1.485, (1.530 sec/step)\n",
      "step 9142 - loss = 1.182, (1.573 sec/step)\n",
      "step 9143 - loss = 1.221, (1.312 sec/step)\n",
      "step 9144 - loss = 1.715, (1.507 sec/step)\n",
      "step 9145 - loss = 2.223, (2.482 sec/step)\n",
      "step 9146 - loss = 1.085, (0.694 sec/step)\n",
      "step 9147 - loss = 1.252, (2.577 sec/step)\n",
      "step 9148 - loss = 1.600, (1.067 sec/step)\n",
      "step 9149 - loss = 2.168, (1.401 sec/step)\n",
      "step 9150 - loss = 2.067, (1.556 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9151 - loss = 1.355, (0.959 sec/step)\n",
      "step 9152 - loss = 1.906, (1.943 sec/step)\n",
      "step 9153 - loss = 2.309, (1.209 sec/step)\n",
      "step 9154 - loss = 1.958, (2.689 sec/step)\n",
      "step 9155 - loss = 2.189, (1.358 sec/step)\n",
      "step 9156 - loss = 1.340, (1.017 sec/step)\n",
      "step 9157 - loss = 2.132, (1.281 sec/step)\n",
      "step 9158 - loss = 1.707, (1.996 sec/step)\n",
      "step 9159 - loss = 2.344, (1.314 sec/step)\n",
      "step 9160 - loss = 1.504, (1.313 sec/step)\n",
      "step 9161 - loss = 2.037, (1.403 sec/step)\n",
      "step 9162 - loss = 1.988, (1.065 sec/step)\n",
      "step 9163 - loss = 1.907, (1.100 sec/step)\n",
      "step 9164 - loss = 1.625, (2.224 sec/step)\n",
      "step 9165 - loss = 1.835, (1.035 sec/step)\n",
      "step 9166 - loss = 2.175, (2.016 sec/step)\n",
      "step 9167 - loss = 1.679, (0.939 sec/step)\n",
      "step 9168 - loss = 1.938, (2.489 sec/step)\n",
      "step 9169 - loss = 1.964, (1.795 sec/step)\n",
      "step 9170 - loss = 2.241, (1.658 sec/step)\n",
      "step 9171 - loss = 1.987, (1.065 sec/step)\n",
      "step 9172 - loss = 2.106, (1.229 sec/step)\n",
      "step 9173 - loss = 2.080, (3.109 sec/step)\n",
      "step 9174 - loss = 2.216, (1.252 sec/step)\n",
      "step 9175 - loss = 2.013, (1.226 sec/step)\n",
      "step 9176 - loss = 1.887, (2.485 sec/step)\n",
      "step 9177 - loss = 1.768, (2.400 sec/step)\n",
      "step 9178 - loss = 1.978, (1.283 sec/step)\n",
      "step 9179 - loss = 2.021, (2.579 sec/step)\n",
      "step 9180 - loss = 1.435, (1.428 sec/step)\n",
      "step 9181 - loss = 2.052, (1.312 sec/step)\n",
      "step 9182 - loss = 1.729, (2.645 sec/step)\n",
      "step 9183 - loss = 1.414, (1.163 sec/step)\n",
      "step 9184 - loss = 1.330, (2.518 sec/step)\n",
      "step 9185 - loss = 1.533, (1.155 sec/step)\n",
      "step 9186 - loss = 2.264, (2.485 sec/step)\n",
      "step 9187 - loss = 1.927, (1.674 sec/step)\n",
      "step 9188 - loss = 1.406, (2.177 sec/step)\n",
      "step 9189 - loss = 2.199, (1.999 sec/step)\n",
      "step 9190 - loss = 2.448, (1.492 sec/step)\n",
      "step 9191 - loss = 1.609, (1.556 sec/step)\n",
      "step 9192 - loss = 1.791, (1.400 sec/step)\n",
      "step 9193 - loss = 1.875, (1.420 sec/step)\n",
      "step 9194 - loss = 1.315, (1.245 sec/step)\n",
      "step 9195 - loss = 1.633, (1.107 sec/step)\n",
      "step 9196 - loss = 1.720, (0.986 sec/step)\n",
      "step 9197 - loss = 1.092, (2.482 sec/step)\n",
      "step 9198 - loss = 0.605, (0.166 sec/step)\n",
      "step 9199 - loss = 2.599, (2.481 sec/step)\n",
      "step 9200 - loss = 2.154, (2.019 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9201 - loss = 1.432, (1.102 sec/step)\n",
      "step 9202 - loss = 1.775, (1.512 sec/step)\n",
      "step 9203 - loss = 1.805, (1.905 sec/step)\n",
      "step 9204 - loss = 1.867, (1.027 sec/step)\n",
      "step 9205 - loss = 1.644, (1.201 sec/step)\n",
      "step 9206 - loss = 2.065, (2.664 sec/step)\n",
      "step 9207 - loss = 2.111, (1.311 sec/step)\n",
      "step 9208 - loss = 1.614, (2.369 sec/step)\n",
      "step 9209 - loss = 1.546, (1.882 sec/step)\n",
      "step 9210 - loss = 1.679, (1.230 sec/step)\n",
      "step 9211 - loss = 1.710, (2.482 sec/step)\n",
      "step 9212 - loss = 1.768, (1.048 sec/step)\n",
      "step 9213 - loss = 1.628, (1.947 sec/step)\n",
      "step 9214 - loss = 1.903, (2.968 sec/step)\n",
      "step 9215 - loss = 1.367, (1.536 sec/step)\n",
      "step 9216 - loss = 2.181, (1.478 sec/step)\n",
      "step 9217 - loss = 1.571, (0.644 sec/step)\n",
      "step 9218 - loss = 1.787, (1.585 sec/step)\n",
      "step 9219 - loss = 2.212, (1.687 sec/step)\n",
      "step 9220 - loss = 2.078, (1.277 sec/step)\n",
      "step 9221 - loss = 1.385, (3.156 sec/step)\n",
      "step 9222 - loss = 1.873, (0.805 sec/step)\n",
      "step 9223 - loss = 1.245, (1.180 sec/step)\n",
      "step 9224 - loss = 1.862, (1.952 sec/step)\n",
      "step 9225 - loss = 1.321, (1.373 sec/step)\n",
      "step 9226 - loss = 1.602, (2.825 sec/step)\n",
      "step 9227 - loss = 1.870, (1.179 sec/step)\n",
      "step 9228 - loss = 2.066, (1.171 sec/step)\n",
      "step 9229 - loss = 1.122, (1.160 sec/step)\n",
      "step 9230 - loss = 2.050, (1.605 sec/step)\n",
      "step 9231 - loss = 1.727, (2.568 sec/step)\n",
      "step 9232 - loss = 1.606, (1.161 sec/step)\n",
      "step 9233 - loss = 2.032, (1.036 sec/step)\n",
      "step 9234 - loss = 1.581, (1.574 sec/step)\n",
      "step 9235 - loss = 1.835, (2.485 sec/step)\n",
      "step 9236 - loss = 1.753, (1.368 sec/step)\n",
      "step 9237 - loss = 0.954, (2.187 sec/step)\n",
      "step 9238 - loss = 1.808, (1.405 sec/step)\n",
      "step 9239 - loss = 2.290, (1.762 sec/step)\n",
      "step 9240 - loss = 2.292, (1.874 sec/step)\n",
      "step 9241 - loss = 1.323, (1.243 sec/step)\n",
      "step 9242 - loss = 2.200, (1.746 sec/step)\n",
      "step 9243 - loss = 1.794, (0.999 sec/step)\n",
      "step 9244 - loss = 1.516, (1.553 sec/step)\n",
      "step 9245 - loss = 1.408, (1.294 sec/step)\n",
      "step 9246 - loss = 1.677, (1.192 sec/step)\n",
      "step 9247 - loss = 1.815, (1.646 sec/step)\n",
      "step 9248 - loss = 1.426, (1.160 sec/step)\n",
      "step 9249 - loss = 1.776, (1.099 sec/step)\n",
      "step 9250 - loss = 2.092, (1.343 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9251 - loss = 1.577, (0.965 sec/step)\n",
      "step 9252 - loss = 1.876, (0.861 sec/step)\n",
      "step 9253 - loss = 1.507, (1.292 sec/step)\n",
      "step 9254 - loss = 2.082, (1.331 sec/step)\n",
      "step 9255 - loss = 1.600, (0.971 sec/step)\n",
      "step 9256 - loss = 1.615, (1.896 sec/step)\n",
      "step 9257 - loss = 1.575, (0.957 sec/step)\n",
      "step 9258 - loss = 1.861, (0.926 sec/step)\n",
      "step 9259 - loss = 1.380, (0.783 sec/step)\n",
      "step 9260 - loss = 1.675, (2.147 sec/step)\n",
      "step 9261 - loss = 1.415, (1.301 sec/step)\n",
      "step 9262 - loss = 2.002, (1.029 sec/step)\n",
      "step 9263 - loss = 1.354, (1.653 sec/step)\n",
      "step 9264 - loss = 1.829, (1.739 sec/step)\n",
      "step 9265 - loss = 2.262, (1.002 sec/step)\n",
      "step 9266 - loss = 1.541, (1.394 sec/step)\n",
      "step 9267 - loss = 2.359, (1.521 sec/step)\n",
      "step 9268 - loss = 1.964, (2.379 sec/step)\n",
      "step 9269 - loss = 1.801, (1.729 sec/step)\n",
      "step 9270 - loss = 1.831, (1.479 sec/step)\n",
      "step 9271 - loss = 1.727, (1.334 sec/step)\n",
      "step 9272 - loss = 1.777, (1.513 sec/step)\n",
      "step 9273 - loss = 1.580, (1.656 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9274 - loss = 2.069, (1.740 sec/step)\n",
      "step 9275 - loss = 2.028, (1.846 sec/step)\n",
      "step 9276 - loss = 1.868, (1.722 sec/step)\n",
      "step 9277 - loss = 1.668, (2.282 sec/step)\n",
      "step 9278 - loss = 1.724, (1.334 sec/step)\n",
      "step 9279 - loss = 1.958, (1.087 sec/step)\n",
      "step 9280 - loss = 1.883, (1.357 sec/step)\n",
      "step 9281 - loss = 1.765, (1.298 sec/step)\n",
      "step 9282 - loss = 1.855, (1.294 sec/step)\n",
      "step 9283 - loss = 1.937, (1.329 sec/step)\n",
      "step 9284 - loss = 1.373, (1.560 sec/step)\n",
      "step 9285 - loss = 1.791, (1.524 sec/step)\n",
      "step 9286 - loss = 2.281, (1.781 sec/step)\n",
      "step 9287 - loss = 1.498, (0.819 sec/step)\n",
      "step 9288 - loss = 1.374, (2.109 sec/step)\n",
      "step 9289 - loss = 1.712, (1.039 sec/step)\n",
      "step 9290 - loss = 1.462, (1.698 sec/step)\n",
      "step 9291 - loss = 1.821, (2.485 sec/step)\n",
      "step 9292 - loss = 0.633, (0.711 sec/step)\n",
      "step 9293 - loss = 1.752, (1.427 sec/step)\n",
      "step 9294 - loss = 1.846, (1.148 sec/step)\n",
      "step 9295 - loss = 1.766, (1.185 sec/step)\n",
      "step 9296 - loss = 1.422, (1.935 sec/step)\n",
      "step 9297 - loss = 1.342, (2.195 sec/step)\n",
      "step 9298 - loss = 1.720, (2.218 sec/step)\n",
      "step 9299 - loss = 2.186, (1.492 sec/step)\n",
      "step 9300 - loss = 1.537, (1.713 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9301 - loss = 1.199, (2.348 sec/step)\n",
      "step 9302 - loss = 1.459, (1.001 sec/step)\n",
      "step 9303 - loss = 1.275, (0.999 sec/step)\n",
      "step 9304 - loss = 1.522, (1.152 sec/step)\n",
      "step 9305 - loss = 1.583, (1.487 sec/step)\n",
      "step 9306 - loss = 1.775, (2.461 sec/step)\n",
      "step 9307 - loss = 1.566, (1.158 sec/step)\n",
      "step 9308 - loss = 1.744, (1.085 sec/step)\n",
      "step 9309 - loss = 2.275, (1.069 sec/step)\n",
      "step 9310 - loss = 1.925, (1.922 sec/step)\n",
      "step 9311 - loss = 1.809, (2.747 sec/step)\n",
      "step 9312 - loss = 1.220, (2.486 sec/step)\n",
      "step 9313 - loss = 0.720, (0.215 sec/step)\n",
      "step 9314 - loss = 2.263, (1.854 sec/step)\n",
      "step 9315 - loss = 1.816, (1.347 sec/step)\n",
      "step 9316 - loss = 2.342, (2.484 sec/step)\n",
      "step 9317 - loss = 2.753, (1.483 sec/step)\n",
      "step 9318 - loss = 1.581, (2.122 sec/step)\n",
      "step 9319 - loss = 2.277, (1.517 sec/step)\n",
      "step 9320 - loss = 1.530, (1.819 sec/step)\n",
      "step 9321 - loss = 1.546, (1.658 sec/step)\n",
      "step 9322 - loss = 1.589, (0.923 sec/step)\n",
      "step 9323 - loss = 1.752, (1.067 sec/step)\n",
      "step 9324 - loss = 2.159, (1.100 sec/step)\n",
      "step 9325 - loss = 2.040, (1.703 sec/step)\n",
      "step 9326 - loss = 2.400, (2.483 sec/step)\n",
      "step 9327 - loss = 1.864, (1.213 sec/step)\n",
      "step 9328 - loss = 2.239, (1.445 sec/step)\n",
      "step 9329 - loss = 1.807, (2.825 sec/step)\n",
      "step 9330 - loss = 1.834, (1.237 sec/step)\n",
      "step 9331 - loss = 2.108, (2.808 sec/step)\n",
      "step 9332 - loss = 1.734, (1.101 sec/step)\n",
      "step 9333 - loss = 1.933, (1.407 sec/step)\n",
      "step 9334 - loss = 1.761, (1.500 sec/step)\n",
      "step 9335 - loss = 1.870, (2.491 sec/step)\n",
      "step 9336 - loss = 2.384, (1.990 sec/step)\n",
      "step 9337 - loss = 1.829, (2.340 sec/step)\n",
      "step 9338 - loss = 1.681, (1.621 sec/step)\n",
      "step 9339 - loss = 2.139, (1.251 sec/step)\n",
      "step 9340 - loss = 1.901, (1.291 sec/step)\n",
      "step 9341 - loss = 2.296, (1.723 sec/step)\n",
      "step 9342 - loss = 1.675, (2.594 sec/step)\n",
      "step 9343 - loss = 1.978, (2.483 sec/step)\n",
      "step 9344 - loss = 0.565, (0.652 sec/step)\n",
      "step 9345 - loss = 2.757, (2.483 sec/step)\n",
      "step 9346 - loss = 1.674, (2.322 sec/step)\n",
      "step 9347 - loss = 1.857, (1.273 sec/step)\n",
      "step 9348 - loss = 2.141, (0.968 sec/step)\n",
      "step 9349 - loss = 2.513, (1.654 sec/step)\n",
      "step 9350 - loss = 2.081, (1.792 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9351 - loss = 1.676, (2.275 sec/step)\n",
      "step 9352 - loss = 1.919, (2.097 sec/step)\n",
      "step 9353 - loss = 1.806, (1.146 sec/step)\n",
      "step 9354 - loss = 1.626, (1.223 sec/step)\n",
      "step 9355 - loss = 1.715, (2.019 sec/step)\n",
      "step 9356 - loss = 1.672, (1.970 sec/step)\n",
      "step 9357 - loss = 2.156, (1.439 sec/step)\n",
      "step 9358 - loss = 1.626, (2.393 sec/step)\n",
      "step 9359 - loss = 1.674, (1.725 sec/step)\n",
      "step 9360 - loss = 2.115, (2.058 sec/step)\n",
      "step 9361 - loss = 2.366, (1.563 sec/step)\n",
      "step 9362 - loss = 1.836, (1.182 sec/step)\n",
      "step 9363 - loss = 1.316, (1.636 sec/step)\n",
      "step 9364 - loss = 2.337, (1.331 sec/step)\n",
      "step 9365 - loss = 1.904, (1.491 sec/step)\n",
      "step 9366 - loss = 1.906, (1.259 sec/step)\n",
      "step 9367 - loss = 2.336, (1.035 sec/step)\n",
      "step 9368 - loss = 1.965, (1.408 sec/step)\n",
      "step 9369 - loss = 2.235, (2.559 sec/step)\n",
      "step 9370 - loss = 1.379, (1.049 sec/step)\n",
      "step 9371 - loss = 1.466, (1.745 sec/step)\n",
      "step 9372 - loss = 1.484, (2.017 sec/step)\n",
      "step 9373 - loss = 1.356, (1.567 sec/step)\n",
      "step 9374 - loss = 1.699, (2.660 sec/step)\n",
      "step 9375 - loss = 2.068, (1.941 sec/step)\n",
      "step 9376 - loss = 1.501, (1.429 sec/step)\n",
      "step 9377 - loss = 1.511, (1.243 sec/step)\n",
      "step 9378 - loss = 1.839, (1.692 sec/step)\n",
      "step 9379 - loss = 1.465, (1.230 sec/step)\n",
      "step 9380 - loss = 1.750, (1.649 sec/step)\n",
      "step 9381 - loss = 1.703, (1.148 sec/step)\n",
      "step 9382 - loss = 2.060, (0.825 sec/step)\n",
      "step 9383 - loss = 1.644, (1.683 sec/step)\n",
      "step 9384 - loss = 1.735, (1.820 sec/step)\n",
      "step 9385 - loss = 1.687, (0.910 sec/step)\n",
      "step 9386 - loss = 1.295, (1.074 sec/step)\n",
      "step 9387 - loss = 1.741, (1.106 sec/step)\n",
      "step 9388 - loss = 2.092, (1.526 sec/step)\n",
      "step 9389 - loss = 2.319, (2.484 sec/step)\n",
      "step 9390 - loss = 1.095, (1.340 sec/step)\n",
      "step 9391 - loss = 1.867, (3.553 sec/step)\n",
      "step 9392 - loss = 1.348, (2.861 sec/step)\n",
      "step 9393 - loss = 1.978, (1.233 sec/step)\n",
      "step 9394 - loss = 2.111, (2.485 sec/step)\n",
      "step 9395 - loss = 2.044, (1.434 sec/step)\n",
      "step 9396 - loss = 1.668, (1.561 sec/step)\n",
      "step 9397 - loss = 1.862, (1.953 sec/step)\n",
      "step 9398 - loss = 2.474, (1.513 sec/step)\n",
      "step 9399 - loss = 1.979, (1.845 sec/step)\n",
      "step 9400 - loss = 1.245, (1.248 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9401 - loss = 2.453, (1.345 sec/step)\n",
      "step 9402 - loss = 1.583, (1.888 sec/step)\n",
      "step 9403 - loss = 1.250, (1.222 sec/step)\n",
      "step 9404 - loss = 2.039, (1.855 sec/step)\n",
      "step 9405 - loss = 1.370, (1.780 sec/step)\n",
      "step 9406 - loss = 1.678, (1.358 sec/step)\n",
      "step 9407 - loss = 1.686, (1.261 sec/step)\n",
      "step 9408 - loss = 2.017, (1.646 sec/step)\n",
      "step 9409 - loss = 1.791, (1.457 sec/step)\n",
      "step 9410 - loss = 2.171, (1.901 sec/step)\n",
      "step 9411 - loss = 2.150, (1.215 sec/step)\n",
      "step 9412 - loss = 1.790, (2.597 sec/step)\n",
      "step 9413 - loss = 1.179, (1.312 sec/step)\n",
      "step 9414 - loss = 1.732, (2.019 sec/step)\n",
      "step 9415 - loss = 1.621, (2.323 sec/step)\n",
      "step 9416 - loss = 2.148, (1.496 sec/step)\n",
      "step 9417 - loss = 1.682, (3.218 sec/step)\n",
      "step 9418 - loss = 1.676, (1.341 sec/step)\n",
      "step 9419 - loss = 1.619, (2.465 sec/step)\n",
      "step 9420 - loss = 1.250, (1.941 sec/step)\n",
      "step 9421 - loss = 1.806, (1.106 sec/step)\n",
      "step 9422 - loss = 1.753, (1.935 sec/step)\n",
      "step 9423 - loss = 1.706, (1.153 sec/step)\n",
      "step 9424 - loss = 1.690, (1.378 sec/step)\n",
      "step 9425 - loss = 1.711, (1.242 sec/step)\n",
      "step 9426 - loss = 1.736, (1.086 sec/step)\n",
      "step 9427 - loss = 2.015, (1.151 sec/step)\n",
      "step 9428 - loss = 1.669, (1.100 sec/step)\n",
      "step 9429 - loss = 2.133, (1.411 sec/step)\n",
      "step 9430 - loss = 2.083, (1.952 sec/step)\n",
      "step 9431 - loss = 1.923, (2.330 sec/step)\n",
      "step 9432 - loss = 2.095, (1.522 sec/step)\n",
      "step 9433 - loss = 1.731, (1.473 sec/step)\n",
      "step 9434 - loss = 1.774, (0.857 sec/step)\n",
      "step 9435 - loss = 1.836, (1.480 sec/step)\n",
      "step 9436 - loss = 1.403, (1.051 sec/step)\n",
      "step 9437 - loss = 1.782, (1.225 sec/step)\n",
      "step 9438 - loss = 1.763, (1.293 sec/step)\n",
      "step 9439 - loss = 1.840, (2.047 sec/step)\n",
      "step 9440 - loss = 1.846, (1.315 sec/step)\n",
      "step 9441 - loss = 1.702, (2.281 sec/step)\n",
      "step 9442 - loss = 2.393, (2.486 sec/step)\n",
      "step 9443 - loss = 1.161, (1.516 sec/step)\n",
      "step 9444 - loss = 1.480, (1.053 sec/step)\n",
      "step 9445 - loss = 1.537, (2.487 sec/step)\n",
      "step 9446 - loss = 1.679, (0.351 sec/step)\n",
      "step 9447 - loss = 1.420, (1.200 sec/step)\n",
      "step 9448 - loss = 2.279, (2.485 sec/step)\n",
      "step 9449 - loss = 2.220, (2.488 sec/step)\n",
      "step 9450 - loss = 1.998, (1.160 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9451 - loss = 2.191, (2.485 sec/step)\n",
      "step 9452 - loss = 2.044, (2.313 sec/step)\n",
      "step 9453 - loss = 1.692, (1.648 sec/step)\n",
      "step 9454 - loss = 1.581, (1.328 sec/step)\n",
      "step 9455 - loss = 1.280, (1.014 sec/step)\n",
      "step 9456 - loss = 1.728, (2.289 sec/step)\n",
      "step 9457 - loss = 2.098, (1.099 sec/step)\n",
      "step 9458 - loss = 1.883, (1.178 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9459 - loss = 1.729, (1.785 sec/step)\n",
      "step 9460 - loss = 2.457, (1.431 sec/step)\n",
      "step 9461 - loss = 1.719, (1.476 sec/step)\n",
      "step 9462 - loss = 2.012, (2.145 sec/step)\n",
      "step 9463 - loss = 1.976, (2.545 sec/step)\n",
      "step 9464 - loss = 1.446, (1.148 sec/step)\n",
      "step 9465 - loss = 2.049, (1.629 sec/step)\n",
      "step 9466 - loss = 1.728, (2.486 sec/step)\n",
      "step 9467 - loss = 0.632, (0.462 sec/step)\n",
      "step 9468 - loss = 1.908, (1.156 sec/step)\n",
      "step 9469 - loss = 2.155, (1.499 sec/step)\n",
      "step 9470 - loss = 2.100, (2.811 sec/step)\n",
      "step 9471 - loss = 1.701, (1.087 sec/step)\n",
      "step 9472 - loss = 1.909, (2.483 sec/step)\n",
      "step 9473 - loss = 1.201, (0.365 sec/step)\n",
      "step 9474 - loss = 1.953, (2.243 sec/step)\n",
      "step 9475 - loss = 2.544, (1.050 sec/step)\n",
      "step 9476 - loss = 1.795, (1.208 sec/step)\n",
      "step 9477 - loss = 1.671, (2.605 sec/step)\n",
      "step 9478 - loss = 1.393, (1.444 sec/step)\n",
      "step 9479 - loss = 1.960, (1.702 sec/step)\n",
      "step 9480 - loss = 2.051, (0.926 sec/step)\n",
      "step 9481 - loss = 1.683, (1.169 sec/step)\n",
      "step 9482 - loss = 1.644, (0.923 sec/step)\n",
      "step 9483 - loss = 1.697, (1.115 sec/step)\n",
      "step 9484 - loss = 2.398, (1.159 sec/step)\n",
      "step 9485 - loss = 1.997, (2.292 sec/step)\n",
      "step 9486 - loss = 1.548, (1.315 sec/step)\n",
      "step 9487 - loss = 1.329, (1.394 sec/step)\n",
      "step 9488 - loss = 1.938, (1.937 sec/step)\n",
      "step 9489 - loss = 1.637, (1.099 sec/step)\n",
      "step 9490 - loss = 1.636, (1.074 sec/step)\n",
      "step 9491 - loss = 1.660, (1.359 sec/step)\n",
      "step 9492 - loss = 1.737, (1.107 sec/step)\n",
      "step 9493 - loss = 1.935, (1.201 sec/step)\n",
      "step 9494 - loss = 2.279, (1.603 sec/step)\n",
      "step 9495 - loss = 1.451, (0.804 sec/step)\n",
      "step 9496 - loss = 2.060, (2.081 sec/step)\n",
      "step 9497 - loss = 1.633, (1.940 sec/step)\n",
      "step 9498 - loss = 1.945, (1.475 sec/step)\n",
      "step 9499 - loss = 1.501, (0.755 sec/step)\n",
      "step 9500 - loss = 1.936, (1.255 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9501 - loss = 2.102, (2.160 sec/step)\n",
      "step 9502 - loss = 1.982, (1.568 sec/step)\n",
      "step 9503 - loss = 1.916, (1.354 sec/step)\n",
      "step 9504 - loss = 2.244, (1.344 sec/step)\n",
      "step 9505 - loss = 2.072, (2.486 sec/step)\n",
      "step 9506 - loss = 2.268, (2.485 sec/step)\n",
      "step 9507 - loss = 1.085, (1.132 sec/step)\n",
      "step 9508 - loss = 2.041, (1.474 sec/step)\n",
      "step 9509 - loss = 1.487, (1.160 sec/step)\n",
      "step 9510 - loss = 1.488, (1.146 sec/step)\n",
      "step 9511 - loss = 1.424, (0.939 sec/step)\n",
      "step 9512 - loss = 1.874, (1.497 sec/step)\n",
      "step 9513 - loss = 2.411, (2.484 sec/step)\n",
      "step 9514 - loss = 2.177, (1.650 sec/step)\n",
      "step 9515 - loss = 2.034, (1.356 sec/step)\n",
      "step 9516 - loss = 1.910, (1.742 sec/step)\n",
      "step 9517 - loss = 1.341, (2.485 sec/step)\n",
      "step 9518 - loss = 0.547, (0.961 sec/step)\n",
      "step 9519 - loss = 2.144, (1.295 sec/step)\n",
      "step 9520 - loss = 1.875, (1.095 sec/step)\n",
      "step 9521 - loss = 1.694, (1.360 sec/step)\n",
      "step 9522 - loss = 2.050, (1.330 sec/step)\n",
      "step 9523 - loss = 1.588, (1.151 sec/step)\n",
      "step 9524 - loss = 1.608, (1.517 sec/step)\n",
      "step 9525 - loss = 2.084, (1.179 sec/step)\n",
      "step 9526 - loss = 1.385, (1.853 sec/step)\n",
      "step 9527 - loss = 1.377, (1.823 sec/step)\n",
      "step 9528 - loss = 2.190, (1.085 sec/step)\n",
      "step 9529 - loss = 1.356, (1.460 sec/step)\n",
      "step 9530 - loss = 1.386, (1.160 sec/step)\n",
      "step 9531 - loss = 1.595, (1.092 sec/step)\n",
      "step 9532 - loss = 1.716, (1.098 sec/step)\n",
      "step 9533 - loss = 1.751, (1.973 sec/step)\n",
      "step 9534 - loss = 1.863, (1.150 sec/step)\n",
      "step 9535 - loss = 1.894, (1.292 sec/step)\n",
      "step 9536 - loss = 1.682, (1.596 sec/step)\n",
      "step 9537 - loss = 2.143, (1.323 sec/step)\n",
      "step 9538 - loss = 1.614, (2.355 sec/step)\n",
      "step 9539 - loss = 1.804, (1.597 sec/step)\n",
      "step 9540 - loss = 1.877, (1.429 sec/step)\n",
      "step 9541 - loss = 2.090, (1.123 sec/step)\n",
      "step 9542 - loss = 2.173, (1.766 sec/step)\n",
      "step 9543 - loss = 2.054, (1.771 sec/step)\n",
      "step 9544 - loss = 1.783, (1.181 sec/step)\n",
      "step 9545 - loss = 2.545, (1.972 sec/step)\n",
      "step 9546 - loss = 1.248, (1.806 sec/step)\n",
      "step 9547 - loss = 1.707, (1.654 sec/step)\n",
      "step 9548 - loss = 1.706, (1.151 sec/step)\n",
      "step 9549 - loss = 1.746, (1.129 sec/step)\n",
      "step 9550 - loss = 1.916, (1.019 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9551 - loss = 1.876, (1.259 sec/step)\n",
      "step 9552 - loss = 1.942, (1.357 sec/step)\n",
      "step 9553 - loss = 1.799, (1.277 sec/step)\n",
      "step 9554 - loss = 1.265, (1.030 sec/step)\n",
      "step 9555 - loss = 2.358, (1.193 sec/step)\n",
      "step 9556 - loss = 1.740, (1.968 sec/step)\n",
      "step 9557 - loss = 1.478, (1.865 sec/step)\n",
      "step 9558 - loss = 2.418, (1.526 sec/step)\n",
      "step 9559 - loss = 1.774, (1.161 sec/step)\n",
      "step 9560 - loss = 1.991, (1.116 sec/step)\n",
      "step 9561 - loss = 1.253, (1.313 sec/step)\n",
      "step 9562 - loss = 1.307, (1.085 sec/step)\n",
      "step 9563 - loss = 1.802, (1.031 sec/step)\n",
      "step 9564 - loss = 1.433, (1.888 sec/step)\n",
      "step 9565 - loss = 1.580, (1.472 sec/step)\n",
      "step 9566 - loss = 1.788, (1.159 sec/step)\n",
      "step 9567 - loss = 1.590, (1.253 sec/step)\n",
      "step 9568 - loss = 1.427, (1.016 sec/step)\n",
      "step 9569 - loss = 1.488, (2.485 sec/step)\n",
      "step 9570 - loss = 1.725, (1.084 sec/step)\n",
      "step 9571 - loss = 1.678, (1.076 sec/step)\n",
      "step 9572 - loss = 1.757, (1.729 sec/step)\n",
      "step 9573 - loss = 1.519, (0.972 sec/step)\n",
      "step 9574 - loss = 1.839, (1.360 sec/step)\n",
      "step 9575 - loss = 1.361, (1.710 sec/step)\n",
      "step 9576 - loss = 1.898, (1.134 sec/step)\n",
      "step 9577 - loss = 1.575, (1.172 sec/step)\n",
      "step 9578 - loss = 1.662, (1.441 sec/step)\n",
      "step 9579 - loss = 2.046, (1.608 sec/step)\n",
      "step 9580 - loss = 1.949, (1.564 sec/step)\n",
      "step 9581 - loss = 1.771, (1.222 sec/step)\n",
      "step 9582 - loss = 1.408, (1.027 sec/step)\n",
      "step 9583 - loss = 1.838, (1.016 sec/step)\n",
      "step 9584 - loss = 1.886, (2.103 sec/step)\n",
      "step 9585 - loss = 1.885, (3.133 sec/step)\n",
      "step 9586 - loss = 1.757, (1.386 sec/step)\n",
      "step 9587 - loss = 2.008, (0.970 sec/step)\n",
      "step 9588 - loss = 2.074, (2.139 sec/step)\n",
      "step 9589 - loss = 1.468, (1.127 sec/step)\n",
      "step 9590 - loss = 1.397, (1.030 sec/step)\n",
      "step 9591 - loss = 1.826, (0.940 sec/step)\n",
      "step 9592 - loss = 1.564, (1.163 sec/step)\n",
      "step 9593 - loss = 1.718, (1.198 sec/step)\n",
      "step 9594 - loss = 2.483, (1.363 sec/step)\n",
      "step 9595 - loss = 1.685, (2.202 sec/step)\n",
      "step 9596 - loss = 2.209, (1.780 sec/step)\n",
      "step 9597 - loss = 2.052, (2.198 sec/step)\n",
      "step 9598 - loss = 2.517, (1.447 sec/step)\n",
      "step 9599 - loss = 1.733, (1.575 sec/step)\n",
      "step 9600 - loss = 1.878, (1.200 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9601 - loss = 2.448, (2.394 sec/step)\n",
      "step 9602 - loss = 1.537, (1.177 sec/step)\n",
      "step 9603 - loss = 1.952, (1.473 sec/step)\n",
      "step 9604 - loss = 1.885, (2.821 sec/step)\n",
      "step 9605 - loss = 1.626, (1.444 sec/step)\n",
      "step 9606 - loss = 1.984, (1.017 sec/step)\n",
      "step 9607 - loss = 1.874, (1.327 sec/step)\n",
      "step 9608 - loss = 1.747, (1.913 sec/step)\n",
      "step 9609 - loss = 1.335, (1.513 sec/step)\n",
      "step 9610 - loss = 1.744, (1.127 sec/step)\n",
      "step 9611 - loss = 1.599, (0.970 sec/step)\n",
      "step 9612 - loss = 1.203, (1.397 sec/step)\n",
      "step 9613 - loss = 1.860, (2.483 sec/step)\n",
      "step 9614 - loss = 0.615, (1.244 sec/step)\n",
      "step 9615 - loss = 1.814, (2.013 sec/step)\n",
      "step 9616 - loss = 2.075, (0.914 sec/step)\n",
      "step 9617 - loss = 1.976, (1.134 sec/step)\n",
      "step 9618 - loss = 2.316, (1.885 sec/step)\n",
      "step 9619 - loss = 2.148, (1.337 sec/step)\n",
      "step 9620 - loss = 1.748, (1.071 sec/step)\n",
      "step 9621 - loss = 1.763, (1.114 sec/step)\n",
      "step 9622 - loss = 1.747, (2.487 sec/step)\n",
      "step 9623 - loss = 0.690, (0.321 sec/step)\n",
      "step 9624 - loss = 1.922, (0.958 sec/step)\n",
      "step 9625 - loss = 2.165, (0.968 sec/step)\n",
      "step 9626 - loss = 2.023, (1.561 sec/step)\n",
      "step 9627 - loss = 1.596, (2.353 sec/step)\n",
      "step 9628 - loss = 1.217, (1.460 sec/step)\n",
      "step 9629 - loss = 2.022, (0.982 sec/step)\n",
      "step 9630 - loss = 1.920, (1.245 sec/step)\n",
      "step 9631 - loss = 2.169, (2.486 sec/step)\n",
      "step 9632 - loss = 1.183, (0.273 sec/step)\n",
      "step 9633 - loss = 1.599, (1.107 sec/step)\n",
      "step 9634 - loss = 1.656, (2.275 sec/step)\n",
      "step 9635 - loss = 1.537, (0.777 sec/step)\n",
      "step 9636 - loss = 2.136, (2.290 sec/step)\n",
      "step 9637 - loss = 1.445, (1.450 sec/step)\n",
      "step 9638 - loss = 2.126, (1.571 sec/step)\n",
      "step 9639 - loss = 1.801, (1.405 sec/step)\n",
      "step 9640 - loss = 1.324, (0.913 sec/step)\n",
      "step 9641 - loss = 2.137, (1.013 sec/step)\n",
      "step 9642 - loss = 2.048, (1.475 sec/step)\n",
      "step 9643 - loss = 1.790, (1.917 sec/step)\n",
      "step 9644 - loss = 1.693, (1.074 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9645 - loss = 2.142, (2.660 sec/step)\n",
      "step 9646 - loss = 1.866, (1.219 sec/step)\n",
      "step 9647 - loss = 1.929, (1.573 sec/step)\n",
      "step 9648 - loss = 2.060, (1.315 sec/step)\n",
      "step 9649 - loss = 1.931, (2.412 sec/step)\n",
      "step 9650 - loss = 1.838, (2.483 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9651 - loss = 2.454, (1.650 sec/step)\n",
      "step 9652 - loss = 1.942, (1.013 sec/step)\n",
      "step 9653 - loss = 2.312, (1.786 sec/step)\n",
      "step 9654 - loss = 1.835, (1.520 sec/step)\n",
      "step 9655 - loss = 1.123, (1.445 sec/step)\n",
      "step 9656 - loss = 1.322, (1.331 sec/step)\n",
      "step 9657 - loss = 1.967, (2.486 sec/step)\n",
      "step 9658 - loss = 2.024, (2.485 sec/step)\n",
      "step 9659 - loss = 0.793, (0.819 sec/step)\n",
      "step 9660 - loss = 2.193, (2.230 sec/step)\n",
      "step 9661 - loss = 1.796, (1.407 sec/step)\n",
      "step 9662 - loss = 1.372, (1.492 sec/step)\n",
      "step 9663 - loss = 1.828, (1.261 sec/step)\n",
      "step 9664 - loss = 2.300, (1.377 sec/step)\n",
      "step 9665 - loss = 1.885, (1.386 sec/step)\n",
      "step 9666 - loss = 1.317, (1.034 sec/step)\n",
      "step 9667 - loss = 1.428, (1.003 sec/step)\n",
      "step 9668 - loss = 1.960, (2.172 sec/step)\n",
      "step 9669 - loss = 1.462, (1.283 sec/step)\n",
      "step 9670 - loss = 1.906, (2.089 sec/step)\n",
      "step 9671 - loss = 2.112, (1.396 sec/step)\n",
      "step 9672 - loss = 1.817, (2.714 sec/step)\n",
      "step 9673 - loss = 1.617, (1.265 sec/step)\n",
      "step 9674 - loss = 1.666, (1.277 sec/step)\n",
      "step 9675 - loss = 1.699, (1.476 sec/step)\n",
      "step 9676 - loss = 1.650, (1.976 sec/step)\n",
      "step 9677 - loss = 1.963, (1.574 sec/step)\n",
      "step 9678 - loss = 1.832, (1.390 sec/step)\n",
      "step 9679 - loss = 1.910, (1.142 sec/step)\n",
      "step 9680 - loss = 1.850, (2.103 sec/step)\n",
      "step 9681 - loss = 1.775, (1.384 sec/step)\n",
      "step 9682 - loss = 2.110, (1.987 sec/step)\n",
      "step 9683 - loss = 1.269, (1.115 sec/step)\n",
      "step 9684 - loss = 1.729, (0.940 sec/step)\n",
      "step 9685 - loss = 1.778, (1.396 sec/step)\n",
      "step 9686 - loss = 2.009, (2.224 sec/step)\n",
      "step 9687 - loss = 1.722, (1.208 sec/step)\n",
      "step 9688 - loss = 2.176, (1.348 sec/step)\n",
      "step 9689 - loss = 1.421, (2.333 sec/step)\n",
      "step 9690 - loss = 1.779, (1.354 sec/step)\n",
      "step 9691 - loss = 1.450, (2.802 sec/step)\n",
      "step 9692 - loss = 2.024, (1.357 sec/step)\n",
      "step 9693 - loss = 1.230, (1.407 sec/step)\n",
      "step 9694 - loss = 2.326, (2.317 sec/step)\n",
      "step 9695 - loss = 1.565, (1.346 sec/step)\n",
      "step 9696 - loss = 2.077, (1.178 sec/step)\n",
      "step 9697 - loss = 1.808, (1.799 sec/step)\n",
      "step 9698 - loss = 2.408, (2.420 sec/step)\n",
      "step 9699 - loss = 2.273, (1.728 sec/step)\n",
      "step 9700 - loss = 2.056, (2.858 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9701 - loss = 2.134, (1.028 sec/step)\n",
      "step 9702 - loss = 1.939, (1.407 sec/step)\n",
      "step 9703 - loss = 1.138, (1.602 sec/step)\n",
      "step 9704 - loss = 1.412, (0.944 sec/step)\n",
      "step 9705 - loss = 1.613, (1.376 sec/step)\n",
      "step 9706 - loss = 1.871, (1.246 sec/step)\n",
      "step 9707 - loss = 2.092, (1.796 sec/step)\n",
      "step 9708 - loss = 1.908, (1.469 sec/step)\n",
      "step 9709 - loss = 2.208, (1.100 sec/step)\n",
      "step 9710 - loss = 2.678, (0.987 sec/step)\n",
      "step 9711 - loss = 1.791, (1.014 sec/step)\n",
      "step 9712 - loss = 1.676, (1.771 sec/step)\n",
      "step 9713 - loss = 1.280, (1.309 sec/step)\n",
      "step 9714 - loss = 1.564, (1.649 sec/step)\n",
      "step 9715 - loss = 1.997, (1.493 sec/step)\n",
      "step 9716 - loss = 1.696, (1.259 sec/step)\n",
      "step 9717 - loss = 1.773, (0.987 sec/step)\n",
      "step 9718 - loss = 1.732, (1.153 sec/step)\n",
      "step 9719 - loss = 1.765, (2.532 sec/step)\n",
      "step 9720 - loss = 1.530, (1.594 sec/step)\n",
      "step 9721 - loss = 1.382, (1.202 sec/step)\n",
      "step 9722 - loss = 1.253, (1.557 sec/step)\n",
      "step 9723 - loss = 1.429, (1.642 sec/step)\n",
      "step 9724 - loss = 1.579, (1.541 sec/step)\n",
      "step 9725 - loss = 1.454, (2.115 sec/step)\n",
      "step 9726 - loss = 1.313, (1.408 sec/step)\n",
      "step 9727 - loss = 1.778, (1.092 sec/step)\n",
      "step 9728 - loss = 2.624, (3.491 sec/step)\n",
      "step 9729 - loss = 2.177, (1.250 sec/step)\n",
      "step 9730 - loss = 1.831, (1.498 sec/step)\n",
      "step 9731 - loss = 2.014, (1.034 sec/step)\n",
      "step 9732 - loss = 1.473, (1.012 sec/step)\n",
      "step 9733 - loss = 1.882, (0.939 sec/step)\n",
      "step 9734 - loss = 2.164, (1.293 sec/step)\n",
      "step 9735 - loss = 1.276, (1.954 sec/step)\n",
      "step 9736 - loss = 2.363, (1.867 sec/step)\n",
      "step 9737 - loss = 2.012, (1.781 sec/step)\n",
      "step 9738 - loss = 1.674, (1.180 sec/step)\n",
      "step 9739 - loss = 2.257, (1.831 sec/step)\n",
      "step 9740 - loss = 1.406, (1.458 sec/step)\n",
      "step 9741 - loss = 1.991, (1.275 sec/step)\n",
      "step 9742 - loss = 1.930, (1.522 sec/step)\n",
      "step 9743 - loss = 1.532, (1.889 sec/step)\n",
      "step 9744 - loss = 1.275, (1.656 sec/step)\n",
      "step 9745 - loss = 1.532, (1.125 sec/step)\n",
      "step 9746 - loss = 1.578, (1.959 sec/step)\n",
      "step 9747 - loss = 1.380, (0.776 sec/step)\n",
      "step 9748 - loss = 2.324, (1.029 sec/step)\n",
      "step 9749 - loss = 1.272, (0.953 sec/step)\n",
      "step 9750 - loss = 2.023, (2.033 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9751 - loss = 1.734, (2.349 sec/step)\n",
      "step 9752 - loss = 2.025, (2.455 sec/step)\n",
      "step 9753 - loss = 1.731, (2.722 sec/step)\n",
      "step 9754 - loss = 1.861, (2.389 sec/step)\n",
      "step 9755 - loss = 1.755, (1.529 sec/step)\n",
      "step 9756 - loss = 1.376, (0.924 sec/step)\n",
      "step 9757 - loss = 1.587, (2.297 sec/step)\n",
      "step 9758 - loss = 1.783, (1.479 sec/step)\n",
      "step 9759 - loss = 1.878, (1.285 sec/step)\n",
      "step 9760 - loss = 2.293, (1.337 sec/step)\n",
      "step 9761 - loss = 1.927, (1.526 sec/step)\n",
      "step 9762 - loss = 1.932, (1.481 sec/step)\n",
      "step 9763 - loss = 1.647, (0.957 sec/step)\n",
      "step 9764 - loss = 2.027, (1.200 sec/step)\n",
      "step 9765 - loss = 1.312, (1.272 sec/step)\n",
      "step 9766 - loss = 1.850, (1.606 sec/step)\n",
      "step 9767 - loss = 1.296, (2.544 sec/step)\n",
      "step 9768 - loss = 1.277, (1.955 sec/step)\n",
      "step 9769 - loss = 1.729, (1.734 sec/step)\n",
      "step 9770 - loss = 1.648, (0.941 sec/step)\n",
      "step 9771 - loss = 1.710, (1.280 sec/step)\n",
      "step 9772 - loss = 1.615, (1.226 sec/step)\n",
      "step 9773 - loss = 1.396, (1.495 sec/step)\n",
      "step 9774 - loss = 2.236, (2.108 sec/step)\n",
      "step 9775 - loss = 1.413, (1.296 sec/step)\n",
      "step 9776 - loss = 2.219, (1.317 sec/step)\n",
      "step 9777 - loss = 1.587, (0.710 sec/step)\n",
      "step 9778 - loss = 1.745, (1.105 sec/step)\n",
      "step 9779 - loss = 1.716, (0.969 sec/step)\n",
      "step 9780 - loss = 1.539, (1.158 sec/step)\n",
      "step 9781 - loss = 2.428, (3.082 sec/step)\n",
      "step 9782 - loss = 1.760, (1.425 sec/step)\n",
      "step 9783 - loss = 1.327, (1.427 sec/step)\n",
      "step 9784 - loss = 2.061, (1.199 sec/step)\n",
      "step 9785 - loss = 1.705, (1.394 sec/step)\n",
      "step 9786 - loss = 1.793, (1.037 sec/step)\n",
      "step 9787 - loss = 1.893, (1.070 sec/step)\n",
      "step 9788 - loss = 1.665, (2.690 sec/step)\n",
      "step 9789 - loss = 1.718, (1.068 sec/step)\n",
      "step 9790 - loss = 1.912, (1.128 sec/step)\n",
      "step 9791 - loss = 1.754, (1.493 sec/step)\n",
      "step 9792 - loss = 1.684, (1.016 sec/step)\n",
      "step 9793 - loss = 1.692, (1.993 sec/step)\n",
      "step 9794 - loss = 2.075, (1.118 sec/step)\n",
      "step 9795 - loss = 2.089, (1.125 sec/step)\n",
      "step 9796 - loss = 1.839, (1.225 sec/step)\n",
      "step 9797 - loss = 2.570, (2.068 sec/step)\n",
      "step 9798 - loss = 2.000, (1.437 sec/step)\n",
      "step 9799 - loss = 1.858, (1.226 sec/step)\n",
      "step 9800 - loss = 1.707, (1.830 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9801 - loss = 1.317, (1.826 sec/step)\n",
      "step 9802 - loss = 1.816, (1.155 sec/step)\n",
      "step 9803 - loss = 1.526, (2.377 sec/step)\n",
      "step 9804 - loss = 1.565, (1.480 sec/step)\n",
      "step 9805 - loss = 1.609, (1.968 sec/step)\n",
      "step 9806 - loss = 1.437, (1.431 sec/step)\n",
      "step 9807 - loss = 1.197, (2.482 sec/step)\n",
      "step 9808 - loss = 0.550, (1.128 sec/step)\n",
      "step 9809 - loss = 1.695, (0.910 sec/step)\n",
      "step 9810 - loss = 1.969, (1.307 sec/step)\n",
      "step 9811 - loss = 1.558, (2.477 sec/step)\n",
      "step 9812 - loss = 1.817, (1.623 sec/step)\n",
      "step 9813 - loss = 1.719, (1.167 sec/step)\n",
      "step 9814 - loss = 1.712, (1.124 sec/step)\n",
      "step 9815 - loss = 1.676, (2.174 sec/step)\n",
      "step 9816 - loss = 1.398, (1.412 sec/step)\n",
      "step 9817 - loss = 1.641, (1.283 sec/step)\n",
      "step 9818 - loss = 2.413, (1.272 sec/step)\n",
      "step 9819 - loss = 1.816, (1.156 sec/step)\n",
      "step 9820 - loss = 1.816, (2.281 sec/step)\n",
      "step 9821 - loss = 1.581, (1.067 sec/step)\n",
      "step 9822 - loss = 1.633, (1.257 sec/step)\n",
      "step 9823 - loss = 1.325, (1.574 sec/step)\n",
      "step 9824 - loss = 1.512, (1.895 sec/step)\n",
      "step 9825 - loss = 1.697, (1.425 sec/step)\n",
      "step 9826 - loss = 1.597, (1.275 sec/step)\n",
      "step 9827 - loss = 1.388, (1.326 sec/step)\n",
      "step 9828 - loss = 1.659, (1.651 sec/step)\n",
      "step 9829 - loss = 1.501, (1.756 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9830 - loss = 2.211, (1.457 sec/step)\n",
      "step 9831 - loss = 1.502, (1.464 sec/step)\n",
      "step 9832 - loss = 2.065, (1.744 sec/step)\n",
      "step 9833 - loss = 1.552, (1.480 sec/step)\n",
      "step 9834 - loss = 2.166, (1.271 sec/step)\n",
      "step 9835 - loss = 1.870, (1.372 sec/step)\n",
      "step 9836 - loss = 1.916, (1.050 sec/step)\n",
      "step 9837 - loss = 1.335, (1.391 sec/step)\n",
      "step 9838 - loss = 2.458, (1.386 sec/step)\n",
      "step 9839 - loss = 1.499, (2.258 sec/step)\n",
      "step 9840 - loss = 1.634, (1.525 sec/step)\n",
      "step 9841 - loss = 2.095, (1.368 sec/step)\n",
      "step 9842 - loss = 1.604, (1.729 sec/step)\n",
      "step 9843 - loss = 1.908, (1.392 sec/step)\n",
      "step 9844 - loss = 1.715, (2.154 sec/step)\n",
      "step 9845 - loss = 1.877, (1.828 sec/step)\n",
      "step 9846 - loss = 1.471, (2.199 sec/step)\n",
      "step 9847 - loss = 1.856, (1.245 sec/step)\n",
      "step 9848 - loss = 1.636, (1.095 sec/step)\n",
      "step 9849 - loss = 1.488, (3.107 sec/step)\n",
      "step 9850 - loss = 2.007, (2.328 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9851 - loss = 2.030, (1.731 sec/step)\n",
      "step 9852 - loss = 1.814, (2.591 sec/step)\n",
      "step 9853 - loss = 2.205, (1.868 sec/step)\n",
      "step 9854 - loss = 1.243, (1.765 sec/step)\n",
      "step 9855 - loss = 2.097, (2.140 sec/step)\n",
      "step 9856 - loss = 1.855, (1.088 sec/step)\n",
      "step 9857 - loss = 1.495, (1.124 sec/step)\n",
      "step 9858 - loss = 1.590, (1.174 sec/step)\n",
      "step 9859 - loss = 2.120, (1.274 sec/step)\n",
      "step 9860 - loss = 2.209, (1.355 sec/step)\n",
      "step 9861 - loss = 1.804, (1.097 sec/step)\n",
      "step 9862 - loss = 1.888, (1.654 sec/step)\n",
      "step 9863 - loss = 1.390, (1.256 sec/step)\n",
      "step 9864 - loss = 2.008, (1.848 sec/step)\n",
      "step 9865 - loss = 1.259, (1.157 sec/step)\n",
      "step 9866 - loss = 1.867, (1.374 sec/step)\n",
      "step 9867 - loss = 1.882, (1.561 sec/step)\n",
      "step 9868 - loss = 2.144, (2.096 sec/step)\n",
      "step 9869 - loss = 1.566, (1.194 sec/step)\n",
      "step 9870 - loss = 1.650, (1.706 sec/step)\n",
      "step 9871 - loss = 2.386, (1.297 sec/step)\n",
      "step 9872 - loss = 1.719, (0.956 sec/step)\n",
      "step 9873 - loss = 1.548, (1.292 sec/step)\n",
      "step 9874 - loss = 1.656, (0.940 sec/step)\n",
      "step 9875 - loss = 1.649, (1.250 sec/step)\n",
      "step 9876 - loss = 1.450, (0.956 sec/step)\n",
      "step 9877 - loss = 1.964, (1.257 sec/step)\n",
      "step 9878 - loss = 1.930, (1.481 sec/step)\n",
      "step 9879 - loss = 2.146, (1.644 sec/step)\n",
      "step 9880 - loss = 1.686, (0.898 sec/step)\n",
      "step 9881 - loss = 1.874, (1.071 sec/step)\n",
      "step 9882 - loss = 1.859, (1.555 sec/step)\n",
      "step 9883 - loss = 2.003, (1.173 sec/step)\n",
      "step 9884 - loss = 2.009, (1.212 sec/step)\n",
      "step 9885 - loss = 1.273, (2.088 sec/step)\n",
      "step 9886 - loss = 1.802, (1.260 sec/step)\n",
      "step 9887 - loss = 1.857, (1.146 sec/step)\n",
      "step 9888 - loss = 1.517, (0.997 sec/step)\n",
      "step 9889 - loss = 1.869, (1.893 sec/step)\n",
      "step 9890 - loss = 1.779, (1.803 sec/step)\n",
      "step 9891 - loss = 1.369, (1.002 sec/step)\n",
      "step 9892 - loss = 1.698, (1.229 sec/step)\n",
      "step 9893 - loss = 2.077, (1.345 sec/step)\n",
      "step 9894 - loss = 1.840, (2.018 sec/step)\n",
      "step 9895 - loss = 1.503, (1.490 sec/step)\n",
      "step 9896 - loss = 1.873, (1.768 sec/step)\n",
      "step 9897 - loss = 1.277, (2.200 sec/step)\n",
      "step 9898 - loss = 1.842, (1.199 sec/step)\n",
      "step 9899 - loss = 1.855, (1.543 sec/step)\n",
      "step 9900 - loss = 2.053, (1.160 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9901 - loss = 1.989, (1.033 sec/step)\n",
      "step 9902 - loss = 1.985, (1.923 sec/step)\n",
      "step 9903 - loss = 1.624, (1.128 sec/step)\n",
      "step 9904 - loss = 1.449, (1.289 sec/step)\n",
      "step 9905 - loss = 2.209, (2.483 sec/step)\n",
      "step 9906 - loss = 1.831, (0.982 sec/step)\n",
      "step 9907 - loss = 2.133, (1.680 sec/step)\n",
      "step 9908 - loss = 2.229, (3.325 sec/step)\n",
      "step 9909 - loss = 1.685, (2.018 sec/step)\n",
      "step 9910 - loss = 2.457, (1.219 sec/step)\n",
      "step 9911 - loss = 2.053, (2.485 sec/step)\n",
      "step 9912 - loss = 2.518, (2.855 sec/step)\n",
      "step 9913 - loss = 1.663, (1.587 sec/step)\n",
      "step 9914 - loss = 2.455, (1.428 sec/step)\n",
      "step 9915 - loss = 1.478, (1.085 sec/step)\n",
      "step 9916 - loss = 1.769, (1.476 sec/step)\n",
      "step 9917 - loss = 2.309, (1.179 sec/step)\n",
      "step 9918 - loss = 1.946, (1.648 sec/step)\n",
      "step 9919 - loss = 1.992, (2.011 sec/step)\n",
      "step 9920 - loss = 2.484, (2.243 sec/step)\n",
      "step 9921 - loss = 1.785, (1.319 sec/step)\n",
      "step 9922 - loss = 2.163, (2.038 sec/step)\n",
      "step 9923 - loss = 1.702, (1.557 sec/step)\n",
      "step 9924 - loss = 2.099, (1.282 sec/step)\n",
      "step 9925 - loss = 2.018, (1.227 sec/step)\n",
      "step 9926 - loss = 1.742, (1.767 sec/step)\n",
      "step 9927 - loss = 1.675, (1.180 sec/step)\n",
      "step 9928 - loss = 1.809, (2.485 sec/step)\n",
      "step 9929 - loss = 1.074, (1.570 sec/step)\n",
      "step 9930 - loss = 2.104, (2.195 sec/step)\n",
      "step 9931 - loss = 2.078, (1.479 sec/step)\n",
      "step 9932 - loss = 1.714, (2.343 sec/step)\n",
      "step 9933 - loss = 2.231, (1.376 sec/step)\n",
      "step 9934 - loss = 2.050, (1.090 sec/step)\n",
      "step 9935 - loss = 2.346, (1.315 sec/step)\n",
      "step 9936 - loss = 1.442, (1.895 sec/step)\n",
      "step 9937 - loss = 1.726, (1.057 sec/step)\n",
      "step 9938 - loss = 2.049, (1.362 sec/step)\n",
      "step 9939 - loss = 1.478, (1.574 sec/step)\n",
      "step 9940 - loss = 1.630, (1.458 sec/step)\n",
      "step 9941 - loss = 1.603, (1.093 sec/step)\n",
      "step 9942 - loss = 1.835, (2.089 sec/step)\n",
      "step 9943 - loss = 2.224, (1.936 sec/step)\n",
      "step 9944 - loss = 2.109, (1.190 sec/step)\n",
      "step 9945 - loss = 2.131, (2.600 sec/step)\n",
      "step 9946 - loss = 1.905, (1.158 sec/step)\n",
      "step 9947 - loss = 1.700, (1.345 sec/step)\n",
      "step 9948 - loss = 1.437, (1.065 sec/step)\n",
      "step 9949 - loss = 1.745, (2.038 sec/step)\n",
      "step 9950 - loss = 2.389, (1.393 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 9951 - loss = 1.357, (0.841 sec/step)\n",
      "step 9952 - loss = 2.181, (1.093 sec/step)\n",
      "step 9953 - loss = 1.604, (1.937 sec/step)\n",
      "step 9954 - loss = 2.139, (1.357 sec/step)\n",
      "step 9955 - loss = 1.732, (2.083 sec/step)\n",
      "step 9956 - loss = 1.221, (1.256 sec/step)\n",
      "step 9957 - loss = 1.524, (1.700 sec/step)\n",
      "step 9958 - loss = 1.954, (1.921 sec/step)\n",
      "step 9959 - loss = 1.706, (1.495 sec/step)\n",
      "step 9960 - loss = 2.069, (1.339 sec/step)\n",
      "step 9961 - loss = 1.791, (1.395 sec/step)\n",
      "step 9962 - loss = 1.586, (1.918 sec/step)\n",
      "step 9963 - loss = 1.753, (1.098 sec/step)\n",
      "step 9964 - loss = 2.379, (1.243 sec/step)\n",
      "step 9965 - loss = 1.649, (1.864 sec/step)\n",
      "step 9966 - loss = 1.946, (1.200 sec/step)\n",
      "step 9967 - loss = 1.607, (1.515 sec/step)\n",
      "step 9968 - loss = 1.466, (0.789 sec/step)\n",
      "step 9969 - loss = 1.617, (1.278 sec/step)\n",
      "step 9970 - loss = 1.912, (1.680 sec/step)\n",
      "step 9971 - loss = 2.036, (1.653 sec/step)\n",
      "step 9972 - loss = 1.843, (1.276 sec/step)\n",
      "step 9973 - loss = 1.687, (1.410 sec/step)\n",
      "step 9974 - loss = 1.732, (1.015 sec/step)\n",
      "step 9975 - loss = 2.045, (1.515 sec/step)\n",
      "step 9976 - loss = 2.323, (2.338 sec/step)\n",
      "step 9977 - loss = 2.278, (1.890 sec/step)\n",
      "step 9978 - loss = 1.502, (0.926 sec/step)\n",
      "step 9979 - loss = 2.008, (1.623 sec/step)\n",
      "step 9980 - loss = 1.779, (1.500 sec/step)\n",
      "step 9981 - loss = 1.250, (1.274 sec/step)\n",
      "step 9982 - loss = 1.782, (2.192 sec/step)\n",
      "step 9983 - loss = 2.222, (2.863 sec/step)\n",
      "step 9984 - loss = 1.955, (1.278 sec/step)\n",
      "step 9985 - loss = 1.754, (1.511 sec/step)\n",
      "step 9986 - loss = 2.028, (0.970 sec/step)\n",
      "step 9987 - loss = 1.578, (1.970 sec/step)\n",
      "step 9988 - loss = 1.291, (1.409 sec/step)\n",
      "step 9989 - loss = 1.763, (1.342 sec/step)\n",
      "step 9990 - loss = 2.050, (1.392 sec/step)\n",
      "step 9991 - loss = 1.556, (1.727 sec/step)\n",
      "step 9992 - loss = 1.659, (1.993 sec/step)\n",
      "step 9993 - loss = 2.035, (1.442 sec/step)\n",
      "step 9994 - loss = 1.901, (1.393 sec/step)\n",
      "step 9995 - loss = 1.989, (1.102 sec/step)\n",
      "step 9996 - loss = 1.492, (2.483 sec/step)\n",
      "step 9997 - loss = 2.145, (0.720 sec/step)\n",
      "step 9998 - loss = 1.656, (1.276 sec/step)\n",
      "step 9999 - loss = 2.306, (2.126 sec/step)\n",
      "step 10000 - loss = 1.749, (1.125 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10001 - loss = 1.455, (1.480 sec/step)\n",
      "step 10002 - loss = 2.156, (2.267 sec/step)\n",
      "step 10003 - loss = 1.802, (3.407 sec/step)\n",
      "step 10004 - loss = 2.009, (1.362 sec/step)\n",
      "step 10005 - loss = 1.714, (1.053 sec/step)\n",
      "step 10006 - loss = 1.598, (1.067 sec/step)\n",
      "step 10007 - loss = 2.152, (1.258 sec/step)\n",
      "step 10008 - loss = 1.877, (1.426 sec/step)\n",
      "step 10009 - loss = 1.947, (1.258 sec/step)\n",
      "step 10010 - loss = 1.581, (1.605 sec/step)\n",
      "step 10011 - loss = 2.043, (1.541 sec/step)\n",
      "step 10012 - loss = 1.831, (1.033 sec/step)\n",
      "step 10013 - loss = 1.400, (1.385 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10014 - loss = 1.950, (1.161 sec/step)\n",
      "step 10015 - loss = 1.871, (1.474 sec/step)\n",
      "step 10016 - loss = 1.709, (2.995 sec/step)\n",
      "step 10017 - loss = 2.494, (0.922 sec/step)\n",
      "step 10018 - loss = 2.137, (2.482 sec/step)\n",
      "step 10019 - loss = 0.583, (0.693 sec/step)\n",
      "step 10020 - loss = 1.956, (1.569 sec/step)\n",
      "step 10021 - loss = 2.266, (1.441 sec/step)\n",
      "step 10022 - loss = 1.787, (1.389 sec/step)\n",
      "step 10023 - loss = 1.371, (1.888 sec/step)\n",
      "step 10024 - loss = 1.876, (1.701 sec/step)\n",
      "step 10025 - loss = 1.669, (1.125 sec/step)\n",
      "step 10026 - loss = 1.640, (1.256 sec/step)\n",
      "step 10027 - loss = 2.108, (1.278 sec/step)\n",
      "step 10028 - loss = 1.864, (1.644 sec/step)\n",
      "step 10029 - loss = 1.961, (1.331 sec/step)\n",
      "step 10030 - loss = 1.882, (1.410 sec/step)\n",
      "step 10031 - loss = 2.149, (1.472 sec/step)\n",
      "step 10032 - loss = 1.402, (2.042 sec/step)\n",
      "step 10033 - loss = 1.283, (2.416 sec/step)\n",
      "step 10034 - loss = 2.358, (2.485 sec/step)\n",
      "step 10035 - loss = 1.736, (1.528 sec/step)\n",
      "step 10036 - loss = 2.043, (1.120 sec/step)\n",
      "step 10037 - loss = 2.208, (1.574 sec/step)\n",
      "step 10038 - loss = 2.177, (1.608 sec/step)\n",
      "step 10039 - loss = 1.603, (1.309 sec/step)\n",
      "step 10040 - loss = 1.545, (1.015 sec/step)\n",
      "step 10041 - loss = 1.693, (2.269 sec/step)\n",
      "step 10042 - loss = 2.487, (1.572 sec/step)\n",
      "step 10043 - loss = 1.428, (2.536 sec/step)\n",
      "step 10044 - loss = 1.708, (1.887 sec/step)\n",
      "step 10045 - loss = 1.768, (0.939 sec/step)\n",
      "step 10046 - loss = 1.703, (2.369 sec/step)\n",
      "step 10047 - loss = 2.373, (1.848 sec/step)\n",
      "step 10048 - loss = 1.420, (1.354 sec/step)\n",
      "step 10049 - loss = 1.898, (0.923 sec/step)\n",
      "step 10050 - loss = 1.974, (1.311 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10051 - loss = 1.516, (1.723 sec/step)\n",
      "step 10052 - loss = 2.157, (1.494 sec/step)\n",
      "step 10053 - loss = 1.730, (1.230 sec/step)\n",
      "step 10054 - loss = 1.945, (1.743 sec/step)\n",
      "step 10055 - loss = 1.764, (1.245 sec/step)\n",
      "step 10056 - loss = 1.712, (2.488 sec/step)\n",
      "step 10057 - loss = 0.881, (2.769 sec/step)\n",
      "step 10058 - loss = 1.539, (1.656 sec/step)\n",
      "step 10059 - loss = 1.562, (1.305 sec/step)\n",
      "step 10060 - loss = 1.710, (1.181 sec/step)\n",
      "step 10061 - loss = 1.650, (2.158 sec/step)\n",
      "step 10062 - loss = 2.053, (1.635 sec/step)\n",
      "step 10063 - loss = 2.356, (0.963 sec/step)\n",
      "step 10064 - loss = 1.624, (1.321 sec/step)\n",
      "step 10065 - loss = 1.980, (2.487 sec/step)\n",
      "step 10066 - loss = 0.889, (0.632 sec/step)\n",
      "step 10067 - loss = 2.321, (1.710 sec/step)\n",
      "step 10068 - loss = 2.037, (1.636 sec/step)\n",
      "step 10069 - loss = 1.913, (2.000 sec/step)\n",
      "step 10070 - loss = 2.038, (1.540 sec/step)\n",
      "step 10071 - loss = 1.747, (1.295 sec/step)\n",
      "step 10072 - loss = 2.013, (1.390 sec/step)\n",
      "step 10073 - loss = 1.293, (2.050 sec/step)\n",
      "step 10074 - loss = 1.336, (0.984 sec/step)\n",
      "step 10075 - loss = 1.542, (2.512 sec/step)\n",
      "step 10076 - loss = 1.699, (1.148 sec/step)\n",
      "step 10077 - loss = 1.657, (2.349 sec/step)\n",
      "step 10078 - loss = 1.768, (0.971 sec/step)\n",
      "step 10079 - loss = 2.083, (1.315 sec/step)\n",
      "step 10080 - loss = 1.657, (1.230 sec/step)\n",
      "step 10081 - loss = 1.785, (2.208 sec/step)\n",
      "step 10082 - loss = 1.555, (1.330 sec/step)\n",
      "step 10083 - loss = 2.188, (1.148 sec/step)\n",
      "step 10084 - loss = 1.887, (2.009 sec/step)\n",
      "step 10085 - loss = 2.072, (1.420 sec/step)\n",
      "step 10086 - loss = 1.663, (1.518 sec/step)\n",
      "step 10087 - loss = 1.623, (1.148 sec/step)\n",
      "step 10088 - loss = 1.506, (1.015 sec/step)\n",
      "step 10089 - loss = 1.590, (1.330 sec/step)\n",
      "step 10090 - loss = 1.439, (1.330 sec/step)\n",
      "step 10091 - loss = 1.892, (1.087 sec/step)\n",
      "step 10092 - loss = 1.475, (1.068 sec/step)\n",
      "step 10093 - loss = 2.083, (1.587 sec/step)\n",
      "step 10094 - loss = 2.176, (1.212 sec/step)\n",
      "step 10095 - loss = 1.667, (1.654 sec/step)\n",
      "step 10096 - loss = 1.698, (2.067 sec/step)\n",
      "step 10097 - loss = 1.853, (0.838 sec/step)\n",
      "step 10098 - loss = 2.042, (1.520 sec/step)\n",
      "step 10099 - loss = 0.509, (0.788 sec/step)\n",
      "step 10100 - loss = 2.015, (1.385 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10101 - loss = 1.601, (1.232 sec/step)\n",
      "step 10102 - loss = 1.765, (1.521 sec/step)\n",
      "step 10103 - loss = 2.259, (1.561 sec/step)\n",
      "step 10104 - loss = 1.868, (1.131 sec/step)\n",
      "step 10105 - loss = 1.787, (1.461 sec/step)\n",
      "step 10106 - loss = 2.121, (1.685 sec/step)\n",
      "step 10107 - loss = 1.301, (2.375 sec/step)\n",
      "step 10108 - loss = 1.547, (0.986 sec/step)\n",
      "step 10109 - loss = 1.885, (1.410 sec/step)\n",
      "step 10110 - loss = 2.369, (1.156 sec/step)\n",
      "step 10111 - loss = 1.607, (1.154 sec/step)\n",
      "step 10112 - loss = 1.366, (1.179 sec/step)\n",
      "step 10113 - loss = 2.062, (1.099 sec/step)\n",
      "step 10114 - loss = 1.569, (0.892 sec/step)\n",
      "step 10115 - loss = 2.156, (1.357 sec/step)\n",
      "step 10116 - loss = 1.770, (1.763 sec/step)\n",
      "step 10117 - loss = 1.245, (1.447 sec/step)\n",
      "step 10118 - loss = 1.746, (1.228 sec/step)\n",
      "step 10119 - loss = 2.030, (1.220 sec/step)\n",
      "step 10120 - loss = 2.136, (1.341 sec/step)\n",
      "step 10121 - loss = 1.963, (1.214 sec/step)\n",
      "step 10122 - loss = 1.640, (0.975 sec/step)\n",
      "step 10123 - loss = 1.712, (1.149 sec/step)\n",
      "step 10124 - loss = 1.539, (1.795 sec/step)\n",
      "step 10125 - loss = 1.524, (3.021 sec/step)\n",
      "step 10126 - loss = 1.695, (0.980 sec/step)\n",
      "step 10127 - loss = 1.010, (1.358 sec/step)\n",
      "step 10128 - loss = 1.836, (1.826 sec/step)\n",
      "step 10129 - loss = 1.869, (1.197 sec/step)\n",
      "step 10130 - loss = 1.798, (1.884 sec/step)\n",
      "step 10131 - loss = 1.737, (1.051 sec/step)\n",
      "step 10132 - loss = 1.250, (0.991 sec/step)\n",
      "step 10133 - loss = 1.649, (1.393 sec/step)\n",
      "step 10134 - loss = 1.917, (1.650 sec/step)\n",
      "step 10135 - loss = 1.560, (1.228 sec/step)\n",
      "step 10136 - loss = 1.330, (1.067 sec/step)\n",
      "step 10137 - loss = 1.466, (2.449 sec/step)\n",
      "step 10138 - loss = 1.496, (0.970 sec/step)\n",
      "step 10139 - loss = 1.620, (1.356 sec/step)\n",
      "step 10140 - loss = 1.461, (1.357 sec/step)\n",
      "step 10141 - loss = 2.045, (1.455 sec/step)\n",
      "step 10142 - loss = 1.299, (1.199 sec/step)\n",
      "step 10143 - loss = 1.429, (1.013 sec/step)\n",
      "step 10144 - loss = 1.928, (1.459 sec/step)\n",
      "step 10145 - loss = 2.163, (1.606 sec/step)\n",
      "step 10146 - loss = 2.102, (1.198 sec/step)\n",
      "step 10147 - loss = 1.877, (1.084 sec/step)\n",
      "step 10148 - loss = 1.671, (1.211 sec/step)\n",
      "step 10149 - loss = 2.117, (1.113 sec/step)\n",
      "step 10150 - loss = 2.389, (2.485 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10151 - loss = 2.209, (2.359 sec/step)\n",
      "step 10152 - loss = 1.350, (1.257 sec/step)\n",
      "step 10153 - loss = 2.107, (1.251 sec/step)\n",
      "step 10154 - loss = 1.707, (2.624 sec/step)\n",
      "step 10155 - loss = 1.817, (1.932 sec/step)\n",
      "step 10156 - loss = 1.987, (1.511 sec/step)\n",
      "step 10157 - loss = 2.057, (1.066 sec/step)\n",
      "step 10158 - loss = 2.006, (1.529 sec/step)\n",
      "step 10159 - loss = 1.834, (1.242 sec/step)\n",
      "step 10160 - loss = 1.760, (1.330 sec/step)\n",
      "step 10161 - loss = 1.959, (2.646 sec/step)\n",
      "step 10162 - loss = 2.122, (1.920 sec/step)\n",
      "step 10163 - loss = 1.580, (2.035 sec/step)\n",
      "step 10164 - loss = 2.041, (1.677 sec/step)\n",
      "step 10165 - loss = 1.826, (1.088 sec/step)\n",
      "step 10166 - loss = 1.743, (0.929 sec/step)\n",
      "step 10167 - loss = 1.519, (1.150 sec/step)\n",
      "step 10168 - loss = 1.779, (1.913 sec/step)\n",
      "step 10169 - loss = 1.876, (1.088 sec/step)\n",
      "step 10170 - loss = 1.378, (1.032 sec/step)\n",
      "step 10171 - loss = 1.542, (1.574 sec/step)\n",
      "step 10172 - loss = 1.558, (1.109 sec/step)\n",
      "step 10173 - loss = 2.337, (1.409 sec/step)\n",
      "step 10174 - loss = 1.645, (2.803 sec/step)\n",
      "step 10175 - loss = 1.775, (1.353 sec/step)\n",
      "step 10176 - loss = 2.190, (1.743 sec/step)\n",
      "step 10177 - loss = 2.234, (2.485 sec/step)\n",
      "step 10178 - loss = 1.227, (1.369 sec/step)\n",
      "step 10179 - loss = 1.683, (1.819 sec/step)\n",
      "step 10180 - loss = 1.866, (2.454 sec/step)\n",
      "step 10181 - loss = 2.228, (1.798 sec/step)\n",
      "step 10182 - loss = 1.639, (1.254 sec/step)\n",
      "step 10183 - loss = 2.058, (1.634 sec/step)\n",
      "step 10184 - loss = 1.692, (1.686 sec/step)\n",
      "step 10185 - loss = 1.784, (0.959 sec/step)\n",
      "step 10186 - loss = 1.985, (2.316 sec/step)\n",
      "step 10187 - loss = 1.985, (1.242 sec/step)\n",
      "step 10188 - loss = 2.400, (2.485 sec/step)\n",
      "step 10189 - loss = 2.144, (1.212 sec/step)\n",
      "step 10190 - loss = 1.816, (2.688 sec/step)\n",
      "step 10191 - loss = 1.583, (1.012 sec/step)\n",
      "step 10192 - loss = 2.042, (1.380 sec/step)\n",
      "step 10193 - loss = 2.043, (1.143 sec/step)\n",
      "step 10194 - loss = 2.468, (2.553 sec/step)\n",
      "step 10195 - loss = 1.719, (1.231 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10196 - loss = 1.933, (1.444 sec/step)\n",
      "step 10197 - loss = 1.494, (1.053 sec/step)\n",
      "step 10198 - loss = 1.902, (1.560 sec/step)\n",
      "step 10199 - loss = 1.484, (0.956 sec/step)\n",
      "step 10200 - loss = 2.334, (2.018 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10201 - loss = 1.854, (1.946 sec/step)\n",
      "step 10202 - loss = 1.820, (1.222 sec/step)\n",
      "step 10203 - loss = 1.794, (2.375 sec/step)\n",
      "step 10204 - loss = 1.413, (0.979 sec/step)\n",
      "step 10205 - loss = 2.014, (1.460 sec/step)\n",
      "step 10206 - loss = 1.914, (1.483 sec/step)\n",
      "step 10207 - loss = 1.649, (1.179 sec/step)\n",
      "step 10208 - loss = 2.460, (1.091 sec/step)\n",
      "step 10209 - loss = 2.145, (2.179 sec/step)\n",
      "step 10210 - loss = 2.318, (1.311 sec/step)\n",
      "step 10211 - loss = 1.289, (1.955 sec/step)\n",
      "step 10212 - loss = 1.602, (2.383 sec/step)\n",
      "step 10213 - loss = 1.881, (1.220 sec/step)\n",
      "step 10214 - loss = 1.787, (1.150 sec/step)\n",
      "step 10215 - loss = 1.792, (1.202 sec/step)\n",
      "step 10216 - loss = 2.265, (1.491 sec/step)\n",
      "step 10217 - loss = 1.827, (2.056 sec/step)\n",
      "step 10218 - loss = 1.621, (1.200 sec/step)\n",
      "step 10219 - loss = 0.484, (1.883 sec/step)\n",
      "step 10220 - loss = 2.381, (1.223 sec/step)\n",
      "step 10221 - loss = 1.917, (1.177 sec/step)\n",
      "step 10222 - loss = 1.999, (1.262 sec/step)\n",
      "step 10223 - loss = 2.362, (1.484 sec/step)\n",
      "step 10224 - loss = 1.450, (1.356 sec/step)\n",
      "step 10225 - loss = 1.938, (1.084 sec/step)\n",
      "step 10226 - loss = 1.966, (1.460 sec/step)\n",
      "step 10227 - loss = 1.382, (3.006 sec/step)\n",
      "step 10228 - loss = 1.410, (1.552 sec/step)\n",
      "step 10229 - loss = 1.666, (0.996 sec/step)\n",
      "step 10230 - loss = 1.559, (1.554 sec/step)\n",
      "step 10231 - loss = 2.154, (1.737 sec/step)\n",
      "step 10232 - loss = 1.890, (0.843 sec/step)\n",
      "step 10233 - loss = 1.918, (0.909 sec/step)\n",
      "step 10234 - loss = 1.907, (1.141 sec/step)\n",
      "step 10235 - loss = 1.925, (0.791 sec/step)\n",
      "step 10236 - loss = 2.183, (1.098 sec/step)\n",
      "step 10237 - loss = 2.112, (1.155 sec/step)\n",
      "step 10238 - loss = 1.333, (0.954 sec/step)\n",
      "step 10239 - loss = 1.501, (2.517 sec/step)\n",
      "step 10240 - loss = 1.744, (1.000 sec/step)\n",
      "step 10241 - loss = 2.360, (1.176 sec/step)\n",
      "step 10242 - loss = 1.589, (2.289 sec/step)\n",
      "step 10243 - loss = 1.863, (1.378 sec/step)\n",
      "step 10244 - loss = 1.557, (1.239 sec/step)\n",
      "step 10245 - loss = 1.762, (0.870 sec/step)\n",
      "step 10246 - loss = 2.421, (1.358 sec/step)\n",
      "step 10247 - loss = 1.744, (1.445 sec/step)\n",
      "step 10248 - loss = 1.619, (1.399 sec/step)\n",
      "step 10249 - loss = 1.847, (1.626 sec/step)\n",
      "step 10250 - loss = 1.680, (1.126 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10251 - loss = 1.483, (2.265 sec/step)\n",
      "step 10252 - loss = 1.859, (1.181 sec/step)\n",
      "step 10253 - loss = 2.102, (0.977 sec/step)\n",
      "step 10254 - loss = 2.089, (1.259 sec/step)\n",
      "step 10255 - loss = 1.448, (2.268 sec/step)\n",
      "step 10256 - loss = 2.190, (1.590 sec/step)\n",
      "step 10257 - loss = 1.474, (1.710 sec/step)\n",
      "step 10258 - loss = 1.460, (1.303 sec/step)\n",
      "step 10259 - loss = 1.494, (1.687 sec/step)\n",
      "step 10260 - loss = 1.648, (1.612 sec/step)\n",
      "step 10261 - loss = 1.703, (1.707 sec/step)\n",
      "step 10262 - loss = 1.691, (1.200 sec/step)\n",
      "step 10263 - loss = 1.466, (2.610 sec/step)\n",
      "step 10264 - loss = 1.993, (1.659 sec/step)\n",
      "step 10265 - loss = 1.699, (1.684 sec/step)\n",
      "step 10266 - loss = 2.329, (1.329 sec/step)\n",
      "step 10267 - loss = 1.038, (1.863 sec/step)\n",
      "step 10268 - loss = 1.630, (1.780 sec/step)\n",
      "step 10269 - loss = 1.948, (1.384 sec/step)\n",
      "step 10270 - loss = 1.625, (1.161 sec/step)\n",
      "step 10271 - loss = 1.739, (1.050 sec/step)\n",
      "step 10272 - loss = 2.051, (1.478 sec/step)\n",
      "step 10273 - loss = 1.929, (1.311 sec/step)\n",
      "step 10274 - loss = 1.945, (1.704 sec/step)\n",
      "step 10275 - loss = 1.663, (1.346 sec/step)\n",
      "step 10276 - loss = 2.356, (2.224 sec/step)\n",
      "step 10277 - loss = 1.929, (2.319 sec/step)\n",
      "step 10278 - loss = 1.882, (2.444 sec/step)\n",
      "step 10279 - loss = 1.565, (0.925 sec/step)\n",
      "step 10280 - loss = 2.011, (1.245 sec/step)\n",
      "step 10281 - loss = 2.041, (2.080 sec/step)\n",
      "step 10282 - loss = 1.732, (1.575 sec/step)\n",
      "step 10283 - loss = 1.504, (2.172 sec/step)\n",
      "step 10284 - loss = 1.764, (1.458 sec/step)\n",
      "step 10285 - loss = 1.943, (1.807 sec/step)\n",
      "step 10286 - loss = 2.242, (1.474 sec/step)\n",
      "step 10287 - loss = 1.255, (1.452 sec/step)\n",
      "step 10288 - loss = 1.520, (1.719 sec/step)\n",
      "step 10289 - loss = 2.152, (1.605 sec/step)\n",
      "step 10290 - loss = 1.450, (2.339 sec/step)\n",
      "step 10291 - loss = 1.621, (1.148 sec/step)\n",
      "step 10292 - loss = 1.407, (1.545 sec/step)\n",
      "step 10293 - loss = 2.318, (1.129 sec/step)\n",
      "step 10294 - loss = 1.786, (1.390 sec/step)\n",
      "step 10295 - loss = 1.214, (0.971 sec/step)\n",
      "step 10296 - loss = 1.803, (2.487 sec/step)\n",
      "step 10297 - loss = 1.322, (0.844 sec/step)\n",
      "step 10298 - loss = 1.946, (1.645 sec/step)\n",
      "step 10299 - loss = 2.362, (3.045 sec/step)\n",
      "step 10300 - loss = 1.505, (1.053 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10301 - loss = 1.907, (0.981 sec/step)\n",
      "step 10302 - loss = 1.806, (0.968 sec/step)\n",
      "step 10303 - loss = 1.869, (1.600 sec/step)\n",
      "step 10304 - loss = 1.729, (2.441 sec/step)\n",
      "step 10305 - loss = 1.963, (1.228 sec/step)\n",
      "step 10306 - loss = 1.418, (0.955 sec/step)\n",
      "step 10307 - loss = 1.749, (2.360 sec/step)\n",
      "step 10308 - loss = 2.169, (2.482 sec/step)\n",
      "step 10309 - loss = 0.442, (1.018 sec/step)\n",
      "step 10310 - loss = 1.699, (1.646 sec/step)\n",
      "step 10311 - loss = 1.839, (0.967 sec/step)\n",
      "step 10312 - loss = 2.079, (1.478 sec/step)\n",
      "step 10313 - loss = 1.849, (1.414 sec/step)\n",
      "step 10314 - loss = 2.173, (2.104 sec/step)\n",
      "step 10315 - loss = 1.810, (1.330 sec/step)\n",
      "step 10316 - loss = 2.347, (1.219 sec/step)\n",
      "step 10317 - loss = 2.726, (1.000 sec/step)\n",
      "step 10318 - loss = 1.699, (1.052 sec/step)\n",
      "step 10319 - loss = 2.240, (1.014 sec/step)\n",
      "step 10320 - loss = 2.033, (1.212 sec/step)\n",
      "step 10321 - loss = 1.764, (1.540 sec/step)\n",
      "step 10322 - loss = 2.002, (0.939 sec/step)\n",
      "step 10323 - loss = 1.796, (2.601 sec/step)\n",
      "step 10324 - loss = 1.629, (1.710 sec/step)\n",
      "step 10325 - loss = 1.243, (1.018 sec/step)\n",
      "step 10326 - loss = 1.581, (1.236 sec/step)\n",
      "step 10327 - loss = 1.936, (1.097 sec/step)\n",
      "step 10328 - loss = 2.353, (1.765 sec/step)\n",
      "step 10329 - loss = 2.242, (1.540 sec/step)\n",
      "step 10330 - loss = 1.470, (0.906 sec/step)\n",
      "step 10331 - loss = 1.993, (1.199 sec/step)\n",
      "step 10332 - loss = 1.473, (1.443 sec/step)\n",
      "step 10333 - loss = 1.627, (1.636 sec/step)\n",
      "step 10334 - loss = 1.975, (1.955 sec/step)\n",
      "step 10335 - loss = 2.011, (1.199 sec/step)\n",
      "step 10336 - loss = 1.360, (2.480 sec/step)\n",
      "step 10337 - loss = 1.969, (1.507 sec/step)\n",
      "step 10338 - loss = 2.212, (1.256 sec/step)\n",
      "step 10339 - loss = 1.565, (1.878 sec/step)\n",
      "step 10340 - loss = 1.656, (0.969 sec/step)\n",
      "step 10341 - loss = 1.606, (1.553 sec/step)\n",
      "step 10342 - loss = 2.301, (2.483 sec/step)\n",
      "step 10343 - loss = 1.036, (2.126 sec/step)\n",
      "step 10344 - loss = 1.482, (1.606 sec/step)\n",
      "step 10345 - loss = 2.075, (1.634 sec/step)\n",
      "step 10346 - loss = 1.721, (2.056 sec/step)\n",
      "step 10347 - loss = 1.943, (1.147 sec/step)\n",
      "step 10348 - loss = 1.351, (2.564 sec/step)\n",
      "step 10349 - loss = 1.542, (0.940 sec/step)\n",
      "step 10350 - loss = 2.181, (1.199 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10351 - loss = 1.467, (3.119 sec/step)\n",
      "step 10352 - loss = 1.319, (1.016 sec/step)\n",
      "step 10353 - loss = 2.145, (1.086 sec/step)\n",
      "step 10354 - loss = 2.388, (1.251 sec/step)\n",
      "step 10355 - loss = 2.267, (1.852 sec/step)\n",
      "step 10356 - loss = 2.165, (1.202 sec/step)\n",
      "step 10357 - loss = 1.794, (1.109 sec/step)\n",
      "step 10358 - loss = 1.911, (1.258 sec/step)\n",
      "step 10359 - loss = 1.763, (1.761 sec/step)\n",
      "step 10360 - loss = 1.654, (1.264 sec/step)\n",
      "step 10361 - loss = 2.079, (3.016 sec/step)\n",
      "step 10362 - loss = 1.913, (1.291 sec/step)\n",
      "step 10363 - loss = 1.666, (1.084 sec/step)\n",
      "step 10364 - loss = 2.318, (1.542 sec/step)\n",
      "step 10365 - loss = 2.094, (1.926 sec/step)\n",
      "step 10366 - loss = 1.767, (1.033 sec/step)\n",
      "step 10367 - loss = 2.178, (0.870 sec/step)\n",
      "step 10368 - loss = 1.113, (1.970 sec/step)\n",
      "step 10369 - loss = 1.829, (1.380 sec/step)\n",
      "step 10370 - loss = 1.766, (1.906 sec/step)\n",
      "step 10371 - loss = 1.116, (1.383 sec/step)\n",
      "step 10372 - loss = 1.584, (1.409 sec/step)\n",
      "step 10373 - loss = 1.477, (1.117 sec/step)\n",
      "step 10374 - loss = 1.849, (1.973 sec/step)\n",
      "step 10375 - loss = 2.224, (2.488 sec/step)\n",
      "step 10376 - loss = 1.683, (1.643 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10377 - loss = 1.754, (1.421 sec/step)\n",
      "step 10378 - loss = 2.017, (2.650 sec/step)\n",
      "step 10379 - loss = 1.462, (0.966 sec/step)\n",
      "step 10380 - loss = 2.083, (1.972 sec/step)\n",
      "step 10381 - loss = 1.621, (1.141 sec/step)\n",
      "step 10382 - loss = 1.849, (1.405 sec/step)\n",
      "step 10383 - loss = 1.854, (1.289 sec/step)\n",
      "step 10384 - loss = 2.197, (1.699 sec/step)\n",
      "step 10385 - loss = 2.138, (1.561 sec/step)\n",
      "step 10386 - loss = 1.500, (1.293 sec/step)\n",
      "step 10387 - loss = 1.974, (1.684 sec/step)\n",
      "step 10388 - loss = 1.101, (2.485 sec/step)\n",
      "step 10389 - loss = 0.803, (1.970 sec/step)\n",
      "step 10390 - loss = 2.444, (0.940 sec/step)\n",
      "step 10391 - loss = 1.232, (1.461 sec/step)\n",
      "step 10392 - loss = 1.177, (1.744 sec/step)\n",
      "step 10393 - loss = 2.077, (1.711 sec/step)\n",
      "step 10394 - loss = 2.000, (1.257 sec/step)\n",
      "step 10395 - loss = 2.515, (1.486 sec/step)\n",
      "step 10396 - loss = 1.351, (1.176 sec/step)\n",
      "step 10397 - loss = 1.609, (1.519 sec/step)\n",
      "step 10398 - loss = 1.720, (1.538 sec/step)\n",
      "step 10399 - loss = 2.268, (1.474 sec/step)\n",
      "step 10400 - loss = 2.185, (1.348 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10401 - loss = 1.862, (1.421 sec/step)\n",
      "step 10402 - loss = 1.518, (1.822 sec/step)\n",
      "step 10403 - loss = 1.214, (1.113 sec/step)\n",
      "step 10404 - loss = 1.744, (1.114 sec/step)\n",
      "step 10405 - loss = 1.811, (1.780 sec/step)\n",
      "step 10406 - loss = 2.138, (2.221 sec/step)\n",
      "step 10407 - loss = 1.667, (1.217 sec/step)\n",
      "step 10408 - loss = 1.424, (1.246 sec/step)\n",
      "step 10409 - loss = 1.883, (1.375 sec/step)\n",
      "step 10410 - loss = 1.594, (1.486 sec/step)\n",
      "step 10411 - loss = 2.025, (1.292 sec/step)\n",
      "step 10412 - loss = 1.212, (1.332 sec/step)\n",
      "step 10413 - loss = 2.083, (1.497 sec/step)\n",
      "step 10414 - loss = 1.795, (2.488 sec/step)\n",
      "step 10415 - loss = 1.330, (2.491 sec/step)\n",
      "step 10416 - loss = 0.541, (0.249 sec/step)\n",
      "step 10417 - loss = 1.734, (0.777 sec/step)\n",
      "step 10418 - loss = 1.627, (1.462 sec/step)\n",
      "step 10419 - loss = 1.282, (0.895 sec/step)\n",
      "step 10420 - loss = 1.486, (1.291 sec/step)\n",
      "step 10421 - loss = 1.229, (1.614 sec/step)\n",
      "step 10422 - loss = 1.972, (1.912 sec/step)\n",
      "step 10423 - loss = 1.639, (0.894 sec/step)\n",
      "step 10424 - loss = 2.311, (1.347 sec/step)\n",
      "step 10425 - loss = 2.712, (1.853 sec/step)\n",
      "step 10426 - loss = 2.013, (1.046 sec/step)\n",
      "step 10427 - loss = 1.588, (0.970 sec/step)\n",
      "step 10428 - loss = 1.896, (1.547 sec/step)\n",
      "step 10429 - loss = 1.625, (1.161 sec/step)\n",
      "step 10430 - loss = 1.785, (1.255 sec/step)\n",
      "step 10431 - loss = 1.714, (1.018 sec/step)\n",
      "step 10432 - loss = 2.246, (2.493 sec/step)\n",
      "step 10433 - loss = 1.941, (2.766 sec/step)\n",
      "step 10434 - loss = 1.580, (2.309 sec/step)\n",
      "step 10435 - loss = 1.991, (1.117 sec/step)\n",
      "step 10436 - loss = 1.469, (0.993 sec/step)\n",
      "step 10437 - loss = 1.116, (1.116 sec/step)\n",
      "step 10438 - loss = 1.864, (3.092 sec/step)\n",
      "step 10439 - loss = 1.788, (1.811 sec/step)\n",
      "step 10440 - loss = 2.055, (1.387 sec/step)\n",
      "step 10441 - loss = 1.943, (2.293 sec/step)\n",
      "step 10442 - loss = 2.538, (1.379 sec/step)\n",
      "step 10443 - loss = 1.178, (0.728 sec/step)\n",
      "step 10444 - loss = 1.426, (0.855 sec/step)\n",
      "step 10445 - loss = 1.996, (1.033 sec/step)\n",
      "step 10446 - loss = 1.778, (1.231 sec/step)\n",
      "step 10447 - loss = 1.795, (1.094 sec/step)\n",
      "step 10448 - loss = 1.577, (1.011 sec/step)\n",
      "step 10449 - loss = 1.732, (1.649 sec/step)\n",
      "step 10450 - loss = 1.732, (2.398 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10451 - loss = 1.684, (1.556 sec/step)\n",
      "step 10452 - loss = 2.021, (1.834 sec/step)\n",
      "step 10453 - loss = 1.763, (1.096 sec/step)\n",
      "step 10454 - loss = 2.131, (1.312 sec/step)\n",
      "step 10455 - loss = 1.725, (1.519 sec/step)\n",
      "step 10456 - loss = 2.435, (1.343 sec/step)\n",
      "step 10457 - loss = 2.174, (1.913 sec/step)\n",
      "step 10458 - loss = 1.576, (1.329 sec/step)\n",
      "step 10459 - loss = 1.712, (2.119 sec/step)\n",
      "step 10460 - loss = 2.116, (1.114 sec/step)\n",
      "step 10461 - loss = 2.199, (3.377 sec/step)\n",
      "step 10462 - loss = 1.923, (1.452 sec/step)\n",
      "step 10463 - loss = 1.837, (2.812 sec/step)\n",
      "step 10464 - loss = 2.166, (1.587 sec/step)\n",
      "step 10465 - loss = 1.399, (1.359 sec/step)\n",
      "step 10466 - loss = 1.592, (1.040 sec/step)\n",
      "step 10467 - loss = 1.895, (1.915 sec/step)\n",
      "step 10468 - loss = 1.424, (1.101 sec/step)\n",
      "step 10469 - loss = 1.533, (2.711 sec/step)\n",
      "step 10470 - loss = 1.266, (0.941 sec/step)\n",
      "step 10471 - loss = 1.860, (1.262 sec/step)\n",
      "step 10472 - loss = 1.970, (2.250 sec/step)\n",
      "step 10473 - loss = 1.590, (1.656 sec/step)\n",
      "step 10474 - loss = 1.317, (2.487 sec/step)\n",
      "step 10475 - loss = 1.072, (2.133 sec/step)\n",
      "step 10476 - loss = 1.392, (1.314 sec/step)\n",
      "step 10477 - loss = 2.110, (2.484 sec/step)\n",
      "step 10478 - loss = 1.338, (1.506 sec/step)\n",
      "step 10479 - loss = 2.086, (0.896 sec/step)\n",
      "step 10480 - loss = 1.916, (2.283 sec/step)\n",
      "step 10481 - loss = 2.065, (1.038 sec/step)\n",
      "step 10482 - loss = 1.619, (1.527 sec/step)\n",
      "step 10483 - loss = 1.546, (1.897 sec/step)\n",
      "step 10484 - loss = 2.048, (1.602 sec/step)\n",
      "step 10485 - loss = 1.477, (1.032 sec/step)\n",
      "step 10486 - loss = 1.505, (3.616 sec/step)\n",
      "step 10487 - loss = 1.622, (1.280 sec/step)\n",
      "step 10488 - loss = 1.480, (1.457 sec/step)\n",
      "step 10489 - loss = 2.674, (2.486 sec/step)\n",
      "step 10490 - loss = 1.667, (1.664 sec/step)\n",
      "step 10491 - loss = 1.134, (1.017 sec/step)\n",
      "step 10492 - loss = 1.293, (1.331 sec/step)\n",
      "step 10493 - loss = 1.413, (2.707 sec/step)\n",
      "step 10494 - loss = 1.718, (1.943 sec/step)\n",
      "step 10495 - loss = 1.927, (1.707 sec/step)\n",
      "step 10496 - loss = 2.135, (1.597 sec/step)\n",
      "step 10497 - loss = 2.102, (1.893 sec/step)\n",
      "step 10498 - loss = 2.319, (1.714 sec/step)\n",
      "step 10499 - loss = 1.575, (1.723 sec/step)\n",
      "step 10500 - loss = 1.851, (1.783 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10501 - loss = 1.886, (1.348 sec/step)\n",
      "step 10502 - loss = 2.207, (1.299 sec/step)\n",
      "step 10503 - loss = 1.265, (1.651 sec/step)\n",
      "step 10504 - loss = 2.398, (2.485 sec/step)\n",
      "step 10505 - loss = 1.700, (2.387 sec/step)\n",
      "step 10506 - loss = 2.059, (1.460 sec/step)\n",
      "step 10507 - loss = 1.581, (1.416 sec/step)\n",
      "step 10508 - loss = 1.650, (1.596 sec/step)\n",
      "step 10509 - loss = 1.036, (1.343 sec/step)\n",
      "step 10510 - loss = 1.857, (2.469 sec/step)\n",
      "step 10511 - loss = 1.868, (2.074 sec/step)\n",
      "step 10512 - loss = 1.945, (1.231 sec/step)\n",
      "step 10513 - loss = 1.775, (1.937 sec/step)\n",
      "step 10514 - loss = 1.791, (1.762 sec/step)\n",
      "step 10515 - loss = 2.386, (1.126 sec/step)\n",
      "step 10516 - loss = 1.412, (1.969 sec/step)\n",
      "step 10517 - loss = 1.710, (1.531 sec/step)\n",
      "step 10518 - loss = 1.946, (1.255 sec/step)\n",
      "step 10519 - loss = 1.994, (1.201 sec/step)\n",
      "step 10520 - loss = 1.879, (2.295 sec/step)\n",
      "step 10521 - loss = 2.055, (1.444 sec/step)\n",
      "step 10522 - loss = 2.119, (1.016 sec/step)\n",
      "step 10523 - loss = 1.989, (1.647 sec/step)\n",
      "step 10524 - loss = 1.914, (1.460 sec/step)\n",
      "step 10525 - loss = 1.628, (0.895 sec/step)\n",
      "step 10526 - loss = 2.082, (1.100 sec/step)\n",
      "step 10527 - loss = 1.793, (0.999 sec/step)\n",
      "step 10528 - loss = 2.122, (1.606 sec/step)\n",
      "step 10529 - loss = 1.676, (1.947 sec/step)\n",
      "step 10530 - loss = 1.433, (1.607 sec/step)\n",
      "step 10531 - loss = 1.771, (1.290 sec/step)\n",
      "step 10532 - loss = 2.029, (1.068 sec/step)\n",
      "step 10533 - loss = 1.911, (1.113 sec/step)\n",
      "step 10534 - loss = 1.337, (2.183 sec/step)\n",
      "step 10535 - loss = 1.487, (1.497 sec/step)\n",
      "step 10536 - loss = 2.245, (1.070 sec/step)\n",
      "step 10537 - loss = 1.342, (1.572 sec/step)\n",
      "step 10538 - loss = 2.091, (2.426 sec/step)\n",
      "step 10539 - loss = 1.744, (1.322 sec/step)\n",
      "step 10540 - loss = 1.913, (1.602 sec/step)\n",
      "step 10541 - loss = 2.162, (1.830 sec/step)\n",
      "step 10542 - loss = 1.881, (1.420 sec/step)\n",
      "step 10543 - loss = 1.898, (1.197 sec/step)\n",
      "step 10544 - loss = 1.805, (1.295 sec/step)\n",
      "step 10545 - loss = 1.429, (1.650 sec/step)\n",
      "step 10546 - loss = 1.936, (2.039 sec/step)\n",
      "step 10547 - loss = 1.547, (2.530 sec/step)\n",
      "step 10548 - loss = 1.500, (1.017 sec/step)\n",
      "step 10549 - loss = 2.151, (1.683 sec/step)\n",
      "step 10550 - loss = 1.859, (1.128 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10551 - loss = 1.635, (1.869 sec/step)\n",
      "step 10552 - loss = 1.346, (0.894 sec/step)\n",
      "step 10553 - loss = 1.841, (1.216 sec/step)\n",
      "step 10554 - loss = 1.790, (1.200 sec/step)\n",
      "step 10555 - loss = 2.026, (1.568 sec/step)\n",
      "step 10556 - loss = 1.874, (1.190 sec/step)\n",
      "step 10557 - loss = 2.051, (2.484 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10558 - loss = 2.455, (0.682 sec/step)\n",
      "step 10559 - loss = 1.793, (1.298 sec/step)\n",
      "step 10560 - loss = 1.520, (1.384 sec/step)\n",
      "step 10561 - loss = 1.252, (1.158 sec/step)\n",
      "step 10562 - loss = 2.150, (1.259 sec/step)\n",
      "step 10563 - loss = 1.967, (1.847 sec/step)\n",
      "step 10564 - loss = 1.737, (1.345 sec/step)\n",
      "step 10565 - loss = 2.419, (2.511 sec/step)\n",
      "step 10566 - loss = 1.744, (1.379 sec/step)\n",
      "step 10567 - loss = 1.953, (1.861 sec/step)\n",
      "step 10568 - loss = 2.187, (1.090 sec/step)\n",
      "step 10569 - loss = 0.897, (1.719 sec/step)\n",
      "step 10570 - loss = 1.928, (1.573 sec/step)\n",
      "step 10571 - loss = 1.847, (1.246 sec/step)\n",
      "step 10572 - loss = 1.939, (1.721 sec/step)\n",
      "step 10573 - loss = 1.886, (2.468 sec/step)\n",
      "step 10574 - loss = 1.647, (2.565 sec/step)\n",
      "step 10575 - loss = 1.821, (1.099 sec/step)\n",
      "step 10576 - loss = 1.715, (1.446 sec/step)\n",
      "step 10577 - loss = 1.897, (1.646 sec/step)\n",
      "step 10578 - loss = 1.768, (1.502 sec/step)\n",
      "step 10579 - loss = 1.915, (1.491 sec/step)\n",
      "step 10580 - loss = 1.048, (1.085 sec/step)\n",
      "step 10581 - loss = 2.144, (2.544 sec/step)\n",
      "step 10582 - loss = 2.245, (1.224 sec/step)\n",
      "step 10583 - loss = 1.568, (1.249 sec/step)\n",
      "step 10584 - loss = 1.823, (2.164 sec/step)\n",
      "step 10585 - loss = 1.607, (1.097 sec/step)\n",
      "step 10586 - loss = 2.008, (1.254 sec/step)\n",
      "step 10587 - loss = 1.799, (1.148 sec/step)\n",
      "step 10588 - loss = 2.249, (2.839 sec/step)\n",
      "step 10589 - loss = 1.576, (1.129 sec/step)\n",
      "step 10590 - loss = 2.329, (1.407 sec/step)\n",
      "step 10591 - loss = 1.931, (1.314 sec/step)\n",
      "step 10592 - loss = 1.748, (2.118 sec/step)\n",
      "step 10593 - loss = 1.784, (0.892 sec/step)\n",
      "step 10594 - loss = 1.815, (2.452 sec/step)\n",
      "step 10595 - loss = 1.526, (1.820 sec/step)\n",
      "step 10596 - loss = 1.535, (2.404 sec/step)\n",
      "step 10597 - loss = 1.910, (1.746 sec/step)\n",
      "step 10598 - loss = 1.651, (1.144 sec/step)\n",
      "step 10599 - loss = 2.373, (2.483 sec/step)\n",
      "step 10600 - loss = 2.670, (2.485 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10601 - loss = 1.165, (1.979 sec/step)\n",
      "step 10602 - loss = 2.249, (1.251 sec/step)\n",
      "step 10603 - loss = 1.619, (2.778 sec/step)\n",
      "step 10604 - loss = 2.285, (1.987 sec/step)\n",
      "step 10605 - loss = 2.116, (1.030 sec/step)\n",
      "step 10606 - loss = 1.959, (0.859 sec/step)\n",
      "step 10607 - loss = 1.511, (1.764 sec/step)\n",
      "step 10608 - loss = 1.722, (1.722 sec/step)\n",
      "step 10609 - loss = 1.780, (1.675 sec/step)\n",
      "step 10610 - loss = 1.862, (2.034 sec/step)\n",
      "step 10611 - loss = 1.664, (2.085 sec/step)\n",
      "step 10612 - loss = 2.331, (2.487 sec/step)\n",
      "step 10613 - loss = 2.170, (2.663 sec/step)\n",
      "step 10614 - loss = 1.767, (1.035 sec/step)\n",
      "step 10615 - loss = 2.003, (1.457 sec/step)\n",
      "step 10616 - loss = 1.592, (1.359 sec/step)\n",
      "step 10617 - loss = 1.896, (1.980 sec/step)\n",
      "step 10618 - loss = 1.334, (0.710 sec/step)\n",
      "step 10619 - loss = 1.726, (1.263 sec/step)\n",
      "step 10620 - loss = 2.243, (2.487 sec/step)\n",
      "step 10621 - loss = 1.432, (0.935 sec/step)\n",
      "step 10622 - loss = 1.996, (1.089 sec/step)\n",
      "step 10623 - loss = 2.025, (1.212 sec/step)\n",
      "step 10624 - loss = 1.511, (1.227 sec/step)\n",
      "step 10625 - loss = 1.637, (1.336 sec/step)\n",
      "step 10626 - loss = 2.130, (1.358 sec/step)\n",
      "step 10627 - loss = 1.609, (1.342 sec/step)\n",
      "step 10628 - loss = 1.616, (1.186 sec/step)\n",
      "step 10629 - loss = 2.001, (1.390 sec/step)\n",
      "step 10630 - loss = 1.430, (1.526 sec/step)\n",
      "step 10631 - loss = 1.517, (0.927 sec/step)\n",
      "step 10632 - loss = 2.080, (1.572 sec/step)\n",
      "step 10633 - loss = 2.084, (1.200 sec/step)\n",
      "step 10634 - loss = 2.113, (1.167 sec/step)\n",
      "step 10635 - loss = 1.678, (2.517 sec/step)\n",
      "step 10636 - loss = 1.770, (1.341 sec/step)\n",
      "step 10637 - loss = 1.634, (1.385 sec/step)\n",
      "step 10638 - loss = 2.230, (2.103 sec/step)\n",
      "step 10639 - loss = 1.178, (1.256 sec/step)\n",
      "step 10640 - loss = 1.623, (2.193 sec/step)\n",
      "step 10641 - loss = 1.705, (0.939 sec/step)\n",
      "step 10642 - loss = 2.158, (1.714 sec/step)\n",
      "step 10643 - loss = 2.690, (1.543 sec/step)\n",
      "step 10644 - loss = 2.138, (1.278 sec/step)\n",
      "step 10645 - loss = 1.494, (1.356 sec/step)\n",
      "step 10646 - loss = 1.762, (1.559 sec/step)\n",
      "step 10647 - loss = 1.846, (0.911 sec/step)\n",
      "step 10648 - loss = 1.718, (1.844 sec/step)\n",
      "step 10649 - loss = 2.125, (1.050 sec/step)\n",
      "step 10650 - loss = 2.159, (1.872 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10651 - loss = 2.097, (1.358 sec/step)\n",
      "step 10652 - loss = 1.936, (1.848 sec/step)\n",
      "step 10653 - loss = 2.110, (1.293 sec/step)\n",
      "step 10654 - loss = 1.516, (1.229 sec/step)\n",
      "step 10655 - loss = 1.749, (2.561 sec/step)\n",
      "step 10656 - loss = 2.175, (2.228 sec/step)\n",
      "step 10657 - loss = 2.293, (2.484 sec/step)\n",
      "step 10658 - loss = 0.556, (0.322 sec/step)\n",
      "step 10659 - loss = 1.912, (1.517 sec/step)\n",
      "step 10660 - loss = 1.722, (2.357 sec/step)\n",
      "step 10661 - loss = 1.270, (1.426 sec/step)\n",
      "step 10662 - loss = 2.285, (2.623 sec/step)\n",
      "step 10663 - loss = 1.742, (0.967 sec/step)\n",
      "step 10664 - loss = 1.145, (1.228 sec/step)\n",
      "step 10665 - loss = 1.858, (1.211 sec/step)\n",
      "step 10666 - loss = 1.560, (1.322 sec/step)\n",
      "step 10667 - loss = 1.630, (1.516 sec/step)\n",
      "step 10668 - loss = 1.777, (0.954 sec/step)\n",
      "step 10669 - loss = 2.389, (2.483 sec/step)\n",
      "step 10670 - loss = 1.552, (2.327 sec/step)\n",
      "step 10671 - loss = 2.194, (1.712 sec/step)\n",
      "step 10672 - loss = 1.696, (0.911 sec/step)\n",
      "step 10673 - loss = 1.784, (1.570 sec/step)\n",
      "step 10674 - loss = 1.643, (1.245 sec/step)\n",
      "step 10675 - loss = 1.668, (2.249 sec/step)\n",
      "step 10676 - loss = 2.261, (2.244 sec/step)\n",
      "step 10677 - loss = 2.065, (1.495 sec/step)\n",
      "step 10678 - loss = 2.068, (1.518 sec/step)\n",
      "step 10679 - loss = 1.987, (1.083 sec/step)\n",
      "step 10680 - loss = 1.726, (1.210 sec/step)\n",
      "step 10681 - loss = 2.695, (2.483 sec/step)\n",
      "step 10682 - loss = 1.736, (0.465 sec/step)\n",
      "step 10683 - loss = 1.500, (2.303 sec/step)\n",
      "step 10684 - loss = 1.024, (1.555 sec/step)\n",
      "step 10685 - loss = 2.147, (1.400 sec/step)\n",
      "step 10686 - loss = 1.548, (2.841 sec/step)\n",
      "step 10687 - loss = 1.769, (1.274 sec/step)\n",
      "step 10688 - loss = 1.458, (2.470 sec/step)\n",
      "step 10689 - loss = 2.251, (2.484 sec/step)\n",
      "step 10690 - loss = 0.850, (0.309 sec/step)\n",
      "step 10691 - loss = 1.965, (2.232 sec/step)\n",
      "step 10692 - loss = 1.928, (1.731 sec/step)\n",
      "step 10693 - loss = 2.225, (1.332 sec/step)\n",
      "step 10694 - loss = 1.742, (1.577 sec/step)\n",
      "step 10695 - loss = 2.048, (1.289 sec/step)\n",
      "step 10696 - loss = 1.731, (1.836 sec/step)\n",
      "step 10697 - loss = 1.908, (2.732 sec/step)\n",
      "step 10698 - loss = 1.688, (2.155 sec/step)\n",
      "step 10699 - loss = 1.763, (0.999 sec/step)\n",
      "step 10700 - loss = 1.359, (1.228 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10701 - loss = 2.051, (1.145 sec/step)\n",
      "step 10702 - loss = 1.873, (1.277 sec/step)\n",
      "step 10703 - loss = 2.009, (0.954 sec/step)\n",
      "step 10704 - loss = 1.780, (1.000 sec/step)\n",
      "step 10705 - loss = 1.637, (1.393 sec/step)\n",
      "step 10706 - loss = 2.156, (1.448 sec/step)\n",
      "step 10707 - loss = 1.647, (1.590 sec/step)\n",
      "step 10708 - loss = 1.855, (1.981 sec/step)\n",
      "step 10709 - loss = 1.726, (2.488 sec/step)\n",
      "step 10710 - loss = 1.405, (2.684 sec/step)\n",
      "step 10711 - loss = 1.181, (2.118 sec/step)\n",
      "step 10712 - loss = 1.778, (0.841 sec/step)\n",
      "step 10713 - loss = 2.001, (0.964 sec/step)\n",
      "step 10714 - loss = 2.130, (2.487 sec/step)\n",
      "step 10715 - loss = 1.146, (2.283 sec/step)\n",
      "step 10716 - loss = 1.957, (2.487 sec/step)\n",
      "step 10717 - loss = 1.786, (1.438 sec/step)\n",
      "step 10718 - loss = 1.952, (1.112 sec/step)\n",
      "step 10719 - loss = 1.630, (1.446 sec/step)\n",
      "step 10720 - loss = 2.169, (1.840 sec/step)\n",
      "step 10721 - loss = 1.944, (2.254 sec/step)\n",
      "step 10722 - loss = 2.242, (1.259 sec/step)\n",
      "step 10723 - loss = 2.065, (1.376 sec/step)\n",
      "step 10724 - loss = 2.187, (1.241 sec/step)\n",
      "step 10725 - loss = 1.553, (1.116 sec/step)\n",
      "step 10726 - loss = 1.917, (1.427 sec/step)\n",
      "step 10727 - loss = 2.123, (1.098 sec/step)\n",
      "step 10728 - loss = 1.624, (1.557 sec/step)\n",
      "step 10729 - loss = 1.706, (1.247 sec/step)\n",
      "step 10730 - loss = 1.599, (0.892 sec/step)\n",
      "step 10731 - loss = 2.027, (2.210 sec/step)\n",
      "step 10732 - loss = 1.131, (2.139 sec/step)\n",
      "step 10733 - loss = 1.822, (1.077 sec/step)\n",
      "step 10734 - loss = 1.931, (1.661 sec/step)\n",
      "step 10735 - loss = 2.175, (1.318 sec/step)\n",
      "step 10736 - loss = 1.719, (1.482 sec/step)\n",
      "step 10737 - loss = 1.772, (1.278 sec/step)\n",
      "step 10738 - loss = 1.748, (1.688 sec/step)\n",
      "step 10739 - loss = 2.470, (2.488 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10740 - loss = 2.623, (1.450 sec/step)\n",
      "step 10741 - loss = 1.828, (1.312 sec/step)\n",
      "step 10742 - loss = 1.848, (1.623 sec/step)\n",
      "step 10743 - loss = 1.727, (1.099 sec/step)\n",
      "step 10744 - loss = 2.223, (1.273 sec/step)\n",
      "step 10745 - loss = 1.795, (1.100 sec/step)\n",
      "step 10746 - loss = 2.099, (2.957 sec/step)\n",
      "step 10747 - loss = 2.013, (3.046 sec/step)\n",
      "step 10748 - loss = 1.801, (1.890 sec/step)\n",
      "step 10749 - loss = 1.614, (1.099 sec/step)\n",
      "step 10750 - loss = 2.014, (1.759 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10751 - loss = 2.032, (1.311 sec/step)\n",
      "step 10752 - loss = 1.825, (1.710 sec/step)\n",
      "step 10753 - loss = 1.955, (1.275 sec/step)\n",
      "step 10754 - loss = 2.269, (2.483 sec/step)\n",
      "step 10755 - loss = 1.022, (1.453 sec/step)\n",
      "step 10756 - loss = 1.960, (1.099 sec/step)\n",
      "step 10757 - loss = 1.488, (1.817 sec/step)\n",
      "step 10758 - loss = 1.728, (1.706 sec/step)\n",
      "step 10759 - loss = 2.153, (1.710 sec/step)\n",
      "step 10760 - loss = 1.625, (0.997 sec/step)\n",
      "step 10761 - loss = 2.284, (1.956 sec/step)\n",
      "step 10762 - loss = 2.002, (1.220 sec/step)\n",
      "step 10763 - loss = 1.978, (2.247 sec/step)\n",
      "step 10764 - loss = 1.834, (2.009 sec/step)\n",
      "step 10765 - loss = 1.945, (1.342 sec/step)\n",
      "step 10766 - loss = 2.092, (2.485 sec/step)\n",
      "step 10767 - loss = 1.612, (0.754 sec/step)\n",
      "step 10768 - loss = 1.806, (1.151 sec/step)\n",
      "step 10769 - loss = 1.805, (1.949 sec/step)\n",
      "step 10770 - loss = 2.197, (2.485 sec/step)\n",
      "step 10771 - loss = 0.809, (1.736 sec/step)\n",
      "step 10772 - loss = 1.449, (0.863 sec/step)\n",
      "step 10773 - loss = 1.990, (1.357 sec/step)\n",
      "step 10774 - loss = 1.644, (1.567 sec/step)\n",
      "step 10775 - loss = 2.508, (1.657 sec/step)\n",
      "step 10776 - loss = 1.822, (1.393 sec/step)\n",
      "step 10777 - loss = 2.018, (2.429 sec/step)\n",
      "step 10778 - loss = 1.305, (0.760 sec/step)\n",
      "step 10779 - loss = 1.959, (1.346 sec/step)\n",
      "step 10780 - loss = 1.618, (1.410 sec/step)\n",
      "step 10781 - loss = 1.821, (1.099 sec/step)\n",
      "step 10782 - loss = 2.357, (1.713 sec/step)\n",
      "step 10783 - loss = 1.914, (0.988 sec/step)\n",
      "step 10784 - loss = 1.303, (1.131 sec/step)\n",
      "step 10785 - loss = 1.377, (1.633 sec/step)\n",
      "step 10786 - loss = 2.270, (1.709 sec/step)\n",
      "step 10787 - loss = 1.434, (1.003 sec/step)\n",
      "step 10788 - loss = 1.960, (1.849 sec/step)\n",
      "step 10789 - loss = 1.948, (0.935 sec/step)\n",
      "step 10790 - loss = 1.596, (1.527 sec/step)\n",
      "step 10791 - loss = 2.146, (1.457 sec/step)\n",
      "step 10792 - loss = 2.039, (1.684 sec/step)\n",
      "step 10793 - loss = 1.873, (1.229 sec/step)\n",
      "step 10794 - loss = 1.923, (0.913 sec/step)\n",
      "step 10795 - loss = 1.309, (1.312 sec/step)\n",
      "step 10796 - loss = 1.348, (1.653 sec/step)\n",
      "step 10797 - loss = 2.010, (1.216 sec/step)\n",
      "step 10798 - loss = 2.212, (1.138 sec/step)\n",
      "step 10799 - loss = 1.825, (1.356 sec/step)\n",
      "step 10800 - loss = 1.908, (1.377 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10801 - loss = 1.460, (1.092 sec/step)\n",
      "step 10802 - loss = 1.946, (2.095 sec/step)\n",
      "step 10803 - loss = 1.510, (1.392 sec/step)\n",
      "step 10804 - loss = 2.232, (1.864 sec/step)\n",
      "step 10805 - loss = 1.554, (2.411 sec/step)\n",
      "step 10806 - loss = 1.937, (1.546 sec/step)\n",
      "step 10807 - loss = 1.699, (1.460 sec/step)\n",
      "step 10808 - loss = 1.896, (1.513 sec/step)\n",
      "step 10809 - loss = 2.121, (2.206 sec/step)\n",
      "step 10810 - loss = 1.852, (0.986 sec/step)\n",
      "step 10811 - loss = 2.385, (1.718 sec/step)\n",
      "step 10812 - loss = 2.009, (0.971 sec/step)\n",
      "step 10813 - loss = 1.674, (1.069 sec/step)\n",
      "step 10814 - loss = 1.447, (1.050 sec/step)\n",
      "step 10815 - loss = 1.607, (1.948 sec/step)\n",
      "step 10816 - loss = 1.877, (2.495 sec/step)\n",
      "step 10817 - loss = 2.217, (1.823 sec/step)\n",
      "step 10818 - loss = 2.211, (1.443 sec/step)\n",
      "step 10819 - loss = 1.983, (1.018 sec/step)\n",
      "step 10820 - loss = 1.926, (1.112 sec/step)\n",
      "step 10821 - loss = 1.697, (2.171 sec/step)\n",
      "step 10822 - loss = 1.299, (1.586 sec/step)\n",
      "step 10823 - loss = 1.957, (1.133 sec/step)\n",
      "step 10824 - loss = 1.897, (1.180 sec/step)\n",
      "step 10825 - loss = 1.581, (1.451 sec/step)\n",
      "step 10826 - loss = 1.986, (2.313 sec/step)\n",
      "step 10827 - loss = 2.077, (1.146 sec/step)\n",
      "step 10828 - loss = 1.293, (1.798 sec/step)\n",
      "step 10829 - loss = 1.867, (1.193 sec/step)\n",
      "step 10830 - loss = 1.557, (1.036 sec/step)\n",
      "step 10831 - loss = 1.771, (0.987 sec/step)\n",
      "step 10832 - loss = 2.138, (2.454 sec/step)\n",
      "step 10833 - loss = 1.858, (0.895 sec/step)\n",
      "step 10834 - loss = 1.868, (0.954 sec/step)\n",
      "step 10835 - loss = 1.876, (2.492 sec/step)\n",
      "step 10836 - loss = 1.894, (1.814 sec/step)\n",
      "step 10837 - loss = 2.076, (1.229 sec/step)\n",
      "step 10838 - loss = 1.707, (1.514 sec/step)\n",
      "step 10839 - loss = 1.620, (0.856 sec/step)\n",
      "step 10840 - loss = 1.943, (1.420 sec/step)\n",
      "step 10841 - loss = 1.468, (1.395 sec/step)\n",
      "step 10842 - loss = 2.129, (1.070 sec/step)\n",
      "step 10843 - loss = 1.929, (1.346 sec/step)\n",
      "step 10844 - loss = 1.471, (2.026 sec/step)\n",
      "step 10845 - loss = 2.074, (1.952 sec/step)\n",
      "step 10846 - loss = 1.699, (2.581 sec/step)\n",
      "step 10847 - loss = 1.252, (1.540 sec/step)\n",
      "step 10848 - loss = 1.325, (0.914 sec/step)\n",
      "step 10849 - loss = 1.817, (1.071 sec/step)\n",
      "step 10850 - loss = 1.684, (1.133 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10851 - loss = 1.782, (1.233 sec/step)\n",
      "step 10852 - loss = 2.026, (1.126 sec/step)\n",
      "step 10853 - loss = 1.537, (1.053 sec/step)\n",
      "step 10854 - loss = 2.352, (1.331 sec/step)\n",
      "step 10855 - loss = 1.969, (1.992 sec/step)\n",
      "step 10856 - loss = 1.494, (1.110 sec/step)\n",
      "step 10857 - loss = 0.817, (2.486 sec/step)\n",
      "step 10858 - loss = 2.331, (1.629 sec/step)\n",
      "step 10859 - loss = 1.470, (2.158 sec/step)\n",
      "step 10860 - loss = 2.082, (1.573 sec/step)\n",
      "step 10861 - loss = 2.231, (1.455 sec/step)\n",
      "step 10862 - loss = 1.937, (1.311 sec/step)\n",
      "step 10863 - loss = 1.302, (2.485 sec/step)\n",
      "step 10864 - loss = 0.573, (0.513 sec/step)\n",
      "step 10865 - loss = 2.337, (1.831 sec/step)\n",
      "step 10866 - loss = 1.618, (1.334 sec/step)\n",
      "step 10867 - loss = 1.821, (0.953 sec/step)\n",
      "step 10868 - loss = 1.670, (1.068 sec/step)\n",
      "step 10869 - loss = 1.927, (2.485 sec/step)\n",
      "step 10870 - loss = 0.747, (0.906 sec/step)\n",
      "step 10871 - loss = 1.221, (1.817 sec/step)\n",
      "step 10872 - loss = 1.121, (2.809 sec/step)\n",
      "step 10873 - loss = 1.354, (1.384 sec/step)\n",
      "step 10874 - loss = 2.008, (2.487 sec/step)\n",
      "step 10875 - loss = 2.619, (1.153 sec/step)\n",
      "step 10876 - loss = 1.492, (2.481 sec/step)\n",
      "step 10877 - loss = 1.358, (2.466 sec/step)\n",
      "step 10878 - loss = 2.172, (1.296 sec/step)\n",
      "step 10879 - loss = 1.894, (2.484 sec/step)\n",
      "step 10880 - loss = 0.510, (0.155 sec/step)\n",
      "step 10881 - loss = 2.302, (1.455 sec/step)\n",
      "step 10882 - loss = 2.443, (1.175 sec/step)\n",
      "step 10883 - loss = 1.292, (1.445 sec/step)\n",
      "step 10884 - loss = 1.396, (1.688 sec/step)\n",
      "step 10885 - loss = 1.717, (1.216 sec/step)\n",
      "step 10886 - loss = 1.897, (2.836 sec/step)\n",
      "step 10887 - loss = 1.954, (1.286 sec/step)\n",
      "step 10888 - loss = 1.978, (1.460 sec/step)\n",
      "step 10889 - loss = 2.099, (1.312 sec/step)\n",
      "step 10890 - loss = 2.059, (1.341 sec/step)\n",
      "step 10891 - loss = 1.948, (1.099 sec/step)\n",
      "step 10892 - loss = 2.008, (1.622 sec/step)\n",
      "step 10893 - loss = 1.890, (1.887 sec/step)\n",
      "step 10894 - loss = 2.114, (2.115 sec/step)\n",
      "step 10895 - loss = 1.326, (2.489 sec/step)\n",
      "step 10896 - loss = 0.763, (0.549 sec/step)\n",
      "step 10897 - loss = 1.884, (1.653 sec/step)\n",
      "step 10898 - loss = 1.109, (0.923 sec/step)\n",
      "step 10899 - loss = 1.242, (1.796 sec/step)\n",
      "step 10900 - loss = 1.992, (1.526 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10901 - loss = 1.800, (1.823 sec/step)\n",
      "step 10902 - loss = 1.972, (1.393 sec/step)\n",
      "step 10903 - loss = 1.795, (1.214 sec/step)\n",
      "step 10904 - loss = 1.605, (0.938 sec/step)\n",
      "step 10905 - loss = 2.267, (1.768 sec/step)\n",
      "step 10906 - loss = 1.945, (2.498 sec/step)\n",
      "step 10907 - loss = 1.756, (1.947 sec/step)\n",
      "step 10908 - loss = 1.543, (0.940 sec/step)\n",
      "step 10909 - loss = 1.897, (1.392 sec/step)\n",
      "step 10910 - loss = 2.587, (3.146 sec/step)\n",
      "step 10911 - loss = 1.847, (0.970 sec/step)\n",
      "step 10912 - loss = 1.732, (0.867 sec/step)\n",
      "step 10913 - loss = 2.022, (1.178 sec/step)\n",
      "step 10914 - loss = 2.034, (1.662 sec/step)\n",
      "step 10915 - loss = 1.801, (1.225 sec/step)\n",
      "step 10916 - loss = 1.228, (2.640 sec/step)\n",
      "step 10917 - loss = 1.522, (1.953 sec/step)\n",
      "step 10918 - loss = 2.187, (1.444 sec/step)\n",
      "step 10919 - loss = 1.742, (1.069 sec/step)\n",
      "step 10920 - loss = 1.926, (1.312 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10921 - loss = 2.027, (1.768 sec/step)\n",
      "step 10922 - loss = 1.978, (2.478 sec/step)\n",
      "step 10923 - loss = 1.788, (1.161 sec/step)\n",
      "step 10924 - loss = 1.469, (2.532 sec/step)\n",
      "step 10925 - loss = 1.973, (2.474 sec/step)\n",
      "step 10926 - loss = 1.803, (1.377 sec/step)\n",
      "step 10927 - loss = 1.800, (1.017 sec/step)\n",
      "step 10928 - loss = 2.243, (2.363 sec/step)\n",
      "step 10929 - loss = 1.826, (1.768 sec/step)\n",
      "step 10930 - loss = 2.014, (1.212 sec/step)\n",
      "step 10931 - loss = 1.161, (1.254 sec/step)\n",
      "step 10932 - loss = 1.280, (1.227 sec/step)\n",
      "step 10933 - loss = 1.773, (2.444 sec/step)\n",
      "step 10934 - loss = 1.713, (1.198 sec/step)\n",
      "step 10935 - loss = 1.687, (1.655 sec/step)\n",
      "step 10936 - loss = 1.999, (1.287 sec/step)\n",
      "step 10937 - loss = 2.250, (1.974 sec/step)\n",
      "step 10938 - loss = 1.860, (1.261 sec/step)\n",
      "step 10939 - loss = 1.715, (1.051 sec/step)\n",
      "step 10940 - loss = 1.377, (1.330 sec/step)\n",
      "step 10941 - loss = 1.437, (2.931 sec/step)\n",
      "step 10942 - loss = 1.823, (1.647 sec/step)\n",
      "step 10943 - loss = 2.103, (3.014 sec/step)\n",
      "step 10944 - loss = 1.546, (1.725 sec/step)\n",
      "step 10945 - loss = 1.590, (1.279 sec/step)\n",
      "step 10946 - loss = 1.923, (1.360 sec/step)\n",
      "step 10947 - loss = 1.843, (1.507 sec/step)\n",
      "step 10948 - loss = 1.879, (1.733 sec/step)\n",
      "step 10949 - loss = 1.761, (1.305 sec/step)\n",
      "step 10950 - loss = 1.986, (1.447 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 10951 - loss = 1.838, (1.295 sec/step)\n",
      "step 10952 - loss = 2.121, (2.212 sec/step)\n",
      "step 10953 - loss = 1.872, (1.877 sec/step)\n",
      "step 10954 - loss = 1.844, (1.060 sec/step)\n",
      "step 10955 - loss = 1.916, (1.556 sec/step)\n",
      "step 10956 - loss = 2.330, (1.408 sec/step)\n",
      "step 10957 - loss = 2.011, (1.899 sec/step)\n",
      "step 10958 - loss = 1.850, (1.460 sec/step)\n",
      "step 10959 - loss = 1.962, (1.201 sec/step)\n",
      "step 10960 - loss = 1.362, (0.896 sec/step)\n",
      "step 10961 - loss = 1.689, (0.907 sec/step)\n",
      "step 10962 - loss = 1.311, (1.163 sec/step)\n",
      "step 10963 - loss = 1.686, (1.600 sec/step)\n",
      "step 10964 - loss = 1.953, (1.244 sec/step)\n",
      "step 10965 - loss = 1.578, (1.231 sec/step)\n",
      "step 10966 - loss = 1.858, (1.126 sec/step)\n",
      "step 10967 - loss = 1.609, (1.455 sec/step)\n",
      "step 10968 - loss = 2.303, (1.475 sec/step)\n",
      "step 10969 - loss = 1.784, (0.870 sec/step)\n",
      "step 10970 - loss = 1.674, (1.767 sec/step)\n",
      "step 10971 - loss = 1.547, (1.587 sec/step)\n",
      "step 10972 - loss = 1.790, (0.927 sec/step)\n",
      "step 10973 - loss = 1.926, (1.208 sec/step)\n",
      "step 10974 - loss = 1.687, (1.292 sec/step)\n",
      "step 10975 - loss = 1.493, (1.291 sec/step)\n",
      "step 10976 - loss = 1.866, (0.853 sec/step)\n",
      "step 10977 - loss = 1.771, (1.191 sec/step)\n",
      "step 10978 - loss = 2.368, (2.015 sec/step)\n",
      "step 10979 - loss = 2.042, (2.005 sec/step)\n",
      "step 10980 - loss = 1.693, (2.384 sec/step)\n",
      "step 10981 - loss = 1.663, (1.606 sec/step)\n",
      "step 10982 - loss = 1.698, (1.217 sec/step)\n",
      "step 10983 - loss = 1.595, (1.064 sec/step)\n",
      "step 10984 - loss = 1.476, (1.592 sec/step)\n",
      "step 10985 - loss = 1.808, (1.128 sec/step)\n",
      "step 10986 - loss = 1.292, (3.340 sec/step)\n",
      "step 10987 - loss = 2.634, (1.515 sec/step)\n",
      "step 10988 - loss = 0.765, (0.294 sec/step)\n",
      "step 10989 - loss = 1.883, (1.425 sec/step)\n",
      "step 10990 - loss = 1.705, (1.622 sec/step)\n",
      "step 10991 - loss = 1.762, (1.520 sec/step)\n",
      "step 10992 - loss = 1.512, (3.207 sec/step)\n",
      "step 10993 - loss = 2.358, (1.568 sec/step)\n",
      "step 10994 - loss = 2.012, (2.404 sec/step)\n",
      "step 10995 - loss = 2.056, (1.230 sec/step)\n",
      "step 10996 - loss = 1.514, (1.273 sec/step)\n",
      "step 10997 - loss = 1.997, (2.119 sec/step)\n",
      "step 10998 - loss = 2.004, (2.236 sec/step)\n",
      "step 10999 - loss = 1.733, (2.343 sec/step)\n",
      "step 11000 - loss = 1.915, (1.201 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11001 - loss = 1.788, (1.164 sec/step)\n",
      "step 11002 - loss = 1.524, (0.980 sec/step)\n",
      "step 11003 - loss = 1.684, (1.365 sec/step)\n",
      "step 11004 - loss = 1.350, (1.320 sec/step)\n",
      "step 11005 - loss = 2.079, (2.429 sec/step)\n",
      "step 11006 - loss = 1.993, (1.841 sec/step)\n",
      "step 11007 - loss = 1.320, (1.444 sec/step)\n",
      "step 11008 - loss = 2.113, (0.868 sec/step)\n",
      "step 11009 - loss = 2.233, (1.390 sec/step)\n",
      "step 11010 - loss = 2.462, (1.560 sec/step)\n",
      "step 11011 - loss = 1.650, (1.685 sec/step)\n",
      "step 11012 - loss = 1.503, (1.381 sec/step)\n",
      "step 11013 - loss = 1.633, (1.072 sec/step)\n",
      "step 11014 - loss = 1.637, (0.778 sec/step)\n",
      "step 11015 - loss = 2.058, (0.941 sec/step)\n",
      "step 11016 - loss = 1.673, (1.587 sec/step)\n",
      "step 11017 - loss = 1.937, (1.543 sec/step)\n",
      "step 11018 - loss = 2.080, (1.729 sec/step)\n",
      "step 11019 - loss = 1.858, (1.210 sec/step)\n",
      "step 11020 - loss = 1.640, (1.382 sec/step)\n",
      "step 11021 - loss = 1.956, (2.811 sec/step)\n",
      "step 11022 - loss = 2.316, (1.446 sec/step)\n",
      "step 11023 - loss = 1.854, (3.062 sec/step)\n",
      "step 11024 - loss = 2.157, (1.171 sec/step)\n",
      "step 11025 - loss = 1.692, (1.051 sec/step)\n",
      "step 11026 - loss = 1.781, (1.339 sec/step)\n",
      "step 11027 - loss = 1.543, (1.260 sec/step)\n",
      "step 11028 - loss = 2.002, (1.289 sec/step)\n",
      "step 11029 - loss = 1.851, (2.002 sec/step)\n",
      "step 11030 - loss = 2.495, (1.210 sec/step)\n",
      "step 11031 - loss = 1.476, (1.344 sec/step)\n",
      "step 11032 - loss = 1.612, (1.563 sec/step)\n",
      "step 11033 - loss = 1.543, (2.478 sec/step)\n",
      "step 11034 - loss = 2.450, (1.115 sec/step)\n",
      "step 11035 - loss = 2.312, (1.592 sec/step)\n",
      "step 11036 - loss = 1.609, (0.998 sec/step)\n",
      "step 11037 - loss = 1.893, (1.479 sec/step)\n",
      "step 11038 - loss = 1.342, (1.199 sec/step)\n",
      "step 11039 - loss = 1.905, (1.475 sec/step)\n",
      "step 11040 - loss = 1.909, (1.983 sec/step)\n",
      "step 11041 - loss = 1.597, (2.885 sec/step)\n",
      "step 11042 - loss = 1.384, (2.366 sec/step)\n",
      "step 11043 - loss = 1.626, (1.257 sec/step)\n",
      "step 11044 - loss = 1.733, (0.819 sec/step)\n",
      "step 11045 - loss = 1.438, (2.136 sec/step)\n",
      "step 11046 - loss = 1.958, (1.294 sec/step)\n",
      "step 11047 - loss = 1.930, (1.477 sec/step)\n",
      "step 11048 - loss = 2.423, (1.541 sec/step)\n",
      "step 11049 - loss = 2.000, (2.369 sec/step)\n",
      "step 11050 - loss = 1.970, (2.482 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11051 - loss = 0.611, (0.667 sec/step)\n",
      "step 11052 - loss = 1.924, (1.699 sec/step)\n",
      "step 11053 - loss = 1.839, (0.997 sec/step)\n",
      "step 11054 - loss = 1.519, (1.708 sec/step)\n",
      "step 11055 - loss = 1.543, (1.472 sec/step)\n",
      "step 11056 - loss = 2.124, (1.854 sec/step)\n",
      "step 11057 - loss = 1.906, (1.174 sec/step)\n",
      "step 11058 - loss = 2.029, (2.096 sec/step)\n",
      "step 11059 - loss = 2.017, (2.626 sec/step)\n",
      "step 11060 - loss = 1.954, (2.498 sec/step)\n",
      "step 11061 - loss = 1.300, (1.419 sec/step)\n",
      "step 11062 - loss = 1.303, (1.001 sec/step)\n",
      "step 11063 - loss = 1.883, (1.747 sec/step)\n",
      "step 11064 - loss = 1.939, (1.098 sec/step)\n",
      "step 11065 - loss = 1.573, (0.858 sec/step)\n",
      "step 11066 - loss = 2.006, (2.486 sec/step)\n",
      "step 11067 - loss = 0.496, (0.127 sec/step)\n",
      "step 11068 - loss = 1.635, (1.260 sec/step)\n",
      "step 11069 - loss = 1.882, (1.151 sec/step)\n",
      "step 11070 - loss = 1.873, (1.515 sec/step)\n",
      "step 11071 - loss = 1.701, (1.370 sec/step)\n",
      "step 11072 - loss = 1.800, (1.550 sec/step)\n",
      "step 11073 - loss = 1.933, (1.681 sec/step)\n",
      "step 11074 - loss = 1.993, (1.683 sec/step)\n",
      "step 11075 - loss = 2.126, (2.034 sec/step)\n",
      "step 11076 - loss = 1.872, (1.477 sec/step)\n",
      "step 11077 - loss = 2.104, (1.126 sec/step)\n",
      "step 11078 - loss = 1.996, (0.955 sec/step)\n",
      "step 11079 - loss = 1.582, (0.911 sec/step)\n",
      "step 11080 - loss = 1.981, (2.842 sec/step)\n",
      "step 11081 - loss = 1.737, (1.255 sec/step)\n",
      "step 11082 - loss = 1.692, (1.053 sec/step)\n",
      "step 11083 - loss = 1.802, (1.432 sec/step)\n",
      "step 11084 - loss = 1.793, (1.728 sec/step)\n",
      "step 11085 - loss = 2.276, (2.415 sec/step)\n",
      "step 11086 - loss = 2.641, (2.488 sec/step)\n",
      "step 11087 - loss = 1.813, (0.540 sec/step)\n",
      "step 11088 - loss = 2.494, (2.202 sec/step)\n",
      "step 11089 - loss = 1.840, (1.161 sec/step)\n",
      "step 11090 - loss = 1.802, (1.297 sec/step)\n",
      "step 11091 - loss = 2.333, (1.444 sec/step)\n",
      "step 11092 - loss = 1.792, (1.326 sec/step)\n",
      "step 11093 - loss = 1.728, (1.511 sec/step)\n",
      "step 11094 - loss = 1.583, (1.975 sec/step)\n",
      "step 11095 - loss = 1.511, (1.183 sec/step)\n",
      "step 11096 - loss = 1.771, (1.333 sec/step)\n",
      "step 11097 - loss = 2.051, (1.228 sec/step)\n",
      "step 11098 - loss = 1.516, (1.407 sec/step)\n",
      "step 11099 - loss = 1.808, (2.483 sec/step)\n",
      "step 11100 - loss = 1.405, (1.115 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11101 - loss = 1.543, (1.693 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11102 - loss = 2.288, (2.779 sec/step)\n",
      "step 11103 - loss = 1.904, (2.124 sec/step)\n",
      "step 11104 - loss = 1.609, (0.969 sec/step)\n",
      "step 11105 - loss = 1.603, (0.936 sec/step)\n",
      "step 11106 - loss = 1.321, (1.196 sec/step)\n",
      "step 11107 - loss = 1.328, (1.589 sec/step)\n",
      "step 11108 - loss = 1.807, (1.289 sec/step)\n",
      "step 11109 - loss = 1.867, (1.555 sec/step)\n",
      "step 11110 - loss = 1.980, (0.987 sec/step)\n",
      "step 11111 - loss = 2.709, (1.003 sec/step)\n",
      "step 11112 - loss = 1.653, (1.457 sec/step)\n",
      "step 11113 - loss = 1.625, (2.747 sec/step)\n",
      "step 11114 - loss = 1.543, (1.000 sec/step)\n",
      "step 11115 - loss = 1.827, (1.436 sec/step)\n",
      "step 11116 - loss = 1.947, (1.601 sec/step)\n",
      "step 11117 - loss = 1.977, (1.456 sec/step)\n",
      "step 11118 - loss = 1.754, (1.304 sec/step)\n",
      "step 11119 - loss = 1.831, (1.615 sec/step)\n",
      "step 11120 - loss = 1.759, (1.114 sec/step)\n",
      "step 11121 - loss = 2.268, (1.542 sec/step)\n",
      "step 11122 - loss = 1.350, (2.194 sec/step)\n",
      "step 11123 - loss = 1.085, (1.394 sec/step)\n",
      "step 11124 - loss = 1.675, (0.946 sec/step)\n",
      "step 11125 - loss = 1.585, (1.032 sec/step)\n",
      "step 11126 - loss = 1.668, (1.408 sec/step)\n",
      "step 11127 - loss = 1.815, (1.344 sec/step)\n",
      "step 11128 - loss = 1.679, (1.383 sec/step)\n",
      "step 11129 - loss = 1.736, (1.334 sec/step)\n",
      "step 11130 - loss = 1.814, (1.329 sec/step)\n",
      "step 11131 - loss = 2.137, (1.547 sec/step)\n",
      "step 11132 - loss = 1.985, (1.647 sec/step)\n",
      "step 11133 - loss = 2.083, (1.363 sec/step)\n",
      "step 11134 - loss = 2.135, (1.989 sec/step)\n",
      "step 11135 - loss = 1.801, (1.458 sec/step)\n",
      "step 11136 - loss = 2.162, (1.350 sec/step)\n",
      "step 11137 - loss = 1.838, (2.649 sec/step)\n",
      "step 11138 - loss = 1.438, (2.377 sec/step)\n",
      "step 11139 - loss = 1.749, (1.370 sec/step)\n",
      "step 11140 - loss = 1.738, (1.410 sec/step)\n",
      "step 11141 - loss = 1.680, (2.928 sec/step)\n",
      "step 11142 - loss = 1.514, (2.612 sec/step)\n",
      "step 11143 - loss = 1.555, (2.571 sec/step)\n",
      "step 11144 - loss = 1.521, (1.505 sec/step)\n",
      "step 11145 - loss = 1.513, (0.969 sec/step)\n",
      "step 11146 - loss = 2.034, (1.852 sec/step)\n",
      "step 11147 - loss = 1.891, (1.291 sec/step)\n",
      "step 11148 - loss = 1.571, (1.049 sec/step)\n",
      "step 11149 - loss = 1.936, (1.437 sec/step)\n",
      "step 11150 - loss = 2.331, (2.795 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11151 - loss = 2.113, (1.441 sec/step)\n",
      "step 11152 - loss = 1.784, (1.251 sec/step)\n",
      "step 11153 - loss = 1.833, (1.390 sec/step)\n",
      "step 11154 - loss = 1.643, (1.090 sec/step)\n",
      "step 11155 - loss = 2.242, (1.411 sec/step)\n",
      "step 11156 - loss = 1.888, (1.148 sec/step)\n",
      "step 11157 - loss = 1.532, (2.081 sec/step)\n",
      "step 11158 - loss = 1.499, (1.066 sec/step)\n",
      "step 11159 - loss = 1.546, (1.054 sec/step)\n",
      "step 11160 - loss = 2.458, (1.209 sec/step)\n",
      "step 11161 - loss = 1.637, (1.415 sec/step)\n",
      "step 11162 - loss = 1.728, (1.345 sec/step)\n",
      "step 11163 - loss = 2.407, (1.571 sec/step)\n",
      "step 11164 - loss = 1.763, (1.849 sec/step)\n",
      "step 11165 - loss = 1.931, (2.702 sec/step)\n",
      "step 11166 - loss = 1.418, (1.242 sec/step)\n",
      "step 11167 - loss = 1.886, (2.658 sec/step)\n",
      "step 11168 - loss = 1.584, (1.306 sec/step)\n",
      "step 11169 - loss = 1.600, (1.114 sec/step)\n",
      "step 11170 - loss = 1.865, (1.586 sec/step)\n",
      "step 11171 - loss = 1.566, (1.178 sec/step)\n",
      "step 11172 - loss = 1.237, (1.610 sec/step)\n",
      "step 11173 - loss = 1.375, (1.709 sec/step)\n",
      "step 11174 - loss = 1.743, (1.100 sec/step)\n",
      "step 11175 - loss = 1.726, (1.212 sec/step)\n",
      "step 11176 - loss = 2.283, (2.685 sec/step)\n",
      "step 11177 - loss = 1.888, (1.507 sec/step)\n",
      "step 11178 - loss = 1.890, (1.170 sec/step)\n",
      "step 11179 - loss = 1.762, (1.459 sec/step)\n",
      "step 11180 - loss = 2.001, (2.375 sec/step)\n",
      "step 11181 - loss = 1.661, (1.035 sec/step)\n",
      "step 11182 - loss = 2.070, (1.845 sec/step)\n",
      "step 11183 - loss = 2.212, (1.879 sec/step)\n",
      "step 11184 - loss = 1.991, (1.213 sec/step)\n",
      "step 11185 - loss = 1.616, (2.810 sec/step)\n",
      "step 11186 - loss = 1.922, (1.098 sec/step)\n",
      "step 11187 - loss = 1.291, (2.483 sec/step)\n",
      "step 11188 - loss = 0.577, (2.257 sec/step)\n",
      "step 11189 - loss = 1.685, (1.842 sec/step)\n",
      "step 11190 - loss = 1.593, (1.245 sec/step)\n",
      "step 11191 - loss = 1.857, (2.225 sec/step)\n",
      "step 11192 - loss = 1.866, (1.376 sec/step)\n",
      "step 11193 - loss = 1.572, (1.109 sec/step)\n",
      "step 11194 - loss = 1.993, (1.512 sec/step)\n",
      "step 11195 - loss = 1.656, (1.311 sec/step)\n",
      "step 11196 - loss = 2.028, (2.030 sec/step)\n",
      "step 11197 - loss = 2.119, (1.278 sec/step)\n",
      "step 11198 - loss = 1.784, (1.326 sec/step)\n",
      "step 11199 - loss = 1.641, (2.301 sec/step)\n",
      "step 11200 - loss = 2.098, (1.661 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11201 - loss = 1.314, (2.301 sec/step)\n",
      "step 11202 - loss = 1.407, (1.431 sec/step)\n",
      "step 11203 - loss = 1.488, (1.686 sec/step)\n",
      "step 11204 - loss = 2.039, (1.819 sec/step)\n",
      "step 11205 - loss = 2.362, (0.910 sec/step)\n",
      "step 11206 - loss = 1.675, (1.441 sec/step)\n",
      "step 11207 - loss = 1.823, (2.709 sec/step)\n",
      "step 11208 - loss = 1.477, (1.356 sec/step)\n",
      "step 11209 - loss = 1.504, (1.251 sec/step)\n",
      "step 11210 - loss = 1.485, (2.113 sec/step)\n",
      "step 11211 - loss = 1.779, (1.162 sec/step)\n",
      "step 11212 - loss = 1.603, (1.706 sec/step)\n",
      "step 11213 - loss = 1.631, (1.095 sec/step)\n",
      "step 11214 - loss = 2.107, (1.524 sec/step)\n",
      "step 11215 - loss = 1.684, (1.446 sec/step)\n",
      "step 11216 - loss = 2.085, (1.246 sec/step)\n",
      "step 11217 - loss = 1.972, (1.601 sec/step)\n",
      "step 11218 - loss = 1.665, (2.483 sec/step)\n",
      "step 11219 - loss = 2.109, (1.039 sec/step)\n",
      "step 11220 - loss = 1.611, (1.727 sec/step)\n",
      "step 11221 - loss = 1.807, (1.105 sec/step)\n",
      "step 11222 - loss = 1.657, (1.126 sec/step)\n",
      "step 11223 - loss = 1.878, (1.210 sec/step)\n",
      "step 11224 - loss = 1.576, (1.050 sec/step)\n",
      "step 11225 - loss = 1.865, (1.654 sec/step)\n",
      "step 11226 - loss = 1.534, (1.664 sec/step)\n",
      "step 11227 - loss = 1.871, (1.445 sec/step)\n",
      "step 11228 - loss = 1.557, (2.479 sec/step)\n",
      "step 11229 - loss = 2.103, (1.963 sec/step)\n",
      "step 11230 - loss = 1.469, (1.545 sec/step)\n",
      "step 11231 - loss = 1.254, (1.418 sec/step)\n",
      "step 11232 - loss = 1.990, (1.916 sec/step)\n",
      "step 11233 - loss = 1.509, (1.604 sec/step)\n",
      "step 11234 - loss = 1.980, (1.178 sec/step)\n",
      "step 11235 - loss = 2.143, (1.514 sec/step)\n",
      "step 11236 - loss = 1.653, (2.485 sec/step)\n",
      "step 11237 - loss = 2.091, (1.040 sec/step)\n",
      "step 11238 - loss = 1.525, (1.623 sec/step)\n",
      "step 11239 - loss = 2.056, (1.224 sec/step)\n",
      "step 11240 - loss = 2.367, (1.417 sec/step)\n",
      "step 11241 - loss = 1.686, (1.809 sec/step)\n",
      "step 11242 - loss = 2.077, (2.173 sec/step)\n",
      "step 11243 - loss = 1.640, (1.282 sec/step)\n",
      "step 11244 - loss = 1.676, (1.001 sec/step)\n",
      "step 11245 - loss = 1.535, (1.181 sec/step)\n",
      "step 11246 - loss = 1.647, (1.179 sec/step)\n",
      "step 11247 - loss = 2.061, (1.248 sec/step)\n",
      "step 11248 - loss = 1.528, (1.100 sec/step)\n",
      "step 11249 - loss = 1.230, (1.050 sec/step)\n",
      "step 11250 - loss = 1.300, (2.507 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11251 - loss = 1.958, (1.628 sec/step)\n",
      "step 11252 - loss = 2.213, (1.311 sec/step)\n",
      "step 11253 - loss = 2.159, (2.309 sec/step)\n",
      "step 11254 - loss = 1.527, (1.379 sec/step)\n",
      "step 11255 - loss = 2.020, (2.137 sec/step)\n",
      "step 11256 - loss = 1.694, (1.540 sec/step)\n",
      "step 11257 - loss = 1.902, (1.476 sec/step)\n",
      "step 11258 - loss = 2.045, (2.571 sec/step)\n",
      "step 11259 - loss = 1.935, (2.079 sec/step)\n",
      "step 11260 - loss = 2.222, (1.791 sec/step)\n",
      "step 11261 - loss = 1.498, (2.415 sec/step)\n",
      "step 11262 - loss = 1.363, (2.037 sec/step)\n",
      "step 11263 - loss = 2.083, (1.293 sec/step)\n",
      "step 11264 - loss = 2.207, (1.742 sec/step)\n",
      "step 11265 - loss = 1.837, (1.352 sec/step)\n",
      "step 11266 - loss = 1.875, (1.547 sec/step)\n",
      "step 11267 - loss = 1.750, (1.025 sec/step)\n",
      "step 11268 - loss = 1.829, (1.358 sec/step)\n",
      "step 11269 - loss = 1.360, (0.938 sec/step)\n",
      "step 11270 - loss = 1.949, (1.633 sec/step)\n",
      "step 11271 - loss = 1.946, (1.650 sec/step)\n",
      "step 11272 - loss = 1.866, (1.130 sec/step)\n",
      "step 11273 - loss = 1.521, (2.254 sec/step)\n",
      "step 11274 - loss = 1.899, (1.447 sec/step)\n",
      "step 11275 - loss = 2.332, (1.285 sec/step)\n",
      "step 11276 - loss = 2.061, (1.346 sec/step)\n",
      "step 11277 - loss = 1.840, (1.069 sec/step)\n",
      "step 11278 - loss = 1.534, (1.106 sec/step)\n",
      "step 11279 - loss = 2.243, (1.256 sec/step)\n",
      "step 11280 - loss = 1.677, (2.612 sec/step)\n",
      "step 11281 - loss = 1.965, (1.294 sec/step)\n",
      "step 11282 - loss = 1.912, (1.477 sec/step)\n",
      "step 11283 - loss = 1.643, (1.126 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11284 - loss = 2.004, (1.542 sec/step)\n",
      "step 11285 - loss = 1.579, (3.062 sec/step)\n",
      "step 11286 - loss = 1.408, (1.445 sec/step)\n",
      "step 11287 - loss = 1.361, (1.292 sec/step)\n",
      "step 11288 - loss = 1.490, (2.589 sec/step)\n",
      "step 11289 - loss = 1.420, (1.156 sec/step)\n",
      "step 11290 - loss = 1.868, (0.858 sec/step)\n",
      "step 11291 - loss = 1.846, (1.544 sec/step)\n",
      "step 11292 - loss = 1.698, (1.067 sec/step)\n",
      "step 11293 - loss = 2.044, (2.738 sec/step)\n",
      "step 11294 - loss = 1.966, (2.123 sec/step)\n",
      "step 11295 - loss = 2.002, (1.227 sec/step)\n",
      "step 11296 - loss = 1.841, (1.345 sec/step)\n",
      "step 11297 - loss = 1.710, (2.012 sec/step)\n",
      "step 11298 - loss = 2.245, (3.000 sec/step)\n",
      "step 11299 - loss = 1.620, (1.187 sec/step)\n",
      "step 11300 - loss = 1.850, (1.339 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11301 - loss = 1.684, (1.152 sec/step)\n",
      "step 11302 - loss = 2.489, (1.372 sec/step)\n",
      "step 11303 - loss = 2.068, (1.254 sec/step)\n",
      "step 11304 - loss = 1.760, (1.415 sec/step)\n",
      "step 11305 - loss = 1.808, (1.897 sec/step)\n",
      "step 11306 - loss = 1.297, (2.486 sec/step)\n",
      "step 11307 - loss = 0.748, (0.198 sec/step)\n",
      "step 11308 - loss = 1.516, (1.423 sec/step)\n",
      "step 11309 - loss = 1.483, (2.561 sec/step)\n",
      "step 11310 - loss = 1.474, (2.010 sec/step)\n",
      "step 11311 - loss = 1.899, (1.479 sec/step)\n",
      "step 11312 - loss = 1.380, (1.313 sec/step)\n",
      "step 11313 - loss = 1.878, (1.791 sec/step)\n",
      "step 11314 - loss = 2.201, (1.066 sec/step)\n",
      "step 11315 - loss = 1.711, (0.970 sec/step)\n",
      "step 11316 - loss = 1.764, (1.115 sec/step)\n",
      "step 11317 - loss = 2.330, (1.115 sec/step)\n",
      "step 11318 - loss = 2.522, (2.103 sec/step)\n",
      "step 11319 - loss = 1.570, (1.162 sec/step)\n",
      "step 11320 - loss = 1.905, (1.515 sec/step)\n",
      "step 11321 - loss = 2.015, (2.141 sec/step)\n",
      "step 11322 - loss = 1.798, (1.342 sec/step)\n",
      "step 11323 - loss = 1.894, (0.997 sec/step)\n",
      "step 11324 - loss = 2.519, (2.485 sec/step)\n",
      "step 11325 - loss = 2.138, (1.841 sec/step)\n",
      "step 11326 - loss = 1.748, (1.555 sec/step)\n",
      "step 11327 - loss = 1.712, (1.663 sec/step)\n",
      "step 11328 - loss = 2.025, (3.107 sec/step)\n",
      "step 11329 - loss = 2.642, (1.514 sec/step)\n",
      "step 11330 - loss = 1.502, (2.024 sec/step)\n",
      "step 11331 - loss = 1.604, (1.283 sec/step)\n",
      "step 11332 - loss = 1.964, (2.277 sec/step)\n",
      "step 11333 - loss = 2.215, (1.456 sec/step)\n",
      "step 11334 - loss = 1.856, (1.529 sec/step)\n",
      "step 11335 - loss = 1.590, (1.151 sec/step)\n",
      "step 11336 - loss = 1.674, (1.048 sec/step)\n",
      "step 11337 - loss = 1.518, (1.034 sec/step)\n",
      "step 11338 - loss = 1.891, (2.484 sec/step)\n",
      "step 11339 - loss = 0.524, (1.478 sec/step)\n",
      "step 11340 - loss = 1.458, (1.109 sec/step)\n",
      "step 11341 - loss = 1.625, (1.056 sec/step)\n",
      "step 11342 - loss = 2.088, (1.092 sec/step)\n",
      "step 11343 - loss = 1.830, (0.775 sec/step)\n",
      "step 11344 - loss = 1.348, (1.844 sec/step)\n",
      "step 11345 - loss = 2.100, (1.046 sec/step)\n",
      "step 11346 - loss = 1.702, (1.031 sec/step)\n",
      "step 11347 - loss = 1.633, (2.348 sec/step)\n",
      "step 11348 - loss = 2.463, (2.483 sec/step)\n",
      "step 11349 - loss = 2.322, (2.608 sec/step)\n",
      "step 11350 - loss = 1.700, (1.713 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11351 - loss = 1.774, (1.026 sec/step)\n",
      "step 11352 - loss = 1.812, (1.731 sec/step)\n",
      "step 11353 - loss = 1.938, (1.276 sec/step)\n",
      "step 11354 - loss = 1.345, (1.304 sec/step)\n",
      "step 11355 - loss = 1.222, (2.485 sec/step)\n",
      "step 11356 - loss = 0.907, (0.476 sec/step)\n",
      "step 11357 - loss = 1.946, (1.591 sec/step)\n",
      "step 11358 - loss = 1.833, (1.070 sec/step)\n",
      "step 11359 - loss = 1.986, (1.606 sec/step)\n",
      "step 11360 - loss = 1.921, (1.645 sec/step)\n",
      "step 11361 - loss = 1.804, (0.965 sec/step)\n",
      "step 11362 - loss = 1.586, (1.251 sec/step)\n",
      "step 11363 - loss = 2.155, (1.447 sec/step)\n",
      "step 11364 - loss = 2.000, (1.210 sec/step)\n",
      "step 11365 - loss = 1.739, (1.180 sec/step)\n",
      "step 11366 - loss = 1.687, (1.317 sec/step)\n",
      "step 11367 - loss = 1.562, (2.105 sec/step)\n",
      "step 11368 - loss = 1.167, (1.245 sec/step)\n",
      "step 11369 - loss = 1.943, (1.110 sec/step)\n",
      "step 11370 - loss = 1.737, (1.002 sec/step)\n",
      "step 11371 - loss = 1.725, (1.034 sec/step)\n",
      "step 11372 - loss = 1.847, (1.445 sec/step)\n",
      "step 11373 - loss = 1.881, (1.033 sec/step)\n",
      "step 11374 - loss = 1.494, (1.481 sec/step)\n",
      "step 11375 - loss = 1.716, (1.391 sec/step)\n",
      "step 11376 - loss = 1.602, (1.865 sec/step)\n",
      "step 11377 - loss = 2.190, (1.683 sec/step)\n",
      "step 11378 - loss = 2.294, (2.303 sec/step)\n",
      "step 11379 - loss = 2.058, (1.541 sec/step)\n",
      "step 11380 - loss = 1.968, (1.226 sec/step)\n",
      "step 11381 - loss = 1.989, (1.202 sec/step)\n",
      "step 11382 - loss = 1.867, (1.250 sec/step)\n",
      "step 11383 - loss = 1.407, (1.553 sec/step)\n",
      "step 11384 - loss = 2.001, (1.446 sec/step)\n",
      "step 11385 - loss = 1.792, (1.325 sec/step)\n",
      "step 11386 - loss = 1.559, (1.109 sec/step)\n",
      "step 11387 - loss = 1.889, (1.360 sec/step)\n",
      "step 11388 - loss = 2.415, (2.484 sec/step)\n",
      "step 11389 - loss = 2.312, (1.901 sec/step)\n",
      "step 11390 - loss = 1.827, (1.358 sec/step)\n",
      "step 11391 - loss = 1.517, (1.226 sec/step)\n",
      "step 11392 - loss = 2.398, (1.445 sec/step)\n",
      "step 11393 - loss = 1.533, (1.153 sec/step)\n",
      "step 11394 - loss = 1.784, (1.160 sec/step)\n",
      "step 11395 - loss = 1.666, (1.652 sec/step)\n",
      "step 11396 - loss = 2.413, (1.655 sec/step)\n",
      "step 11397 - loss = 1.794, (1.208 sec/step)\n",
      "step 11398 - loss = 1.681, (1.555 sec/step)\n",
      "step 11399 - loss = 1.645, (1.293 sec/step)\n",
      "step 11400 - loss = 1.777, (1.092 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11401 - loss = 2.301, (2.132 sec/step)\n",
      "step 11402 - loss = 1.509, (1.113 sec/step)\n",
      "step 11403 - loss = 1.959, (1.647 sec/step)\n",
      "step 11404 - loss = 1.582, (1.446 sec/step)\n",
      "step 11405 - loss = 1.876, (1.339 sec/step)\n",
      "step 11406 - loss = 1.513, (1.872 sec/step)\n",
      "step 11407 - loss = 1.676, (1.306 sec/step)\n",
      "step 11408 - loss = 1.831, (1.178 sec/step)\n",
      "step 11409 - loss = 1.677, (1.440 sec/step)\n",
      "step 11410 - loss = 1.936, (1.988 sec/step)\n",
      "step 11411 - loss = 1.692, (1.086 sec/step)\n",
      "step 11412 - loss = 1.492, (1.705 sec/step)\n",
      "step 11413 - loss = 1.521, (1.280 sec/step)\n",
      "step 11414 - loss = 1.711, (2.013 sec/step)\n",
      "step 11415 - loss = 1.352, (2.381 sec/step)\n",
      "step 11416 - loss = 1.608, (3.082 sec/step)\n",
      "step 11417 - loss = 1.873, (1.069 sec/step)\n",
      "step 11418 - loss = 1.943, (1.738 sec/step)\n",
      "step 11419 - loss = 1.719, (1.238 sec/step)\n",
      "step 11420 - loss = 2.296, (1.521 sec/step)\n",
      "step 11421 - loss = 1.532, (1.542 sec/step)\n",
      "step 11422 - loss = 1.513, (1.194 sec/step)\n",
      "step 11423 - loss = 1.642, (1.112 sec/step)\n",
      "step 11424 - loss = 1.513, (2.203 sec/step)\n",
      "step 11425 - loss = 1.449, (1.541 sec/step)\n",
      "step 11426 - loss = 1.728, (1.071 sec/step)\n",
      "step 11427 - loss = 2.250, (2.487 sec/step)\n",
      "step 11428 - loss = 1.745, (2.608 sec/step)\n",
      "step 11429 - loss = 1.352, (2.387 sec/step)\n",
      "step 11430 - loss = 1.738, (1.379 sec/step)\n",
      "step 11431 - loss = 1.679, (1.215 sec/step)\n",
      "step 11432 - loss = 1.249, (1.533 sec/step)\n",
      "step 11433 - loss = 2.152, (2.574 sec/step)\n",
      "step 11434 - loss = 1.590, (1.146 sec/step)\n",
      "step 11435 - loss = 2.490, (2.680 sec/step)\n",
      "step 11436 - loss = 2.056, (1.562 sec/step)\n",
      "step 11437 - loss = 1.686, (1.162 sec/step)\n",
      "step 11438 - loss = 2.085, (1.644 sec/step)\n",
      "step 11439 - loss = 1.358, (1.163 sec/step)\n",
      "step 11440 - loss = 1.983, (1.834 sec/step)\n",
      "step 11441 - loss = 1.163, (1.716 sec/step)\n",
      "step 11442 - loss = 2.148, (2.167 sec/step)\n",
      "step 11443 - loss = 1.592, (1.447 sec/step)\n",
      "step 11444 - loss = 2.181, (1.902 sec/step)\n",
      "step 11445 - loss = 1.648, (1.653 sec/step)\n",
      "step 11446 - loss = 1.397, (1.047 sec/step)\n",
      "step 11447 - loss = 2.063, (2.486 sec/step)\n",
      "step 11448 - loss = 1.430, (0.641 sec/step)\n",
      "step 11449 - loss = 1.902, (1.198 sec/step)\n",
      "step 11450 - loss = 2.194, (1.260 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11451 - loss = 1.419, (1.280 sec/step)\n",
      "step 11452 - loss = 2.180, (1.200 sec/step)\n",
      "step 11453 - loss = 2.113, (1.444 sec/step)\n",
      "step 11454 - loss = 2.068, (1.456 sec/step)\n",
      "step 11455 - loss = 2.422, (1.360 sec/step)\n",
      "step 11456 - loss = 1.940, (1.559 sec/step)\n",
      "step 11457 - loss = 1.771, (0.936 sec/step)\n",
      "step 11458 - loss = 1.792, (1.068 sec/step)\n",
      "step 11459 - loss = 1.997, (2.057 sec/step)\n",
      "step 11460 - loss = 1.378, (1.712 sec/step)\n",
      "step 11461 - loss = 1.723, (1.701 sec/step)\n",
      "step 11462 - loss = 2.299, (1.326 sec/step)\n",
      "step 11463 - loss = 1.924, (1.395 sec/step)\n",
      "step 11464 - loss = 1.386, (1.292 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11465 - loss = 1.482, (1.207 sec/step)\n",
      "step 11466 - loss = 1.344, (1.291 sec/step)\n",
      "step 11467 - loss = 1.638, (1.042 sec/step)\n",
      "step 11468 - loss = 1.811, (0.989 sec/step)\n",
      "step 11469 - loss = 1.820, (0.856 sec/step)\n",
      "step 11470 - loss = 2.175, (1.252 sec/step)\n",
      "step 11471 - loss = 1.453, (1.710 sec/step)\n",
      "step 11472 - loss = 1.283, (1.031 sec/step)\n",
      "step 11473 - loss = 1.798, (1.427 sec/step)\n",
      "step 11474 - loss = 1.396, (1.391 sec/step)\n",
      "step 11475 - loss = 1.721, (1.145 sec/step)\n",
      "step 11476 - loss = 1.572, (1.020 sec/step)\n",
      "step 11477 - loss = 1.985, (2.385 sec/step)\n",
      "step 11478 - loss = 1.884, (2.041 sec/step)\n",
      "step 11479 - loss = 2.079, (1.068 sec/step)\n",
      "step 11480 - loss = 1.555, (2.374 sec/step)\n",
      "step 11481 - loss = 1.683, (2.486 sec/step)\n",
      "step 11482 - loss = 0.885, (1.063 sec/step)\n",
      "step 11483 - loss = 1.830, (1.970 sec/step)\n",
      "step 11484 - loss = 1.830, (1.395 sec/step)\n",
      "step 11485 - loss = 1.661, (1.392 sec/step)\n",
      "step 11486 - loss = 1.703, (1.644 sec/step)\n",
      "step 11487 - loss = 1.718, (1.848 sec/step)\n",
      "step 11488 - loss = 2.017, (2.071 sec/step)\n",
      "step 11489 - loss = 1.717, (1.358 sec/step)\n",
      "step 11490 - loss = 1.938, (1.228 sec/step)\n",
      "step 11491 - loss = 2.366, (2.247 sec/step)\n",
      "step 11492 - loss = 1.756, (2.633 sec/step)\n",
      "step 11493 - loss = 1.955, (1.645 sec/step)\n",
      "step 11494 - loss = 2.003, (1.992 sec/step)\n",
      "step 11495 - loss = 2.097, (1.538 sec/step)\n",
      "step 11496 - loss = 2.281, (1.459 sec/step)\n",
      "step 11497 - loss = 1.650, (1.315 sec/step)\n",
      "step 11498 - loss = 2.167, (1.923 sec/step)\n",
      "step 11499 - loss = 1.869, (1.055 sec/step)\n",
      "step 11500 - loss = 2.082, (1.129 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11501 - loss = 1.464, (1.577 sec/step)\n",
      "step 11502 - loss = 1.137, (2.485 sec/step)\n",
      "step 11503 - loss = 1.879, (1.193 sec/step)\n",
      "step 11504 - loss = 1.326, (0.869 sec/step)\n",
      "step 11505 - loss = 1.481, (1.229 sec/step)\n",
      "step 11506 - loss = 1.703, (1.315 sec/step)\n",
      "step 11507 - loss = 1.980, (1.255 sec/step)\n",
      "step 11508 - loss = 1.734, (1.198 sec/step)\n",
      "step 11509 - loss = 1.493, (0.772 sec/step)\n",
      "step 11510 - loss = 1.734, (1.127 sec/step)\n",
      "step 11511 - loss = 1.782, (1.193 sec/step)\n",
      "step 11512 - loss = 1.602, (0.862 sec/step)\n",
      "step 11513 - loss = 1.789, (1.781 sec/step)\n",
      "step 11514 - loss = 2.091, (1.067 sec/step)\n",
      "step 11515 - loss = 1.614, (0.857 sec/step)\n",
      "step 11516 - loss = 1.570, (0.791 sec/step)\n",
      "step 11517 - loss = 1.533, (1.814 sec/step)\n",
      "step 11518 - loss = 1.276, (1.154 sec/step)\n",
      "step 11519 - loss = 1.849, (1.476 sec/step)\n",
      "step 11520 - loss = 2.316, (1.198 sec/step)\n",
      "step 11521 - loss = 2.125, (1.179 sec/step)\n",
      "step 11522 - loss = 2.127, (1.200 sec/step)\n",
      "step 11523 - loss = 2.168, (2.485 sec/step)\n",
      "step 11524 - loss = 2.745, (1.156 sec/step)\n",
      "step 11525 - loss = 1.777, (1.540 sec/step)\n",
      "step 11526 - loss = 1.523, (1.480 sec/step)\n",
      "step 11527 - loss = 1.610, (1.925 sec/step)\n",
      "step 11528 - loss = 2.056, (1.174 sec/step)\n",
      "step 11529 - loss = 1.873, (1.076 sec/step)\n",
      "step 11530 - loss = 1.597, (1.219 sec/step)\n",
      "step 11531 - loss = 1.865, (1.429 sec/step)\n",
      "step 11532 - loss = 1.740, (1.611 sec/step)\n",
      "step 11533 - loss = 1.735, (1.428 sec/step)\n",
      "step 11534 - loss = 1.659, (1.361 sec/step)\n",
      "step 11535 - loss = 1.837, (2.465 sec/step)\n",
      "step 11536 - loss = 2.106, (1.447 sec/step)\n",
      "step 11537 - loss = 1.672, (1.065 sec/step)\n",
      "step 11538 - loss = 2.005, (1.274 sec/step)\n",
      "step 11539 - loss = 1.904, (2.734 sec/step)\n",
      "step 11540 - loss = 1.462, (1.254 sec/step)\n",
      "step 11541 - loss = 1.339, (0.971 sec/step)\n",
      "step 11542 - loss = 1.906, (1.332 sec/step)\n",
      "step 11543 - loss = 1.995, (1.100 sec/step)\n",
      "step 11544 - loss = 1.781, (2.488 sec/step)\n",
      "step 11545 - loss = 2.044, (1.380 sec/step)\n",
      "step 11546 - loss = 1.799, (0.793 sec/step)\n",
      "step 11547 - loss = 1.983, (1.311 sec/step)\n",
      "step 11548 - loss = 2.383, (2.080 sec/step)\n",
      "step 11549 - loss = 2.343, (2.494 sec/step)\n",
      "step 11550 - loss = 1.643, (1.247 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11551 - loss = 1.461, (1.260 sec/step)\n",
      "step 11552 - loss = 1.489, (3.007 sec/step)\n",
      "step 11553 - loss = 1.390, (1.006 sec/step)\n",
      "step 11554 - loss = 1.223, (1.059 sec/step)\n",
      "step 11555 - loss = 1.386, (0.913 sec/step)\n",
      "step 11556 - loss = 2.336, (1.257 sec/step)\n",
      "step 11557 - loss = 1.817, (1.149 sec/step)\n",
      "step 11558 - loss = 1.806, (0.914 sec/step)\n",
      "step 11559 - loss = 1.593, (1.278 sec/step)\n",
      "step 11560 - loss = 1.891, (1.660 sec/step)\n",
      "step 11561 - loss = 2.028, (2.484 sec/step)\n",
      "step 11562 - loss = 1.880, (0.506 sec/step)\n",
      "step 11563 - loss = 1.784, (1.394 sec/step)\n",
      "step 11564 - loss = 1.667, (1.088 sec/step)\n",
      "step 11565 - loss = 1.365, (1.431 sec/step)\n",
      "step 11566 - loss = 1.843, (1.612 sec/step)\n",
      "step 11567 - loss = 2.290, (1.456 sec/step)\n",
      "step 11568 - loss = 1.997, (1.100 sec/step)\n",
      "step 11569 - loss = 2.070, (1.028 sec/step)\n",
      "step 11570 - loss = 1.616, (1.590 sec/step)\n",
      "step 11571 - loss = 1.975, (1.344 sec/step)\n",
      "step 11572 - loss = 1.568, (1.409 sec/step)\n",
      "step 11573 - loss = 2.069, (1.251 sec/step)\n",
      "step 11574 - loss = 1.602, (1.409 sec/step)\n",
      "step 11575 - loss = 2.080, (1.818 sec/step)\n",
      "step 11576 - loss = 2.254, (1.127 sec/step)\n",
      "step 11577 - loss = 1.861, (1.218 sec/step)\n",
      "step 11578 - loss = 1.855, (2.695 sec/step)\n",
      "step 11579 - loss = 1.598, (0.647 sec/step)\n",
      "step 11580 - loss = 1.820, (1.780 sec/step)\n",
      "step 11581 - loss = 2.062, (1.286 sec/step)\n",
      "step 11582 - loss = 1.227, (1.279 sec/step)\n",
      "step 11583 - loss = 1.595, (1.279 sec/step)\n",
      "step 11584 - loss = 1.378, (2.090 sec/step)\n",
      "step 11585 - loss = 1.982, (1.251 sec/step)\n",
      "step 11586 - loss = 1.852, (1.545 sec/step)\n",
      "step 11587 - loss = 1.616, (1.786 sec/step)\n",
      "step 11588 - loss = 1.461, (1.765 sec/step)\n",
      "step 11589 - loss = 1.324, (2.501 sec/step)\n",
      "step 11590 - loss = 1.369, (1.385 sec/step)\n",
      "step 11591 - loss = 1.441, (3.028 sec/step)\n",
      "step 11592 - loss = 1.210, (2.073 sec/step)\n",
      "step 11593 - loss = 1.298, (0.759 sec/step)\n",
      "step 11594 - loss = 1.775, (1.162 sec/step)\n",
      "step 11595 - loss = 1.920, (2.541 sec/step)\n",
      "step 11596 - loss = 1.641, (1.311 sec/step)\n",
      "step 11597 - loss = 1.772, (1.261 sec/step)\n",
      "step 11598 - loss = 1.926, (1.182 sec/step)\n",
      "step 11599 - loss = 1.618, (1.863 sec/step)\n",
      "step 11600 - loss = 1.599, (1.111 sec/step)\n",
      "Storing checkpoint to ./logdir/train/2018-05-31T10-54-40 ... Done.\n",
      "step 11601 - loss = 2.095, (1.497 sec/step)\n",
      "step 11602 - loss = 1.920, (1.157 sec/step)\n",
      "step 11603 - loss = 2.131, (1.445 sec/step)\n",
      "step 11604 - loss = 1.617, (1.209 sec/step)\n",
      "step 11605 - loss = 1.419, (2.026 sec/step)\n",
      "step 11606 - loss = 1.834, (1.071 sec/step)\n",
      "step 11607 - loss = 2.052, (1.794 sec/step)\n",
      "step 11608 - loss = 1.612, (2.014 sec/step)\n",
      "step 11609 - loss = 1.585, (1.283 sec/step)\n",
      "step 11610 - loss = 1.769, (2.850 sec/step)\n",
      "step 11611 - loss = 1.393, (1.127 sec/step)\n",
      "step 11612 - loss = 1.486, (1.356 sec/step)\n",
      "step 11613 - loss = 1.803, (2.403 sec/step)\n",
      "step 11614 - loss = 1.533, (0.988 sec/step)\n",
      "step 11615 - loss = 1.465, (1.661 sec/step)\n",
      "step 11616 - loss = 1.799, (1.382 sec/step)\n",
      "step 11617 - loss = 1.550, (1.030 sec/step)\n",
      "step 11618 - loss = 2.650, (2.485 sec/step)\n",
      "step 11619 - loss = 2.305, (0.352 sec/step)\n",
      "step 11620 - loss = 1.556, (1.002 sec/step)\n",
      "step 11621 - loss = 1.539, (1.910 sec/step)\n",
      "step 11622 - loss = 1.892, (2.081 sec/step)\n",
      "step 11623 - loss = 1.574, (2.482 sec/step)\n",
      "step 11624 - loss = 1.712, (2.115 sec/step)\n",
      "step 11625 - loss = 1.154, (1.275 sec/step)\n",
      "step 11626 - loss = 1.900, (1.496 sec/step)\n",
      "step 11627 - loss = 1.990, (1.068 sec/step)\n",
      "step 11628 - loss = 1.876, (1.015 sec/step)\n",
      "step 11629 - loss = 1.736, (0.973 sec/step)\n",
      "step 11630 - loss = 2.208, (2.514 sec/step)\n",
      "step 11631 - loss = 1.628, (1.708 sec/step)\n",
      "step 11632 - loss = 1.546, (1.128 sec/step)\n",
      "step 11633 - loss = 1.079, (1.741 sec/step)\n",
      "step 11634 - loss = 1.885, (1.568 sec/step)\n",
      "step 11635 - loss = 1.771, (1.313 sec/step)\n",
      "step 11636 - loss = 1.976, (1.441 sec/step)\n",
      "step 11637 - loss = 1.677, (1.198 sec/step)\n",
      "step 11638 - loss = 1.450, (1.562 sec/step)\n"
     ]
    }
   ],
   "source": [
    "args = get_arguments()\n",
    "\n",
    "try:\n",
    "    directories = validate_directories(args)\n",
    "except ValueError as e:\n",
    "    print(\"Some arguments are wrong:\")\n",
    "    print(str(e))\n",
    "\n",
    "logdir = directories['logdir']\n",
    "restore_from = directories['restore_from']\n",
    "\n",
    "# Even if we restored the model, we will treat it as new training\n",
    "# if the trained model is written into an arbitrary location.\n",
    "is_overwritten_training = logdir != restore_from\n",
    "\n",
    "with open(args.wavenet_params, 'r') as f:\n",
    "    wavenet_params = json.load(f)\n",
    "\n",
    "# Create coordinator.\n",
    "coord = tf.train.Coordinator()\n",
    "\n",
    "# Load raw waveform from VCTK corpus.\n",
    "with tf.name_scope('create_inputs'):\n",
    "    # Allow silence trimming to be skipped by specifying a threshold near\n",
    "    # zero.\n",
    "    silence_threshold = args.silence_threshold if args.silence_threshold > \\\n",
    "                                                  EPSILON else None\n",
    "    gc_enabled = args.gc_channels is not None\n",
    "    reader = AudioReader(\n",
    "        args.data_dir,\n",
    "        coord,\n",
    "        sample_rate=wavenet_params['sample_rate'],\n",
    "        gc_enabled=gc_enabled,\n",
    "        receptive_field=WaveNetModel.calculate_receptive_field(wavenet_params[\"filter_width\"],\n",
    "                                                               wavenet_params[\"dilations\"],\n",
    "                                                               wavenet_params[\"scalar_input\"],\n",
    "                                                               wavenet_params[\"initial_filter_width\"]),\n",
    "        sample_size=args.sample_size,\n",
    "        silence_threshold=silence_threshold)\n",
    "    audio_batch = reader.dequeue(args.batch_size)\n",
    "    if gc_enabled:\n",
    "        gc_id_batch = reader.dequeue_gc(args.batch_size)\n",
    "    else:\n",
    "        gc_id_batch = None\n",
    "\n",
    "# Create network.\n",
    "net = WaveNetModel(\n",
    "    batch_size=args.batch_size,\n",
    "    dilations=wavenet_params[\"dilations\"],\n",
    "    filter_width=wavenet_params[\"filter_width\"],\n",
    "    residual_channels=wavenet_params[\"residual_channels\"],\n",
    "    dilation_channels=wavenet_params[\"dilation_channels\"],\n",
    "    skip_channels=wavenet_params[\"skip_channels\"],\n",
    "    quantization_channels=wavenet_params[\"quantization_channels\"],\n",
    "    use_biases=wavenet_params[\"use_biases\"],\n",
    "    scalar_input=wavenet_params[\"scalar_input\"],\n",
    "    initial_filter_width=wavenet_params[\"initial_filter_width\"],\n",
    "    histograms=args.histograms,\n",
    "    global_condition_channels=args.gc_channels,\n",
    "    global_condition_cardinality=reader.gc_category_cardinality)\n",
    "\n",
    "if args.l2_regularization_strength == 0:\n",
    "    args.l2_regularization_strength = None\n",
    "loss = net.loss(input_batch=audio_batch,\n",
    "                global_condition_batch=gc_id_batch,\n",
    "                l2_regularization_strength=args.l2_regularization_strength)\n",
    "optimizer = optimizer_factory[args.optimizer](\n",
    "                learning_rate=args.learning_rate,\n",
    "                momentum=args.momentum)\n",
    "trainable = tf.trainable_variables()\n",
    "optim = optimizer.minimize(loss, var_list=trainable)\n",
    "\n",
    "# Set up logging for TensorBoard.\n",
    "writer = tf.summary.FileWriter(logdir)\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "run_metadata = tf.RunMetadata()\n",
    "summaries = tf.summary.merge_all()\n",
    "\n",
    "# Set up session\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=False))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Saver for storing checkpoints of the model.\n",
    "saver = tf.train.Saver(var_list=tf.trainable_variables(), max_to_keep=args.max_checkpoints)\n",
    "\n",
    "try:\n",
    "    saved_global_step = load(saver, sess, restore_from)\n",
    "    if is_overwritten_training or saved_global_step is None:\n",
    "        # The first training step will be saved_global_step + 1,\n",
    "        # therefore we put -1 here for new or overwritten trainings.\n",
    "        saved_global_step = -1\n",
    "\n",
    "except:\n",
    "    print(\"Something went wrong while restoring checkpoint. \"\n",
    "          \"We will terminate training to avoid accidentally overwriting \"\n",
    "          \"the previous model.\")\n",
    "    raise\n",
    "\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "reader.start_threads(sess)\n",
    "\n",
    "step = None\n",
    "last_saved_step = saved_global_step\n",
    "try:\n",
    "    for step in range(saved_global_step + 1, args.num_steps):\n",
    "        start_time = time.time()\n",
    "        if args.store_metadata and step % 50 == 0:\n",
    "            # Slow run that stores extra information for debugging.\n",
    "            print('Storing metadata')\n",
    "            run_options = tf.RunOptions(\n",
    "                trace_level=tf.RunOptions.FULL_TRACE)\n",
    "            summary, loss_value, _ = sess.run(\n",
    "                [summaries, loss, optim],\n",
    "                options=run_options,\n",
    "                run_metadata=run_metadata)\n",
    "            writer.add_summary(summary, step)\n",
    "            writer.add_run_metadata(run_metadata,\n",
    "                                    'step_{:04d}'.format(step))\n",
    "            tl = timeline.Timeline(run_metadata.step_stats)\n",
    "            timeline_path = os.path.join(logdir, 'timeline.trace')\n",
    "            with open(timeline_path, 'w') as f:\n",
    "                f.write(tl.generate_chrome_trace_format(show_memory=True))\n",
    "        else:\n",
    "            summary, loss_value, _ = sess.run([summaries, loss, optim])\n",
    "            writer.add_summary(summary, step)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "        print('step {:d} - loss = {:.3f}, ({:.3f} sec/step)'\n",
    "              .format(step, loss_value, duration))\n",
    "\n",
    "        if step % args.checkpoint_every == 0:\n",
    "            save(saver, sess, logdir, step)\n",
    "            last_saved_step = step\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    # Introduce a line break after ^C is displayed so save message\n",
    "    # is on its own line.\n",
    "    print()\n",
    "finally:\n",
    "    if step > last_saved_step:\n",
    "        save(saver, sess, logdir, step)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
