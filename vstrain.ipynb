{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T15:37:23.737785Z",
     "start_time": "2018-06-19T15:37:22.615028Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import time\n",
    "import os\n",
    "from torch.utils import data\n",
    "from wavenet import Wavenet\n",
    "from transformData import x_mu_law_encode,y_mu_law_encode,mu_law_decode,onehot,cateToSignal\n",
    "from readDataset2 import Dataset,Testset,RandomCrop,ToTensor\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T15:37:23.751767Z",
     "start_time": "2018-06-19T15:37:23.740012Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleSize=16000#the length of the sample size\n",
    "quantization_channels=256\n",
    "sample_rate=16000\n",
    "dilations=[2**i for i in range(9)]*7  #idea from wavenet, have more receptive field\n",
    "residualDim=128 #\n",
    "skipDim=512\n",
    "shapeoftest = 190500\n",
    "filterSize=3\n",
    "songnum=10\n",
    "savemusic='./vsCorpus/notextr{}.wav'\n",
    "resumefile='./model/testac' # name of checkpoint\n",
    "lossname='testacloss.txt' # name of loss file\n",
    "continueTrain=False # whether use checkpoint\n",
    "pad = np.sum(dilations) # padding for dilate convolutional layers\n",
    "lossrecord=[]  #list for record loss\n",
    "sampleCnt=0\n",
    "#pad=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #            |----------------------------------------|     *residual*\n",
    "    #            |                                        |\n",
    "    #            |    |-- conv -- tanh --|                |\n",
    "    # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n",
    "    #                 |-- conv -- sigm --|     |    ||\n",
    "    #                                         1x1=residualDim\n",
    "    #                                          |\n",
    "    # ---------------------------------------> + ------------->\t*skip=skipDim*\n",
    "    image changed from https://github.com/vincentherrmann/pytorch-wavenet/blob/master/wavenet_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T15:37:23.756106Z",
     "start_time": "2018-06-19T15:37:23.753349Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # use specific GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T15:37:23.770842Z",
     "start_time": "2018-06-19T15:37:23.757546Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available() # whether have available GPU\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#device = 'cpu'\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor') #set_default_tensor_type as cuda tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T15:37:23.953285Z",
     "start_time": "2018-06-19T15:37:23.948940Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform=transforms.Compose([RandomCrop(),ToTensor()])\n",
    "training_set = Dataset(np.arange(0, songnum), np.arange(0, songnum), 'ccmixter2/x/', 'ccmixter2/y/',transform)\n",
    "validation_set = Testset(np.arange(0, songnum), 'ccmixter2/x/')\n",
    "loadtr = data.DataLoader(training_set, batch_size=1,shuffle=True,num_workers=2)  # pytorch dataloader, more faster than mine\n",
    "loadval = data.DataLoader(validation_set,batch_size=1,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T15:37:24.092231Z",
     "start_time": "2018-06-19T15:37:23.954918Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Wavenet(pad,skipDim,quantization_channels,residualDim,dilations).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#in wavenet paper, they said crossentropyloss is far better than MSELoss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3,weight_decay=1e-5)\n",
    "#use adam to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T15:37:24.102725Z",
     "start_time": "2018-06-19T15:37:24.094216Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_epoch=0\n",
    "if continueTrain:# if continueTrain, the program will find the checkpoints\n",
    "    if os.path.isfile(resumefile):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resumefile))\n",
    "        checkpoint = torch.load(resumefile)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        #best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(resumefile, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resumefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-19T15:37:22.619Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test():  # testing data\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for iloader, xtrain in enumerate(loadval):\n",
    "            listofpred = []\n",
    "            for ind in range(pad, xtrain.shape[-1] - pad, sampleSize):\n",
    "                output = model(xtrain[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "                pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "                listofpred.append(pred)\n",
    "            ans = mu_law_decode(np.concatenate(listofpred))\n",
    "            sf.write(savemusic.format(iloader), ans, sample_rate)\n",
    "            print('test stored done', np.round(time.time() - start_time))\n",
    "\n",
    "\n",
    "def train(epoch):  # training data, the audio except for last 15 seconds\n",
    "    model.train()\n",
    "    for iloader, (xtrain, ytrain) in enumerate(loadtr):\n",
    "        start_time = time.time()\n",
    "        data, target = xtrain.to(device), ytrain.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        lossrecord.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global sampleCnt\n",
    "        sampleCnt+=1\n",
    "        print('Train Epoch: {} iloader:{} Loss:{:.6f}: , ({:.3f} sec/step)'.format(\n",
    "            epoch, iloader, loss.item(), time.time() - start_time))\n",
    "        if sampleCnt % 5000 == 0 and sampleCnt > 0:\n",
    "            for param in optimizer.param_groups:\n",
    "                param['lr'] *= 0.98\n",
    "\n",
    "    if epoch % 100 == 0 and epoch > 0:\n",
    "        with open(\"./lossRecord/\" + lossname, \"w\") as f:\n",
    "            for s in lossrecord:\n",
    "                f.write(str(s) + \"\\n\")\n",
    "        print('write finish')\n",
    "        if not os.path.exists('./model/'): os.makedirs('./model/')\n",
    "        state = {'epoch': epoch,\n",
    "                 'state_dict': model.state_dict(),\n",
    "                 'optimizer': optimizer.state_dict()}\n",
    "        torch.save(state, resumefile)\n",
    "\n",
    "    if epoch % 1000 == 0 and epoch > 0:\n",
    "        test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-19T15:37:22.632Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 iloader:0 Loss:5.559141: , (72.744 sec/step)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    train(epoch+start_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLalgorithm/mnistPyTorch.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
