{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:31:20.803488Z",
     "start_time": "2018-06-16T02:31:19.903563Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import time\n",
    "import os\n",
    "from torch.utils import data\n",
    "from wavenet import Wavenet\n",
    "from transformData import x_mu_law_encode,y_mu_law_encode,mu_law_decode,onehot,cateToSignal\n",
    "from readDataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:31:20.815194Z",
     "start_time": "2018-06-16T02:31:20.805482Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampleSize=32000#the length of the sample size\n",
    "quantization_channels=256\n",
    "sample_rate=16000\n",
    "dilations=[2**i for i in range(9)]*5  #idea from wavenet, have more receptive field\n",
    "residualDim=128 #\n",
    "skipDim=512\n",
    "shapeoftest = 190500\n",
    "filterSize=3\n",
    "resumefile='./model/testac' # name of checkpoint\n",
    "lossname='testacloss.txt' # name of loss file\n",
    "continueTrain=True # whether use checkpoint\n",
    "pad = np.sum(dilations) # padding for dilate convolutional layers\n",
    "lossrecord=[]  #list for record loss\n",
    "#pad=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #            |----------------------------------------|     *residual*\n",
    "    #            |                                        |\n",
    "    #            |    |-- conv -- tanh --|                |\n",
    "    # -> dilate -|----|                  * ----|-- 1x1 -- + -->\t*input*\n",
    "    #                 |-- conv -- sigm --|     |    ||\n",
    "    #                                         1x1=residualDim\n",
    "    #                                          |\n",
    "    # ---------------------------------------> + ------------->\t*skip=skipDim*\n",
    "    image changed from https://github.com/vincentherrmann/pytorch-wavenet/blob/master/wavenet_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:31:20.819584Z",
     "start_time": "2018-06-16T02:31:20.816731Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"  # use specific GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:31:20.844065Z",
     "start_time": "2018-06-16T02:31:20.820886Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available() # whether have available GPU\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#device = 'cpu'\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor') #set_default_tensor_type as cuda tensor\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:31:20.850799Z",
     "start_time": "2018-06-16T02:31:20.845549Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'batch_size': 1,'shuffle': True,'num_workers': 1}\n",
    "training_set = Dataset(['origin_mix'],['origin_vocal'],'./vsCorpus/','./vsCorpus/')\n",
    "testing_set = Dataset(['pred_mix'],['pred_mix'],'./vsCorpus/','./vsCorpus/')\n",
    "loadtr = data.DataLoader(training_set, **params) #pytorch dataloader, more faster than mine\n",
    "loadval = data.DataLoader(testing_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:31:24.499955Z",
     "start_time": "2018-06-16T02:31:20.852118Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Wavenet(pad,skipDim,quantization_channels,residualDim,dilations).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#in wavenet paper, they said crossentropyloss is far better than MSELoss\n",
    "#optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3,weight_decay=1e-5)\n",
    "#use adam to train\n",
    "#optimizer = optim.SGD(model.parameters(), lr = 0.1, momentum=0.9, weight_decay=1e-5)\n",
    "#scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "#scheduler = MultiStepLR(optimizer, milestones=[20,40], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-16T02:31:25.142472Z",
     "start_time": "2018-06-16T02:31:24.502168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint './model/testac'\n",
      "=> loaded checkpoint './model/testac' (epoch 65)\n"
     ]
    }
   ],
   "source": [
    "if continueTrain:# if continueTrain, the program will find the checkpoints\n",
    "    if os.path.isfile(resumefile):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resumefile))\n",
    "        checkpoint = torch.load(resumefile)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        #best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(resumefile, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resumefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T02:31:19.909Z"
    },
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def val(xtrain,ytrain): #validation last 15 seconds of the audio.\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        idx = np.arange(xtrain.shape[-1]-pad-10*sampleSize,xtrain.shape[-1]-pad-sampleSize,1000)\n",
    "        np.random.shuffle(idx)\n",
    "        data = xtrain[:,:,idx[0]-pad:pad+idx[0]+sampleSize].to(device)\n",
    "        target = ytrain[:,idx[0]:idx[0]+sampleSize].to(device)\n",
    "        output = model(data)\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct = pred.eq(target.view_as(pred)).sum().item() / pred.shape[-1]\n",
    "        val_loss = criterion(output, target).item()\n",
    "        print(correct,'accurate')\n",
    "        print('\\nval set:loss{:.4f}:, ({:.3f} sec/step)\\n'.format(val_loss,time.time()-start_time))\n",
    "        \n",
    "        listofpred = []\n",
    "        for ind in range(xtrain.shape[-1]-pad-10*sampleSize,xtrain.shape[-1]-pad-sampleSize,sampleSize):\n",
    "            output = model(xtrain[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "            pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "            listofpred.append(pred)\n",
    "        ans = mu_law_decode(np.concatenate(listofpred))\n",
    "        sf.write('./vsCorpus/notexval.wav', ans, sample_rate)\n",
    "        print('val stored done',time.time() - start_time)\n",
    "        \n",
    "\n",
    "def test(xtrain):# testing data\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for iloader,(xtest,_) in enumerate(loadval):\n",
    "            listofpred = []\n",
    "            for ind in range(pad, xtest.shape[-1] - pad, sampleSize):\n",
    "                output = model(xtest[:, :, ind - pad:ind + sampleSize + pad].to(device))\n",
    "                pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "                listofpred.append(pred)\n",
    "            ans = mu_law_decode(np.concatenate(listofpred))\n",
    "            sf.write('./vsCorpus/notexte.wav', ans, sample_rate)\n",
    "\n",
    "            listofpred=[]\n",
    "            for ind in range(pad,xtrain.shape[-1]-pad,sampleSize):\n",
    "                output = model(xtrain[:, :, ind-pad:ind+sampleSize+pad].to(device))\n",
    "                pred = output.max(1, keepdim=True)[1].cpu().numpy().reshape(-1)\n",
    "                listofpred.append(pred)\n",
    "            ans = mu_law_decode(np.concatenate(listofpred))\n",
    "            sf.write('./vsCorpus/notextr.wav', ans, sample_rate)\n",
    "            print('test stored done',time.time() - start_time)\n",
    "    \n",
    "def train(epoch):#training data, the audio except for last 15 seconds\n",
    "    model.train()\n",
    "    for iloader,(xtrain,ytrain) in enumerate(loadtr):\n",
    "        idx = np.arange(pad,xtrain.shape[-1]-pad-11*sampleSize,16000)\n",
    "        np.random.shuffle(idx)#random the starting points\n",
    "        for i, ind in enumerate(idx):\n",
    "            start_time = time.time()\n",
    "            data, target = xtrain[:,:,ind-pad:ind+sampleSize+pad].to(device), ytrain[:,ind:ind+sampleSize].to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            lossrecord.append(loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)] Loss:{:.6f}: , ({:.3f} sec/step)'.format(\n",
    "                    epoch, i, len(idx),100. * i / len(idx), loss.item(),time.time() - start_time))\n",
    "            if i % 100 == 0:\n",
    "                with open(\"./lossRecord/\"+lossname, \"w\") as f:\n",
    "                    for s in lossrecord:\n",
    "                        f.write(str(s) +\"\\n\")\n",
    "                print('write finish')\n",
    "\n",
    "        val(xtrain,ytrain)\n",
    "        test(xtrain)\n",
    "        state={'epoch': epoch + 1,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()}\n",
    "        torch.save(state, resumefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-16T02:31:19.910Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/214 (0%)] Loss:1.166864: , (2.126 sec/step)\n",
      "write finish\n",
      "Train Epoch: 0 [1/214 (0%)] Loss:1.355406: , (2.119 sec/step)\n",
      "Train Epoch: 0 [2/214 (1%)] Loss:1.352069: , (2.118 sec/step)\n",
      "Train Epoch: 0 [3/214 (1%)] Loss:1.534732: , (2.119 sec/step)\n",
      "Train Epoch: 0 [4/214 (2%)] Loss:1.561106: , (2.121 sec/step)\n",
      "Train Epoch: 0 [5/214 (2%)] Loss:1.463008: , (2.120 sec/step)\n",
      "Train Epoch: 0 [6/214 (3%)] Loss:1.260574: , (2.120 sec/step)\n",
      "Train Epoch: 0 [7/214 (3%)] Loss:1.250476: , (2.120 sec/step)\n",
      "Train Epoch: 0 [8/214 (4%)] Loss:1.483780: , (2.119 sec/step)\n",
      "Train Epoch: 0 [9/214 (4%)] Loss:1.308076: , (2.122 sec/step)\n",
      "Train Epoch: 0 [10/214 (5%)] Loss:1.519015: , (2.125 sec/step)\n",
      "Train Epoch: 0 [11/214 (5%)] Loss:1.315021: , (2.126 sec/step)\n",
      "Train Epoch: 0 [12/214 (6%)] Loss:1.489690: , (2.126 sec/step)\n",
      "Train Epoch: 0 [13/214 (6%)] Loss:1.509562: , (2.126 sec/step)\n",
      "Train Epoch: 0 [14/214 (7%)] Loss:1.503773: , (2.126 sec/step)\n",
      "Train Epoch: 0 [15/214 (7%)] Loss:1.525444: , (2.127 sec/step)\n",
      "Train Epoch: 0 [16/214 (7%)] Loss:2.400832: , (2.127 sec/step)\n",
      "Train Epoch: 0 [17/214 (8%)] Loss:1.383054: , (2.130 sec/step)\n",
      "Train Epoch: 0 [18/214 (8%)] Loss:1.296293: , (2.128 sec/step)\n",
      "Train Epoch: 0 [19/214 (9%)] Loss:1.552055: , (2.130 sec/step)\n",
      "Train Epoch: 0 [20/214 (9%)] Loss:1.354711: , (2.129 sec/step)\n",
      "Train Epoch: 0 [21/214 (10%)] Loss:1.757900: , (2.131 sec/step)\n",
      "Train Epoch: 0 [22/214 (10%)] Loss:1.684277: , (2.128 sec/step)\n",
      "Train Epoch: 0 [23/214 (11%)] Loss:1.627725: , (2.129 sec/step)\n",
      "Train Epoch: 0 [24/214 (11%)] Loss:1.539605: , (2.130 sec/step)\n",
      "Train Epoch: 0 [25/214 (12%)] Loss:1.540431: , (2.129 sec/step)\n",
      "Train Epoch: 0 [26/214 (12%)] Loss:1.538484: , (2.132 sec/step)\n",
      "Train Epoch: 0 [27/214 (13%)] Loss:2.223503: , (2.130 sec/step)\n",
      "Train Epoch: 0 [28/214 (13%)] Loss:1.602657: , (2.130 sec/step)\n",
      "Train Epoch: 0 [29/214 (14%)] Loss:1.498887: , (2.131 sec/step)\n",
      "Train Epoch: 0 [30/214 (14%)] Loss:1.604042: , (2.130 sec/step)\n",
      "Train Epoch: 0 [31/214 (14%)] Loss:1.481460: , (2.131 sec/step)\n",
      "Train Epoch: 0 [32/214 (15%)] Loss:1.547920: , (2.129 sec/step)\n",
      "Train Epoch: 0 [33/214 (15%)] Loss:1.576892: , (2.132 sec/step)\n",
      "Train Epoch: 0 [34/214 (16%)] Loss:1.953364: , (2.132 sec/step)\n",
      "Train Epoch: 0 [35/214 (16%)] Loss:1.317974: , (2.130 sec/step)\n",
      "Train Epoch: 0 [36/214 (17%)] Loss:2.591684: , (2.131 sec/step)\n",
      "Train Epoch: 0 [37/214 (17%)] Loss:2.100816: , (2.131 sec/step)\n",
      "Train Epoch: 0 [38/214 (18%)] Loss:2.724201: , (2.134 sec/step)\n",
      "Train Epoch: 0 [39/214 (18%)] Loss:2.130689: , (2.133 sec/step)\n",
      "Train Epoch: 0 [40/214 (19%)] Loss:1.347146: , (2.133 sec/step)\n",
      "Train Epoch: 0 [41/214 (19%)] Loss:1.337450: , (2.134 sec/step)\n",
      "Train Epoch: 0 [42/214 (20%)] Loss:1.952748: , (2.132 sec/step)\n",
      "Train Epoch: 0 [43/214 (20%)] Loss:1.492308: , (2.132 sec/step)\n",
      "Train Epoch: 0 [44/214 (21%)] Loss:1.557827: , (2.132 sec/step)\n",
      "Train Epoch: 0 [45/214 (21%)] Loss:1.487846: , (2.132 sec/step)\n",
      "Train Epoch: 0 [46/214 (21%)] Loss:1.437119: , (2.130 sec/step)\n",
      "Train Epoch: 0 [47/214 (22%)] Loss:1.512716: , (2.130 sec/step)\n",
      "Train Epoch: 0 [48/214 (22%)] Loss:2.073787: , (2.131 sec/step)\n",
      "Train Epoch: 0 [49/214 (23%)] Loss:1.389943: , (2.133 sec/step)\n",
      "Train Epoch: 0 [50/214 (23%)] Loss:1.617980: , (2.131 sec/step)\n",
      "Train Epoch: 0 [51/214 (24%)] Loss:1.633319: , (2.132 sec/step)\n",
      "Train Epoch: 0 [52/214 (24%)] Loss:1.604638: , (2.131 sec/step)\n",
      "Train Epoch: 0 [53/214 (25%)] Loss:1.460386: , (2.133 sec/step)\n",
      "Train Epoch: 0 [54/214 (25%)] Loss:1.136999: , (2.133 sec/step)\n",
      "Train Epoch: 0 [55/214 (26%)] Loss:1.453805: , (2.133 sec/step)\n",
      "Train Epoch: 0 [56/214 (26%)] Loss:1.267883: , (2.130 sec/step)\n",
      "Train Epoch: 0 [57/214 (27%)] Loss:1.486779: , (2.131 sec/step)\n",
      "Train Epoch: 0 [58/214 (27%)] Loss:1.662274: , (2.132 sec/step)\n",
      "Train Epoch: 0 [59/214 (28%)] Loss:1.576091: , (2.133 sec/step)\n",
      "Train Epoch: 0 [60/214 (28%)] Loss:1.441493: , (2.132 sec/step)\n",
      "Train Epoch: 0 [61/214 (29%)] Loss:2.042577: , (2.133 sec/step)\n",
      "Train Epoch: 0 [62/214 (29%)] Loss:0.982854: , (2.131 sec/step)\n",
      "Train Epoch: 0 [63/214 (29%)] Loss:1.584775: , (2.131 sec/step)\n",
      "Train Epoch: 0 [64/214 (30%)] Loss:1.259374: , (2.133 sec/step)\n",
      "Train Epoch: 0 [65/214 (30%)] Loss:1.198731: , (2.132 sec/step)\n",
      "Train Epoch: 0 [66/214 (31%)] Loss:1.363084: , (2.132 sec/step)\n",
      "Train Epoch: 0 [67/214 (31%)] Loss:1.269918: , (2.133 sec/step)\n",
      "Train Epoch: 0 [68/214 (32%)] Loss:1.595353: , (2.135 sec/step)\n",
      "Train Epoch: 0 [69/214 (32%)] Loss:1.146151: , (2.133 sec/step)\n",
      "Train Epoch: 0 [70/214 (33%)] Loss:1.453511: , (2.135 sec/step)\n",
      "Train Epoch: 0 [71/214 (33%)] Loss:1.403972: , (2.133 sec/step)\n",
      "Train Epoch: 0 [72/214 (34%)] Loss:1.104731: , (2.132 sec/step)\n",
      "Train Epoch: 0 [73/214 (34%)] Loss:1.638104: , (2.132 sec/step)\n",
      "Train Epoch: 0 [74/214 (35%)] Loss:1.492504: , (2.133 sec/step)\n",
      "Train Epoch: 0 [75/214 (35%)] Loss:1.649446: , (2.133 sec/step)\n",
      "Train Epoch: 0 [76/214 (36%)] Loss:2.049387: , (2.134 sec/step)\n",
      "Train Epoch: 0 [77/214 (36%)] Loss:1.383467: , (2.133 sec/step)\n",
      "Train Epoch: 0 [78/214 (36%)] Loss:1.353916: , (2.134 sec/step)\n",
      "Train Epoch: 0 [79/214 (37%)] Loss:2.003216: , (2.134 sec/step)\n",
      "Train Epoch: 0 [80/214 (37%)] Loss:1.471868: , (2.133 sec/step)\n",
      "Train Epoch: 0 [81/214 (38%)] Loss:1.716215: , (2.134 sec/step)\n",
      "Train Epoch: 0 [82/214 (38%)] Loss:1.992077: , (2.132 sec/step)\n",
      "Train Epoch: 0 [83/214 (39%)] Loss:1.697697: , (2.134 sec/step)\n",
      "Train Epoch: 0 [84/214 (39%)] Loss:1.797791: , (2.132 sec/step)\n",
      "Train Epoch: 0 [85/214 (40%)] Loss:1.325399: , (2.135 sec/step)\n",
      "Train Epoch: 0 [86/214 (40%)] Loss:1.298538: , (2.133 sec/step)\n",
      "Train Epoch: 0 [87/214 (41%)] Loss:1.476229: , (2.134 sec/step)\n",
      "Train Epoch: 0 [88/214 (41%)] Loss:1.447747: , (2.135 sec/step)\n",
      "Train Epoch: 0 [89/214 (42%)] Loss:2.517866: , (2.133 sec/step)\n",
      "Train Epoch: 0 [90/214 (42%)] Loss:2.215287: , (2.134 sec/step)\n",
      "Train Epoch: 0 [91/214 (43%)] Loss:1.827862: , (2.135 sec/step)\n",
      "Train Epoch: 0 [92/214 (43%)] Loss:1.568292: , (2.133 sec/step)\n",
      "Train Epoch: 0 [93/214 (43%)] Loss:1.632518: , (2.133 sec/step)\n",
      "Train Epoch: 0 [94/214 (44%)] Loss:1.657330: , (2.134 sec/step)\n",
      "Train Epoch: 0 [95/214 (44%)] Loss:1.635906: , (2.136 sec/step)\n",
      "Train Epoch: 0 [96/214 (45%)] Loss:1.937531: , (2.134 sec/step)\n",
      "Train Epoch: 0 [97/214 (45%)] Loss:1.379634: , (2.134 sec/step)\n",
      "Train Epoch: 0 [98/214 (46%)] Loss:1.313255: , (2.132 sec/step)\n",
      "Train Epoch: 0 [99/214 (46%)] Loss:1.971191: , (2.132 sec/step)\n",
      "Train Epoch: 0 [100/214 (47%)] Loss:2.033497: , (2.132 sec/step)\n",
      "write finish\n",
      "Train Epoch: 0 [101/214 (47%)] Loss:1.618766: , (2.133 sec/step)\n",
      "Train Epoch: 0 [102/214 (48%)] Loss:2.182870: , (2.134 sec/step)\n",
      "Train Epoch: 0 [103/214 (48%)] Loss:2.721728: , (2.134 sec/step)\n",
      "Train Epoch: 0 [104/214 (49%)] Loss:1.482435: , (2.134 sec/step)\n",
      "Train Epoch: 0 [105/214 (49%)] Loss:2.179493: , (2.134 sec/step)\n",
      "Train Epoch: 0 [106/214 (50%)] Loss:1.373367: , (2.132 sec/step)\n",
      "Train Epoch: 0 [107/214 (50%)] Loss:1.390568: , (2.133 sec/step)\n",
      "Train Epoch: 0 [108/214 (50%)] Loss:1.551761: , (2.134 sec/step)\n",
      "Train Epoch: 0 [109/214 (51%)] Loss:1.487264: , (2.133 sec/step)\n",
      "Train Epoch: 0 [110/214 (51%)] Loss:1.657262: , (2.134 sec/step)\n",
      "Train Epoch: 0 [111/214 (52%)] Loss:1.432210: , (2.137 sec/step)\n",
      "Train Epoch: 0 [112/214 (52%)] Loss:1.736339: , (2.135 sec/step)\n",
      "Train Epoch: 0 [113/214 (53%)] Loss:1.669069: , (2.134 sec/step)\n",
      "Train Epoch: 0 [114/214 (53%)] Loss:1.329298: , (2.134 sec/step)\n",
      "Train Epoch: 0 [115/214 (54%)] Loss:1.684353: , (2.137 sec/step)\n",
      "Train Epoch: 0 [116/214 (54%)] Loss:1.627080: , (2.134 sec/step)\n",
      "Train Epoch: 0 [117/214 (55%)] Loss:1.297572: , (2.136 sec/step)\n",
      "Train Epoch: 0 [118/214 (55%)] Loss:1.447071: , (2.136 sec/step)\n",
      "Train Epoch: 0 [119/214 (56%)] Loss:1.521201: , (2.134 sec/step)\n",
      "Train Epoch: 0 [120/214 (56%)] Loss:1.707348: , (2.134 sec/step)\n",
      "Train Epoch: 0 [121/214 (57%)] Loss:1.562392: , (2.135 sec/step)\n",
      "Train Epoch: 0 [122/214 (57%)] Loss:2.000367: , (2.135 sec/step)\n",
      "Train Epoch: 0 [123/214 (57%)] Loss:1.502410: , (2.135 sec/step)\n",
      "Train Epoch: 0 [124/214 (58%)] Loss:1.356369: , (2.135 sec/step)\n",
      "Train Epoch: 0 [125/214 (58%)] Loss:1.604064: , (2.136 sec/step)\n",
      "Train Epoch: 0 [126/214 (59%)] Loss:1.704957: , (2.134 sec/step)\n",
      "Train Epoch: 0 [127/214 (59%)] Loss:1.639398: , (2.134 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [128/214 (60%)] Loss:1.300221: , (2.135 sec/step)\n",
      "Train Epoch: 0 [129/214 (60%)] Loss:1.816449: , (2.133 sec/step)\n",
      "Train Epoch: 0 [130/214 (61%)] Loss:1.314174: , (2.132 sec/step)\n",
      "Train Epoch: 0 [131/214 (61%)] Loss:1.733001: , (2.135 sec/step)\n",
      "Train Epoch: 0 [132/214 (62%)] Loss:1.506857: , (2.134 sec/step)\n",
      "Train Epoch: 0 [133/214 (62%)] Loss:1.556709: , (2.134 sec/step)\n",
      "Train Epoch: 0 [134/214 (63%)] Loss:1.845950: , (2.135 sec/step)\n",
      "Train Epoch: 0 [135/214 (63%)] Loss:1.729309: , (2.137 sec/step)\n",
      "Train Epoch: 0 [136/214 (64%)] Loss:1.774106: , (2.134 sec/step)\n",
      "Train Epoch: 0 [137/214 (64%)] Loss:1.488728: , (2.134 sec/step)\n",
      "Train Epoch: 0 [138/214 (64%)] Loss:1.771289: , (2.134 sec/step)\n",
      "Train Epoch: 0 [139/214 (65%)] Loss:1.577339: , (2.134 sec/step)\n",
      "Train Epoch: 0 [140/214 (65%)] Loss:1.515217: , (2.135 sec/step)\n",
      "Train Epoch: 0 [141/214 (66%)] Loss:1.901796: , (2.135 sec/step)\n",
      "Train Epoch: 0 [142/214 (66%)] Loss:2.187353: , (2.135 sec/step)\n",
      "Train Epoch: 0 [143/214 (67%)] Loss:1.880887: , (2.134 sec/step)\n",
      "Train Epoch: 0 [144/214 (67%)] Loss:1.135290: , (2.134 sec/step)\n",
      "Train Epoch: 0 [145/214 (68%)] Loss:1.808982: , (2.137 sec/step)\n",
      "Train Epoch: 0 [146/214 (68%)] Loss:1.404963: , (2.135 sec/step)\n",
      "Train Epoch: 0 [147/214 (69%)] Loss:1.738602: , (2.136 sec/step)\n",
      "Train Epoch: 0 [148/214 (69%)] Loss:1.827858: , (2.137 sec/step)\n",
      "Train Epoch: 0 [149/214 (70%)] Loss:1.967686: , (2.135 sec/step)\n",
      "Train Epoch: 0 [150/214 (70%)] Loss:1.702099: , (2.135 sec/step)\n",
      "Train Epoch: 0 [151/214 (71%)] Loss:1.292902: , (2.135 sec/step)\n",
      "Train Epoch: 0 [152/214 (71%)] Loss:1.701878: , (2.137 sec/step)\n",
      "Train Epoch: 0 [153/214 (71%)] Loss:1.659289: , (2.138 sec/step)\n",
      "Train Epoch: 0 [154/214 (72%)] Loss:1.816581: , (2.138 sec/step)\n",
      "Train Epoch: 0 [155/214 (72%)] Loss:1.728492: , (2.138 sec/step)\n",
      "Train Epoch: 0 [156/214 (73%)] Loss:1.521099: , (2.136 sec/step)\n",
      "Train Epoch: 0 [157/214 (73%)] Loss:1.641344: , (2.135 sec/step)\n",
      "Train Epoch: 0 [158/214 (74%)] Loss:1.592475: , (2.136 sec/step)\n",
      "Train Epoch: 0 [159/214 (74%)] Loss:1.382793: , (2.134 sec/step)\n",
      "Train Epoch: 0 [160/214 (75%)] Loss:1.438325: , (2.134 sec/step)\n",
      "Train Epoch: 0 [161/214 (75%)] Loss:2.503625: , (2.135 sec/step)\n",
      "Train Epoch: 0 [162/214 (76%)] Loss:1.770539: , (2.136 sec/step)\n",
      "Train Epoch: 0 [163/214 (76%)] Loss:1.558544: , (2.134 sec/step)\n",
      "Train Epoch: 0 [164/214 (77%)] Loss:2.022672: , (2.135 sec/step)\n",
      "Train Epoch: 0 [165/214 (77%)] Loss:1.735372: , (2.135 sec/step)\n",
      "Train Epoch: 0 [166/214 (78%)] Loss:1.502345: , (2.133 sec/step)\n",
      "Train Epoch: 0 [167/214 (78%)] Loss:1.731562: , (2.135 sec/step)\n",
      "Train Epoch: 0 [168/214 (79%)] Loss:1.811676: , (2.134 sec/step)\n",
      "Train Epoch: 0 [169/214 (79%)] Loss:1.462086: , (2.136 sec/step)\n",
      "Train Epoch: 0 [170/214 (79%)] Loss:2.076695: , (2.134 sec/step)\n",
      "Train Epoch: 0 [171/214 (80%)] Loss:2.063432: , (2.133 sec/step)\n",
      "Train Epoch: 0 [172/214 (80%)] Loss:1.585448: , (2.134 sec/step)\n",
      "Train Epoch: 0 [173/214 (81%)] Loss:1.742031: , (2.134 sec/step)\n",
      "Train Epoch: 0 [174/214 (81%)] Loss:1.957531: , (2.133 sec/step)\n",
      "Train Epoch: 0 [175/214 (82%)] Loss:1.498568: , (2.134 sec/step)\n",
      "Train Epoch: 0 [176/214 (82%)] Loss:1.424227: , (2.133 sec/step)\n",
      "Train Epoch: 0 [177/214 (83%)] Loss:1.892466: , (2.134 sec/step)\n",
      "Train Epoch: 0 [178/214 (83%)] Loss:1.517005: , (2.131 sec/step)\n",
      "Train Epoch: 0 [179/214 (84%)] Loss:2.255642: , (2.134 sec/step)\n",
      "Train Epoch: 0 [180/214 (84%)] Loss:1.487124: , (2.134 sec/step)\n",
      "Train Epoch: 0 [181/214 (85%)] Loss:1.749644: , (2.136 sec/step)\n",
      "Train Epoch: 0 [182/214 (85%)] Loss:1.679357: , (2.136 sec/step)\n",
      "Train Epoch: 0 [183/214 (86%)] Loss:1.530929: , (2.134 sec/step)\n",
      "Train Epoch: 0 [184/214 (86%)] Loss:1.435441: , (2.133 sec/step)\n",
      "Train Epoch: 0 [185/214 (86%)] Loss:1.446207: , (2.135 sec/step)\n",
      "Train Epoch: 0 [186/214 (87%)] Loss:1.563121: , (2.133 sec/step)\n",
      "Train Epoch: 0 [187/214 (87%)] Loss:1.631507: , (2.133 sec/step)\n",
      "Train Epoch: 0 [188/214 (88%)] Loss:1.828759: , (2.133 sec/step)\n",
      "Train Epoch: 0 [189/214 (88%)] Loss:1.552571: , (2.134 sec/step)\n",
      "Train Epoch: 0 [190/214 (89%)] Loss:1.689452: , (2.133 sec/step)\n",
      "Train Epoch: 0 [191/214 (89%)] Loss:2.172941: , (2.134 sec/step)\n",
      "Train Epoch: 0 [192/214 (90%)] Loss:1.462339: , (2.134 sec/step)\n",
      "Train Epoch: 0 [193/214 (90%)] Loss:1.453063: , (2.132 sec/step)\n",
      "Train Epoch: 0 [194/214 (91%)] Loss:1.651931: , (2.134 sec/step)\n",
      "Train Epoch: 0 [195/214 (91%)] Loss:1.619460: , (2.133 sec/step)\n",
      "Train Epoch: 0 [196/214 (92%)] Loss:1.385538: , (2.134 sec/step)\n",
      "Train Epoch: 0 [197/214 (92%)] Loss:1.318023: , (2.133 sec/step)\n",
      "Train Epoch: 0 [198/214 (93%)] Loss:1.156586: , (2.134 sec/step)\n",
      "Train Epoch: 0 [199/214 (93%)] Loss:2.026522: , (2.135 sec/step)\n",
      "Train Epoch: 0 [200/214 (93%)] Loss:2.051065: , (2.133 sec/step)\n",
      "write finish\n",
      "Train Epoch: 0 [201/214 (94%)] Loss:1.796319: , (2.135 sec/step)\n",
      "Train Epoch: 0 [202/214 (94%)] Loss:1.804912: , (2.134 sec/step)\n",
      "Train Epoch: 0 [203/214 (95%)] Loss:1.800919: , (2.133 sec/step)\n",
      "Train Epoch: 0 [204/214 (95%)] Loss:1.387304: , (2.133 sec/step)\n",
      "Train Epoch: 0 [205/214 (96%)] Loss:1.695111: , (2.134 sec/step)\n",
      "Train Epoch: 0 [206/214 (96%)] Loss:1.355685: , (2.133 sec/step)\n",
      "Train Epoch: 0 [207/214 (97%)] Loss:1.812164: , (2.133 sec/step)\n",
      "Train Epoch: 0 [208/214 (97%)] Loss:1.603858: , (2.133 sec/step)\n",
      "Train Epoch: 0 [209/214 (98%)] Loss:1.502507: , (2.135 sec/step)\n",
      "Train Epoch: 0 [210/214 (98%)] Loss:1.969827: , (2.133 sec/step)\n",
      "Train Epoch: 0 [211/214 (99%)] Loss:1.623784: , (2.134 sec/step)\n",
      "Train Epoch: 0 [212/214 (99%)] Loss:1.744890: , (2.135 sec/step)\n",
      "Train Epoch: 0 [213/214 (100%)] Loss:1.750377: , (2.133 sec/step)\n",
      "0.02553125 accurate\n",
      "\n",
      "val set:loss10.4109:, (0.664 sec/step)\n",
      "\n",
      "val stored done 6.647839784622192\n",
      "test stored done 82.91593790054321\n",
      "Train Epoch: 1 [0/214 (0%)] Loss:1.815677: , (2.133 sec/step)\n",
      "write finish\n",
      "Train Epoch: 1 [1/214 (0%)] Loss:0.802922: , (2.132 sec/step)\n",
      "Train Epoch: 1 [2/214 (1%)] Loss:1.443995: , (2.133 sec/step)\n",
      "Train Epoch: 1 [3/214 (1%)] Loss:1.237177: , (2.133 sec/step)\n",
      "Train Epoch: 1 [4/214 (2%)] Loss:1.323356: , (2.133 sec/step)\n",
      "Train Epoch: 1 [5/214 (2%)] Loss:1.489585: , (2.134 sec/step)\n",
      "Train Epoch: 1 [6/214 (3%)] Loss:1.464816: , (2.134 sec/step)\n",
      "Train Epoch: 1 [7/214 (3%)] Loss:1.342530: , (2.131 sec/step)\n",
      "Train Epoch: 1 [8/214 (4%)] Loss:1.245014: , (2.133 sec/step)\n",
      "Train Epoch: 1 [9/214 (4%)] Loss:1.298192: , (2.133 sec/step)\n",
      "Train Epoch: 1 [10/214 (5%)] Loss:1.429478: , (2.133 sec/step)\n",
      "Train Epoch: 1 [11/214 (5%)] Loss:1.400386: , (2.133 sec/step)\n",
      "Train Epoch: 1 [12/214 (6%)] Loss:1.589986: , (2.133 sec/step)\n",
      "Train Epoch: 1 [13/214 (6%)] Loss:1.358559: , (2.133 sec/step)\n",
      "Train Epoch: 1 [14/214 (7%)] Loss:0.988371: , (2.132 sec/step)\n",
      "Train Epoch: 1 [15/214 (7%)] Loss:1.275684: , (2.133 sec/step)\n",
      "Train Epoch: 1 [16/214 (7%)] Loss:1.643995: , (2.133 sec/step)\n",
      "Train Epoch: 1 [17/214 (8%)] Loss:1.347695: , (2.133 sec/step)\n",
      "Train Epoch: 1 [18/214 (8%)] Loss:1.366276: , (2.134 sec/step)\n",
      "Train Epoch: 1 [19/214 (9%)] Loss:1.589348: , (2.134 sec/step)\n",
      "Train Epoch: 1 [20/214 (9%)] Loss:1.929481: , (2.135 sec/step)\n",
      "Train Epoch: 1 [21/214 (10%)] Loss:1.587240: , (2.134 sec/step)\n",
      "Train Epoch: 1 [22/214 (10%)] Loss:1.841268: , (2.135 sec/step)\n",
      "Train Epoch: 1 [23/214 (11%)] Loss:1.566155: , (2.135 sec/step)\n",
      "Train Epoch: 1 [24/214 (11%)] Loss:1.583333: , (2.134 sec/step)\n",
      "Train Epoch: 1 [25/214 (12%)] Loss:1.378166: , (2.137 sec/step)\n",
      "Train Epoch: 1 [26/214 (12%)] Loss:1.361144: , (2.146 sec/step)\n",
      "Train Epoch: 1 [27/214 (13%)] Loss:1.808057: , (2.135 sec/step)\n",
      "Train Epoch: 1 [28/214 (13%)] Loss:1.691136: , (2.136 sec/step)\n",
      "Train Epoch: 1 [29/214 (14%)] Loss:1.839195: , (2.135 sec/step)\n",
      "Train Epoch: 1 [30/214 (14%)] Loss:1.199737: , (2.135 sec/step)\n",
      "Train Epoch: 1 [31/214 (14%)] Loss:1.243625: , (2.133 sec/step)\n",
      "Train Epoch: 1 [32/214 (15%)] Loss:1.315700: , (2.135 sec/step)\n",
      "Train Epoch: 1 [33/214 (15%)] Loss:1.260764: , (2.136 sec/step)\n",
      "Train Epoch: 1 [34/214 (16%)] Loss:1.367851: , (2.134 sec/step)\n",
      "Train Epoch: 1 [35/214 (16%)] Loss:1.336290: , (2.133 sec/step)\n",
      "Train Epoch: 1 [36/214 (17%)] Loss:2.183173: , (2.133 sec/step)\n",
      "Train Epoch: 1 [37/214 (17%)] Loss:1.770400: , (2.133 sec/step)\n",
      "Train Epoch: 1 [38/214 (18%)] Loss:1.452956: , (2.133 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [39/214 (18%)] Loss:1.459196: , (2.133 sec/step)\n",
      "Train Epoch: 1 [40/214 (19%)] Loss:1.497208: , (2.134 sec/step)\n",
      "Train Epoch: 1 [41/214 (19%)] Loss:1.382822: , (2.135 sec/step)\n",
      "Train Epoch: 1 [42/214 (20%)] Loss:2.111525: , (2.133 sec/step)\n",
      "Train Epoch: 1 [43/214 (20%)] Loss:1.923267: , (2.135 sec/step)\n",
      "Train Epoch: 1 [44/214 (21%)] Loss:1.563558: , (2.134 sec/step)\n",
      "Train Epoch: 1 [45/214 (21%)] Loss:1.378688: , (2.135 sec/step)\n",
      "Train Epoch: 1 [46/214 (21%)] Loss:1.312755: , (2.134 sec/step)\n",
      "Train Epoch: 1 [47/214 (22%)] Loss:1.369437: , (2.135 sec/step)\n",
      "Train Epoch: 1 [48/214 (22%)] Loss:1.508787: , (2.134 sec/step)\n",
      "Train Epoch: 1 [49/214 (23%)] Loss:1.234402: , (2.133 sec/step)\n",
      "Train Epoch: 1 [50/214 (23%)] Loss:1.740749: , (2.133 sec/step)\n",
      "Train Epoch: 1 [51/214 (24%)] Loss:1.273612: , (2.134 sec/step)\n",
      "Train Epoch: 1 [52/214 (24%)] Loss:1.409329: , (2.134 sec/step)\n",
      "Train Epoch: 1 [53/214 (25%)] Loss:1.700603: , (2.135 sec/step)\n",
      "Train Epoch: 1 [54/214 (25%)] Loss:1.482051: , (2.134 sec/step)\n",
      "Train Epoch: 1 [55/214 (26%)] Loss:1.316718: , (2.133 sec/step)\n",
      "Train Epoch: 1 [56/214 (26%)] Loss:1.865881: , (2.135 sec/step)\n",
      "Train Epoch: 1 [57/214 (27%)] Loss:1.232297: , (2.134 sec/step)\n",
      "Train Epoch: 1 [58/214 (27%)] Loss:1.374403: , (2.133 sec/step)\n",
      "Train Epoch: 1 [59/214 (28%)] Loss:2.050563: , (2.134 sec/step)\n",
      "Train Epoch: 1 [60/214 (28%)] Loss:1.388664: , (2.133 sec/step)\n",
      "Train Epoch: 1 [61/214 (29%)] Loss:1.393490: , (2.134 sec/step)\n",
      "Train Epoch: 1 [62/214 (29%)] Loss:1.335959: , (2.135 sec/step)\n",
      "Train Epoch: 1 [63/214 (29%)] Loss:2.095554: , (2.134 sec/step)\n",
      "Train Epoch: 1 [64/214 (30%)] Loss:1.357949: , (2.132 sec/step)\n",
      "Train Epoch: 1 [65/214 (30%)] Loss:1.496013: , (2.134 sec/step)\n",
      "Train Epoch: 1 [66/214 (31%)] Loss:2.907866: , (2.133 sec/step)\n",
      "Train Epoch: 1 [67/214 (31%)] Loss:1.471109: , (2.133 sec/step)\n",
      "Train Epoch: 1 [68/214 (32%)] Loss:1.700598: , (2.132 sec/step)\n",
      "Train Epoch: 1 [69/214 (32%)] Loss:1.385858: , (2.134 sec/step)\n",
      "Train Epoch: 1 [70/214 (33%)] Loss:1.475731: , (2.135 sec/step)\n",
      "Train Epoch: 1 [71/214 (33%)] Loss:1.617893: , (2.134 sec/step)\n",
      "Train Epoch: 1 [72/214 (34%)] Loss:1.348490: , (2.134 sec/step)\n",
      "Train Epoch: 1 [73/214 (34%)] Loss:1.869168: , (2.136 sec/step)\n",
      "Train Epoch: 1 [74/214 (35%)] Loss:1.548088: , (2.135 sec/step)\n",
      "Train Epoch: 1 [75/214 (35%)] Loss:1.503465: , (2.135 sec/step)\n",
      "Train Epoch: 1 [76/214 (36%)] Loss:1.466503: , (2.135 sec/step)\n",
      "Train Epoch: 1 [77/214 (36%)] Loss:1.527208: , (2.134 sec/step)\n",
      "Train Epoch: 1 [78/214 (36%)] Loss:1.401271: , (2.133 sec/step)\n",
      "Train Epoch: 1 [79/214 (37%)] Loss:1.414468: , (2.133 sec/step)\n",
      "Train Epoch: 1 [80/214 (37%)] Loss:1.465368: , (2.134 sec/step)\n",
      "Train Epoch: 1 [81/214 (38%)] Loss:1.699721: , (2.134 sec/step)\n",
      "Train Epoch: 1 [82/214 (38%)] Loss:1.591658: , (2.135 sec/step)\n",
      "Train Epoch: 1 [83/214 (39%)] Loss:1.992631: , (2.134 sec/step)\n",
      "Train Epoch: 1 [84/214 (39%)] Loss:1.413447: , (2.132 sec/step)\n",
      "Train Epoch: 1 [85/214 (40%)] Loss:1.714667: , (2.134 sec/step)\n",
      "Train Epoch: 1 [86/214 (40%)] Loss:1.455420: , (2.135 sec/step)\n",
      "Train Epoch: 1 [87/214 (41%)] Loss:1.765183: , (2.133 sec/step)\n",
      "Train Epoch: 1 [88/214 (41%)] Loss:1.528694: , (2.132 sec/step)\n",
      "Train Epoch: 1 [89/214 (42%)] Loss:2.268951: , (2.133 sec/step)\n",
      "Train Epoch: 1 [90/214 (42%)] Loss:1.790992: , (2.134 sec/step)\n",
      "Train Epoch: 1 [91/214 (43%)] Loss:1.395360: , (2.134 sec/step)\n",
      "Train Epoch: 1 [92/214 (43%)] Loss:1.666541: , (2.133 sec/step)\n",
      "Train Epoch: 1 [93/214 (43%)] Loss:1.306063: , (2.133 sec/step)\n",
      "Train Epoch: 1 [94/214 (44%)] Loss:1.351877: , (2.133 sec/step)\n",
      "Train Epoch: 1 [95/214 (44%)] Loss:1.471523: , (2.133 sec/step)\n",
      "Train Epoch: 1 [96/214 (45%)] Loss:1.550198: , (2.133 sec/step)\n",
      "Train Epoch: 1 [97/214 (45%)] Loss:1.532333: , (2.134 sec/step)\n",
      "Train Epoch: 1 [98/214 (46%)] Loss:1.557755: , (2.133 sec/step)\n",
      "Train Epoch: 1 [99/214 (46%)] Loss:1.082168: , (2.133 sec/step)\n",
      "Train Epoch: 1 [100/214 (47%)] Loss:0.983921: , (2.133 sec/step)\n",
      "write finish\n",
      "Train Epoch: 1 [101/214 (47%)] Loss:1.354903: , (2.133 sec/step)\n",
      "Train Epoch: 1 [102/214 (48%)] Loss:1.688789: , (2.134 sec/step)\n",
      "Train Epoch: 1 [103/214 (48%)] Loss:1.367985: , (2.132 sec/step)\n",
      "Train Epoch: 1 [104/214 (49%)] Loss:1.979589: , (2.132 sec/step)\n",
      "Train Epoch: 1 [105/214 (49%)] Loss:1.659253: , (2.133 sec/step)\n",
      "Train Epoch: 1 [106/214 (50%)] Loss:1.627691: , (2.133 sec/step)\n",
      "Train Epoch: 1 [107/214 (50%)] Loss:1.784820: , (2.134 sec/step)\n",
      "Train Epoch: 1 [108/214 (50%)] Loss:1.428438: , (2.132 sec/step)\n",
      "Train Epoch: 1 [109/214 (51%)] Loss:1.445564: , (2.134 sec/step)\n",
      "Train Epoch: 1 [110/214 (51%)] Loss:1.336976: , (2.134 sec/step)\n",
      "Train Epoch: 1 [111/214 (52%)] Loss:1.261563: , (2.132 sec/step)\n",
      "Train Epoch: 1 [112/214 (52%)] Loss:1.935377: , (2.133 sec/step)\n",
      "Train Epoch: 1 [113/214 (53%)] Loss:1.525854: , (2.133 sec/step)\n",
      "Train Epoch: 1 [114/214 (53%)] Loss:1.518579: , (2.133 sec/step)\n",
      "Train Epoch: 1 [115/214 (54%)] Loss:1.429250: , (2.132 sec/step)\n",
      "Train Epoch: 1 [116/214 (54%)] Loss:1.513174: , (2.135 sec/step)\n",
      "Train Epoch: 1 [117/214 (55%)] Loss:1.378912: , (2.134 sec/step)\n",
      "Train Epoch: 1 [118/214 (55%)] Loss:2.349971: , (2.134 sec/step)\n",
      "Train Epoch: 1 [119/214 (56%)] Loss:1.778371: , (2.134 sec/step)\n",
      "Train Epoch: 1 [120/214 (56%)] Loss:1.341650: , (2.133 sec/step)\n",
      "Train Epoch: 1 [121/214 (57%)] Loss:1.449725: , (2.133 sec/step)\n",
      "Train Epoch: 1 [122/214 (57%)] Loss:1.653580: , (2.132 sec/step)\n",
      "Train Epoch: 1 [123/214 (57%)] Loss:2.020801: , (2.133 sec/step)\n",
      "Train Epoch: 1 [124/214 (58%)] Loss:1.603734: , (2.134 sec/step)\n",
      "Train Epoch: 1 [125/214 (58%)] Loss:1.380152: , (2.132 sec/step)\n",
      "Train Epoch: 1 [126/214 (59%)] Loss:1.394550: , (2.134 sec/step)\n",
      "Train Epoch: 1 [127/214 (59%)] Loss:1.241146: , (2.134 sec/step)\n",
      "Train Epoch: 1 [128/214 (60%)] Loss:1.563731: , (2.134 sec/step)\n",
      "Train Epoch: 1 [129/214 (60%)] Loss:1.881772: , (2.134 sec/step)\n",
      "Train Epoch: 1 [130/214 (61%)] Loss:1.599142: , (2.134 sec/step)\n",
      "Train Epoch: 1 [131/214 (61%)] Loss:1.442139: , (2.136 sec/step)\n",
      "Train Epoch: 1 [132/214 (62%)] Loss:1.335595: , (2.136 sec/step)\n",
      "Train Epoch: 1 [133/214 (62%)] Loss:1.544418: , (2.135 sec/step)\n",
      "Train Epoch: 1 [134/214 (63%)] Loss:2.095959: , (2.135 sec/step)\n",
      "Train Epoch: 1 [135/214 (63%)] Loss:1.475453: , (2.134 sec/step)\n",
      "Train Epoch: 1 [136/214 (64%)] Loss:1.499378: , (2.136 sec/step)\n",
      "Train Epoch: 1 [137/214 (64%)] Loss:1.616053: , (2.136 sec/step)\n",
      "Train Epoch: 1 [138/214 (64%)] Loss:1.896773: , (2.135 sec/step)\n",
      "Train Epoch: 1 [139/214 (65%)] Loss:1.755877: , (2.134 sec/step)\n",
      "Train Epoch: 1 [140/214 (65%)] Loss:1.350024: , (2.134 sec/step)\n",
      "Train Epoch: 1 [141/214 (66%)] Loss:1.934312: , (2.135 sec/step)\n",
      "Train Epoch: 1 [142/214 (66%)] Loss:1.838119: , (2.133 sec/step)\n",
      "Train Epoch: 1 [143/214 (67%)] Loss:1.622030: , (2.134 sec/step)\n",
      "Train Epoch: 1 [144/214 (67%)] Loss:1.239060: , (2.134 sec/step)\n",
      "Train Epoch: 1 [145/214 (68%)] Loss:2.363226: , (2.134 sec/step)\n",
      "Train Epoch: 1 [146/214 (68%)] Loss:1.570616: , (2.134 sec/step)\n",
      "Train Epoch: 1 [147/214 (69%)] Loss:1.452671: , (2.134 sec/step)\n",
      "Train Epoch: 1 [148/214 (69%)] Loss:1.574472: , (2.134 sec/step)\n",
      "Train Epoch: 1 [149/214 (70%)] Loss:1.282710: , (2.135 sec/step)\n",
      "Train Epoch: 1 [150/214 (70%)] Loss:1.596355: , (2.137 sec/step)\n",
      "Train Epoch: 1 [151/214 (71%)] Loss:1.571548: , (2.133 sec/step)\n",
      "Train Epoch: 1 [152/214 (71%)] Loss:1.582659: , (2.133 sec/step)\n",
      "Train Epoch: 1 [153/214 (71%)] Loss:1.420954: , (2.134 sec/step)\n",
      "Train Epoch: 1 [154/214 (72%)] Loss:1.301065: , (2.133 sec/step)\n",
      "Train Epoch: 1 [155/214 (72%)] Loss:1.369155: , (2.134 sec/step)\n",
      "Train Epoch: 1 [156/214 (73%)] Loss:1.323812: , (2.133 sec/step)\n",
      "Train Epoch: 1 [157/214 (73%)] Loss:1.628927: , (2.135 sec/step)\n",
      "Train Epoch: 1 [158/214 (74%)] Loss:1.437529: , (2.133 sec/step)\n",
      "Train Epoch: 1 [159/214 (74%)] Loss:1.526232: , (2.135 sec/step)\n",
      "Train Epoch: 1 [160/214 (75%)] Loss:1.500732: , (2.135 sec/step)\n",
      "Train Epoch: 1 [161/214 (75%)] Loss:1.423621: , (2.135 sec/step)\n",
      "Train Epoch: 1 [162/214 (76%)] Loss:1.527993: , (2.133 sec/step)\n",
      "Train Epoch: 1 [163/214 (76%)] Loss:1.305605: , (2.134 sec/step)\n",
      "Train Epoch: 1 [164/214 (77%)] Loss:1.559812: , (2.135 sec/step)\n",
      "Train Epoch: 1 [165/214 (77%)] Loss:1.528547: , (2.133 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [166/214 (78%)] Loss:1.407983: , (2.133 sec/step)\n",
      "Train Epoch: 1 [167/214 (78%)] Loss:1.260544: , (2.135 sec/step)\n",
      "Train Epoch: 1 [168/214 (79%)] Loss:1.449898: , (2.135 sec/step)\n",
      "Train Epoch: 1 [169/214 (79%)] Loss:1.127281: , (2.133 sec/step)\n",
      "Train Epoch: 1 [170/214 (79%)] Loss:1.354030: , (2.135 sec/step)\n",
      "Train Epoch: 1 [171/214 (80%)] Loss:1.673305: , (2.134 sec/step)\n",
      "Train Epoch: 1 [172/214 (80%)] Loss:1.544323: , (2.133 sec/step)\n",
      "Train Epoch: 1 [173/214 (81%)] Loss:2.015117: , (2.134 sec/step)\n",
      "Train Epoch: 1 [174/214 (81%)] Loss:2.445705: , (2.135 sec/step)\n",
      "Train Epoch: 1 [175/214 (82%)] Loss:1.610141: , (2.132 sec/step)\n",
      "Train Epoch: 1 [176/214 (82%)] Loss:1.429478: , (2.134 sec/step)\n",
      "Train Epoch: 1 [177/214 (83%)] Loss:2.193564: , (2.134 sec/step)\n",
      "Train Epoch: 1 [178/214 (83%)] Loss:1.807058: , (2.134 sec/step)\n",
      "Train Epoch: 1 [179/214 (84%)] Loss:1.321150: , (2.133 sec/step)\n",
      "Train Epoch: 1 [180/214 (84%)] Loss:1.421357: , (2.132 sec/step)\n",
      "Train Epoch: 1 [181/214 (85%)] Loss:1.391571: , (2.134 sec/step)\n",
      "Train Epoch: 1 [182/214 (85%)] Loss:1.476553: , (2.133 sec/step)\n",
      "Train Epoch: 1 [183/214 (86%)] Loss:1.501749: , (2.134 sec/step)\n",
      "Train Epoch: 1 [184/214 (86%)] Loss:1.658560: , (2.134 sec/step)\n",
      "Train Epoch: 1 [185/214 (86%)] Loss:1.998186: , (2.133 sec/step)\n",
      "Train Epoch: 1 [186/214 (87%)] Loss:1.458116: , (2.133 sec/step)\n",
      "Train Epoch: 1 [187/214 (87%)] Loss:1.368055: , (2.132 sec/step)\n",
      "Train Epoch: 1 [188/214 (88%)] Loss:2.016262: , (2.133 sec/step)\n",
      "Train Epoch: 1 [189/214 (88%)] Loss:1.558266: , (2.133 sec/step)\n",
      "Train Epoch: 1 [190/214 (89%)] Loss:1.610385: , (2.133 sec/step)\n",
      "Train Epoch: 1 [191/214 (89%)] Loss:1.824970: , (2.133 sec/step)\n",
      "Train Epoch: 1 [192/214 (90%)] Loss:1.519906: , (2.133 sec/step)\n",
      "Train Epoch: 1 [193/214 (90%)] Loss:2.526954: , (2.133 sec/step)\n",
      "Train Epoch: 1 [194/214 (91%)] Loss:1.670683: , (2.134 sec/step)\n",
      "Train Epoch: 1 [195/214 (91%)] Loss:1.500593: , (2.133 sec/step)\n",
      "Train Epoch: 1 [196/214 (92%)] Loss:1.524304: , (2.134 sec/step)\n",
      "Train Epoch: 1 [197/214 (92%)] Loss:1.428946: , (2.134 sec/step)\n",
      "Train Epoch: 1 [198/214 (93%)] Loss:1.498835: , (2.133 sec/step)\n",
      "Train Epoch: 1 [199/214 (93%)] Loss:1.551206: , (2.133 sec/step)\n",
      "Train Epoch: 1 [200/214 (93%)] Loss:1.583716: , (2.133 sec/step)\n",
      "write finish\n",
      "Train Epoch: 1 [201/214 (94%)] Loss:1.727328: , (2.133 sec/step)\n",
      "Train Epoch: 1 [202/214 (94%)] Loss:1.605578: , (2.134 sec/step)\n",
      "Train Epoch: 1 [203/214 (95%)] Loss:1.378816: , (2.134 sec/step)\n",
      "Train Epoch: 1 [204/214 (95%)] Loss:2.664324: , (2.134 sec/step)\n",
      "Train Epoch: 1 [205/214 (96%)] Loss:1.491007: , (2.133 sec/step)\n",
      "Train Epoch: 1 [206/214 (96%)] Loss:1.747163: , (2.134 sec/step)\n",
      "Train Epoch: 1 [207/214 (97%)] Loss:1.742938: , (2.134 sec/step)\n",
      "Train Epoch: 1 [208/214 (97%)] Loss:2.300323: , (2.134 sec/step)\n",
      "Train Epoch: 1 [209/214 (98%)] Loss:1.723406: , (2.134 sec/step)\n",
      "Train Epoch: 1 [210/214 (98%)] Loss:1.771845: , (2.132 sec/step)\n",
      "Train Epoch: 1 [211/214 (99%)] Loss:2.757866: , (2.133 sec/step)\n",
      "Train Epoch: 1 [212/214 (99%)] Loss:1.694270: , (2.133 sec/step)\n",
      "Train Epoch: 1 [213/214 (100%)] Loss:1.589489: , (2.134 sec/step)\n",
      "0.03553125 accurate\n",
      "\n",
      "val set:loss10.1373:, (0.664 sec/step)\n",
      "\n",
      "val stored done 6.645713567733765\n",
      "test stored done 82.85042715072632\n",
      "Train Epoch: 2 [0/214 (0%)] Loss:1.798436: , (2.132 sec/step)\n",
      "write finish\n",
      "Train Epoch: 2 [1/214 (0%)] Loss:1.429974: , (2.133 sec/step)\n",
      "Train Epoch: 2 [2/214 (1%)] Loss:1.577735: , (2.132 sec/step)\n",
      "Train Epoch: 2 [3/214 (1%)] Loss:1.669535: , (2.131 sec/step)\n",
      "Train Epoch: 2 [4/214 (2%)] Loss:1.667560: , (2.131 sec/step)\n",
      "Train Epoch: 2 [5/214 (2%)] Loss:2.242505: , (2.133 sec/step)\n",
      "Train Epoch: 2 [6/214 (3%)] Loss:1.591569: , (2.132 sec/step)\n",
      "Train Epoch: 2 [7/214 (3%)] Loss:1.614633: , (2.137 sec/step)\n",
      "Train Epoch: 2 [8/214 (4%)] Loss:1.448496: , (2.140 sec/step)\n",
      "Train Epoch: 2 [9/214 (4%)] Loss:1.696270: , (2.140 sec/step)\n",
      "Train Epoch: 2 [10/214 (5%)] Loss:1.436305: , (2.135 sec/step)\n",
      "Train Epoch: 2 [11/214 (5%)] Loss:1.948331: , (2.139 sec/step)\n",
      "Train Epoch: 2 [12/214 (6%)] Loss:1.426223: , (2.137 sec/step)\n",
      "Train Epoch: 2 [13/214 (6%)] Loss:1.459645: , (2.135 sec/step)\n",
      "Train Epoch: 2 [14/214 (7%)] Loss:1.546459: , (2.134 sec/step)\n",
      "Train Epoch: 2 [15/214 (7%)] Loss:1.353081: , (2.135 sec/step)\n",
      "Train Epoch: 2 [16/214 (7%)] Loss:1.419196: , (2.139 sec/step)\n",
      "Train Epoch: 2 [17/214 (8%)] Loss:1.773764: , (2.137 sec/step)\n",
      "Train Epoch: 2 [18/214 (8%)] Loss:1.461319: , (2.141 sec/step)\n",
      "Train Epoch: 2 [19/214 (9%)] Loss:1.469231: , (2.138 sec/step)\n",
      "Train Epoch: 2 [20/214 (9%)] Loss:2.059471: , (2.138 sec/step)\n",
      "Train Epoch: 2 [21/214 (10%)] Loss:1.336755: , (2.139 sec/step)\n",
      "Train Epoch: 2 [22/214 (10%)] Loss:1.427701: , (2.137 sec/step)\n",
      "Train Epoch: 2 [23/214 (11%)] Loss:1.345883: , (2.139 sec/step)\n",
      "Train Epoch: 2 [24/214 (11%)] Loss:1.463112: , (2.139 sec/step)\n",
      "Train Epoch: 2 [25/214 (12%)] Loss:1.211795: , (2.140 sec/step)\n",
      "Train Epoch: 2 [26/214 (12%)] Loss:1.110014: , (2.139 sec/step)\n",
      "Train Epoch: 2 [27/214 (13%)] Loss:1.431922: , (2.138 sec/step)\n",
      "Train Epoch: 2 [28/214 (13%)] Loss:2.004952: , (2.138 sec/step)\n",
      "Train Epoch: 2 [29/214 (14%)] Loss:1.892028: , (2.141 sec/step)\n",
      "Train Epoch: 2 [30/214 (14%)] Loss:1.672184: , (2.137 sec/step)\n",
      "Train Epoch: 2 [31/214 (14%)] Loss:1.375880: , (2.138 sec/step)\n",
      "Train Epoch: 2 [32/214 (15%)] Loss:2.191048: , (2.140 sec/step)\n",
      "Train Epoch: 2 [33/214 (15%)] Loss:2.070741: , (2.139 sec/step)\n",
      "Train Epoch: 2 [34/214 (16%)] Loss:1.420944: , (2.140 sec/step)\n",
      "Train Epoch: 2 [35/214 (16%)] Loss:2.068298: , (2.140 sec/step)\n",
      "Train Epoch: 2 [36/214 (17%)] Loss:1.490822: , (2.139 sec/step)\n",
      "Train Epoch: 2 [37/214 (17%)] Loss:2.126235: , (2.140 sec/step)\n",
      "Train Epoch: 2 [38/214 (18%)] Loss:1.733219: , (2.138 sec/step)\n",
      "Train Epoch: 2 [39/214 (18%)] Loss:1.804865: , (2.136 sec/step)\n",
      "Train Epoch: 2 [40/214 (19%)] Loss:2.059483: , (2.135 sec/step)\n",
      "Train Epoch: 2 [41/214 (19%)] Loss:1.426270: , (2.135 sec/step)\n",
      "Train Epoch: 2 [42/214 (20%)] Loss:1.505111: , (2.134 sec/step)\n",
      "Train Epoch: 2 [43/214 (20%)] Loss:1.812970: , (2.139 sec/step)\n",
      "Train Epoch: 2 [44/214 (21%)] Loss:1.691496: , (2.137 sec/step)\n",
      "Train Epoch: 2 [45/214 (21%)] Loss:1.843528: , (2.135 sec/step)\n",
      "Train Epoch: 2 [46/214 (21%)] Loss:1.269056: , (2.134 sec/step)\n",
      "Train Epoch: 2 [47/214 (22%)] Loss:1.527090: , (2.134 sec/step)\n",
      "Train Epoch: 2 [48/214 (22%)] Loss:1.373526: , (2.135 sec/step)\n",
      "Train Epoch: 2 [49/214 (23%)] Loss:1.488762: , (2.136 sec/step)\n",
      "Train Epoch: 2 [50/214 (23%)] Loss:1.330991: , (2.134 sec/step)\n",
      "Train Epoch: 2 [51/214 (24%)] Loss:1.511839: , (2.136 sec/step)\n",
      "Train Epoch: 2 [52/214 (24%)] Loss:1.982962: , (2.135 sec/step)\n",
      "Train Epoch: 2 [53/214 (25%)] Loss:1.636547: , (2.134 sec/step)\n",
      "Train Epoch: 2 [54/214 (25%)] Loss:1.626428: , (2.135 sec/step)\n",
      "Train Epoch: 2 [55/214 (26%)] Loss:1.466855: , (2.134 sec/step)\n",
      "Train Epoch: 2 [56/214 (26%)] Loss:1.506161: , (2.134 sec/step)\n",
      "Train Epoch: 2 [57/214 (27%)] Loss:2.554336: , (2.135 sec/step)\n",
      "Train Epoch: 2 [58/214 (27%)] Loss:1.578503: , (2.135 sec/step)\n",
      "Train Epoch: 2 [59/214 (28%)] Loss:1.255869: , (2.138 sec/step)\n",
      "Train Epoch: 2 [60/214 (28%)] Loss:1.640734: , (2.138 sec/step)\n",
      "Train Epoch: 2 [61/214 (29%)] Loss:2.719240: , (2.137 sec/step)\n",
      "Train Epoch: 2 [62/214 (29%)] Loss:1.979593: , (2.136 sec/step)\n",
      "Train Epoch: 2 [63/214 (29%)] Loss:1.708632: , (2.134 sec/step)\n",
      "Train Epoch: 2 [64/214 (30%)] Loss:1.476009: , (2.134 sec/step)\n",
      "Train Epoch: 2 [65/214 (30%)] Loss:1.739414: , (2.136 sec/step)\n",
      "Train Epoch: 2 [66/214 (31%)] Loss:1.553486: , (2.134 sec/step)\n",
      "Train Epoch: 2 [67/214 (31%)] Loss:1.529412: , (2.134 sec/step)\n",
      "Train Epoch: 2 [68/214 (32%)] Loss:1.825062: , (2.134 sec/step)\n",
      "Train Epoch: 2 [69/214 (32%)] Loss:1.579193: , (2.134 sec/step)\n",
      "Train Epoch: 2 [70/214 (33%)] Loss:1.873051: , (2.133 sec/step)\n",
      "Train Epoch: 2 [71/214 (33%)] Loss:1.325040: , (2.135 sec/step)\n",
      "Train Epoch: 2 [72/214 (34%)] Loss:2.209810: , (2.135 sec/step)\n",
      "Train Epoch: 2 [73/214 (34%)] Loss:1.946889: , (2.134 sec/step)\n",
      "Train Epoch: 2 [74/214 (35%)] Loss:1.486612: , (2.136 sec/step)\n",
      "Train Epoch: 2 [75/214 (35%)] Loss:1.830843: , (2.140 sec/step)\n",
      "Train Epoch: 2 [76/214 (36%)] Loss:1.709396: , (2.138 sec/step)\n",
      "Train Epoch: 2 [77/214 (36%)] Loss:1.783103: , (2.142 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [78/214 (36%)] Loss:1.616882: , (2.137 sec/step)\n",
      "Train Epoch: 2 [79/214 (37%)] Loss:2.391163: , (2.136 sec/step)\n",
      "Train Epoch: 2 [80/214 (37%)] Loss:1.654932: , (2.138 sec/step)\n",
      "Train Epoch: 2 [81/214 (38%)] Loss:1.481777: , (2.140 sec/step)\n",
      "Train Epoch: 2 [82/214 (38%)] Loss:1.427055: , (2.137 sec/step)\n",
      "Train Epoch: 2 [83/214 (39%)] Loss:1.489349: , (2.135 sec/step)\n",
      "Train Epoch: 2 [84/214 (39%)] Loss:1.667156: , (2.134 sec/step)\n",
      "Train Epoch: 2 [85/214 (40%)] Loss:1.625500: , (2.134 sec/step)\n",
      "Train Epoch: 2 [86/214 (40%)] Loss:2.388121: , (2.135 sec/step)\n",
      "Train Epoch: 2 [87/214 (41%)] Loss:1.871988: , (2.133 sec/step)\n",
      "Train Epoch: 2 [88/214 (41%)] Loss:1.672120: , (2.139 sec/step)\n",
      "Train Epoch: 2 [89/214 (42%)] Loss:1.513729: , (2.137 sec/step)\n",
      "Train Epoch: 2 [90/214 (42%)] Loss:1.689420: , (2.138 sec/step)\n",
      "Train Epoch: 2 [91/214 (43%)] Loss:1.747125: , (2.137 sec/step)\n",
      "Train Epoch: 2 [92/214 (43%)] Loss:1.855471: , (2.135 sec/step)\n",
      "Train Epoch: 2 [93/214 (43%)] Loss:1.770904: , (2.134 sec/step)\n",
      "Train Epoch: 2 [94/214 (44%)] Loss:1.859593: , (2.134 sec/step)\n",
      "Train Epoch: 2 [95/214 (44%)] Loss:1.571119: , (2.136 sec/step)\n",
      "Train Epoch: 2 [96/214 (45%)] Loss:1.942056: , (2.134 sec/step)\n",
      "Train Epoch: 2 [97/214 (45%)] Loss:1.780644: , (2.134 sec/step)\n",
      "Train Epoch: 2 [98/214 (46%)] Loss:1.573532: , (2.134 sec/step)\n",
      "Train Epoch: 2 [99/214 (46%)] Loss:2.563731: , (2.134 sec/step)\n",
      "Train Epoch: 2 [100/214 (47%)] Loss:1.894627: , (2.134 sec/step)\n",
      "write finish\n",
      "Train Epoch: 2 [101/214 (47%)] Loss:1.779208: , (2.134 sec/step)\n",
      "Train Epoch: 2 [102/214 (48%)] Loss:2.306426: , (2.139 sec/step)\n",
      "Train Epoch: 2 [103/214 (48%)] Loss:1.874704: , (2.137 sec/step)\n",
      "Train Epoch: 2 [104/214 (49%)] Loss:1.636234: , (2.141 sec/step)\n",
      "Train Epoch: 2 [105/214 (49%)] Loss:1.608529: , (2.142 sec/step)\n",
      "Train Epoch: 2 [106/214 (50%)] Loss:1.699343: , (2.140 sec/step)\n",
      "Train Epoch: 2 [107/214 (50%)] Loss:1.598693: , (2.138 sec/step)\n",
      "Train Epoch: 2 [108/214 (50%)] Loss:1.817198: , (2.136 sec/step)\n",
      "Train Epoch: 2 [109/214 (51%)] Loss:1.668836: , (2.141 sec/step)\n",
      "Train Epoch: 2 [110/214 (51%)] Loss:1.348323: , (2.139 sec/step)\n",
      "Train Epoch: 2 [111/214 (52%)] Loss:2.209347: , (2.140 sec/step)\n",
      "Train Epoch: 2 [112/214 (52%)] Loss:1.769106: , (2.141 sec/step)\n",
      "Train Epoch: 2 [113/214 (53%)] Loss:1.571274: , (2.137 sec/step)\n",
      "Train Epoch: 2 [114/214 (53%)] Loss:1.974704: , (2.136 sec/step)\n",
      "Train Epoch: 2 [115/214 (54%)] Loss:1.638759: , (2.134 sec/step)\n",
      "Train Epoch: 2 [116/214 (54%)] Loss:1.645729: , (2.133 sec/step)\n",
      "Train Epoch: 2 [117/214 (55%)] Loss:1.410635: , (2.139 sec/step)\n",
      "Train Epoch: 2 [118/214 (55%)] Loss:2.351754: , (2.138 sec/step)\n",
      "Train Epoch: 2 [119/214 (56%)] Loss:1.710228: , (2.137 sec/step)\n",
      "Train Epoch: 2 [120/214 (56%)] Loss:2.052043: , (2.135 sec/step)\n",
      "Train Epoch: 2 [121/214 (57%)] Loss:1.636914: , (2.134 sec/step)\n",
      "Train Epoch: 2 [122/214 (57%)] Loss:1.654252: , (2.137 sec/step)\n",
      "Train Epoch: 2 [123/214 (57%)] Loss:1.565729: , (2.139 sec/step)\n",
      "Train Epoch: 2 [124/214 (58%)] Loss:2.078041: , (2.137 sec/step)\n",
      "Train Epoch: 2 [125/214 (58%)] Loss:1.690874: , (2.134 sec/step)\n",
      "Train Epoch: 2 [126/214 (59%)] Loss:1.819716: , (2.134 sec/step)\n",
      "Train Epoch: 2 [127/214 (59%)] Loss:1.455961: , (2.135 sec/step)\n",
      "Train Epoch: 2 [128/214 (60%)] Loss:1.744240: , (2.135 sec/step)\n",
      "Train Epoch: 2 [129/214 (60%)] Loss:1.723837: , (2.136 sec/step)\n",
      "Train Epoch: 2 [130/214 (61%)] Loss:1.613311: , (2.138 sec/step)\n",
      "Train Epoch: 2 [131/214 (61%)] Loss:2.476281: , (2.141 sec/step)\n",
      "Train Epoch: 2 [132/214 (62%)] Loss:1.946405: , (2.142 sec/step)\n",
      "Train Epoch: 2 [133/214 (62%)] Loss:1.603804: , (2.141 sec/step)\n",
      "Train Epoch: 2 [134/214 (63%)] Loss:2.267802: , (2.138 sec/step)\n",
      "Train Epoch: 2 [135/214 (63%)] Loss:2.389722: , (2.133 sec/step)\n",
      "Train Epoch: 2 [136/214 (64%)] Loss:1.753751: , (2.134 sec/step)\n",
      "Train Epoch: 2 [137/214 (64%)] Loss:1.579450: , (2.135 sec/step)\n",
      "Train Epoch: 2 [138/214 (64%)] Loss:1.483034: , (2.136 sec/step)\n",
      "Train Epoch: 2 [139/214 (65%)] Loss:1.629544: , (2.135 sec/step)\n",
      "Train Epoch: 2 [140/214 (65%)] Loss:1.296899: , (2.133 sec/step)\n",
      "Train Epoch: 2 [141/214 (66%)] Loss:1.672765: , (2.134 sec/step)\n",
      "Train Epoch: 2 [142/214 (66%)] Loss:1.694415: , (2.134 sec/step)\n",
      "Train Epoch: 2 [143/214 (67%)] Loss:1.746894: , (2.134 sec/step)\n",
      "Train Epoch: 2 [144/214 (67%)] Loss:1.735510: , (2.135 sec/step)\n",
      "Train Epoch: 2 [145/214 (68%)] Loss:1.644273: , (2.136 sec/step)\n",
      "Train Epoch: 2 [146/214 (68%)] Loss:1.446603: , (2.135 sec/step)\n",
      "Train Epoch: 2 [147/214 (69%)] Loss:1.369166: , (2.132 sec/step)\n",
      "Train Epoch: 2 [148/214 (69%)] Loss:1.799577: , (2.133 sec/step)\n",
      "Train Epoch: 2 [149/214 (70%)] Loss:1.730694: , (2.140 sec/step)\n",
      "Train Epoch: 2 [150/214 (70%)] Loss:2.022999: , (2.140 sec/step)\n",
      "Train Epoch: 2 [151/214 (71%)] Loss:1.573825: , (2.138 sec/step)\n",
      "Train Epoch: 2 [152/214 (71%)] Loss:1.661230: , (2.135 sec/step)\n",
      "Train Epoch: 2 [153/214 (71%)] Loss:1.727402: , (2.135 sec/step)\n",
      "Train Epoch: 2 [154/214 (72%)] Loss:1.441995: , (2.135 sec/step)\n",
      "Train Epoch: 2 [155/214 (72%)] Loss:1.685012: , (2.135 sec/step)\n",
      "Train Epoch: 2 [156/214 (73%)] Loss:1.628428: , (2.136 sec/step)\n",
      "Train Epoch: 2 [157/214 (73%)] Loss:1.373177: , (2.136 sec/step)\n",
      "Train Epoch: 2 [158/214 (74%)] Loss:1.570203: , (2.135 sec/step)\n",
      "Train Epoch: 2 [159/214 (74%)] Loss:1.683697: , (2.138 sec/step)\n",
      "Train Epoch: 2 [160/214 (75%)] Loss:1.563412: , (2.134 sec/step)\n",
      "Train Epoch: 2 [161/214 (75%)] Loss:1.608476: , (2.133 sec/step)\n",
      "Train Epoch: 2 [162/214 (76%)] Loss:1.758634: , (2.139 sec/step)\n",
      "Train Epoch: 2 [163/214 (76%)] Loss:1.523453: , (2.136 sec/step)\n",
      "Train Epoch: 2 [164/214 (77%)] Loss:1.435535: , (2.134 sec/step)\n",
      "Train Epoch: 2 [165/214 (77%)] Loss:1.444634: , (2.135 sec/step)\n",
      "Train Epoch: 2 [166/214 (78%)] Loss:1.396124: , (2.135 sec/step)\n",
      "Train Epoch: 2 [167/214 (78%)] Loss:1.643461: , (2.135 sec/step)\n",
      "Train Epoch: 2 [168/214 (79%)] Loss:1.196701: , (2.134 sec/step)\n",
      "Train Epoch: 2 [169/214 (79%)] Loss:1.643769: , (2.142 sec/step)\n",
      "Train Epoch: 2 [170/214 (79%)] Loss:1.382905: , (2.138 sec/step)\n",
      "Train Epoch: 2 [171/214 (80%)] Loss:1.241645: , (2.138 sec/step)\n",
      "Train Epoch: 2 [172/214 (80%)] Loss:1.317528: , (2.139 sec/step)\n",
      "Train Epoch: 2 [173/214 (81%)] Loss:1.354307: , (2.141 sec/step)\n",
      "Train Epoch: 2 [174/214 (81%)] Loss:1.468056: , (2.137 sec/step)\n",
      "Train Epoch: 2 [175/214 (82%)] Loss:1.694714: , (2.135 sec/step)\n",
      "Train Epoch: 2 [176/214 (82%)] Loss:1.650576: , (2.136 sec/step)\n",
      "Train Epoch: 2 [177/214 (83%)] Loss:2.057562: , (2.136 sec/step)\n",
      "Train Epoch: 2 [178/214 (83%)] Loss:1.582859: , (2.138 sec/step)\n",
      "Train Epoch: 2 [179/214 (84%)] Loss:2.011076: , (2.136 sec/step)\n",
      "Train Epoch: 2 [180/214 (84%)] Loss:1.682592: , (2.136 sec/step)\n",
      "Train Epoch: 2 [181/214 (85%)] Loss:2.366069: , (2.134 sec/step)\n",
      "Train Epoch: 2 [182/214 (85%)] Loss:1.568470: , (2.135 sec/step)\n",
      "Train Epoch: 2 [183/214 (86%)] Loss:1.569242: , (2.139 sec/step)\n",
      "Train Epoch: 2 [184/214 (86%)] Loss:1.957688: , (2.137 sec/step)\n",
      "Train Epoch: 2 [185/214 (86%)] Loss:1.700060: , (2.138 sec/step)\n",
      "Train Epoch: 2 [186/214 (87%)] Loss:1.423019: , (2.138 sec/step)\n",
      "Train Epoch: 2 [187/214 (87%)] Loss:1.513211: , (2.136 sec/step)\n",
      "Train Epoch: 2 [188/214 (88%)] Loss:1.799968: , (2.134 sec/step)\n",
      "Train Epoch: 2 [189/214 (88%)] Loss:1.516553: , (2.139 sec/step)\n",
      "Train Epoch: 2 [190/214 (89%)] Loss:1.583154: , (2.137 sec/step)\n",
      "Train Epoch: 2 [191/214 (89%)] Loss:1.532001: , (2.137 sec/step)\n",
      "Train Epoch: 2 [192/214 (90%)] Loss:1.832721: , (2.135 sec/step)\n",
      "Train Epoch: 2 [193/214 (90%)] Loss:1.496118: , (2.135 sec/step)\n",
      "Train Epoch: 2 [194/214 (91%)] Loss:2.838970: , (2.134 sec/step)\n",
      "Train Epoch: 2 [195/214 (91%)] Loss:1.702659: , (2.135 sec/step)\n",
      "Train Epoch: 2 [196/214 (92%)] Loss:2.164947: , (2.135 sec/step)\n",
      "Train Epoch: 2 [197/214 (92%)] Loss:1.673275: , (2.135 sec/step)\n",
      "Train Epoch: 2 [198/214 (93%)] Loss:1.772329: , (2.140 sec/step)\n",
      "Train Epoch: 2 [199/214 (93%)] Loss:1.762298: , (2.136 sec/step)\n",
      "Train Epoch: 2 [200/214 (93%)] Loss:1.455098: , (2.135 sec/step)\n",
      "write finish\n",
      "Train Epoch: 2 [201/214 (94%)] Loss:1.557823: , (2.137 sec/step)\n",
      "Train Epoch: 2 [202/214 (94%)] Loss:1.498911: , (2.140 sec/step)\n",
      "Train Epoch: 2 [203/214 (95%)] Loss:1.398196: , (2.140 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [204/214 (95%)] Loss:1.431781: , (2.138 sec/step)\n",
      "Train Epoch: 2 [205/214 (96%)] Loss:1.582385: , (2.137 sec/step)\n",
      "Train Epoch: 2 [206/214 (96%)] Loss:1.466586: , (2.137 sec/step)\n",
      "Train Epoch: 2 [207/214 (97%)] Loss:1.531210: , (2.134 sec/step)\n",
      "Train Epoch: 2 [208/214 (97%)] Loss:1.630603: , (2.134 sec/step)\n",
      "Train Epoch: 2 [209/214 (98%)] Loss:1.497402: , (2.138 sec/step)\n",
      "Train Epoch: 2 [210/214 (98%)] Loss:1.614426: , (2.136 sec/step)\n",
      "Train Epoch: 2 [211/214 (99%)] Loss:1.627607: , (2.135 sec/step)\n",
      "Train Epoch: 2 [212/214 (99%)] Loss:1.543102: , (2.136 sec/step)\n",
      "Train Epoch: 2 [213/214 (100%)] Loss:1.779919: , (2.138 sec/step)\n",
      "0.02378125 accurate\n",
      "\n",
      "val set:loss9.0158:, (0.664 sec/step)\n",
      "\n",
      "val stored done 6.648181676864624\n",
      "test stored done 82.97957849502563\n",
      "Train Epoch: 3 [0/214 (0%)] Loss:1.681332: , (2.139 sec/step)\n",
      "write finish\n",
      "Train Epoch: 3 [1/214 (0%)] Loss:1.313407: , (2.134 sec/step)\n",
      "Train Epoch: 3 [2/214 (1%)] Loss:1.475764: , (2.135 sec/step)\n",
      "Train Epoch: 3 [3/214 (1%)] Loss:1.182154: , (2.134 sec/step)\n",
      "Train Epoch: 3 [4/214 (2%)] Loss:1.359074: , (2.135 sec/step)\n",
      "Train Epoch: 3 [5/214 (2%)] Loss:1.193439: , (2.136 sec/step)\n",
      "Train Epoch: 3 [6/214 (3%)] Loss:1.629581: , (2.135 sec/step)\n",
      "Train Epoch: 3 [7/214 (3%)] Loss:1.165153: , (2.133 sec/step)\n",
      "Train Epoch: 3 [8/214 (4%)] Loss:1.110949: , (2.133 sec/step)\n",
      "Train Epoch: 3 [9/214 (4%)] Loss:1.274872: , (2.135 sec/step)\n",
      "Train Epoch: 3 [10/214 (5%)] Loss:1.393578: , (2.132 sec/step)\n",
      "Train Epoch: 3 [11/214 (5%)] Loss:1.658891: , (2.134 sec/step)\n",
      "Train Epoch: 3 [12/214 (6%)] Loss:1.187766: , (2.133 sec/step)\n",
      "Train Epoch: 3 [13/214 (6%)] Loss:1.737507: , (2.133 sec/step)\n",
      "Train Epoch: 3 [14/214 (7%)] Loss:1.551318: , (2.132 sec/step)\n",
      "Train Epoch: 3 [15/214 (7%)] Loss:1.604430: , (2.133 sec/step)\n",
      "Train Epoch: 3 [16/214 (7%)] Loss:1.325947: , (2.138 sec/step)\n",
      "Train Epoch: 3 [17/214 (8%)] Loss:1.283826: , (2.139 sec/step)\n",
      "Train Epoch: 3 [18/214 (8%)] Loss:1.076690: , (2.142 sec/step)\n",
      "Train Epoch: 3 [19/214 (9%)] Loss:1.673894: , (2.135 sec/step)\n",
      "Train Epoch: 3 [20/214 (9%)] Loss:1.215445: , (2.134 sec/step)\n",
      "Train Epoch: 3 [21/214 (10%)] Loss:2.191566: , (2.132 sec/step)\n",
      "Train Epoch: 3 [22/214 (10%)] Loss:1.645125: , (2.136 sec/step)\n",
      "Train Epoch: 3 [23/214 (11%)] Loss:1.318177: , (2.138 sec/step)\n",
      "Train Epoch: 3 [24/214 (11%)] Loss:1.626748: , (2.138 sec/step)\n",
      "Train Epoch: 3 [25/214 (12%)] Loss:1.345145: , (2.137 sec/step)\n",
      "Train Epoch: 3 [26/214 (12%)] Loss:1.486584: , (2.136 sec/step)\n",
      "Train Epoch: 3 [27/214 (13%)] Loss:1.116473: , (2.136 sec/step)\n",
      "Train Epoch: 3 [28/214 (13%)] Loss:1.386028: , (2.136 sec/step)\n",
      "Train Epoch: 3 [29/214 (14%)] Loss:1.382096: , (2.136 sec/step)\n",
      "Train Epoch: 3 [30/214 (14%)] Loss:1.846303: , (2.134 sec/step)\n",
      "Train Epoch: 3 [31/214 (14%)] Loss:1.618196: , (2.135 sec/step)\n",
      "Train Epoch: 3 [32/214 (15%)] Loss:1.541569: , (2.134 sec/step)\n",
      "Train Epoch: 3 [33/214 (15%)] Loss:1.458481: , (2.136 sec/step)\n",
      "Train Epoch: 3 [34/214 (16%)] Loss:1.388731: , (2.134 sec/step)\n",
      "Train Epoch: 3 [35/214 (16%)] Loss:1.608213: , (2.135 sec/step)\n",
      "Train Epoch: 3 [36/214 (17%)] Loss:1.603984: , (2.135 sec/step)\n",
      "Train Epoch: 3 [37/214 (17%)] Loss:1.754475: , (2.133 sec/step)\n",
      "Train Epoch: 3 [38/214 (18%)] Loss:1.478394: , (2.134 sec/step)\n",
      "Train Epoch: 3 [39/214 (18%)] Loss:1.699371: , (2.136 sec/step)\n",
      "Train Epoch: 3 [40/214 (19%)] Loss:1.539769: , (2.135 sec/step)\n",
      "Train Epoch: 3 [41/214 (19%)] Loss:2.229437: , (2.134 sec/step)\n",
      "Train Epoch: 3 [42/214 (20%)] Loss:1.556515: , (2.135 sec/step)\n",
      "Train Epoch: 3 [43/214 (20%)] Loss:1.724122: , (2.137 sec/step)\n",
      "Train Epoch: 3 [44/214 (21%)] Loss:1.397542: , (2.135 sec/step)\n",
      "Train Epoch: 3 [45/214 (21%)] Loss:1.083373: , (2.135 sec/step)\n",
      "Train Epoch: 3 [46/214 (21%)] Loss:1.562797: , (2.136 sec/step)\n",
      "Train Epoch: 3 [47/214 (22%)] Loss:1.523235: , (2.137 sec/step)\n",
      "Train Epoch: 3 [48/214 (22%)] Loss:1.461658: , (2.135 sec/step)\n",
      "Train Epoch: 3 [49/214 (23%)] Loss:1.327485: , (2.135 sec/step)\n",
      "Train Epoch: 3 [50/214 (23%)] Loss:1.317486: , (2.137 sec/step)\n",
      "Train Epoch: 3 [51/214 (24%)] Loss:1.572536: , (2.135 sec/step)\n",
      "Train Epoch: 3 [52/214 (24%)] Loss:1.718136: , (2.136 sec/step)\n",
      "Train Epoch: 3 [53/214 (25%)] Loss:1.189269: , (2.137 sec/step)\n",
      "Train Epoch: 3 [54/214 (25%)] Loss:1.282457: , (2.137 sec/step)\n",
      "Train Epoch: 3 [55/214 (26%)] Loss:1.417040: , (2.136 sec/step)\n",
      "Train Epoch: 3 [56/214 (26%)] Loss:1.991628: , (2.135 sec/step)\n",
      "Train Epoch: 3 [57/214 (27%)] Loss:1.527953: , (2.135 sec/step)\n",
      "Train Epoch: 3 [58/214 (27%)] Loss:1.752707: , (2.135 sec/step)\n",
      "Train Epoch: 3 [59/214 (28%)] Loss:1.470578: , (2.136 sec/step)\n",
      "Train Epoch: 3 [60/214 (28%)] Loss:1.549866: , (2.136 sec/step)\n",
      "Train Epoch: 3 [61/214 (29%)] Loss:1.436057: , (2.133 sec/step)\n",
      "Train Epoch: 3 [62/214 (29%)] Loss:1.690647: , (2.134 sec/step)\n",
      "Train Epoch: 3 [63/214 (29%)] Loss:1.313561: , (2.136 sec/step)\n",
      "Train Epoch: 3 [64/214 (30%)] Loss:1.304768: , (2.133 sec/step)\n",
      "Train Epoch: 3 [65/214 (30%)] Loss:2.104068: , (2.134 sec/step)\n",
      "Train Epoch: 3 [66/214 (31%)] Loss:1.268577: , (2.140 sec/step)\n",
      "Train Epoch: 3 [67/214 (31%)] Loss:1.292856: , (2.141 sec/step)\n",
      "Train Epoch: 3 [68/214 (32%)] Loss:1.236198: , (2.140 sec/step)\n",
      "Train Epoch: 3 [69/214 (32%)] Loss:1.343206: , (2.140 sec/step)\n",
      "Train Epoch: 3 [70/214 (33%)] Loss:1.401221: , (2.140 sec/step)\n",
      "Train Epoch: 3 [71/214 (33%)] Loss:1.326100: , (2.136 sec/step)\n",
      "Train Epoch: 3 [72/214 (34%)] Loss:1.417533: , (2.134 sec/step)\n",
      "Train Epoch: 3 [73/214 (34%)] Loss:1.707397: , (2.135 sec/step)\n",
      "Train Epoch: 3 [74/214 (35%)] Loss:1.306825: , (2.133 sec/step)\n",
      "Train Epoch: 3 [75/214 (35%)] Loss:1.357543: , (2.136 sec/step)\n",
      "Train Epoch: 3 [76/214 (36%)] Loss:1.696323: , (2.134 sec/step)\n",
      "Train Epoch: 3 [77/214 (36%)] Loss:1.513527: , (2.135 sec/step)\n",
      "Train Epoch: 3 [78/214 (36%)] Loss:1.743710: , (2.135 sec/step)\n",
      "Train Epoch: 3 [79/214 (37%)] Loss:1.624088: , (2.135 sec/step)\n",
      "Train Epoch: 3 [80/214 (37%)] Loss:1.532739: , (2.134 sec/step)\n",
      "Train Epoch: 3 [81/214 (38%)] Loss:2.164239: , (2.137 sec/step)\n",
      "Train Epoch: 3 [82/214 (38%)] Loss:1.156547: , (2.134 sec/step)\n",
      "Train Epoch: 3 [83/214 (39%)] Loss:1.128814: , (2.136 sec/step)\n",
      "Train Epoch: 3 [84/214 (39%)] Loss:1.664710: , (2.134 sec/step)\n",
      "Train Epoch: 3 [85/214 (40%)] Loss:1.529176: , (2.135 sec/step)\n",
      "Train Epoch: 3 [86/214 (40%)] Loss:1.431580: , (2.136 sec/step)\n",
      "Train Epoch: 3 [87/214 (41%)] Loss:1.500467: , (2.134 sec/step)\n",
      "Train Epoch: 3 [88/214 (41%)] Loss:1.508090: , (2.134 sec/step)\n",
      "Train Epoch: 3 [89/214 (42%)] Loss:1.704530: , (2.135 sec/step)\n",
      "Train Epoch: 3 [90/214 (42%)] Loss:1.216831: , (2.133 sec/step)\n",
      "Train Epoch: 3 [91/214 (43%)] Loss:1.563684: , (2.136 sec/step)\n",
      "Train Epoch: 3 [92/214 (43%)] Loss:1.362139: , (2.134 sec/step)\n",
      "Train Epoch: 3 [93/214 (43%)] Loss:1.271052: , (2.135 sec/step)\n",
      "Train Epoch: 3 [94/214 (44%)] Loss:1.605806: , (2.134 sec/step)\n",
      "Train Epoch: 3 [95/214 (44%)] Loss:1.298498: , (2.135 sec/step)\n",
      "Train Epoch: 3 [96/214 (45%)] Loss:1.488040: , (2.135 sec/step)\n",
      "Train Epoch: 3 [97/214 (45%)] Loss:1.556101: , (2.135 sec/step)\n",
      "Train Epoch: 3 [98/214 (46%)] Loss:1.455216: , (2.133 sec/step)\n",
      "Train Epoch: 3 [99/214 (46%)] Loss:1.368981: , (2.134 sec/step)\n",
      "Train Epoch: 3 [100/214 (47%)] Loss:1.487049: , (2.134 sec/step)\n",
      "write finish\n",
      "Train Epoch: 3 [101/214 (47%)] Loss:1.502338: , (2.135 sec/step)\n",
      "Train Epoch: 3 [102/214 (48%)] Loss:1.250514: , (2.135 sec/step)\n",
      "Train Epoch: 3 [103/214 (48%)] Loss:1.478302: , (2.135 sec/step)\n",
      "Train Epoch: 3 [104/214 (49%)] Loss:1.875521: , (2.135 sec/step)\n",
      "Train Epoch: 3 [105/214 (49%)] Loss:1.286709: , (2.133 sec/step)\n",
      "Train Epoch: 3 [106/214 (50%)] Loss:2.440985: , (2.135 sec/step)\n",
      "Train Epoch: 3 [107/214 (50%)] Loss:1.407923: , (2.135 sec/step)\n",
      "Train Epoch: 3 [108/214 (50%)] Loss:1.950262: , (2.135 sec/step)\n",
      "Train Epoch: 3 [109/214 (51%)] Loss:1.272325: , (2.137 sec/step)\n",
      "Train Epoch: 3 [110/214 (51%)] Loss:1.098917: , (2.136 sec/step)\n",
      "Train Epoch: 3 [111/214 (52%)] Loss:1.164886: , (2.134 sec/step)\n",
      "Train Epoch: 3 [112/214 (52%)] Loss:1.756882: , (2.132 sec/step)\n",
      "Train Epoch: 3 [113/214 (53%)] Loss:2.333123: , (2.134 sec/step)\n",
      "Train Epoch: 3 [114/214 (53%)] Loss:1.442816: , (2.137 sec/step)\n",
      "Train Epoch: 3 [115/214 (54%)] Loss:1.752324: , (2.135 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [116/214 (54%)] Loss:1.278168: , (2.135 sec/step)\n",
      "Train Epoch: 3 [117/214 (55%)] Loss:1.359238: , (2.134 sec/step)\n",
      "Train Epoch: 3 [118/214 (55%)] Loss:1.728691: , (2.133 sec/step)\n",
      "Train Epoch: 3 [119/214 (56%)] Loss:1.261246: , (2.135 sec/step)\n",
      "Train Epoch: 3 [120/214 (56%)] Loss:2.547833: , (2.134 sec/step)\n",
      "Train Epoch: 3 [121/214 (57%)] Loss:1.482322: , (2.136 sec/step)\n",
      "Train Epoch: 3 [122/214 (57%)] Loss:1.673439: , (2.136 sec/step)\n",
      "Train Epoch: 3 [123/214 (57%)] Loss:1.604585: , (2.135 sec/step)\n",
      "Train Epoch: 3 [124/214 (58%)] Loss:1.534513: , (2.135 sec/step)\n",
      "Train Epoch: 3 [125/214 (58%)] Loss:1.421844: , (2.136 sec/step)\n",
      "Train Epoch: 3 [126/214 (59%)] Loss:1.606093: , (2.134 sec/step)\n",
      "Train Epoch: 3 [127/214 (59%)] Loss:1.553954: , (2.134 sec/step)\n",
      "Train Epoch: 3 [128/214 (60%)] Loss:1.662209: , (2.133 sec/step)\n",
      "Train Epoch: 3 [129/214 (60%)] Loss:2.070256: , (2.136 sec/step)\n",
      "Train Epoch: 3 [130/214 (61%)] Loss:1.840099: , (2.137 sec/step)\n",
      "Train Epoch: 3 [131/214 (61%)] Loss:1.607417: , (2.137 sec/step)\n",
      "Train Epoch: 3 [132/214 (62%)] Loss:1.195873: , (2.135 sec/step)\n",
      "Train Epoch: 3 [133/214 (62%)] Loss:1.003646: , (2.135 sec/step)\n",
      "Train Epoch: 3 [134/214 (63%)] Loss:1.857717: , (2.135 sec/step)\n",
      "Train Epoch: 3 [135/214 (63%)] Loss:2.770859: , (2.133 sec/step)\n",
      "Train Epoch: 3 [136/214 (64%)] Loss:1.579604: , (2.137 sec/step)\n",
      "Train Epoch: 3 [137/214 (64%)] Loss:1.566437: , (2.137 sec/step)\n",
      "Train Epoch: 3 [138/214 (64%)] Loss:1.507986: , (2.136 sec/step)\n",
      "Train Epoch: 3 [139/214 (65%)] Loss:1.239148: , (2.136 sec/step)\n",
      "Train Epoch: 3 [140/214 (65%)] Loss:1.605689: , (2.137 sec/step)\n",
      "Train Epoch: 3 [141/214 (66%)] Loss:1.765642: , (2.135 sec/step)\n",
      "Train Epoch: 3 [142/214 (66%)] Loss:1.576229: , (2.135 sec/step)\n",
      "Train Epoch: 3 [143/214 (67%)] Loss:1.827897: , (2.135 sec/step)\n",
      "Train Epoch: 3 [144/214 (67%)] Loss:1.508047: , (2.136 sec/step)\n",
      "Train Epoch: 3 [145/214 (68%)] Loss:1.694950: , (2.135 sec/step)\n",
      "Train Epoch: 3 [146/214 (68%)] Loss:1.693971: , (2.135 sec/step)\n",
      "Train Epoch: 3 [147/214 (69%)] Loss:1.418313: , (2.134 sec/step)\n",
      "Train Epoch: 3 [148/214 (69%)] Loss:2.614919: , (2.136 sec/step)\n",
      "Train Epoch: 3 [149/214 (70%)] Loss:1.681645: , (2.134 sec/step)\n",
      "Train Epoch: 3 [150/214 (70%)] Loss:1.778897: , (2.134 sec/step)\n",
      "Train Epoch: 3 [151/214 (71%)] Loss:1.607340: , (2.136 sec/step)\n",
      "Train Epoch: 3 [152/214 (71%)] Loss:2.578553: , (2.136 sec/step)\n",
      "Train Epoch: 3 [153/214 (71%)] Loss:1.642678: , (2.135 sec/step)\n",
      "Train Epoch: 3 [154/214 (72%)] Loss:1.663305: , (2.136 sec/step)\n",
      "Train Epoch: 3 [155/214 (72%)] Loss:1.388051: , (2.134 sec/step)\n",
      "Train Epoch: 3 [156/214 (73%)] Loss:1.455188: , (2.136 sec/step)\n",
      "Train Epoch: 3 [157/214 (73%)] Loss:1.797295: , (2.137 sec/step)\n",
      "Train Epoch: 3 [158/214 (74%)] Loss:1.471000: , (2.135 sec/step)\n",
      "Train Epoch: 3 [159/214 (74%)] Loss:1.445324: , (2.137 sec/step)\n",
      "Train Epoch: 3 [160/214 (75%)] Loss:2.001496: , (2.136 sec/step)\n",
      "Train Epoch: 3 [161/214 (75%)] Loss:2.389113: , (2.136 sec/step)\n",
      "Train Epoch: 3 [162/214 (76%)] Loss:1.294165: , (2.135 sec/step)\n",
      "Train Epoch: 3 [163/214 (76%)] Loss:1.605797: , (2.135 sec/step)\n",
      "Train Epoch: 3 [164/214 (77%)] Loss:2.438267: , (2.136 sec/step)\n",
      "Train Epoch: 3 [165/214 (77%)] Loss:1.678586: , (2.134 sec/step)\n",
      "Train Epoch: 3 [166/214 (78%)] Loss:2.156040: , (2.135 sec/step)\n",
      "Train Epoch: 3 [167/214 (78%)] Loss:1.787813: , (2.135 sec/step)\n",
      "Train Epoch: 3 [168/214 (79%)] Loss:2.094082: , (2.136 sec/step)\n",
      "Train Epoch: 3 [169/214 (79%)] Loss:1.781808: , (2.137 sec/step)\n",
      "Train Epoch: 3 [170/214 (79%)] Loss:1.334299: , (2.136 sec/step)\n",
      "Train Epoch: 3 [171/214 (80%)] Loss:1.382261: , (2.137 sec/step)\n",
      "Train Epoch: 3 [172/214 (80%)] Loss:1.814629: , (2.136 sec/step)\n",
      "Train Epoch: 3 [173/214 (81%)] Loss:1.690277: , (2.136 sec/step)\n",
      "Train Epoch: 3 [174/214 (81%)] Loss:1.526811: , (2.136 sec/step)\n",
      "Train Epoch: 3 [175/214 (82%)] Loss:1.443639: , (2.137 sec/step)\n",
      "Train Epoch: 3 [176/214 (82%)] Loss:1.654416: , (2.136 sec/step)\n",
      "Train Epoch: 3 [177/214 (83%)] Loss:1.788435: , (2.137 sec/step)\n",
      "Train Epoch: 3 [178/214 (83%)] Loss:1.918768: , (2.137 sec/step)\n",
      "Train Epoch: 3 [179/214 (84%)] Loss:1.606262: , (2.136 sec/step)\n",
      "Train Epoch: 3 [180/214 (84%)] Loss:2.038254: , (2.135 sec/step)\n",
      "Train Epoch: 3 [181/214 (85%)] Loss:1.384499: , (2.136 sec/step)\n",
      "Train Epoch: 3 [182/214 (85%)] Loss:1.740801: , (2.135 sec/step)\n",
      "Train Epoch: 3 [183/214 (86%)] Loss:1.551257: , (2.135 sec/step)\n",
      "Train Epoch: 3 [184/214 (86%)] Loss:1.435649: , (2.135 sec/step)\n",
      "Train Epoch: 3 [185/214 (86%)] Loss:1.359297: , (2.135 sec/step)\n",
      "Train Epoch: 3 [186/214 (87%)] Loss:1.513715: , (2.135 sec/step)\n",
      "Train Epoch: 3 [187/214 (87%)] Loss:1.772443: , (2.138 sec/step)\n",
      "Train Epoch: 3 [188/214 (88%)] Loss:1.566507: , (2.136 sec/step)\n",
      "Train Epoch: 3 [189/214 (88%)] Loss:1.537675: , (2.135 sec/step)\n",
      "Train Epoch: 3 [190/214 (89%)] Loss:1.602673: , (2.136 sec/step)\n",
      "Train Epoch: 3 [191/214 (89%)] Loss:1.511315: , (2.137 sec/step)\n",
      "Train Epoch: 3 [192/214 (90%)] Loss:1.330114: , (2.135 sec/step)\n",
      "Train Epoch: 3 [193/214 (90%)] Loss:1.360381: , (2.136 sec/step)\n",
      "Train Epoch: 3 [194/214 (91%)] Loss:1.557795: , (2.137 sec/step)\n",
      "Train Epoch: 3 [195/214 (91%)] Loss:1.620264: , (2.137 sec/step)\n",
      "Train Epoch: 3 [196/214 (92%)] Loss:1.835650: , (2.136 sec/step)\n",
      "Train Epoch: 3 [197/214 (92%)] Loss:1.238302: , (2.136 sec/step)\n",
      "Train Epoch: 3 [198/214 (93%)] Loss:1.622886: , (2.137 sec/step)\n",
      "Train Epoch: 3 [199/214 (93%)] Loss:1.451311: , (2.136 sec/step)\n",
      "Train Epoch: 3 [200/214 (93%)] Loss:1.557103: , (2.134 sec/step)\n",
      "write finish\n",
      "Train Epoch: 3 [201/214 (94%)] Loss:1.613712: , (2.137 sec/step)\n",
      "Train Epoch: 3 [202/214 (94%)] Loss:1.647935: , (2.136 sec/step)\n",
      "Train Epoch: 3 [203/214 (95%)] Loss:2.102545: , (2.138 sec/step)\n",
      "Train Epoch: 3 [204/214 (95%)] Loss:1.675316: , (2.137 sec/step)\n",
      "Train Epoch: 3 [205/214 (96%)] Loss:1.455862: , (2.137 sec/step)\n",
      "Train Epoch: 3 [206/214 (96%)] Loss:1.875066: , (2.136 sec/step)\n",
      "Train Epoch: 3 [207/214 (97%)] Loss:1.934548: , (2.134 sec/step)\n",
      "Train Epoch: 3 [208/214 (97%)] Loss:1.508025: , (2.137 sec/step)\n",
      "Train Epoch: 3 [209/214 (98%)] Loss:1.583586: , (2.136 sec/step)\n",
      "Train Epoch: 3 [210/214 (98%)] Loss:1.771241: , (2.137 sec/step)\n",
      "Train Epoch: 3 [211/214 (99%)] Loss:1.691454: , (2.138 sec/step)\n",
      "Train Epoch: 3 [212/214 (99%)] Loss:1.616013: , (2.137 sec/step)\n",
      "Train Epoch: 3 [213/214 (100%)] Loss:1.619485: , (2.136 sec/step)\n",
      "0.03221875 accurate\n",
      "\n",
      "val set:loss10.2008:, (0.664 sec/step)\n",
      "\n",
      "val stored done 6.662619113922119\n",
      "test stored done 82.98644018173218\n",
      "Train Epoch: 4 [0/214 (0%)] Loss:1.372615: , (2.135 sec/step)\n",
      "write finish\n",
      "Train Epoch: 4 [1/214 (0%)] Loss:1.311529: , (2.135 sec/step)\n",
      "Train Epoch: 4 [2/214 (1%)] Loss:1.323306: , (2.135 sec/step)\n",
      "Train Epoch: 4 [3/214 (1%)] Loss:1.133916: , (2.135 sec/step)\n",
      "Train Epoch: 4 [4/214 (2%)] Loss:1.608804: , (2.135 sec/step)\n",
      "Train Epoch: 4 [5/214 (2%)] Loss:1.361647: , (2.135 sec/step)\n",
      "Train Epoch: 4 [6/214 (3%)] Loss:2.536324: , (2.134 sec/step)\n",
      "Train Epoch: 4 [7/214 (3%)] Loss:1.780977: , (2.136 sec/step)\n",
      "Train Epoch: 4 [8/214 (4%)] Loss:2.079661: , (2.135 sec/step)\n",
      "Train Epoch: 4 [9/214 (4%)] Loss:1.520532: , (2.136 sec/step)\n",
      "Train Epoch: 4 [10/214 (5%)] Loss:1.751044: , (2.135 sec/step)\n",
      "Train Epoch: 4 [11/214 (5%)] Loss:1.296324: , (2.138 sec/step)\n",
      "Train Epoch: 4 [12/214 (6%)] Loss:1.233942: , (2.136 sec/step)\n",
      "Train Epoch: 4 [13/214 (6%)] Loss:2.432115: , (2.135 sec/step)\n",
      "Train Epoch: 4 [14/214 (7%)] Loss:1.262469: , (2.136 sec/step)\n",
      "Train Epoch: 4 [15/214 (7%)] Loss:2.062724: , (2.137 sec/step)\n",
      "Train Epoch: 4 [16/214 (7%)] Loss:1.744124: , (2.135 sec/step)\n",
      "Train Epoch: 4 [17/214 (8%)] Loss:1.410425: , (2.136 sec/step)\n",
      "Train Epoch: 4 [18/214 (8%)] Loss:1.464834: , (2.136 sec/step)\n",
      "Train Epoch: 4 [19/214 (9%)] Loss:1.522521: , (2.135 sec/step)\n",
      "Train Epoch: 4 [20/214 (9%)] Loss:1.370520: , (2.136 sec/step)\n",
      "Train Epoch: 4 [21/214 (10%)] Loss:1.590655: , (2.137 sec/step)\n",
      "Train Epoch: 4 [22/214 (10%)] Loss:1.525286: , (2.138 sec/step)\n",
      "Train Epoch: 4 [23/214 (11%)] Loss:1.393542: , (2.137 sec/step)\n",
      "Train Epoch: 4 [24/214 (11%)] Loss:1.477324: , (2.135 sec/step)\n",
      "Train Epoch: 4 [25/214 (12%)] Loss:1.380838: , (2.134 sec/step)\n",
      "Train Epoch: 4 [26/214 (12%)] Loss:1.483295: , (2.133 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [27/214 (13%)] Loss:1.341089: , (2.133 sec/step)\n",
      "Train Epoch: 4 [28/214 (13%)] Loss:1.514978: , (2.133 sec/step)\n",
      "Train Epoch: 4 [29/214 (14%)] Loss:2.242777: , (2.135 sec/step)\n",
      "Train Epoch: 4 [30/214 (14%)] Loss:1.522233: , (2.133 sec/step)\n",
      "Train Epoch: 4 [31/214 (14%)] Loss:1.556450: , (2.135 sec/step)\n",
      "Train Epoch: 4 [32/214 (15%)] Loss:1.953003: , (2.135 sec/step)\n",
      "Train Epoch: 4 [33/214 (15%)] Loss:2.134035: , (2.133 sec/step)\n",
      "Train Epoch: 4 [34/214 (16%)] Loss:1.495558: , (2.134 sec/step)\n",
      "Train Epoch: 4 [35/214 (16%)] Loss:1.473659: , (2.137 sec/step)\n",
      "Train Epoch: 4 [36/214 (17%)] Loss:1.839964: , (2.135 sec/step)\n",
      "Train Epoch: 4 [37/214 (17%)] Loss:1.501395: , (2.136 sec/step)\n",
      "Train Epoch: 4 [38/214 (18%)] Loss:1.500045: , (2.136 sec/step)\n",
      "Train Epoch: 4 [39/214 (18%)] Loss:1.676770: , (2.137 sec/step)\n",
      "Train Epoch: 4 [40/214 (19%)] Loss:2.263225: , (2.135 sec/step)\n",
      "Train Epoch: 4 [41/214 (19%)] Loss:1.567454: , (2.136 sec/step)\n",
      "Train Epoch: 4 [42/214 (20%)] Loss:1.567657: , (2.135 sec/step)\n",
      "Train Epoch: 4 [43/214 (20%)] Loss:1.468117: , (2.135 sec/step)\n",
      "Train Epoch: 4 [44/214 (21%)] Loss:1.244805: , (2.135 sec/step)\n",
      "Train Epoch: 4 [45/214 (21%)] Loss:1.643560: , (2.135 sec/step)\n",
      "Train Epoch: 4 [46/214 (21%)] Loss:1.575473: , (2.135 sec/step)\n",
      "Train Epoch: 4 [47/214 (22%)] Loss:1.640560: , (2.133 sec/step)\n",
      "Train Epoch: 4 [48/214 (22%)] Loss:1.049721: , (2.136 sec/step)\n",
      "Train Epoch: 4 [49/214 (23%)] Loss:1.702043: , (2.136 sec/step)\n",
      "Train Epoch: 4 [50/214 (23%)] Loss:1.887608: , (2.135 sec/step)\n",
      "Train Epoch: 4 [51/214 (24%)] Loss:1.284302: , (2.134 sec/step)\n",
      "Train Epoch: 4 [52/214 (24%)] Loss:1.274607: , (2.134 sec/step)\n",
      "Train Epoch: 4 [53/214 (25%)] Loss:1.229225: , (2.133 sec/step)\n",
      "Train Epoch: 4 [54/214 (25%)] Loss:1.345300: , (2.134 sec/step)\n",
      "Train Epoch: 4 [55/214 (26%)] Loss:1.355397: , (2.135 sec/step)\n",
      "Train Epoch: 4 [56/214 (26%)] Loss:1.466532: , (2.135 sec/step)\n",
      "Train Epoch: 4 [57/214 (27%)] Loss:1.923504: , (2.133 sec/step)\n",
      "Train Epoch: 4 [58/214 (27%)] Loss:1.588255: , (2.133 sec/step)\n",
      "Train Epoch: 4 [59/214 (28%)] Loss:1.415880: , (2.134 sec/step)\n",
      "Train Epoch: 4 [60/214 (28%)] Loss:1.373077: , (2.134 sec/step)\n",
      "Train Epoch: 4 [61/214 (29%)] Loss:1.767424: , (2.134 sec/step)\n",
      "Train Epoch: 4 [62/214 (29%)] Loss:1.427824: , (2.135 sec/step)\n",
      "Train Epoch: 4 [63/214 (29%)] Loss:1.363444: , (2.136 sec/step)\n",
      "Train Epoch: 4 [64/214 (30%)] Loss:1.413615: , (2.137 sec/step)\n",
      "Train Epoch: 4 [65/214 (30%)] Loss:1.614437: , (2.136 sec/step)\n",
      "Train Epoch: 4 [66/214 (31%)] Loss:1.701216: , (2.134 sec/step)\n",
      "Train Epoch: 4 [67/214 (31%)] Loss:1.277338: , (2.135 sec/step)\n",
      "Train Epoch: 4 [68/214 (32%)] Loss:1.423047: , (2.135 sec/step)\n",
      "Train Epoch: 4 [69/214 (32%)] Loss:1.784906: , (2.137 sec/step)\n",
      "Train Epoch: 4 [70/214 (33%)] Loss:1.422602: , (2.136 sec/step)\n",
      "Train Epoch: 4 [71/214 (33%)] Loss:1.572322: , (2.135 sec/step)\n",
      "Train Epoch: 4 [72/214 (34%)] Loss:0.995218: , (2.137 sec/step)\n",
      "Train Epoch: 4 [73/214 (34%)] Loss:2.129050: , (2.134 sec/step)\n",
      "Train Epoch: 4 [74/214 (35%)] Loss:1.830086: , (2.135 sec/step)\n",
      "Train Epoch: 4 [75/214 (35%)] Loss:1.554250: , (2.136 sec/step)\n",
      "Train Epoch: 4 [76/214 (36%)] Loss:2.529487: , (2.136 sec/step)\n",
      "Train Epoch: 4 [77/214 (36%)] Loss:1.561402: , (2.135 sec/step)\n",
      "Train Epoch: 4 [78/214 (36%)] Loss:1.272150: , (2.135 sec/step)\n",
      "Train Epoch: 4 [79/214 (37%)] Loss:1.493162: , (2.136 sec/step)\n",
      "Train Epoch: 4 [80/214 (37%)] Loss:1.836841: , (2.134 sec/step)\n",
      "Train Epoch: 4 [81/214 (38%)] Loss:1.633262: , (2.136 sec/step)\n",
      "Train Epoch: 4 [82/214 (38%)] Loss:1.241893: , (2.136 sec/step)\n",
      "Train Epoch: 4 [83/214 (39%)] Loss:2.314306: , (2.134 sec/step)\n",
      "Train Epoch: 4 [84/214 (39%)] Loss:1.405500: , (2.134 sec/step)\n",
      "Train Epoch: 4 [85/214 (40%)] Loss:1.676280: , (2.135 sec/step)\n",
      "Train Epoch: 4 [86/214 (40%)] Loss:1.670762: , (2.134 sec/step)\n",
      "Train Epoch: 4 [87/214 (41%)] Loss:1.802620: , (2.134 sec/step)\n",
      "Train Epoch: 4 [88/214 (41%)] Loss:1.332397: , (2.134 sec/step)\n",
      "Train Epoch: 4 [89/214 (42%)] Loss:1.579842: , (2.136 sec/step)\n",
      "Train Epoch: 4 [90/214 (42%)] Loss:1.434573: , (2.133 sec/step)\n",
      "Train Epoch: 4 [91/214 (43%)] Loss:1.654399: , (2.135 sec/step)\n",
      "Train Epoch: 4 [92/214 (43%)] Loss:1.603312: , (2.133 sec/step)\n",
      "Train Epoch: 4 [93/214 (43%)] Loss:1.701465: , (2.134 sec/step)\n",
      "Train Epoch: 4 [94/214 (44%)] Loss:1.453579: , (2.133 sec/step)\n",
      "Train Epoch: 4 [95/214 (44%)] Loss:1.368111: , (2.133 sec/step)\n",
      "Train Epoch: 4 [96/214 (45%)] Loss:1.741086: , (2.135 sec/step)\n",
      "Train Epoch: 4 [97/214 (45%)] Loss:1.325317: , (2.133 sec/step)\n",
      "Train Epoch: 4 [98/214 (46%)] Loss:1.522549: , (2.136 sec/step)\n",
      "Train Epoch: 4 [99/214 (46%)] Loss:1.822421: , (2.136 sec/step)\n",
      "Train Epoch: 4 [100/214 (47%)] Loss:1.191928: , (2.135 sec/step)\n",
      "write finish\n",
      "Train Epoch: 4 [101/214 (47%)] Loss:1.411888: , (2.136 sec/step)\n",
      "Train Epoch: 4 [102/214 (48%)] Loss:1.343801: , (2.135 sec/step)\n",
      "Train Epoch: 4 [103/214 (48%)] Loss:1.377690: , (2.135 sec/step)\n",
      "Train Epoch: 4 [104/214 (49%)] Loss:1.558054: , (2.135 sec/step)\n",
      "Train Epoch: 4 [105/214 (49%)] Loss:1.498174: , (2.134 sec/step)\n",
      "Train Epoch: 4 [106/214 (50%)] Loss:1.834012: , (2.135 sec/step)\n",
      "Train Epoch: 4 [107/214 (50%)] Loss:1.285153: , (2.136 sec/step)\n",
      "Train Epoch: 4 [108/214 (50%)] Loss:1.407197: , (2.134 sec/step)\n",
      "Train Epoch: 4 [109/214 (51%)] Loss:1.990259: , (2.136 sec/step)\n",
      "Train Epoch: 4 [110/214 (51%)] Loss:1.170169: , (2.194 sec/step)\n",
      "Train Epoch: 4 [111/214 (52%)] Loss:1.242048: , (2.268 sec/step)\n",
      "Train Epoch: 4 [112/214 (52%)] Loss:1.619684: , (2.397 sec/step)\n",
      "Train Epoch: 4 [113/214 (53%)] Loss:1.413206: , (2.679 sec/step)\n",
      "Train Epoch: 4 [114/214 (53%)] Loss:1.170005: , (2.669 sec/step)\n",
      "Train Epoch: 4 [115/214 (54%)] Loss:1.698677: , (2.673 sec/step)\n",
      "Train Epoch: 4 [116/214 (54%)] Loss:1.723932: , (2.667 sec/step)\n",
      "Train Epoch: 4 [117/214 (55%)] Loss:2.796233: , (2.651 sec/step)\n",
      "Train Epoch: 4 [118/214 (55%)] Loss:1.551024: , (2.668 sec/step)\n",
      "Train Epoch: 4 [119/214 (56%)] Loss:1.440581: , (2.663 sec/step)\n",
      "Train Epoch: 4 [120/214 (56%)] Loss:1.649255: , (2.663 sec/step)\n",
      "Train Epoch: 4 [121/214 (57%)] Loss:1.350843: , (2.675 sec/step)\n",
      "Train Epoch: 4 [122/214 (57%)] Loss:1.409753: , (2.667 sec/step)\n",
      "Train Epoch: 4 [123/214 (57%)] Loss:2.499544: , (2.664 sec/step)\n",
      "Train Epoch: 4 [124/214 (58%)] Loss:1.659549: , (2.647 sec/step)\n",
      "Train Epoch: 4 [125/214 (58%)] Loss:1.729072: , (2.672 sec/step)\n",
      "Train Epoch: 4 [126/214 (59%)] Loss:1.549281: , (2.676 sec/step)\n",
      "Train Epoch: 4 [127/214 (59%)] Loss:1.469283: , (2.643 sec/step)\n",
      "Train Epoch: 4 [128/214 (60%)] Loss:1.680390: , (2.645 sec/step)\n",
      "Train Epoch: 4 [129/214 (60%)] Loss:1.532874: , (2.659 sec/step)\n",
      "Train Epoch: 4 [130/214 (61%)] Loss:1.345417: , (2.669 sec/step)\n",
      "Train Epoch: 4 [131/214 (61%)] Loss:1.643646: , (2.684 sec/step)\n",
      "Train Epoch: 4 [132/214 (62%)] Loss:1.636959: , (2.681 sec/step)\n",
      "Train Epoch: 4 [133/214 (62%)] Loss:1.718763: , (2.697 sec/step)\n",
      "Train Epoch: 4 [134/214 (63%)] Loss:1.303607: , (2.686 sec/step)\n",
      "Train Epoch: 4 [135/214 (63%)] Loss:1.830975: , (2.676 sec/step)\n",
      "Train Epoch: 4 [136/214 (64%)] Loss:1.607584: , (2.675 sec/step)\n",
      "Train Epoch: 4 [137/214 (64%)] Loss:2.087467: , (2.650 sec/step)\n",
      "Train Epoch: 4 [138/214 (64%)] Loss:1.423461: , (2.651 sec/step)\n",
      "Train Epoch: 4 [139/214 (65%)] Loss:1.198546: , (2.669 sec/step)\n",
      "Train Epoch: 4 [140/214 (65%)] Loss:1.548803: , (2.667 sec/step)\n",
      "Train Epoch: 4 [141/214 (66%)] Loss:1.347402: , (2.698 sec/step)\n",
      "Train Epoch: 4 [142/214 (66%)] Loss:1.542102: , (2.716 sec/step)\n",
      "Train Epoch: 4 [143/214 (67%)] Loss:1.333451: , (2.702 sec/step)\n",
      "Train Epoch: 4 [144/214 (67%)] Loss:1.253704: , (2.690 sec/step)\n",
      "Train Epoch: 4 [145/214 (68%)] Loss:1.301547: , (2.688 sec/step)\n",
      "Train Epoch: 4 [146/214 (68%)] Loss:1.477356: , (2.674 sec/step)\n",
      "Train Epoch: 4 [147/214 (69%)] Loss:1.459164: , (2.674 sec/step)\n",
      "Train Epoch: 4 [148/214 (69%)] Loss:1.512455: , (2.691 sec/step)\n",
      "Train Epoch: 4 [149/214 (70%)] Loss:1.511159: , (2.694 sec/step)\n",
      "Train Epoch: 4 [150/214 (70%)] Loss:1.499954: , (2.694 sec/step)\n",
      "Train Epoch: 4 [151/214 (71%)] Loss:1.749045: , (2.714 sec/step)\n",
      "Train Epoch: 4 [152/214 (71%)] Loss:1.892228: , (2.667 sec/step)\n",
      "Train Epoch: 4 [153/214 (71%)] Loss:1.535119: , (2.676 sec/step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [154/214 (72%)] Loss:1.753192: , (2.688 sec/step)\n",
      "Train Epoch: 4 [155/214 (72%)] Loss:1.597551: , (2.642 sec/step)\n",
      "Train Epoch: 4 [156/214 (73%)] Loss:1.446076: , (2.681 sec/step)\n",
      "Train Epoch: 4 [157/214 (73%)] Loss:1.861878: , (2.679 sec/step)\n",
      "Train Epoch: 4 [158/214 (74%)] Loss:1.585570: , (2.551 sec/step)\n",
      "Train Epoch: 4 [159/214 (74%)] Loss:1.657458: , (2.134 sec/step)\n",
      "Train Epoch: 4 [160/214 (75%)] Loss:1.467692: , (2.134 sec/step)\n",
      "Train Epoch: 4 [161/214 (75%)] Loss:1.955185: , (2.135 sec/step)\n",
      "Train Epoch: 4 [162/214 (76%)] Loss:1.246886: , (2.135 sec/step)\n",
      "Train Epoch: 4 [163/214 (76%)] Loss:1.673168: , (2.136 sec/step)\n",
      "Train Epoch: 4 [164/214 (77%)] Loss:2.506168: , (2.136 sec/step)\n",
      "Train Epoch: 4 [165/214 (77%)] Loss:1.666067: , (2.135 sec/step)\n",
      "Train Epoch: 4 [166/214 (78%)] Loss:2.067657: , (2.134 sec/step)\n",
      "Train Epoch: 4 [167/214 (78%)] Loss:1.449658: , (2.135 sec/step)\n",
      "Train Epoch: 4 [168/214 (79%)] Loss:1.291194: , (2.138 sec/step)\n",
      "Train Epoch: 4 [169/214 (79%)] Loss:1.547681: , (2.136 sec/step)\n",
      "Train Epoch: 4 [170/214 (79%)] Loss:1.328266: , (2.135 sec/step)\n",
      "Train Epoch: 4 [171/214 (80%)] Loss:2.211443: , (2.135 sec/step)\n",
      "Train Epoch: 4 [172/214 (80%)] Loss:1.625994: , (2.135 sec/step)\n",
      "Train Epoch: 4 [173/214 (81%)] Loss:1.791544: , (2.134 sec/step)\n",
      "Train Epoch: 4 [174/214 (81%)] Loss:1.548330: , (2.133 sec/step)\n",
      "Train Epoch: 4 [175/214 (82%)] Loss:1.446958: , (2.137 sec/step)\n",
      "Train Epoch: 4 [176/214 (82%)] Loss:1.297354: , (2.134 sec/step)\n",
      "Train Epoch: 4 [177/214 (83%)] Loss:1.482015: , (2.134 sec/step)\n",
      "Train Epoch: 4 [178/214 (83%)] Loss:2.076507: , (2.134 sec/step)\n",
      "Train Epoch: 4 [179/214 (84%)] Loss:1.578033: , (2.134 sec/step)\n",
      "Train Epoch: 4 [180/214 (84%)] Loss:1.315021: , (2.133 sec/step)\n",
      "Train Epoch: 4 [181/214 (85%)] Loss:1.485617: , (2.134 sec/step)\n",
      "Train Epoch: 4 [182/214 (85%)] Loss:1.539531: , (2.134 sec/step)\n",
      "Train Epoch: 4 [183/214 (86%)] Loss:1.610624: , (2.134 sec/step)\n",
      "Train Epoch: 4 [184/214 (86%)] Loss:1.349747: , (2.134 sec/step)\n",
      "Train Epoch: 4 [185/214 (86%)] Loss:1.426910: , (2.134 sec/step)\n",
      "Train Epoch: 4 [186/214 (87%)] Loss:1.313448: , (2.132 sec/step)\n",
      "Train Epoch: 4 [187/214 (87%)] Loss:1.495039: , (2.134 sec/step)\n",
      "Train Epoch: 4 [188/214 (88%)] Loss:1.366590: , (2.134 sec/step)\n",
      "Train Epoch: 4 [189/214 (88%)] Loss:1.749135: , (2.136 sec/step)\n",
      "Train Epoch: 4 [190/214 (89%)] Loss:1.367774: , (2.134 sec/step)\n",
      "Train Epoch: 4 [191/214 (89%)] Loss:1.426929: , (2.135 sec/step)\n",
      "Train Epoch: 4 [192/214 (90%)] Loss:1.612168: , (2.136 sec/step)\n",
      "Train Epoch: 4 [193/214 (90%)] Loss:1.335662: , (2.135 sec/step)\n",
      "Train Epoch: 4 [194/214 (91%)] Loss:1.539362: , (2.136 sec/step)\n",
      "Train Epoch: 4 [195/214 (91%)] Loss:1.434156: , (2.136 sec/step)\n",
      "Train Epoch: 4 [196/214 (92%)] Loss:2.168256: , (2.135 sec/step)\n",
      "Train Epoch: 4 [197/214 (92%)] Loss:1.624004: , (2.135 sec/step)\n",
      "Train Epoch: 4 [198/214 (93%)] Loss:1.665471: , (2.136 sec/step)\n",
      "Train Epoch: 4 [199/214 (93%)] Loss:1.453405: , (2.134 sec/step)\n",
      "Train Epoch: 4 [200/214 (93%)] Loss:1.641221: , (2.133 sec/step)\n",
      "write finish\n",
      "Train Epoch: 4 [201/214 (94%)] Loss:1.498879: , (2.135 sec/step)\n",
      "Train Epoch: 4 [202/214 (94%)] Loss:1.455974: , (2.136 sec/step)\n",
      "Train Epoch: 4 [203/214 (95%)] Loss:1.457211: , (2.135 sec/step)\n",
      "Train Epoch: 4 [204/214 (95%)] Loss:1.218246: , (2.133 sec/step)\n",
      "Train Epoch: 4 [205/214 (96%)] Loss:1.384306: , (2.135 sec/step)\n",
      "Train Epoch: 4 [206/214 (96%)] Loss:1.569758: , (2.134 sec/step)\n",
      "Train Epoch: 4 [207/214 (97%)] Loss:1.403300: , (2.135 sec/step)\n",
      "Train Epoch: 4 [208/214 (97%)] Loss:1.692278: , (2.135 sec/step)\n",
      "Train Epoch: 4 [209/214 (98%)] Loss:1.531139: , (2.136 sec/step)\n",
      "Train Epoch: 4 [210/214 (98%)] Loss:1.428273: , (2.135 sec/step)\n",
      "Train Epoch: 4 [211/214 (99%)] Loss:1.871026: , (2.136 sec/step)\n",
      "Train Epoch: 4 [212/214 (99%)] Loss:2.627982: , (2.137 sec/step)\n",
      "Train Epoch: 4 [213/214 (100%)] Loss:1.773762: , (2.134 sec/step)\n",
      "0.03296875 accurate\n",
      "\n",
      "val set:loss10.3034:, (0.664 sec/step)\n",
      "\n",
      "val stored done 6.651562452316284\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100000):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "MLalgorithm/mnistPyTorch.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
