{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T10:36:25.447326Z",
     "start_time": "2018-06-03T10:36:22.902747Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T10:42:44.889056Z",
     "start_time": "2018-06-03T10:42:44.792911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.  3.  4.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected int32, got 0.005 of type 'float' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-be369329c094>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0ml1loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1re\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/regularizers.py\u001b[0m in \u001b[0;36mapply_regularization\u001b[0;34m(regularizer, weights_list)\u001b[0m\n\u001b[1;32m    191\u001b[0m   with ops.name_scope('get_regularization_penalty',\n\u001b[1;32m    192\u001b[0m                       values=weights_list) as scope:\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mpenalties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     penalties = [\n\u001b[1;32m    195\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpenalties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/regularizers.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    191\u001b[0m   with ops.name_scope('get_regularization_penalty',\n\u001b[1;32m    192\u001b[0m                       values=weights_list) as scope:\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mpenalties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights_list\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     penalties = [\n\u001b[1;32m    195\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpenalties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/regularizers.py\u001b[0m in \u001b[0;36ml1\u001b[0;34m(weights, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m       my_scale = ops.convert_to_tensor(scale,\n\u001b[1;32m     66\u001b[0m                                        \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                        name='scale')\n\u001b[0m\u001b[1;32m     68\u001b[0m       return standard_ops.multiply(\n\u001b[1;32m     69\u001b[0m           \u001b[0mmy_scale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1012\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    233\u001b[0m                                          as_ref=False):\n\u001b[1;32m    234\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    212\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    213\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 214\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    215\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    430\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m       \u001b[0m_AssertCompatible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m       \u001b[0mnparray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp_dt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m       \u001b[0;31m# check to them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m_AssertCompatible\u001b[0;34m(values, dtype)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n\u001b[0;32m--> 343\u001b[0;31m                       (dtype.name, repr(mismatch), type(mismatch).__name__))\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected int32, got 0.005 of type 'float' instead."
     ]
    }
   ],
   "source": [
    "w = tf.Variable([1.0,2.0,3.0,4.0],trainable=True)\n",
    "x = tf.Variable([1.0,2.0,3.0,4.0],trainable=True)\n",
    "opt = tf.train.AdamOptimizer()\n",
    "l1re=tf.contrib.layers.l1_regularizer(scale=0.005)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(x.initializer)\n",
    "    weights = tf.trainable_variables()\n",
    "    print(sess.run(x[1:10000]))\n",
    "    l1loss = tf.contrib.layers.apply_regularization(l1re,weights)\n",
    "    print(sess.run(l1loss))\n",
    "    print(x.eval())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T07:14:09.574796Z",
     "start_time": "2018-06-03T07:14:09.432862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat_softmax:\n",
      "[[ 0.227863    0.61939586  0.15274114]\n",
      " [ 0.49674623  0.20196195  0.30129182]]\n",
      "\n",
      "y_true: \n",
      "[[ 0.  1.  0.]\n",
      " [ 0.  0.  1.]]\n",
      "\n",
      "y_cross: \n",
      "[[-0.         -0.4790107  -0.        ]\n",
      " [-0.         -0.         -1.19967598]]\n",
      "\n",
      "result: \n",
      "[ 0.4790107   1.19967598]\n",
      "\n",
      "result_tf: \n",
      "[ 0.4790107   1.19967598]\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.convert_to_tensor(np.array([[0.0, 1.0, 0.0],[0.0, 0.0, 1.0]]))\n",
    "y_hat = tf.convert_to_tensor(np.array([[0.5, 1.5, 0.1],[2.2, 1.3, 1.7]]))\n",
    "y_hat_softmax = tf.nn.softmax(y_hat)\n",
    "y_cross = y_true * tf.log(y_hat_softmax)\n",
    "result = - tf.reduce_sum(y_cross, 1)\n",
    "result_tf = tf.nn.softmax_cross_entropy_with_logits_v2(labels = y_true, logits = y_hat)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(result)\n",
    "    sess.run(result_tf)\n",
    "    print('y_hat_softmax:\\n{0}\\n'.format(y_hat_softmax.eval()))\n",
    "    print('y_true: \\n{0}\\n'.format(y_true.eval()))\n",
    "    print('y_cross: \\n{0}\\n'.format(y_cross.eval()))\n",
    "    print('result: \\n{0}\\n'.format(result.eval()))\n",
    "    print('result_tf: \\n{0}'.format(result_tf.eval()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T06:50:39.334166Z",
     "start_time": "2018-06-03T06:50:39.242955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.7310586   0.26894143]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([1.0,0.0])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(x.initializer)\n",
    "    y = tf.nn.softmax(x)\n",
    "    sess.run(y)\n",
    "    y = tf.Print(y,[y])\n",
    "    sess.run(y)\n",
    "    print(y.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-03T07:08:29.995417Z",
     "start_time": "2018-06-03T07:08:29.899813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.31326163  0.51301527]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable([[1.0,0.0],[0.1,0.5]])\n",
    "y = tf.Variable([0,1])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=x,labels=y)\n",
    "    sess.run(loss)\n",
    "    print(loss.eval())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T15:50:40.221173Z",
     "start_time": "2018-06-02T15:50:40.063301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "#sess = tf.Session()\n",
    "a = tf.Variable(5.0)\n",
    "b = tf.Variable(6.0)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(sess.run(tf.report_uninitialized_variables()))\n",
    "c = a * b\n",
    "# We can just use 'c.eval()' without passing 'sess'\n",
    "print(c.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T09:46:35.461867Z",
     "start_time": "2018-06-02T09:46:35.427117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1930834,) (1930834,) (97536,) (97536,)\n"
     ]
    }
   ],
   "source": [
    "'''from scipy.io import wavfile\n",
    "rate,data = wavfile.read('./vocalSeparation/origin_mix.wav')\n",
    "rate1,data1 = wavfile.read('./vocalSeparation/origin_vocal.wav')\n",
    "rate2,data2 = wavfile.read('./vocalSeparation/pred_mix.wav')\n",
    "rate3,data3 = wavfile.read('./vocalSeparation/pred_vocal.wav')\n",
    "print(data.shape,data1.shape,data2.shape,data3.shape)'''\n",
    "#scipy.io.wavfile.write('./vocalSeparation/morigin_mix.wav',rate,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T15:37:08.825269Z",
     "start_time": "2018-06-02T15:37:08.735351Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.name_scope(\"Scope_A\"):\n",
    "    a = tf.add(1, 2, name=\"A_add\")\n",
    "    b = tf.multiply(a, 3, name=\"A_mul\")\n",
    "with tf.name_scope(\"Scope_B\"):\n",
    "    c = tf.add(4, 5, name=\"B_add\")\n",
    "    d = tf.multiply(c, 6, name=\"B_mul\")\n",
    "e = tf.add(b, d, name=\"output\")\n",
    "writer = tf.summary.FileWriter('./name_scope', graph=tf.get_default_graph())\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T15:05:41.063924Z",
     "start_time": "2018-06-02T15:05:40.979824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[[[[ 5.]\n",
      "   [ 6.]]]]\n",
      "[[[[ 5.]\n",
      "   [ 6.]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "with tf.Session() as sess:\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    x = tf.Variable([[1., 2., 3.],[4., 5., 6.]])\n",
    "    rx = tf.reshape(x, [1, 2, 3, 1])\n",
    "    valid_pad = tf.nn.max_pool(rx, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
    "    same_pad = tf.nn.max_pool(rx, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "    psame_pad = tf.Print(same_pad,[same_pad],'where are u')\n",
    "    print(sess.run(x.initializer))\n",
    "    print(sess.run(psame_pad))\n",
    "    print(psame_pad.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T15:01:17.182665Z",
     "start_time": "2018-06-02T15:01:17.125044Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 5.]\n",
      "   [ 6.]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "sess = tf.InteractiveSession()\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "#x = tf.Variable([[1., 2., 3.],[4., 5., 6.]])\n",
    "x = tf.placeholder(dtype=tf.float32,shape=[2,3])\n",
    "rx = tf.reshape(x, [1, 2, 3, 1])\n",
    "valid_pad = tf.nn.max_pool(rx, [1, 2, 2, 1], [1, 2, 2, 1], padding='VALID')\n",
    "same_pad = tf.nn.max_pool(rx, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "#print(valid_pad)\n",
    "psame_pad = tf.Print(same_pad,[same_pad],'where are u')\n",
    "print(sess.run(psame_pad,feed_dict=\n",
    "               {x:np.array([[1., 2., 3.],[4., 5., 6.]],dtype=np.float32)}))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T15:41:02.676550Z",
     "start_time": "2018-06-02T15:41:02.668863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import tensorflow as tf\\nimport numpy as np\\nx = tf.placeholder(dtype=tf.float32,shape=None)\\nresult=tf.nn.conv1d(x,np.zeros((2,3,4),dtype=np.float32),stride=1, padding='VALID')\\nsess = tf.InteractiveSession()\\nprint(sess.run(result,feed_dict={x:np.zeros((1,10,3),dtype=np.float32)}))\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import tensorflow as tf\n",
    "import numpy as np\n",
    "x = tf.placeholder(dtype=tf.float32,shape=None)\n",
    "result=tf.nn.conv1d(x,np.zeros((2,3,4),dtype=np.float32),stride=1, padding='VALID')\n",
    "sess = tf.InteractiveSession()\n",
    "print(sess.run(result,feed_dict={x:np.zeros((1,10,3),dtype=np.float32)}))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-02T05:57:51.654868Z",
     "start_time": "2018-06-02T05:57:51.604315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None None\n",
      "[1, array([1], dtype=int32)] [2, array([2, 3], dtype=int32)] [3, array([4, 5, 6], dtype=int32)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "sess = tf.InteractiveSession()\n",
    "q = tf.PaddingFIFOQueue(capacity=10, dtypes=[tf.int32, tf.int32], shapes=[[], [None]])\n",
    "sample0 = tf.placeholder(dtype=tf.int32, shape=None)\n",
    "sample1 = tf.placeholder(dtype=tf.int32, shape=None)\n",
    "sample2 = tf.placeholder(dtype=tf.int32, shape=None)\n",
    "#eq1 = q.enqueue([1, [1]])\n",
    "eq1 = q.enqueue([sample0, sample1])\n",
    "eq2 = q.enqueue([2,[2,3]])\n",
    "eq3 = q.enqueue([3, [4,5,6]])\n",
    "dq = q.dequeue()\n",
    "print(sess.run(eq1,feed_dict={sample0:1,sample1:[1]}),\n",
    "      sess.run(eq2),sess.run(eq3))\n",
    "print(sess.run(dq) ,sess.run(dq) ,sess.run(dq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
